{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoticore *Stage 2*\n",
    "\n",
    "Evolution from the shallow bigram nueral network architecture to a complete Multiple Layer Perceptron that handles character level context lengths greater than 2.\n",
    "\n",
    "Based on [Bengio et al., 2003](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. **Setup & Data Processing** - Load constants, data readers, and vocabulary builders\n",
    "2. **Model Architecture** - MLP implementation with embedding, hidden, and output layers\n",
    "3. **Training** - Forward/backward passes and optimization\n",
    "4. **Evaluation** - Development set validation\n",
    "5. **Text Generation** - Sample from the trained model\n",
    "6. **Experiments** - Learning rate tuning and architecture exploration\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "- **Input**: Fixed-length character sequences (context windows)\n",
    "- **Architecture**: Embedding → Hidden Layer (tanh) → Output Layer (softmax)\n",
    "- **Task**: Predict the next character given context\n",
    "- **Training**: Cross-entropy loss with mini-batch SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final\n",
    "\n",
    "# Random Seed.\n",
    "SAMPLE_SEED: Final[int] = 534150593\n",
    "\n",
    "# Data Processing.\n",
    "LYRICS_COLUMN: Final[str] = \"text\"\n",
    "DEFAULT_CSV_PATH: Final[str] = \"spotify_lyrics.csv\"\n",
    "\n",
    "# Model Architecture - MLP.\n",
    "BLOCK_SIZE: int = 3  # Context window size (number of characters).\n",
    "\n",
    "# Training Hyperparameters.\n",
    "LEARNING_RATE: float = 0.1\n",
    "REGULARIZATION_FACTOR: float = 0.001\n",
    "EMBEDDING_DIM: int = 10  # Dimension of character embeddings.\n",
    "HIDDEN_LAYER_SIZE: int = 100  # Number of neurons in the hidden layer.\n",
    "BATCH_SIZE: int = 32  # Number of inputs per training iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "\n",
    "def read_all_lyrics(csv_path: str = DEFAULT_CSV_PATH) -> list[str]:\n",
    "    \"\"\"\n",
    "    Process the Spotify lyrics CSV file and extract all lyrics text.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to the CSV file. Defaults to \"spotify_lyrics.csv\".\n",
    "\n",
    "    Returns:\n",
    "        List of lyrics text strings, one per song.\n",
    "    \"\"\"\n",
    "    lyrics_list = []\n",
    "\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "\n",
    "        for row in reader:\n",
    "            # Extract the lyrics text from the 'text' column.\n",
    "            lyrics = row.get(LYRICS_COLUMN, \"\").strip().lower()\n",
    "            if lyrics:  # Only add non-empty lyrics.\n",
    "                lyrics_list.append(lyrics)\n",
    "\n",
    "    return lyrics_list\n",
    "\n",
    "\n",
    "def read_all_unique_words(csv_path: str = DEFAULT_CSV_PATH) -> list[str]:\n",
    "    \"\"\"\n",
    "    Process the Spotify lyrics CSV file and extract all unique individual words.\n",
    "\n",
    "    Punctuation is removed from words before adding them to the vocabulary.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to the CSV file. Defaults to \"spotify_lyrics.csv\".\n",
    "\n",
    "    Returns:\n",
    "        Sorted list of unique words from all lyrics, with punctuation removed.\n",
    "    \"\"\"\n",
    "    words_list = []\n",
    "    # Create a translation table that replaces punctuation with spaces.\n",
    "    translator = str.maketrans({punct: \" \" for punct in string.punctuation})\n",
    "\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            lyrics = row.get(LYRICS_COLUMN, \"\").strip().lower()\n",
    "            if lyrics:\n",
    "                # Replace punctuation with spaces before splitting.\n",
    "                sanitized_lyrics = lyrics.translate(translator)\n",
    "                # Filter out empty strings created by consecutive spaces.\n",
    "                words_list.extend([word for word in sanitized_lyrics.split() if word])\n",
    "\n",
    "    return sorted(set(words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MLP Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Parameters:\n",
    "    C: torch.Tensor\n",
    "    W1: torch.Tensor\n",
    "    W2: torch.Tensor\n",
    "    b1: torch.Tensor\n",
    "    b2: torch.Tensor\n",
    "\n",
    "    @property\n",
    "    def parameters(self) -> tuple[torch.Tensor, ...]:\n",
    "        return (self.C, self.W1, self.W2, self.b1, self.b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_from_words():\n",
    "    \"\"\"\n",
    "    Build vocabulary mappings from unique words.\n",
    "\n",
    "    Reads all unique words from the CSV file and creates string-to-index (stoi)\n",
    "    and index-to-string (itos) mappings for all characters found in the words.\n",
    "    The period character (.) is assigned index 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - stoi (dict[str, int]): Mapping from character to index.\n",
    "            - itos (dict[int, str]): Mapping from index to character.\n",
    "            - words (list[str]): List of all unique words.\n",
    "    \"\"\"\n",
    "    words = read_all_unique_words()\n",
    "    chars = sorted(list(set(\".\".join(words))))\n",
    "    stoi = {char: i for i, char in enumerate(chars)}\n",
    "    stoi[\".\"] = 0\n",
    "    itos = {i: char for i, char in enumerate(stoi)}\n",
    "\n",
    "    return stoi, itos, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(\n",
    "    words: list[str],\n",
    "    stoi: dict[str, int],\n",
    "    block_size: int = BLOCK_SIZE,\n",
    ") -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    \"\"\"\n",
    "    Build training dataset from words using character-level context windows.\n",
    "\n",
    "    Creates input-output pairs where each input is a context window of characters\n",
    "    and the output is the next character to predict. Uses a sliding window approach\n",
    "    with a fixed context length (block_size).\n",
    "\n",
    "    Args:\n",
    "        words: List of words to build the dataset from.\n",
    "        stoi: Mapping from character to index for converting characters to tensor inputs.\n",
    "        block_size: Number of characters in the context window. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - X (torch.Tensor): Input tensor of shape (n_samples, block_size) with context windows.\n",
    "            - Y (torch.Tensor): Output tensor of shape (n_samples,) with target character indices.\n",
    "            - block_size (int): The context window size used.\n",
    "    \"\"\"\n",
    "    # Input and corresponding output (labels) matrices.\n",
    "    X, Y = [], []\n",
    "\n",
    "    for word in words:\n",
    "        prev_char_idxs = [0] * block_size\n",
    "        for char in word + \".\":\n",
    "            next_char_idx = stoi[char]\n",
    "            X.append(prev_char_idxs)\n",
    "            Y.append(next_char_idx)\n",
    "            prev_char_idxs = prev_char_idxs[1:] + [next_char_idx]\n",
    "\n",
    "    return torch.tensor(X), torch.tensor(Y), block_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting\n",
    "\n",
    "Split the data into three disjoint sets:\n",
    "- **Training (80%)**: Used to update model weights via gradient descent\n",
    "- **Development/Validation (10%)**: Used to tune hyperparameters and monitor overfitting\n",
    "- **Testing (10%)**: Held out for final performance evaluation (used only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class SplitData:\n",
    "    vocab_size: int = 0\n",
    "\n",
    "    X_train: torch.Tensor = torch.tensor(0)\n",
    "    X_dev: torch.Tensor = torch.tensor(0)\n",
    "    X_test: torch.Tensor = torch.tensor(0)\n",
    "\n",
    "    Y_train: torch.Tensor = torch.tensor(0)\n",
    "    Y_dev: torch.Tensor = torch.tensor(0)\n",
    "    Y_test: torch.Tensor = torch.tensor(0)\n",
    "\n",
    "    ctxlen_train: int = 0\n",
    "    ctxlen_dev: int = 0\n",
    "    ctxlen_test: int = 0\n",
    "\n",
    "    @property\n",
    "    def train_data(self) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        return (self.X_train, self.Y_train, self.ctxlen_train)\n",
    "\n",
    "    @property\n",
    "    def dev_data(self) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        return (self.X_dev, self.Y_dev, self.ctxlen_dev)\n",
    "\n",
    "    @property\n",
    "    def test_data(self) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        return (self.X_test, self.Y_test, self.ctxlen_test)\n",
    "\n",
    "\n",
    "def split_training_dataset():\n",
    "    random.seed(42)\n",
    "\n",
    "    stoi, itos, words = build_vocab_from_words()\n",
    "\n",
    "    random.shuffle(words)\n",
    "\n",
    "    n1 = int(0.8 * len(words))\n",
    "    n2 = int(0.9 * len(words))\n",
    "\n",
    "    X_train, Y_train, train_ctxlen = build_dataset(words[:n1], stoi)\n",
    "    X_dev, Y_dev, dev_ctxlen = build_dataset(words[n1:n2], stoi)\n",
    "    X_test, Y_test, test_ctxlen = build_dataset(words[n2:], stoi)\n",
    "\n",
    "    return SplitData(\n",
    "        len(stoi),\n",
    "        X_train,\n",
    "        X_dev,\n",
    "        X_test,\n",
    "        Y_train,\n",
    "        Y_dev,\n",
    "        Y_test,\n",
    "        train_ctxlen,\n",
    "        dev_ctxlen,\n",
    "        test_ctxlen,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(\n",
    "    vocab_size: int, block_size: int, generator: torch.Generator | None = None\n",
    ") -> Parameters:\n",
    "    \"\"\"\n",
    "    Initialize network parameters with random values.\n",
    "\n",
    "    Note: Uses standard normal initialization. For better performance with larger\n",
    "    hidden layers, consider using Kaiming/He initialization.\n",
    "\n",
    "    Args:\n",
    "        vocab_size: Size of the vocabulary (number of unique characters).\n",
    "        block_size: Number of characters in the context window.\n",
    "        generator: Optional random number generator for reproducible initialization.\n",
    "\n",
    "    Returns:\n",
    "        Parameters: Container with initialized embedding, weight, and bias tensors.\n",
    "    \"\"\"\n",
    "    if generator is None:\n",
    "        generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "    emb_dims = EMBEDDING_DIM\n",
    "    hidden_layer_size = HIDDEN_LAYER_SIZE\n",
    "\n",
    "    # Embedding layer weights.\n",
    "    C = torch.randn((vocab_size, emb_dims), generator=generator, requires_grad=True)\n",
    "\n",
    "    # Hidden layer weights and bias.\n",
    "    W1 = torch.randn(\n",
    "        (block_size * emb_dims, hidden_layer_size),\n",
    "        generator=generator,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    b1 = torch.randn(hidden_layer_size, generator=generator, requires_grad=True)\n",
    "\n",
    "    # Output layer weights and bias.\n",
    "    W2 = torch.randn(\n",
    "        (hidden_layer_size, vocab_size), generator=generator, requires_grad=True\n",
    "    )\n",
    "    b2 = torch.randn(vocab_size, generator=generator, requires_grad=True)\n",
    "\n",
    "    return Parameters(C, W1, W2, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    parameters: Parameters,\n",
    "    block_size: int,\n",
    ") -> tuple[Parameters, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Perform forward pass through the MLP network for character-level language modeling.\n",
    "\n",
    "    The network consists of:\n",
    "    1. Embedding layer: Converts character indices to dense embeddings.\n",
    "    2. Hidden layer: Fully connected layer with tanh activation.\n",
    "    3. Output layer: Produces logits for next character prediction.\n",
    "\n",
    "    Args:\n",
    "        X: Input tensor of shape (n_samples, block_size) containing character indices.\n",
    "        Y: Target tensor of shape (n_samples,) containing the true next character indices.\n",
    "        parameters: Container with all network parameters (embedding weights, W1, W2, b1, b2).\n",
    "        block_size: Number of characters in the context window.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "            - Parameters: Container with the parameter tensors (same reference as input).\n",
    "            - loss: The cross entropy loss tensor.\n",
    "    \"\"\"\n",
    "    emb_dims = EMBEDDING_DIM\n",
    "\n",
    "    emb = parameters.C[X]  # [num_samples, block_size, emb_dims]\n",
    "    num_samples = emb.shape[0]\n",
    "\n",
    "    # Flatten emb tensor to 2d for matrix multiplication with weight matrix.\n",
    "    # One input sample contains 3 characters and each character is embedded as a vector of size 10.\n",
    "    # Each sample becomes a single 30 element vector containing all the context information.\n",
    "    emb = emb.view(num_samples, block_size * emb_dims)\n",
    "\n",
    "    # Each row of W1 corresponds to one of the 30 input features (after flattening) of an input sample.\n",
    "    # Each hidden neuron receives a weighted sum of all 30 features.\n",
    "    h = torch.tanh(emb @ parameters.W1 + parameters.b1)  # [num_samples, hidden_size]\n",
    "\n",
    "    # Output layer contains a node for each character that comes next; i.e. vocab_size neurons.\n",
    "    logits = h @ parameters.W2 + parameters.b2  # [num_samples, vocab_size]\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "    return parameters, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(\n",
    "    parameters: list[torch.Tensor],\n",
    "    loss: torch.Tensor,\n",
    "    lr: torch.Tensor | float = LEARNING_RATE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform backward pass and update parameters using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        parameters: List of parameters to update (must have requires_grad=True).\n",
    "        loss: The computed loss tensor.\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Note:\n",
    "    The parameters are updated in place.\n",
    "    \"\"\"\n",
    "\n",
    "    # Just in case.\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # Compute gradients via backpropagation.\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters using gradient descent.\n",
    "    for p in parameters:\n",
    "        if p.grad is not None:\n",
    "            p.data -= lr * p.grad\n",
    "        else:\n",
    "            # This shouldn't happen.\n",
    "            print(\n",
    "                f\"Warning: Parameter with shape {p.shape} has no gradient (requires_grad={p.requires_grad})\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.2  # from experiment 1 below\n",
    "\n",
    "\n",
    "def train(\n",
    "    num_iterations: int = 1000,\n",
    "    print_interval: int = 10,\n",
    "    generator: torch.Generator | None = None,\n",
    ") -> tuple[Parameters, SplitData]:\n",
    "    \"\"\"\n",
    "    Train the MLP network for character-level language modeling.\n",
    "\n",
    "    Performs the complete training process: data preparation, parameter initialization,\n",
    "    and training loop with forward and backward passes with input batches.\n",
    "\n",
    "    Args:\n",
    "        num_iterations: Number of training iterations (default: 1000).\n",
    "        print_interval: Print loss every N iterations (default: 10).\n",
    "        generator: Optional random number generator. If None, creates one with SAMPLE_SEED.\n",
    "\n",
    "    Returns:\n",
    "        params: The updated parameters after training.\n",
    "        data:  The dataset split used for training/dev/test.\n",
    "    \"\"\"\n",
    "    # Initialize random number generator with fixed seed for reproducibility.\n",
    "    if generator is None:\n",
    "        generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "    # Build split training dataset from all words.\n",
    "    data = split_training_dataset()\n",
    "\n",
    "    # extract training input and outputs\n",
    "    X, Y, block_size = data.train_data\n",
    "\n",
    "    # Initialize network parameters based on the training dataset\n",
    "    params = initialize_parameters(data.vocab_size, block_size, generator=generator)\n",
    "    print(\"Parameters initialized\")\n",
    "\n",
    "    n_params = sum(p.nelement() for p in params.parameters)\n",
    "    print(\"Total paramters:\", n_params)\n",
    "\n",
    "    # Training loop.\n",
    "    for i in range(num_iterations):\n",
    "        # mini batch construct\n",
    "        ix = torch.randint(0, X.shape[0], (BATCH_SIZE,), generator=generator)\n",
    "\n",
    "        # extract the batches\n",
    "        X_batch, Y_batch = X[ix], Y[ix]\n",
    "\n",
    "        # Forward pass: compute predictions and loss with the mini batch of inputs\n",
    "        params, loss = forward_pass(X_batch, Y_batch, params, block_size)\n",
    "\n",
    "        # Print loss at specified intervals.\n",
    "        if i % print_interval == 0:\n",
    "            print(f\"Iteration {i}: loss = {loss.item():.4f}\")\n",
    "\n",
    "        # Backward pass: compute gradients and update parameters.\n",
    "        backward_pass(list(params.parameters), loss)\n",
    "\n",
    "    print(f\"Training complete. Final loss: {loss.item():.4f}\")\n",
    "\n",
    "    return params, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters initialized\n",
      "Total paramters: 7207\n",
      "Iteration 0: loss = 19.9033\n",
      "Iteration 10: loss = 17.7575\n",
      "Iteration 20: loss = 12.9249\n",
      "Iteration 30: loss = 14.2880\n",
      "Iteration 40: loss = 10.6687\n",
      "Iteration 50: loss = 13.3272\n",
      "Iteration 60: loss = 7.6084\n",
      "Iteration 70: loss = 11.6514\n",
      "Iteration 80: loss = 8.0104\n",
      "Iteration 90: loss = 7.3388\n",
      "Iteration 100: loss = 8.0937\n",
      "Iteration 110: loss = 7.4386\n",
      "Iteration 120: loss = 8.1203\n",
      "Iteration 130: loss = 9.0665\n",
      "Iteration 140: loss = 10.2083\n",
      "Iteration 150: loss = 6.6066\n",
      "Iteration 160: loss = 8.0120\n",
      "Iteration 170: loss = 7.4533\n",
      "Iteration 180: loss = 7.1760\n",
      "Iteration 190: loss = 5.5004\n",
      "Iteration 200: loss = 7.4069\n",
      "Iteration 210: loss = 6.3406\n",
      "Iteration 220: loss = 6.9937\n",
      "Iteration 230: loss = 4.6287\n",
      "Iteration 240: loss = 7.3365\n",
      "Iteration 250: loss = 3.7385\n",
      "Iteration 260: loss = 5.6149\n",
      "Iteration 270: loss = 5.7309\n",
      "Iteration 280: loss = 5.7022\n",
      "Iteration 290: loss = 5.0667\n",
      "Iteration 300: loss = 6.1035\n",
      "Iteration 310: loss = 6.3093\n",
      "Iteration 320: loss = 7.3275\n",
      "Iteration 330: loss = 4.4770\n",
      "Iteration 340: loss = 5.4004\n",
      "Iteration 350: loss = 5.3748\n",
      "Iteration 360: loss = 5.5446\n",
      "Iteration 370: loss = 5.7560\n",
      "Iteration 380: loss = 4.3521\n",
      "Iteration 390: loss = 6.3596\n",
      "Iteration 400: loss = 5.1911\n",
      "Iteration 410: loss = 4.4988\n",
      "Iteration 420: loss = 5.3696\n",
      "Iteration 430: loss = 5.7972\n",
      "Iteration 440: loss = 6.9320\n",
      "Iteration 450: loss = 6.0633\n",
      "Iteration 460: loss = 5.9619\n",
      "Iteration 470: loss = 5.2780\n",
      "Iteration 480: loss = 4.4828\n",
      "Iteration 490: loss = 5.2945\n",
      "Iteration 500: loss = 4.1569\n",
      "Iteration 510: loss = 5.0977\n",
      "Iteration 520: loss = 4.7872\n",
      "Iteration 530: loss = 4.7351\n",
      "Iteration 540: loss = 4.2546\n",
      "Iteration 550: loss = 4.8994\n",
      "Iteration 560: loss = 3.5809\n",
      "Iteration 570: loss = 5.0956\n",
      "Iteration 580: loss = 5.2538\n",
      "Iteration 590: loss = 3.7073\n",
      "Iteration 600: loss = 4.7865\n",
      "Iteration 610: loss = 6.8938\n",
      "Iteration 620: loss = 5.3179\n",
      "Iteration 630: loss = 4.5066\n",
      "Iteration 640: loss = 4.1905\n",
      "Iteration 650: loss = 3.8453\n",
      "Iteration 660: loss = 4.0253\n",
      "Iteration 670: loss = 4.3543\n",
      "Iteration 680: loss = 3.6329\n",
      "Iteration 690: loss = 3.7670\n",
      "Iteration 700: loss = 4.8043\n",
      "Iteration 710: loss = 5.0981\n",
      "Iteration 720: loss = 4.4477\n",
      "Iteration 730: loss = 3.3713\n",
      "Iteration 740: loss = 4.5496\n",
      "Iteration 750: loss = 4.2672\n",
      "Iteration 760: loss = 3.6025\n",
      "Iteration 770: loss = 4.2727\n",
      "Iteration 780: loss = 3.9799\n",
      "Iteration 790: loss = 3.5162\n",
      "Iteration 800: loss = 4.9221\n",
      "Iteration 810: loss = 3.6721\n",
      "Iteration 820: loss = 4.3348\n",
      "Iteration 830: loss = 3.9459\n",
      "Iteration 840: loss = 3.7719\n",
      "Iteration 850: loss = 4.1203\n",
      "Iteration 860: loss = 3.6922\n",
      "Iteration 870: loss = 4.0609\n",
      "Iteration 880: loss = 3.5641\n",
      "Iteration 890: loss = 3.1258\n",
      "Iteration 900: loss = 3.5624\n",
      "Iteration 910: loss = 4.3326\n",
      "Iteration 920: loss = 4.3238\n",
      "Iteration 930: loss = 3.6718\n",
      "Iteration 940: loss = 3.1612\n",
      "Iteration 950: loss = 3.4497\n",
      "Iteration 960: loss = 3.4784\n",
      "Iteration 970: loss = 3.3074\n",
      "Iteration 980: loss = 3.8738\n",
      "Iteration 990: loss = 3.2438\n",
      "Iteration 1000: loss = 3.4451\n",
      "Iteration 1010: loss = 4.2399\n",
      "Iteration 1020: loss = 3.7806\n",
      "Iteration 1030: loss = 3.1042\n",
      "Iteration 1040: loss = 3.5991\n",
      "Iteration 1050: loss = 2.6680\n",
      "Iteration 1060: loss = 3.7081\n",
      "Iteration 1070: loss = 3.0936\n",
      "Iteration 1080: loss = 3.5720\n",
      "Iteration 1090: loss = 4.0106\n",
      "Iteration 1100: loss = 3.7443\n",
      "Iteration 1110: loss = 3.7027\n",
      "Iteration 1120: loss = 3.2818\n",
      "Iteration 1130: loss = 3.7857\n",
      "Iteration 1140: loss = 3.9044\n",
      "Iteration 1150: loss = 3.7019\n",
      "Iteration 1160: loss = 3.4096\n",
      "Iteration 1170: loss = 3.0240\n",
      "Iteration 1180: loss = 3.5552\n",
      "Iteration 1190: loss = 3.0229\n",
      "Iteration 1200: loss = 3.1174\n",
      "Iteration 1210: loss = 2.7207\n",
      "Iteration 1220: loss = 3.7750\n",
      "Iteration 1230: loss = 3.8612\n",
      "Iteration 1240: loss = 3.3422\n",
      "Iteration 1250: loss = 3.7112\n",
      "Iteration 1260: loss = 3.3167\n",
      "Iteration 1270: loss = 3.3548\n",
      "Iteration 1280: loss = 3.5236\n",
      "Iteration 1290: loss = 2.8037\n",
      "Iteration 1300: loss = 3.2457\n",
      "Iteration 1310: loss = 3.0849\n",
      "Iteration 1320: loss = 3.1148\n",
      "Iteration 1330: loss = 2.9638\n",
      "Iteration 1340: loss = 3.0695\n",
      "Iteration 1350: loss = 3.3739\n",
      "Iteration 1360: loss = 3.4112\n",
      "Iteration 1370: loss = 3.6846\n",
      "Iteration 1380: loss = 3.1392\n",
      "Iteration 1390: loss = 2.8978\n",
      "Iteration 1400: loss = 3.3938\n",
      "Iteration 1410: loss = 3.7811\n",
      "Iteration 1420: loss = 3.4168\n",
      "Iteration 1430: loss = 3.5415\n",
      "Iteration 1440: loss = 2.6734\n",
      "Iteration 1450: loss = 3.0248\n",
      "Iteration 1460: loss = 2.8453\n",
      "Iteration 1470: loss = 2.5006\n",
      "Iteration 1480: loss = 3.0575\n",
      "Iteration 1490: loss = 2.7812\n",
      "Iteration 1500: loss = 2.5822\n",
      "Iteration 1510: loss = 2.7801\n",
      "Iteration 1520: loss = 3.5024\n",
      "Iteration 1530: loss = 2.6191\n",
      "Iteration 1540: loss = 3.3101\n",
      "Iteration 1550: loss = 2.7807\n",
      "Iteration 1560: loss = 3.0035\n",
      "Iteration 1570: loss = 3.6304\n",
      "Iteration 1580: loss = 2.7488\n",
      "Iteration 1590: loss = 2.8436\n",
      "Iteration 1600: loss = 2.8146\n",
      "Iteration 1610: loss = 2.7120\n",
      "Iteration 1620: loss = 2.7407\n",
      "Iteration 1630: loss = 3.2085\n",
      "Iteration 1640: loss = 2.9976\n",
      "Iteration 1650: loss = 3.0380\n",
      "Iteration 1660: loss = 2.7372\n",
      "Iteration 1670: loss = 3.7652\n",
      "Iteration 1680: loss = 2.7169\n",
      "Iteration 1690: loss = 2.6709\n",
      "Iteration 1700: loss = 2.7699\n",
      "Iteration 1710: loss = 3.1834\n",
      "Iteration 1720: loss = 3.0646\n",
      "Iteration 1730: loss = 3.0629\n",
      "Iteration 1740: loss = 2.7984\n",
      "Iteration 1750: loss = 2.9487\n",
      "Iteration 1760: loss = 3.1695\n",
      "Iteration 1770: loss = 2.7361\n",
      "Iteration 1780: loss = 2.8558\n",
      "Iteration 1790: loss = 2.4619\n",
      "Iteration 1800: loss = 3.1484\n",
      "Iteration 1810: loss = 2.4398\n",
      "Iteration 1820: loss = 2.5422\n",
      "Iteration 1830: loss = 2.6305\n",
      "Iteration 1840: loss = 2.8080\n",
      "Iteration 1850: loss = 2.9513\n",
      "Iteration 1860: loss = 3.2562\n",
      "Iteration 1870: loss = 3.1537\n",
      "Iteration 1880: loss = 3.8978\n",
      "Iteration 1890: loss = 2.7283\n",
      "Iteration 1900: loss = 2.6557\n",
      "Iteration 1910: loss = 3.1361\n",
      "Iteration 1920: loss = 3.2625\n",
      "Iteration 1930: loss = 3.1309\n",
      "Iteration 1940: loss = 3.3778\n",
      "Iteration 1950: loss = 2.6875\n",
      "Iteration 1960: loss = 2.7772\n",
      "Iteration 1970: loss = 3.1729\n",
      "Iteration 1980: loss = 3.3444\n",
      "Iteration 1990: loss = 3.0798\n",
      "Iteration 2000: loss = 3.0526\n",
      "Iteration 2010: loss = 3.5549\n",
      "Iteration 2020: loss = 2.8908\n",
      "Iteration 2030: loss = 3.3680\n",
      "Iteration 2040: loss = 2.9366\n",
      "Iteration 2050: loss = 2.8619\n",
      "Iteration 2060: loss = 2.9550\n",
      "Iteration 2070: loss = 2.7145\n",
      "Iteration 2080: loss = 2.9751\n",
      "Iteration 2090: loss = 3.2099\n",
      "Iteration 2100: loss = 3.3870\n",
      "Iteration 2110: loss = 3.3017\n",
      "Iteration 2120: loss = 2.8253\n",
      "Iteration 2130: loss = 3.5542\n",
      "Iteration 2140: loss = 3.2344\n",
      "Iteration 2150: loss = 2.6375\n",
      "Iteration 2160: loss = 2.2403\n",
      "Iteration 2170: loss = 2.6684\n",
      "Iteration 2180: loss = 2.9249\n",
      "Iteration 2190: loss = 2.9224\n",
      "Iteration 2200: loss = 3.4475\n",
      "Iteration 2210: loss = 2.7875\n",
      "Iteration 2220: loss = 3.2301\n",
      "Iteration 2230: loss = 2.6699\n",
      "Iteration 2240: loss = 2.4869\n",
      "Iteration 2250: loss = 3.2007\n",
      "Iteration 2260: loss = 2.7220\n",
      "Iteration 2270: loss = 2.9228\n",
      "Iteration 2280: loss = 3.2588\n",
      "Iteration 2290: loss = 2.7938\n",
      "Iteration 2300: loss = 2.6283\n",
      "Iteration 2310: loss = 2.8035\n",
      "Iteration 2320: loss = 3.0161\n",
      "Iteration 2330: loss = 2.6845\n",
      "Iteration 2340: loss = 3.0709\n",
      "Iteration 2350: loss = 2.7581\n",
      "Iteration 2360: loss = 3.1135\n",
      "Iteration 2370: loss = 2.8187\n",
      "Iteration 2380: loss = 3.0287\n",
      "Iteration 2390: loss = 2.7870\n",
      "Iteration 2400: loss = 2.7972\n",
      "Iteration 2410: loss = 2.7675\n",
      "Iteration 2420: loss = 2.7576\n",
      "Iteration 2430: loss = 2.6758\n",
      "Iteration 2440: loss = 2.6559\n",
      "Iteration 2450: loss = 2.8641\n",
      "Iteration 2460: loss = 2.4357\n",
      "Iteration 2470: loss = 3.1401\n",
      "Iteration 2480: loss = 3.1608\n",
      "Iteration 2490: loss = 3.4537\n",
      "Iteration 2500: loss = 2.6748\n",
      "Iteration 2510: loss = 2.8805\n",
      "Iteration 2520: loss = 3.1771\n",
      "Iteration 2530: loss = 2.6609\n",
      "Iteration 2540: loss = 3.2510\n",
      "Iteration 2550: loss = 2.7973\n",
      "Iteration 2560: loss = 2.9894\n",
      "Iteration 2570: loss = 3.1347\n",
      "Iteration 2580: loss = 2.5364\n",
      "Iteration 2590: loss = 3.2412\n",
      "Iteration 2600: loss = 3.0040\n",
      "Iteration 2610: loss = 2.9475\n",
      "Iteration 2620: loss = 3.0526\n",
      "Iteration 2630: loss = 3.1491\n",
      "Iteration 2640: loss = 2.5106\n",
      "Iteration 2650: loss = 2.9262\n",
      "Iteration 2660: loss = 3.0386\n",
      "Iteration 2670: loss = 2.8297\n",
      "Iteration 2680: loss = 2.7155\n",
      "Iteration 2690: loss = 3.1049\n",
      "Iteration 2700: loss = 3.0814\n",
      "Iteration 2710: loss = 2.8921\n",
      "Iteration 2720: loss = 3.0267\n",
      "Iteration 2730: loss = 3.0579\n",
      "Iteration 2740: loss = 3.1209\n",
      "Iteration 2750: loss = 3.1963\n",
      "Iteration 2760: loss = 3.1431\n",
      "Iteration 2770: loss = 3.2544\n",
      "Iteration 2780: loss = 3.2472\n",
      "Iteration 2790: loss = 2.6338\n",
      "Iteration 2800: loss = 3.4864\n",
      "Iteration 2810: loss = 3.0296\n",
      "Iteration 2820: loss = 3.0434\n",
      "Iteration 2830: loss = 2.7556\n",
      "Iteration 2840: loss = 2.5947\n",
      "Iteration 2850: loss = 2.7847\n",
      "Iteration 2860: loss = 2.4892\n",
      "Iteration 2870: loss = 3.0815\n",
      "Iteration 2880: loss = 2.8293\n",
      "Iteration 2890: loss = 2.7988\n",
      "Iteration 2900: loss = 2.7919\n",
      "Iteration 2910: loss = 2.8447\n",
      "Iteration 2920: loss = 2.8670\n",
      "Iteration 2930: loss = 2.9293\n",
      "Iteration 2940: loss = 2.7878\n",
      "Iteration 2950: loss = 3.4205\n",
      "Iteration 2960: loss = 2.8546\n",
      "Iteration 2970: loss = 2.6298\n",
      "Iteration 2980: loss = 2.4387\n",
      "Iteration 2990: loss = 2.7663\n",
      "Iteration 3000: loss = 2.7556\n",
      "Iteration 3010: loss = 2.8619\n",
      "Iteration 3020: loss = 3.0325\n",
      "Iteration 3030: loss = 3.1304\n",
      "Iteration 3040: loss = 2.9633\n",
      "Iteration 3050: loss = 2.7183\n",
      "Iteration 3060: loss = 3.0290\n",
      "Iteration 3070: loss = 2.9791\n",
      "Iteration 3080: loss = 2.7888\n",
      "Iteration 3090: loss = 3.0770\n",
      "Iteration 3100: loss = 2.7566\n",
      "Iteration 3110: loss = 2.8608\n",
      "Iteration 3120: loss = 2.2218\n",
      "Iteration 3130: loss = 2.7978\n",
      "Iteration 3140: loss = 3.3243\n",
      "Iteration 3150: loss = 3.5093\n",
      "Iteration 3160: loss = 2.9035\n",
      "Iteration 3170: loss = 2.5591\n",
      "Iteration 3180: loss = 2.6673\n",
      "Iteration 3190: loss = 2.9917\n",
      "Iteration 3200: loss = 2.5833\n",
      "Iteration 3210: loss = 2.8881\n",
      "Iteration 3220: loss = 2.7678\n",
      "Iteration 3230: loss = 3.0738\n",
      "Iteration 3240: loss = 3.1756\n",
      "Iteration 3250: loss = 3.0547\n",
      "Iteration 3260: loss = 3.0621\n",
      "Iteration 3270: loss = 2.9270\n",
      "Iteration 3280: loss = 2.8845\n",
      "Iteration 3290: loss = 3.0766\n",
      "Iteration 3300: loss = 2.5523\n",
      "Iteration 3310: loss = 3.3146\n",
      "Iteration 3320: loss = 2.9519\n",
      "Iteration 3330: loss = 2.8260\n",
      "Iteration 3340: loss = 3.0233\n",
      "Iteration 3350: loss = 2.4586\n",
      "Iteration 3360: loss = 2.7313\n",
      "Iteration 3370: loss = 3.1044\n",
      "Iteration 3380: loss = 2.8903\n",
      "Iteration 3390: loss = 3.3255\n",
      "Iteration 3400: loss = 2.8704\n",
      "Iteration 3410: loss = 2.9799\n",
      "Iteration 3420: loss = 2.8899\n",
      "Iteration 3430: loss = 2.8661\n",
      "Iteration 3440: loss = 2.9573\n",
      "Iteration 3450: loss = 2.4055\n",
      "Iteration 3460: loss = 2.7192\n",
      "Iteration 3470: loss = 2.8671\n",
      "Iteration 3480: loss = 2.7039\n",
      "Iteration 3490: loss = 2.9836\n",
      "Iteration 3500: loss = 2.6620\n",
      "Iteration 3510: loss = 3.3129\n",
      "Iteration 3520: loss = 3.4893\n",
      "Iteration 3530: loss = 2.7675\n",
      "Iteration 3540: loss = 2.9125\n",
      "Iteration 3550: loss = 2.7637\n",
      "Iteration 3560: loss = 2.6918\n",
      "Iteration 3570: loss = 2.6967\n",
      "Iteration 3580: loss = 2.9038\n",
      "Iteration 3590: loss = 2.5685\n",
      "Iteration 3600: loss = 2.4508\n",
      "Iteration 3610: loss = 3.1943\n",
      "Iteration 3620: loss = 2.9405\n",
      "Iteration 3630: loss = 2.6712\n",
      "Iteration 3640: loss = 2.7737\n",
      "Iteration 3650: loss = 3.0926\n",
      "Iteration 3660: loss = 3.0377\n",
      "Iteration 3670: loss = 2.4865\n",
      "Iteration 3680: loss = 3.0848\n",
      "Iteration 3690: loss = 2.9724\n",
      "Iteration 3700: loss = 3.0492\n",
      "Iteration 3710: loss = 2.8019\n",
      "Iteration 3720: loss = 2.5320\n",
      "Iteration 3730: loss = 2.7006\n",
      "Iteration 3740: loss = 2.5979\n",
      "Iteration 3750: loss = 3.1672\n",
      "Iteration 3760: loss = 2.6078\n",
      "Iteration 3770: loss = 2.6900\n",
      "Iteration 3780: loss = 2.6847\n",
      "Iteration 3790: loss = 2.9700\n",
      "Iteration 3800: loss = 2.9414\n",
      "Iteration 3810: loss = 2.8607\n",
      "Iteration 3820: loss = 2.4770\n",
      "Iteration 3830: loss = 3.1616\n",
      "Iteration 3840: loss = 2.9149\n",
      "Iteration 3850: loss = 2.8262\n",
      "Iteration 3860: loss = 2.6914\n",
      "Iteration 3870: loss = 2.6648\n",
      "Iteration 3880: loss = 2.5157\n",
      "Iteration 3890: loss = 2.7348\n",
      "Iteration 3900: loss = 2.8570\n",
      "Iteration 3910: loss = 2.3991\n",
      "Iteration 3920: loss = 2.6004\n",
      "Iteration 3930: loss = 2.8552\n",
      "Iteration 3940: loss = 2.3440\n",
      "Iteration 3950: loss = 2.9245\n",
      "Iteration 3960: loss = 2.5902\n",
      "Iteration 3970: loss = 3.1917\n",
      "Iteration 3980: loss = 2.5860\n",
      "Iteration 3990: loss = 2.9700\n",
      "Iteration 4000: loss = 2.6679\n",
      "Iteration 4010: loss = 2.7294\n",
      "Iteration 4020: loss = 3.4991\n",
      "Iteration 4030: loss = 3.0027\n",
      "Iteration 4040: loss = 2.7684\n",
      "Iteration 4050: loss = 2.5145\n",
      "Iteration 4060: loss = 2.7709\n",
      "Iteration 4070: loss = 3.2368\n",
      "Iteration 4080: loss = 2.6340\n",
      "Iteration 4090: loss = 2.5842\n",
      "Iteration 4100: loss = 2.7878\n",
      "Iteration 4110: loss = 3.0268\n",
      "Iteration 4120: loss = 2.6850\n",
      "Iteration 4130: loss = 2.7004\n",
      "Iteration 4140: loss = 2.7551\n",
      "Iteration 4150: loss = 2.9966\n",
      "Iteration 4160: loss = 2.9796\n",
      "Iteration 4170: loss = 2.8601\n",
      "Iteration 4180: loss = 3.5142\n",
      "Iteration 4190: loss = 2.2698\n",
      "Iteration 4200: loss = 2.8717\n",
      "Iteration 4210: loss = 3.1755\n",
      "Iteration 4220: loss = 2.7561\n",
      "Iteration 4230: loss = 2.8339\n",
      "Iteration 4240: loss = 2.8208\n",
      "Iteration 4250: loss = 2.7298\n",
      "Iteration 4260: loss = 2.8931\n",
      "Iteration 4270: loss = 3.3866\n",
      "Iteration 4280: loss = 2.8298\n",
      "Iteration 4290: loss = 2.6195\n",
      "Iteration 4300: loss = 2.5631\n",
      "Iteration 4310: loss = 2.5307\n",
      "Iteration 4320: loss = 3.0240\n",
      "Iteration 4330: loss = 3.2634\n",
      "Iteration 4340: loss = 3.0273\n",
      "Iteration 4350: loss = 3.0707\n",
      "Iteration 4360: loss = 2.6202\n",
      "Iteration 4370: loss = 3.0946\n",
      "Iteration 4380: loss = 2.3252\n",
      "Iteration 4390: loss = 2.1267\n",
      "Iteration 4400: loss = 2.9685\n",
      "Iteration 4410: loss = 2.9369\n",
      "Iteration 4420: loss = 2.4242\n",
      "Iteration 4430: loss = 2.5960\n",
      "Iteration 4440: loss = 2.6959\n",
      "Iteration 4450: loss = 2.8437\n",
      "Iteration 4460: loss = 2.7559\n",
      "Iteration 4470: loss = 2.8005\n",
      "Iteration 4480: loss = 2.7157\n",
      "Iteration 4490: loss = 2.6920\n",
      "Iteration 4500: loss = 2.1749\n",
      "Iteration 4510: loss = 2.6961\n",
      "Iteration 4520: loss = 2.4904\n",
      "Iteration 4530: loss = 2.7285\n",
      "Iteration 4540: loss = 2.7954\n",
      "Iteration 4550: loss = 2.7997\n",
      "Iteration 4560: loss = 2.9740\n",
      "Iteration 4570: loss = 3.3509\n",
      "Iteration 4580: loss = 2.5098\n",
      "Iteration 4590: loss = 3.0239\n",
      "Iteration 4600: loss = 2.4087\n",
      "Iteration 4610: loss = 2.7526\n",
      "Iteration 4620: loss = 3.0818\n",
      "Iteration 4630: loss = 3.1832\n",
      "Iteration 4640: loss = 2.6579\n",
      "Iteration 4650: loss = 3.3305\n",
      "Iteration 4660: loss = 2.8902\n",
      "Iteration 4670: loss = 2.5375\n",
      "Iteration 4680: loss = 2.6256\n",
      "Iteration 4690: loss = 2.3165\n",
      "Iteration 4700: loss = 3.6513\n",
      "Iteration 4710: loss = 2.8310\n",
      "Iteration 4720: loss = 3.4876\n",
      "Iteration 4730: loss = 2.5796\n",
      "Iteration 4740: loss = 3.2360\n",
      "Iteration 4750: loss = 2.6127\n",
      "Iteration 4760: loss = 2.7542\n",
      "Iteration 4770: loss = 2.6369\n",
      "Iteration 4780: loss = 3.2915\n",
      "Iteration 4790: loss = 2.3877\n",
      "Iteration 4800: loss = 2.5891\n",
      "Iteration 4810: loss = 2.6665\n",
      "Iteration 4820: loss = 2.7281\n",
      "Iteration 4830: loss = 2.5479\n",
      "Iteration 4840: loss = 3.3575\n",
      "Iteration 4850: loss = 2.5571\n",
      "Iteration 4860: loss = 2.8148\n",
      "Iteration 4870: loss = 2.9283\n",
      "Iteration 4880: loss = 2.6496\n",
      "Iteration 4890: loss = 2.8748\n",
      "Iteration 4900: loss = 2.5233\n",
      "Iteration 4910: loss = 2.8813\n",
      "Iteration 4920: loss = 2.7678\n",
      "Iteration 4930: loss = 2.6798\n",
      "Iteration 4940: loss = 2.9784\n",
      "Iteration 4950: loss = 2.4999\n",
      "Iteration 4960: loss = 2.7217\n",
      "Iteration 4970: loss = 2.5284\n",
      "Iteration 4980: loss = 2.7728\n",
      "Iteration 4990: loss = 2.7667\n",
      "Iteration 5000: loss = 2.8446\n",
      "Iteration 5010: loss = 2.7745\n",
      "Iteration 5020: loss = 2.8463\n",
      "Iteration 5030: loss = 2.5737\n",
      "Iteration 5040: loss = 3.0037\n",
      "Iteration 5050: loss = 2.9315\n",
      "Iteration 5060: loss = 2.7113\n",
      "Iteration 5070: loss = 2.4082\n",
      "Iteration 5080: loss = 2.8278\n",
      "Iteration 5090: loss = 2.8804\n",
      "Iteration 5100: loss = 2.8985\n",
      "Iteration 5110: loss = 2.8459\n",
      "Iteration 5120: loss = 2.7995\n",
      "Iteration 5130: loss = 2.8181\n",
      "Iteration 5140: loss = 2.2687\n",
      "Iteration 5150: loss = 3.1996\n",
      "Iteration 5160: loss = 2.4911\n",
      "Iteration 5170: loss = 2.6944\n",
      "Iteration 5180: loss = 3.1140\n",
      "Iteration 5190: loss = 2.6807\n",
      "Iteration 5200: loss = 3.2594\n",
      "Iteration 5210: loss = 3.7448\n",
      "Iteration 5220: loss = 2.9026\n",
      "Iteration 5230: loss = 2.8272\n",
      "Iteration 5240: loss = 2.9975\n",
      "Iteration 5250: loss = 2.6914\n",
      "Iteration 5260: loss = 2.8242\n",
      "Iteration 5270: loss = 2.7908\n",
      "Iteration 5280: loss = 2.6599\n",
      "Iteration 5290: loss = 2.8540\n",
      "Iteration 5300: loss = 3.2769\n",
      "Iteration 5310: loss = 3.1064\n",
      "Iteration 5320: loss = 2.1818\n",
      "Iteration 5330: loss = 3.0773\n",
      "Iteration 5340: loss = 2.5810\n",
      "Iteration 5350: loss = 2.7608\n",
      "Iteration 5360: loss = 3.0988\n",
      "Iteration 5370: loss = 2.9410\n",
      "Iteration 5380: loss = 2.8132\n",
      "Iteration 5390: loss = 2.3460\n",
      "Iteration 5400: loss = 2.8284\n",
      "Iteration 5410: loss = 3.0340\n",
      "Iteration 5420: loss = 2.9923\n",
      "Iteration 5430: loss = 2.7085\n",
      "Iteration 5440: loss = 2.8495\n",
      "Iteration 5450: loss = 3.1166\n",
      "Iteration 5460: loss = 2.6485\n",
      "Iteration 5470: loss = 3.0824\n",
      "Iteration 5480: loss = 2.6382\n",
      "Iteration 5490: loss = 2.5860\n",
      "Iteration 5500: loss = 2.7382\n",
      "Iteration 5510: loss = 2.6022\n",
      "Iteration 5520: loss = 2.2514\n",
      "Iteration 5530: loss = 2.3052\n",
      "Iteration 5540: loss = 2.4135\n",
      "Iteration 5550: loss = 2.8546\n",
      "Iteration 5560: loss = 3.0863\n",
      "Iteration 5570: loss = 2.8214\n",
      "Iteration 5580: loss = 2.4760\n",
      "Iteration 5590: loss = 2.8994\n",
      "Iteration 5600: loss = 3.2116\n",
      "Iteration 5610: loss = 3.0654\n",
      "Iteration 5620: loss = 2.3477\n",
      "Iteration 5630: loss = 3.1535\n",
      "Iteration 5640: loss = 2.4902\n",
      "Iteration 5650: loss = 2.5327\n",
      "Iteration 5660: loss = 2.6371\n",
      "Iteration 5670: loss = 2.4350\n",
      "Iteration 5680: loss = 2.4076\n",
      "Iteration 5690: loss = 2.7988\n",
      "Iteration 5700: loss = 2.9347\n",
      "Iteration 5710: loss = 2.7867\n",
      "Iteration 5720: loss = 3.1610\n",
      "Iteration 5730: loss = 2.6334\n",
      "Iteration 5740: loss = 2.7136\n",
      "Iteration 5750: loss = 3.0041\n",
      "Iteration 5760: loss = 2.3573\n",
      "Iteration 5770: loss = 3.1193\n",
      "Iteration 5780: loss = 2.4475\n",
      "Iteration 5790: loss = 2.4515\n",
      "Iteration 5800: loss = 2.7065\n",
      "Iteration 5810: loss = 2.8525\n",
      "Iteration 5820: loss = 2.6585\n",
      "Iteration 5830: loss = 2.6629\n",
      "Iteration 5840: loss = 2.9624\n",
      "Iteration 5850: loss = 2.7495\n",
      "Iteration 5860: loss = 2.2170\n",
      "Iteration 5870: loss = 2.5162\n",
      "Iteration 5880: loss = 3.1640\n",
      "Iteration 5890: loss = 2.8328\n",
      "Iteration 5900: loss = 2.5056\n",
      "Iteration 5910: loss = 3.1872\n",
      "Iteration 5920: loss = 2.7871\n",
      "Iteration 5930: loss = 2.5549\n",
      "Iteration 5940: loss = 2.7416\n",
      "Iteration 5950: loss = 2.8142\n",
      "Iteration 5960: loss = 2.7511\n",
      "Iteration 5970: loss = 2.3439\n",
      "Iteration 5980: loss = 2.3461\n",
      "Iteration 5990: loss = 2.8207\n",
      "Iteration 6000: loss = 2.8597\n",
      "Iteration 6010: loss = 2.5952\n",
      "Iteration 6020: loss = 2.9521\n",
      "Iteration 6030: loss = 2.9717\n",
      "Iteration 6040: loss = 2.8918\n",
      "Iteration 6050: loss = 2.5544\n",
      "Iteration 6060: loss = 2.7592\n",
      "Iteration 6070: loss = 3.2283\n",
      "Iteration 6080: loss = 2.5609\n",
      "Iteration 6090: loss = 2.9317\n",
      "Iteration 6100: loss = 2.8709\n",
      "Iteration 6110: loss = 2.6604\n",
      "Iteration 6120: loss = 2.1558\n",
      "Iteration 6130: loss = 3.1345\n",
      "Iteration 6140: loss = 3.5017\n",
      "Iteration 6150: loss = 3.0162\n",
      "Iteration 6160: loss = 2.5789\n",
      "Iteration 6170: loss = 2.8272\n",
      "Iteration 6180: loss = 2.8864\n",
      "Iteration 6190: loss = 2.8844\n",
      "Iteration 6200: loss = 2.6333\n",
      "Iteration 6210: loss = 2.8565\n",
      "Iteration 6220: loss = 2.9664\n",
      "Iteration 6230: loss = 2.8180\n",
      "Iteration 6240: loss = 2.8174\n",
      "Iteration 6250: loss = 2.6157\n",
      "Iteration 6260: loss = 3.0143\n",
      "Iteration 6270: loss = 2.4166\n",
      "Iteration 6280: loss = 2.9333\n",
      "Iteration 6290: loss = 2.7012\n",
      "Iteration 6300: loss = 2.2984\n",
      "Iteration 6310: loss = 2.9838\n",
      "Iteration 6320: loss = 2.6293\n",
      "Iteration 6330: loss = 2.6448\n",
      "Iteration 6340: loss = 2.7148\n",
      "Iteration 6350: loss = 2.3772\n",
      "Iteration 6360: loss = 2.6193\n",
      "Iteration 6370: loss = 2.7135\n",
      "Iteration 6380: loss = 2.5538\n",
      "Iteration 6390: loss = 2.8621\n",
      "Iteration 6400: loss = 2.4855\n",
      "Iteration 6410: loss = 2.5015\n",
      "Iteration 6420: loss = 3.0737\n",
      "Iteration 6430: loss = 2.5128\n",
      "Iteration 6440: loss = 2.8144\n",
      "Iteration 6450: loss = 2.8879\n",
      "Iteration 6460: loss = 2.7308\n",
      "Iteration 6470: loss = 2.3519\n",
      "Iteration 6480: loss = 3.2115\n",
      "Iteration 6490: loss = 2.7027\n",
      "Iteration 6500: loss = 2.8296\n",
      "Iteration 6510: loss = 2.9358\n",
      "Iteration 6520: loss = 2.4316\n",
      "Iteration 6530: loss = 2.6327\n",
      "Iteration 6540: loss = 2.7443\n",
      "Iteration 6550: loss = 2.7615\n",
      "Iteration 6560: loss = 2.7304\n",
      "Iteration 6570: loss = 2.8160\n",
      "Iteration 6580: loss = 2.6976\n",
      "Iteration 6590: loss = 2.9039\n",
      "Iteration 6600: loss = 2.5404\n",
      "Iteration 6610: loss = 2.0687\n",
      "Iteration 6620: loss = 2.7506\n",
      "Iteration 6630: loss = 3.3917\n",
      "Iteration 6640: loss = 2.1670\n",
      "Iteration 6650: loss = 2.9118\n",
      "Iteration 6660: loss = 2.8500\n",
      "Iteration 6670: loss = 2.7847\n",
      "Iteration 6680: loss = 2.8948\n",
      "Iteration 6690: loss = 2.6336\n",
      "Iteration 6700: loss = 2.7210\n",
      "Iteration 6710: loss = 2.8414\n",
      "Iteration 6720: loss = 2.8344\n",
      "Iteration 6730: loss = 2.5983\n",
      "Iteration 6740: loss = 2.6546\n",
      "Iteration 6750: loss = 2.5180\n",
      "Iteration 6760: loss = 2.7431\n",
      "Iteration 6770: loss = 2.0716\n",
      "Iteration 6780: loss = 2.3660\n",
      "Iteration 6790: loss = 2.8146\n",
      "Iteration 6800: loss = 2.4616\n",
      "Iteration 6810: loss = 2.2950\n",
      "Iteration 6820: loss = 2.7257\n",
      "Iteration 6830: loss = 2.9143\n",
      "Iteration 6840: loss = 2.4986\n",
      "Iteration 6850: loss = 2.5004\n",
      "Iteration 6860: loss = 2.6885\n",
      "Iteration 6870: loss = 2.4824\n",
      "Iteration 6880: loss = 2.5424\n",
      "Iteration 6890: loss = 2.5587\n",
      "Iteration 6900: loss = 2.5009\n",
      "Iteration 6910: loss = 2.5167\n",
      "Iteration 6920: loss = 3.4242\n",
      "Iteration 6930: loss = 3.6013\n",
      "Iteration 6940: loss = 2.7821\n",
      "Iteration 6950: loss = 2.4692\n",
      "Iteration 6960: loss = 2.3771\n",
      "Iteration 6970: loss = 2.5592\n",
      "Iteration 6980: loss = 2.6898\n",
      "Iteration 6990: loss = 2.9637\n",
      "Iteration 7000: loss = 2.8121\n",
      "Iteration 7010: loss = 2.7303\n",
      "Iteration 7020: loss = 2.6856\n",
      "Iteration 7030: loss = 2.6532\n",
      "Iteration 7040: loss = 2.6226\n",
      "Iteration 7050: loss = 2.5423\n",
      "Iteration 7060: loss = 3.0197\n",
      "Iteration 7070: loss = 2.2103\n",
      "Iteration 7080: loss = 2.5635\n",
      "Iteration 7090: loss = 2.7802\n",
      "Iteration 7100: loss = 2.3223\n",
      "Iteration 7110: loss = 2.4408\n",
      "Iteration 7120: loss = 2.8466\n",
      "Iteration 7130: loss = 2.9743\n",
      "Iteration 7140: loss = 2.9424\n",
      "Iteration 7150: loss = 2.5189\n",
      "Iteration 7160: loss = 2.7743\n",
      "Iteration 7170: loss = 2.3407\n",
      "Iteration 7180: loss = 3.1363\n",
      "Iteration 7190: loss = 2.2831\n",
      "Iteration 7200: loss = 2.5573\n",
      "Iteration 7210: loss = 2.8094\n",
      "Iteration 7220: loss = 2.8789\n",
      "Iteration 7230: loss = 2.8308\n",
      "Iteration 7240: loss = 3.3240\n",
      "Iteration 7250: loss = 2.5102\n",
      "Iteration 7260: loss = 2.7578\n",
      "Iteration 7270: loss = 2.6296\n",
      "Iteration 7280: loss = 2.4851\n",
      "Iteration 7290: loss = 2.8402\n",
      "Iteration 7300: loss = 2.9884\n",
      "Iteration 7310: loss = 2.9117\n",
      "Iteration 7320: loss = 2.8401\n",
      "Iteration 7330: loss = 2.7953\n",
      "Iteration 7340: loss = 2.6469\n",
      "Iteration 7350: loss = 2.4719\n",
      "Iteration 7360: loss = 2.6863\n",
      "Iteration 7370: loss = 2.6215\n",
      "Iteration 7380: loss = 2.7497\n",
      "Iteration 7390: loss = 2.7485\n",
      "Iteration 7400: loss = 2.8450\n",
      "Iteration 7410: loss = 2.9133\n",
      "Iteration 7420: loss = 2.8772\n",
      "Iteration 7430: loss = 2.6002\n",
      "Iteration 7440: loss = 2.8080\n",
      "Iteration 7450: loss = 3.0013\n",
      "Iteration 7460: loss = 2.8633\n",
      "Iteration 7470: loss = 2.8568\n",
      "Iteration 7480: loss = 2.5854\n",
      "Iteration 7490: loss = 2.9077\n",
      "Iteration 7500: loss = 2.8707\n",
      "Iteration 7510: loss = 2.5734\n",
      "Iteration 7520: loss = 2.6928\n",
      "Iteration 7530: loss = 2.6549\n",
      "Iteration 7540: loss = 2.5970\n",
      "Iteration 7550: loss = 2.4827\n",
      "Iteration 7560: loss = 3.3342\n",
      "Iteration 7570: loss = 2.5239\n",
      "Iteration 7580: loss = 3.1494\n",
      "Iteration 7590: loss = 2.8140\n",
      "Iteration 7600: loss = 3.1639\n",
      "Iteration 7610: loss = 2.9149\n",
      "Iteration 7620: loss = 3.0170\n",
      "Iteration 7630: loss = 2.6639\n",
      "Iteration 7640: loss = 2.5076\n",
      "Iteration 7650: loss = 3.0025\n",
      "Iteration 7660: loss = 2.7257\n",
      "Iteration 7670: loss = 3.1179\n",
      "Iteration 7680: loss = 2.7997\n",
      "Iteration 7690: loss = 2.8665\n",
      "Iteration 7700: loss = 2.6686\n",
      "Iteration 7710: loss = 2.3778\n",
      "Iteration 7720: loss = 2.9304\n",
      "Iteration 7730: loss = 3.0780\n",
      "Iteration 7740: loss = 3.1335\n",
      "Iteration 7750: loss = 2.4072\n",
      "Iteration 7760: loss = 2.4075\n",
      "Iteration 7770: loss = 2.4710\n",
      "Iteration 7780: loss = 2.8953\n",
      "Iteration 7790: loss = 2.7470\n",
      "Iteration 7800: loss = 2.3614\n",
      "Iteration 7810: loss = 2.8391\n",
      "Iteration 7820: loss = 2.6962\n",
      "Iteration 7830: loss = 2.7418\n",
      "Iteration 7840: loss = 2.4470\n",
      "Iteration 7850: loss = 2.8289\n",
      "Iteration 7860: loss = 2.3729\n",
      "Iteration 7870: loss = 2.6320\n",
      "Iteration 7880: loss = 2.6897\n",
      "Iteration 7890: loss = 2.1560\n",
      "Iteration 7900: loss = 2.3779\n",
      "Iteration 7910: loss = 3.0709\n",
      "Iteration 7920: loss = 2.4470\n",
      "Iteration 7930: loss = 2.4916\n",
      "Iteration 7940: loss = 2.5580\n",
      "Iteration 7950: loss = 2.0691\n",
      "Iteration 7960: loss = 2.4696\n",
      "Iteration 7970: loss = 2.6940\n",
      "Iteration 7980: loss = 2.5452\n",
      "Iteration 7990: loss = 2.6835\n",
      "Iteration 8000: loss = 2.5966\n",
      "Iteration 8010: loss = 2.6622\n",
      "Iteration 8020: loss = 2.6603\n",
      "Iteration 8030: loss = 2.7730\n",
      "Iteration 8040: loss = 2.4040\n",
      "Iteration 8050: loss = 2.5767\n",
      "Iteration 8060: loss = 2.5391\n",
      "Iteration 8070: loss = 2.7432\n",
      "Iteration 8080: loss = 2.6748\n",
      "Iteration 8090: loss = 2.2194\n",
      "Iteration 8100: loss = 2.5704\n",
      "Iteration 8110: loss = 2.6275\n",
      "Iteration 8120: loss = 2.7504\n",
      "Iteration 8130: loss = 2.8987\n",
      "Iteration 8140: loss = 3.2859\n",
      "Iteration 8150: loss = 2.7614\n",
      "Iteration 8160: loss = 2.7819\n",
      "Iteration 8170: loss = 2.3776\n",
      "Iteration 8180: loss = 2.3516\n",
      "Iteration 8190: loss = 2.6390\n",
      "Iteration 8200: loss = 2.1187\n",
      "Iteration 8210: loss = 2.6895\n",
      "Iteration 8220: loss = 2.7707\n",
      "Iteration 8230: loss = 2.5144\n",
      "Iteration 8240: loss = 2.4799\n",
      "Iteration 8250: loss = 2.6297\n",
      "Iteration 8260: loss = 2.8267\n",
      "Iteration 8270: loss = 2.8316\n",
      "Iteration 8280: loss = 2.7163\n",
      "Iteration 8290: loss = 2.7009\n",
      "Iteration 8300: loss = 2.3769\n",
      "Iteration 8310: loss = 2.8155\n",
      "Iteration 8320: loss = 2.9387\n",
      "Iteration 8330: loss = 2.7939\n",
      "Iteration 8340: loss = 2.5327\n",
      "Iteration 8350: loss = 2.6006\n",
      "Iteration 8360: loss = 2.7421\n",
      "Iteration 8370: loss = 2.7382\n",
      "Iteration 8380: loss = 2.2083\n",
      "Iteration 8390: loss = 3.0511\n",
      "Iteration 8400: loss = 2.6480\n",
      "Iteration 8410: loss = 2.6010\n",
      "Iteration 8420: loss = 2.6912\n",
      "Iteration 8430: loss = 2.5986\n",
      "Iteration 8440: loss = 3.0730\n",
      "Iteration 8450: loss = 2.5105\n",
      "Iteration 8460: loss = 2.4962\n",
      "Iteration 8470: loss = 2.3147\n",
      "Iteration 8480: loss = 2.7211\n",
      "Iteration 8490: loss = 2.7401\n",
      "Iteration 8500: loss = 2.7457\n",
      "Iteration 8510: loss = 2.4147\n",
      "Iteration 8520: loss = 2.4719\n",
      "Iteration 8530: loss = 2.6344\n",
      "Iteration 8540: loss = 2.5342\n",
      "Iteration 8550: loss = 2.7322\n",
      "Iteration 8560: loss = 2.5880\n",
      "Iteration 8570: loss = 2.5813\n",
      "Iteration 8580: loss = 2.8392\n",
      "Iteration 8590: loss = 2.5517\n",
      "Iteration 8600: loss = 2.5386\n",
      "Iteration 8610: loss = 2.9269\n",
      "Iteration 8620: loss = 3.1012\n",
      "Iteration 8630: loss = 2.4243\n",
      "Iteration 8640: loss = 2.7204\n",
      "Iteration 8650: loss = 2.7522\n",
      "Iteration 8660: loss = 2.5874\n",
      "Iteration 8670: loss = 2.4068\n",
      "Iteration 8680: loss = 2.5608\n",
      "Iteration 8690: loss = 2.8827\n",
      "Iteration 8700: loss = 2.7501\n",
      "Iteration 8710: loss = 2.7613\n",
      "Iteration 8720: loss = 2.8840\n",
      "Iteration 8730: loss = 2.4094\n",
      "Iteration 8740: loss = 2.2567\n",
      "Iteration 8750: loss = 2.6171\n",
      "Iteration 8760: loss = 2.6052\n",
      "Iteration 8770: loss = 2.5778\n",
      "Iteration 8780: loss = 2.7762\n",
      "Iteration 8790: loss = 2.9738\n",
      "Iteration 8800: loss = 3.0957\n",
      "Iteration 8810: loss = 2.5421\n",
      "Iteration 8820: loss = 3.0376\n",
      "Iteration 8830: loss = 2.7811\n",
      "Iteration 8840: loss = 2.8431\n",
      "Iteration 8850: loss = 2.9232\n",
      "Iteration 8860: loss = 2.9481\n",
      "Iteration 8870: loss = 2.8017\n",
      "Iteration 8880: loss = 2.7991\n",
      "Iteration 8890: loss = 2.6029\n",
      "Iteration 8900: loss = 3.1849\n",
      "Iteration 8910: loss = 2.9214\n",
      "Iteration 8920: loss = 3.2386\n",
      "Iteration 8930: loss = 2.5841\n",
      "Iteration 8940: loss = 2.5358\n",
      "Iteration 8950: loss = 2.5895\n",
      "Iteration 8960: loss = 2.8983\n",
      "Iteration 8970: loss = 2.8225\n",
      "Iteration 8980: loss = 2.5752\n",
      "Iteration 8990: loss = 2.7715\n",
      "Iteration 9000: loss = 2.4762\n",
      "Iteration 9010: loss = 2.2178\n",
      "Iteration 9020: loss = 2.5779\n",
      "Iteration 9030: loss = 2.5839\n",
      "Iteration 9040: loss = 2.4622\n",
      "Iteration 9050: loss = 2.4711\n",
      "Iteration 9060: loss = 2.7736\n",
      "Iteration 9070: loss = 2.5444\n",
      "Iteration 9080: loss = 2.6775\n",
      "Iteration 9090: loss = 2.6855\n",
      "Iteration 9100: loss = 2.9218\n",
      "Iteration 9110: loss = 2.8343\n",
      "Iteration 9120: loss = 2.5919\n",
      "Iteration 9130: loss = 2.9327\n",
      "Iteration 9140: loss = 2.2974\n",
      "Iteration 9150: loss = 3.2196\n",
      "Iteration 9160: loss = 2.9445\n",
      "Iteration 9170: loss = 2.8590\n",
      "Iteration 9180: loss = 2.5994\n",
      "Iteration 9190: loss = 2.9185\n",
      "Iteration 9200: loss = 2.4202\n",
      "Iteration 9210: loss = 3.1501\n",
      "Iteration 9220: loss = 2.4066\n",
      "Iteration 9230: loss = 2.3246\n",
      "Iteration 9240: loss = 3.0784\n",
      "Iteration 9250: loss = 3.1801\n",
      "Iteration 9260: loss = 2.3582\n",
      "Iteration 9270: loss = 3.1839\n",
      "Iteration 9280: loss = 2.7509\n",
      "Iteration 9290: loss = 2.8209\n",
      "Iteration 9300: loss = 2.7190\n",
      "Iteration 9310: loss = 2.8298\n",
      "Iteration 9320: loss = 2.6083\n",
      "Iteration 9330: loss = 2.7608\n",
      "Iteration 9340: loss = 2.1485\n",
      "Iteration 9350: loss = 2.5044\n",
      "Iteration 9360: loss = 2.4953\n",
      "Iteration 9370: loss = 2.7398\n",
      "Iteration 9380: loss = 2.6556\n",
      "Iteration 9390: loss = 3.2706\n",
      "Iteration 9400: loss = 2.9896\n",
      "Iteration 9410: loss = 2.8434\n",
      "Iteration 9420: loss = 2.7505\n",
      "Iteration 9430: loss = 2.7500\n",
      "Iteration 9440: loss = 2.7312\n",
      "Iteration 9450: loss = 2.9906\n",
      "Iteration 9460: loss = 3.1106\n",
      "Iteration 9470: loss = 2.4940\n",
      "Iteration 9480: loss = 2.5169\n",
      "Iteration 9490: loss = 2.8256\n",
      "Iteration 9500: loss = 2.8992\n",
      "Iteration 9510: loss = 3.0087\n",
      "Iteration 9520: loss = 2.6349\n",
      "Iteration 9530: loss = 3.0681\n",
      "Iteration 9540: loss = 2.7294\n",
      "Iteration 9550: loss = 2.5177\n",
      "Iteration 9560: loss = 2.5849\n",
      "Iteration 9570: loss = 2.7291\n",
      "Iteration 9580: loss = 2.5392\n",
      "Iteration 9590: loss = 3.1910\n",
      "Iteration 9600: loss = 2.6568\n",
      "Iteration 9610: loss = 2.5731\n",
      "Iteration 9620: loss = 2.9665\n",
      "Iteration 9630: loss = 2.4019\n",
      "Iteration 9640: loss = 2.7730\n",
      "Iteration 9650: loss = 2.8400\n",
      "Iteration 9660: loss = 2.7296\n",
      "Iteration 9670: loss = 2.4940\n",
      "Iteration 9680: loss = 2.3104\n",
      "Iteration 9690: loss = 2.7558\n",
      "Iteration 9700: loss = 3.3132\n",
      "Iteration 9710: loss = 2.8101\n",
      "Iteration 9720: loss = 2.3440\n",
      "Iteration 9730: loss = 2.7107\n",
      "Iteration 9740: loss = 2.2921\n",
      "Iteration 9750: loss = 2.7895\n",
      "Iteration 9760: loss = 2.5900\n",
      "Iteration 9770: loss = 2.3196\n",
      "Iteration 9780: loss = 2.8991\n",
      "Iteration 9790: loss = 2.4604\n",
      "Iteration 9800: loss = 3.1712\n",
      "Iteration 9810: loss = 2.2625\n",
      "Iteration 9820: loss = 3.0351\n",
      "Iteration 9830: loss = 3.0485\n",
      "Iteration 9840: loss = 2.5846\n",
      "Iteration 9850: loss = 2.6608\n",
      "Iteration 9860: loss = 2.7833\n",
      "Iteration 9870: loss = 3.2733\n",
      "Iteration 9880: loss = 2.5182\n",
      "Iteration 9890: loss = 2.7697\n",
      "Iteration 9900: loss = 3.0695\n",
      "Iteration 9910: loss = 2.6876\n",
      "Iteration 9920: loss = 2.8035\n",
      "Iteration 9930: loss = 2.8189\n",
      "Iteration 9940: loss = 2.4377\n",
      "Iteration 9950: loss = 3.0087\n",
      "Iteration 9960: loss = 2.4810\n",
      "Iteration 9970: loss = 2.4178\n",
      "Iteration 9980: loss = 2.6335\n",
      "Iteration 9990: loss = 2.8604\n",
      "Iteration 10000: loss = 2.4560\n",
      "Iteration 10010: loss = 2.3042\n",
      "Iteration 10020: loss = 2.8183\n",
      "Iteration 10030: loss = 2.5660\n",
      "Iteration 10040: loss = 2.2789\n",
      "Iteration 10050: loss = 2.4754\n",
      "Iteration 10060: loss = 2.6158\n",
      "Iteration 10070: loss = 2.3602\n",
      "Iteration 10080: loss = 2.3269\n",
      "Iteration 10090: loss = 2.6570\n",
      "Iteration 10100: loss = 2.6172\n",
      "Iteration 10110: loss = 2.9621\n",
      "Iteration 10120: loss = 2.5580\n",
      "Iteration 10130: loss = 2.6597\n",
      "Iteration 10140: loss = 2.5113\n",
      "Iteration 10150: loss = 2.4231\n",
      "Iteration 10160: loss = 2.7923\n",
      "Iteration 10170: loss = 3.0108\n",
      "Iteration 10180: loss = 2.4508\n",
      "Iteration 10190: loss = 2.6944\n",
      "Iteration 10200: loss = 2.7723\n",
      "Iteration 10210: loss = 2.4489\n",
      "Iteration 10220: loss = 2.5665\n",
      "Iteration 10230: loss = 2.5609\n",
      "Iteration 10240: loss = 2.5253\n",
      "Iteration 10250: loss = 2.7373\n",
      "Iteration 10260: loss = 2.5279\n",
      "Iteration 10270: loss = 2.7607\n",
      "Iteration 10280: loss = 2.7080\n",
      "Iteration 10290: loss = 2.7393\n",
      "Iteration 10300: loss = 2.5555\n",
      "Iteration 10310: loss = 2.2168\n",
      "Iteration 10320: loss = 2.9426\n",
      "Iteration 10330: loss = 2.9030\n",
      "Iteration 10340: loss = 3.5279\n",
      "Iteration 10350: loss = 2.6620\n",
      "Iteration 10360: loss = 2.2730\n",
      "Iteration 10370: loss = 2.9368\n",
      "Iteration 10380: loss = 2.6042\n",
      "Iteration 10390: loss = 2.6229\n",
      "Iteration 10400: loss = 2.5723\n",
      "Iteration 10410: loss = 2.8911\n",
      "Iteration 10420: loss = 2.5502\n",
      "Iteration 10430: loss = 2.7337\n",
      "Iteration 10440: loss = 2.3577\n",
      "Iteration 10450: loss = 2.7660\n",
      "Iteration 10460: loss = 2.7124\n",
      "Iteration 10470: loss = 3.0628\n",
      "Iteration 10480: loss = 2.6401\n",
      "Iteration 10490: loss = 2.3764\n",
      "Iteration 10500: loss = 2.7619\n",
      "Iteration 10510: loss = 2.1867\n",
      "Iteration 10520: loss = 2.3630\n",
      "Iteration 10530: loss = 2.8469\n",
      "Iteration 10540: loss = 2.9646\n",
      "Iteration 10550: loss = 2.3956\n",
      "Iteration 10560: loss = 2.4782\n",
      "Iteration 10570: loss = 2.8496\n",
      "Iteration 10580: loss = 3.2605\n",
      "Iteration 10590: loss = 3.0100\n",
      "Iteration 10600: loss = 2.4964\n",
      "Iteration 10610: loss = 2.4191\n",
      "Iteration 10620: loss = 2.5291\n",
      "Iteration 10630: loss = 2.4285\n",
      "Iteration 10640: loss = 2.6160\n",
      "Iteration 10650: loss = 2.5320\n",
      "Iteration 10660: loss = 2.8898\n",
      "Iteration 10670: loss = 2.3381\n",
      "Iteration 10680: loss = 3.0697\n",
      "Iteration 10690: loss = 2.6796\n",
      "Iteration 10700: loss = 2.6974\n",
      "Iteration 10710: loss = 2.4145\n",
      "Iteration 10720: loss = 2.3477\n",
      "Iteration 10730: loss = 2.6631\n",
      "Iteration 10740: loss = 2.3707\n",
      "Iteration 10750: loss = 2.4757\n",
      "Iteration 10760: loss = 2.8297\n",
      "Iteration 10770: loss = 2.8558\n",
      "Iteration 10780: loss = 2.8532\n",
      "Iteration 10790: loss = 3.0930\n",
      "Iteration 10800: loss = 2.9878\n",
      "Iteration 10810: loss = 2.3973\n",
      "Iteration 10820: loss = 3.0300\n",
      "Iteration 10830: loss = 3.0912\n",
      "Iteration 10840: loss = 2.9856\n",
      "Iteration 10850: loss = 2.6507\n",
      "Iteration 10860: loss = 2.4555\n",
      "Iteration 10870: loss = 2.9859\n",
      "Iteration 10880: loss = 3.0715\n",
      "Iteration 10890: loss = 2.6259\n",
      "Iteration 10900: loss = 2.6572\n",
      "Iteration 10910: loss = 2.6595\n",
      "Iteration 10920: loss = 2.9988\n",
      "Iteration 10930: loss = 2.6997\n",
      "Iteration 10940: loss = 2.6321\n",
      "Iteration 10950: loss = 2.4212\n",
      "Iteration 10960: loss = 2.3112\n",
      "Iteration 10970: loss = 2.7306\n",
      "Iteration 10980: loss = 2.7517\n",
      "Iteration 10990: loss = 2.4165\n",
      "Iteration 11000: loss = 2.5965\n",
      "Iteration 11010: loss = 2.6321\n",
      "Iteration 11020: loss = 2.9807\n",
      "Iteration 11030: loss = 2.4274\n",
      "Iteration 11040: loss = 2.7041\n",
      "Iteration 11050: loss = 2.8334\n",
      "Iteration 11060: loss = 2.7813\n",
      "Iteration 11070: loss = 3.0172\n",
      "Iteration 11080: loss = 2.3256\n",
      "Iteration 11090: loss = 2.3622\n",
      "Iteration 11100: loss = 2.8725\n",
      "Iteration 11110: loss = 2.5241\n",
      "Iteration 11120: loss = 2.2648\n",
      "Iteration 11130: loss = 2.6749\n",
      "Iteration 11140: loss = 2.6661\n",
      "Iteration 11150: loss = 2.5509\n",
      "Iteration 11160: loss = 2.7253\n",
      "Iteration 11170: loss = 2.4175\n",
      "Iteration 11180: loss = 2.6330\n",
      "Iteration 11190: loss = 2.5315\n",
      "Iteration 11200: loss = 2.6482\n",
      "Iteration 11210: loss = 2.5733\n",
      "Iteration 11220: loss = 2.5612\n",
      "Iteration 11230: loss = 2.7727\n",
      "Iteration 11240: loss = 2.8062\n",
      "Iteration 11250: loss = 2.7051\n",
      "Iteration 11260: loss = 2.2808\n",
      "Iteration 11270: loss = 2.8361\n",
      "Iteration 11280: loss = 2.3472\n",
      "Iteration 11290: loss = 2.8060\n",
      "Iteration 11300: loss = 2.9182\n",
      "Iteration 11310: loss = 3.0096\n",
      "Iteration 11320: loss = 2.5608\n",
      "Iteration 11330: loss = 2.6070\n",
      "Iteration 11340: loss = 2.3701\n",
      "Iteration 11350: loss = 2.4192\n",
      "Iteration 11360: loss = 2.4763\n",
      "Iteration 11370: loss = 2.8532\n",
      "Iteration 11380: loss = 2.6734\n",
      "Iteration 11390: loss = 2.9880\n",
      "Iteration 11400: loss = 2.3755\n",
      "Iteration 11410: loss = 2.8354\n",
      "Iteration 11420: loss = 2.6288\n",
      "Iteration 11430: loss = 2.7475\n",
      "Iteration 11440: loss = 2.6121\n",
      "Iteration 11450: loss = 2.7506\n",
      "Iteration 11460: loss = 2.5536\n",
      "Iteration 11470: loss = 2.6570\n",
      "Iteration 11480: loss = 2.4729\n",
      "Iteration 11490: loss = 2.6820\n",
      "Iteration 11500: loss = 2.8724\n",
      "Iteration 11510: loss = 2.8041\n",
      "Iteration 11520: loss = 2.6382\n",
      "Iteration 11530: loss = 2.7320\n",
      "Iteration 11540: loss = 2.8987\n",
      "Iteration 11550: loss = 2.5286\n",
      "Iteration 11560: loss = 2.5804\n",
      "Iteration 11570: loss = 2.6848\n",
      "Iteration 11580: loss = 2.5986\n",
      "Iteration 11590: loss = 2.5354\n",
      "Iteration 11600: loss = 2.5142\n",
      "Iteration 11610: loss = 2.4842\n",
      "Iteration 11620: loss = 2.3435\n",
      "Iteration 11630: loss = 3.0786\n",
      "Iteration 11640: loss = 2.6698\n",
      "Iteration 11650: loss = 2.6241\n",
      "Iteration 11660: loss = 2.4536\n",
      "Iteration 11670: loss = 3.1955\n",
      "Iteration 11680: loss = 2.7276\n",
      "Iteration 11690: loss = 2.5269\n",
      "Iteration 11700: loss = 2.3488\n",
      "Iteration 11710: loss = 2.8483\n",
      "Iteration 11720: loss = 2.4738\n",
      "Iteration 11730: loss = 2.6375\n",
      "Iteration 11740: loss = 2.8371\n",
      "Iteration 11750: loss = 2.7860\n",
      "Iteration 11760: loss = 2.7002\n",
      "Iteration 11770: loss = 2.6181\n",
      "Iteration 11780: loss = 2.6389\n",
      "Iteration 11790: loss = 2.5843\n",
      "Iteration 11800: loss = 2.7944\n",
      "Iteration 11810: loss = 2.6585\n",
      "Iteration 11820: loss = 2.6653\n",
      "Iteration 11830: loss = 2.6591\n",
      "Iteration 11840: loss = 2.7054\n",
      "Iteration 11850: loss = 2.6717\n",
      "Iteration 11860: loss = 2.2644\n",
      "Iteration 11870: loss = 2.2884\n",
      "Iteration 11880: loss = 3.0497\n",
      "Iteration 11890: loss = 2.6550\n",
      "Iteration 11900: loss = 2.6471\n",
      "Iteration 11910: loss = 2.7699\n",
      "Iteration 11920: loss = 2.6276\n",
      "Iteration 11930: loss = 2.7257\n",
      "Iteration 11940: loss = 2.6983\n",
      "Iteration 11950: loss = 2.7217\n",
      "Iteration 11960: loss = 2.9350\n",
      "Iteration 11970: loss = 2.5549\n",
      "Iteration 11980: loss = 2.8867\n",
      "Iteration 11990: loss = 2.7881\n",
      "Iteration 12000: loss = 2.6584\n",
      "Iteration 12010: loss = 2.7060\n",
      "Iteration 12020: loss = 2.5886\n",
      "Iteration 12030: loss = 2.9159\n",
      "Iteration 12040: loss = 2.5887\n",
      "Iteration 12050: loss = 2.4950\n",
      "Iteration 12060: loss = 3.2917\n",
      "Iteration 12070: loss = 2.9689\n",
      "Iteration 12080: loss = 2.5828\n",
      "Iteration 12090: loss = 2.8002\n",
      "Iteration 12100: loss = 2.6750\n",
      "Iteration 12110: loss = 2.5686\n",
      "Iteration 12120: loss = 2.1791\n",
      "Iteration 12130: loss = 3.1425\n",
      "Iteration 12140: loss = 2.5332\n",
      "Iteration 12150: loss = 2.4351\n",
      "Iteration 12160: loss = 2.6722\n",
      "Iteration 12170: loss = 2.2458\n",
      "Iteration 12180: loss = 2.5732\n",
      "Iteration 12190: loss = 2.6854\n",
      "Iteration 12200: loss = 2.4787\n",
      "Iteration 12210: loss = 2.6309\n",
      "Iteration 12220: loss = 2.8437\n",
      "Iteration 12230: loss = 2.6104\n",
      "Iteration 12240: loss = 2.7794\n",
      "Iteration 12250: loss = 2.7362\n",
      "Iteration 12260: loss = 3.0552\n",
      "Iteration 12270: loss = 2.2152\n",
      "Iteration 12280: loss = 2.5264\n",
      "Iteration 12290: loss = 2.7355\n",
      "Iteration 12300: loss = 2.5071\n",
      "Iteration 12310: loss = 2.4626\n",
      "Iteration 12320: loss = 2.3582\n",
      "Iteration 12330: loss = 2.7009\n",
      "Iteration 12340: loss = 2.8743\n",
      "Iteration 12350: loss = 2.5540\n",
      "Iteration 12360: loss = 2.3593\n",
      "Iteration 12370: loss = 3.0829\n",
      "Iteration 12380: loss = 2.5262\n",
      "Iteration 12390: loss = 2.5747\n",
      "Iteration 12400: loss = 2.6146\n",
      "Iteration 12410: loss = 2.8793\n",
      "Iteration 12420: loss = 2.4583\n",
      "Iteration 12430: loss = 2.9936\n",
      "Iteration 12440: loss = 2.5408\n",
      "Iteration 12450: loss = 2.4633\n",
      "Iteration 12460: loss = 2.7670\n",
      "Iteration 12470: loss = 2.1028\n",
      "Iteration 12480: loss = 2.3839\n",
      "Iteration 12490: loss = 2.7484\n",
      "Iteration 12500: loss = 2.4593\n",
      "Iteration 12510: loss = 2.7507\n",
      "Iteration 12520: loss = 2.4843\n",
      "Iteration 12530: loss = 2.8074\n",
      "Iteration 12540: loss = 2.3154\n",
      "Iteration 12550: loss = 2.6150\n",
      "Iteration 12560: loss = 2.6513\n",
      "Iteration 12570: loss = 3.0993\n",
      "Iteration 12580: loss = 2.7149\n",
      "Iteration 12590: loss = 2.6722\n",
      "Iteration 12600: loss = 2.6069\n",
      "Iteration 12610: loss = 2.8450\n",
      "Iteration 12620: loss = 2.5759\n",
      "Iteration 12630: loss = 2.5618\n",
      "Iteration 12640: loss = 2.5977\n",
      "Iteration 12650: loss = 2.6044\n",
      "Iteration 12660: loss = 2.6623\n",
      "Iteration 12670: loss = 2.5639\n",
      "Iteration 12680: loss = 2.8398\n",
      "Iteration 12690: loss = 2.3590\n",
      "Iteration 12700: loss = 2.4817\n",
      "Iteration 12710: loss = 2.7340\n",
      "Iteration 12720: loss = 3.1097\n",
      "Iteration 12730: loss = 2.7907\n",
      "Iteration 12740: loss = 2.7163\n",
      "Iteration 12750: loss = 2.5987\n",
      "Iteration 12760: loss = 2.4850\n",
      "Iteration 12770: loss = 2.3776\n",
      "Iteration 12780: loss = 2.6093\n",
      "Iteration 12790: loss = 2.7145\n",
      "Iteration 12800: loss = 2.7140\n",
      "Iteration 12810: loss = 3.0255\n",
      "Iteration 12820: loss = 2.8367\n",
      "Iteration 12830: loss = 2.7135\n",
      "Iteration 12840: loss = 2.7876\n",
      "Iteration 12850: loss = 2.7065\n",
      "Iteration 12860: loss = 2.6340\n",
      "Iteration 12870: loss = 2.5400\n",
      "Iteration 12880: loss = 2.3469\n",
      "Iteration 12890: loss = 2.4897\n",
      "Iteration 12900: loss = 2.4972\n",
      "Iteration 12910: loss = 2.8776\n",
      "Iteration 12920: loss = 2.3841\n",
      "Iteration 12930: loss = 2.6957\n",
      "Iteration 12940: loss = 2.9012\n",
      "Iteration 12950: loss = 2.8149\n",
      "Iteration 12960: loss = 2.3291\n",
      "Iteration 12970: loss = 2.7966\n",
      "Iteration 12980: loss = 2.2470\n",
      "Iteration 12990: loss = 2.4452\n",
      "Iteration 13000: loss = 2.4982\n",
      "Iteration 13010: loss = 2.5689\n",
      "Iteration 13020: loss = 2.9735\n",
      "Iteration 13030: loss = 2.8168\n",
      "Iteration 13040: loss = 2.2201\n",
      "Iteration 13050: loss = 2.4277\n",
      "Iteration 13060: loss = 2.4872\n",
      "Iteration 13070: loss = 2.3860\n",
      "Iteration 13080: loss = 2.7256\n",
      "Iteration 13090: loss = 2.7998\n",
      "Iteration 13100: loss = 3.0794\n",
      "Iteration 13110: loss = 2.5050\n",
      "Iteration 13120: loss = 2.6445\n",
      "Iteration 13130: loss = 2.5154\n",
      "Iteration 13140: loss = 2.5400\n",
      "Iteration 13150: loss = 2.5737\n",
      "Iteration 13160: loss = 2.2661\n",
      "Iteration 13170: loss = 2.2018\n",
      "Iteration 13180: loss = 2.2785\n",
      "Iteration 13190: loss = 2.4733\n",
      "Iteration 13200: loss = 2.6027\n",
      "Iteration 13210: loss = 2.4750\n",
      "Iteration 13220: loss = 2.5273\n",
      "Iteration 13230: loss = 2.4265\n",
      "Iteration 13240: loss = 2.8630\n",
      "Iteration 13250: loss = 2.7459\n",
      "Iteration 13260: loss = 2.4474\n",
      "Iteration 13270: loss = 2.4146\n",
      "Iteration 13280: loss = 2.6261\n",
      "Iteration 13290: loss = 2.3476\n",
      "Iteration 13300: loss = 2.1682\n",
      "Iteration 13310: loss = 2.6322\n",
      "Iteration 13320: loss = 2.6649\n",
      "Iteration 13330: loss = 2.3599\n",
      "Iteration 13340: loss = 2.8844\n",
      "Iteration 13350: loss = 2.4500\n",
      "Iteration 13360: loss = 2.6795\n",
      "Iteration 13370: loss = 2.6173\n",
      "Iteration 13380: loss = 2.2422\n",
      "Iteration 13390: loss = 2.9457\n",
      "Iteration 13400: loss = 2.7458\n",
      "Iteration 13410: loss = 2.8323\n",
      "Iteration 13420: loss = 2.4650\n",
      "Iteration 13430: loss = 2.8202\n",
      "Iteration 13440: loss = 2.3747\n",
      "Iteration 13450: loss = 2.4982\n",
      "Iteration 13460: loss = 2.8103\n",
      "Iteration 13470: loss = 2.5296\n",
      "Iteration 13480: loss = 2.4461\n",
      "Iteration 13490: loss = 2.6222\n",
      "Iteration 13500: loss = 2.7157\n",
      "Iteration 13510: loss = 2.5228\n",
      "Iteration 13520: loss = 2.5680\n",
      "Iteration 13530: loss = 2.7153\n",
      "Iteration 13540: loss = 2.4910\n",
      "Iteration 13550: loss = 2.9300\n",
      "Iteration 13560: loss = 2.6020\n",
      "Iteration 13570: loss = 2.4550\n",
      "Iteration 13580: loss = 2.4848\n",
      "Iteration 13590: loss = 2.7054\n",
      "Iteration 13600: loss = 2.7066\n",
      "Iteration 13610: loss = 3.0226\n",
      "Iteration 13620: loss = 2.5437\n",
      "Iteration 13630: loss = 2.5970\n",
      "Iteration 13640: loss = 2.8904\n",
      "Iteration 13650: loss = 2.7107\n",
      "Iteration 13660: loss = 2.5359\n",
      "Iteration 13670: loss = 2.9859\n",
      "Iteration 13680: loss = 2.1809\n",
      "Iteration 13690: loss = 2.4909\n",
      "Iteration 13700: loss = 2.7967\n",
      "Iteration 13710: loss = 2.9286\n",
      "Iteration 13720: loss = 2.7416\n",
      "Iteration 13730: loss = 2.5446\n",
      "Iteration 13740: loss = 2.2160\n",
      "Iteration 13750: loss = 2.6980\n",
      "Iteration 13760: loss = 2.4770\n",
      "Iteration 13770: loss = 2.4401\n",
      "Iteration 13780: loss = 2.4552\n",
      "Iteration 13790: loss = 2.1603\n",
      "Iteration 13800: loss = 2.5953\n",
      "Iteration 13810: loss = 2.5973\n",
      "Iteration 13820: loss = 3.0075\n",
      "Iteration 13830: loss = 2.7177\n",
      "Iteration 13840: loss = 2.8035\n",
      "Iteration 13850: loss = 2.6702\n",
      "Iteration 13860: loss = 2.5227\n",
      "Iteration 13870: loss = 2.4652\n",
      "Iteration 13880: loss = 2.4663\n",
      "Iteration 13890: loss = 2.4757\n",
      "Iteration 13900: loss = 2.9130\n",
      "Iteration 13910: loss = 2.8130\n",
      "Iteration 13920: loss = 3.0081\n",
      "Iteration 13930: loss = 2.7681\n",
      "Iteration 13940: loss = 2.3988\n",
      "Iteration 13950: loss = 2.3905\n",
      "Iteration 13960: loss = 2.3913\n",
      "Iteration 13970: loss = 2.5117\n",
      "Iteration 13980: loss = 2.8779\n",
      "Iteration 13990: loss = 2.6222\n",
      "Iteration 14000: loss = 2.4634\n",
      "Iteration 14010: loss = 2.6465\n",
      "Iteration 14020: loss = 2.3778\n",
      "Iteration 14030: loss = 3.0071\n",
      "Iteration 14040: loss = 2.7634\n",
      "Iteration 14050: loss = 2.8503\n",
      "Iteration 14060: loss = 2.7447\n",
      "Iteration 14070: loss = 2.4413\n",
      "Iteration 14080: loss = 2.5227\n",
      "Iteration 14090: loss = 2.6937\n",
      "Iteration 14100: loss = 2.4865\n",
      "Iteration 14110: loss = 2.4768\n",
      "Iteration 14120: loss = 2.5899\n",
      "Iteration 14130: loss = 2.2604\n",
      "Iteration 14140: loss = 2.9200\n",
      "Iteration 14150: loss = 2.5613\n",
      "Iteration 14160: loss = 2.4990\n",
      "Iteration 14170: loss = 2.7019\n",
      "Iteration 14180: loss = 2.8408\n",
      "Iteration 14190: loss = 2.5161\n",
      "Iteration 14200: loss = 2.9296\n",
      "Iteration 14210: loss = 2.6664\n",
      "Iteration 14220: loss = 2.5993\n",
      "Iteration 14230: loss = 2.4161\n",
      "Iteration 14240: loss = 2.5247\n",
      "Iteration 14250: loss = 2.6801\n",
      "Iteration 14260: loss = 2.7422\n",
      "Iteration 14270: loss = 2.6412\n",
      "Iteration 14280: loss = 2.4950\n",
      "Iteration 14290: loss = 2.6146\n",
      "Iteration 14300: loss = 2.5094\n",
      "Iteration 14310: loss = 2.4622\n",
      "Iteration 14320: loss = 2.5333\n",
      "Iteration 14330: loss = 2.6644\n",
      "Iteration 14340: loss = 2.6002\n",
      "Iteration 14350: loss = 2.7507\n",
      "Iteration 14360: loss = 2.4669\n",
      "Iteration 14370: loss = 2.7974\n",
      "Iteration 14380: loss = 2.2204\n",
      "Iteration 14390: loss = 2.5043\n",
      "Iteration 14400: loss = 2.7117\n",
      "Iteration 14410: loss = 2.1877\n",
      "Iteration 14420: loss = 2.3415\n",
      "Iteration 14430: loss = 2.4305\n",
      "Iteration 14440: loss = 2.5405\n",
      "Iteration 14450: loss = 2.6700\n",
      "Iteration 14460: loss = 2.5025\n",
      "Iteration 14470: loss = 2.1989\n",
      "Iteration 14480: loss = 2.5664\n",
      "Iteration 14490: loss = 2.4075\n",
      "Iteration 14500: loss = 2.4262\n",
      "Iteration 14510: loss = 2.8155\n",
      "Iteration 14520: loss = 2.7755\n",
      "Iteration 14530: loss = 2.3965\n",
      "Iteration 14540: loss = 2.6407\n",
      "Iteration 14550: loss = 2.9186\n",
      "Iteration 14560: loss = 2.2270\n",
      "Iteration 14570: loss = 2.7478\n",
      "Iteration 14580: loss = 2.4006\n",
      "Iteration 14590: loss = 2.7737\n",
      "Iteration 14600: loss = 2.8121\n",
      "Iteration 14610: loss = 2.3835\n",
      "Iteration 14620: loss = 2.5625\n",
      "Iteration 14630: loss = 2.5659\n",
      "Iteration 14640: loss = 2.2467\n",
      "Iteration 14650: loss = 2.9929\n",
      "Iteration 14660: loss = 2.5740\n",
      "Iteration 14670: loss = 2.9589\n",
      "Iteration 14680: loss = 2.9677\n",
      "Iteration 14690: loss = 2.4894\n",
      "Iteration 14700: loss = 2.4495\n",
      "Iteration 14710: loss = 2.3993\n",
      "Iteration 14720: loss = 2.7441\n",
      "Iteration 14730: loss = 2.5271\n",
      "Iteration 14740: loss = 2.4750\n",
      "Iteration 14750: loss = 2.5561\n",
      "Iteration 14760: loss = 2.3802\n",
      "Iteration 14770: loss = 3.0690\n",
      "Iteration 14780: loss = 2.3803\n",
      "Iteration 14790: loss = 2.5395\n",
      "Iteration 14800: loss = 2.3298\n",
      "Iteration 14810: loss = 2.9416\n",
      "Iteration 14820: loss = 2.4756\n",
      "Iteration 14830: loss = 2.5546\n",
      "Iteration 14840: loss = 2.8911\n",
      "Iteration 14850: loss = 2.3652\n",
      "Iteration 14860: loss = 2.4494\n",
      "Iteration 14870: loss = 2.6347\n",
      "Iteration 14880: loss = 2.5841\n",
      "Iteration 14890: loss = 2.8491\n",
      "Iteration 14900: loss = 2.5503\n",
      "Iteration 14910: loss = 2.5315\n",
      "Iteration 14920: loss = 2.3707\n",
      "Iteration 14930: loss = 2.6459\n",
      "Iteration 14940: loss = 2.8109\n",
      "Iteration 14950: loss = 2.8377\n",
      "Iteration 14960: loss = 2.8507\n",
      "Iteration 14970: loss = 2.7218\n",
      "Iteration 14980: loss = 2.6822\n",
      "Iteration 14990: loss = 2.6238\n",
      "Iteration 15000: loss = 2.3856\n",
      "Iteration 15010: loss = 2.7926\n",
      "Iteration 15020: loss = 2.4647\n",
      "Iteration 15030: loss = 2.4885\n",
      "Iteration 15040: loss = 2.3764\n",
      "Iteration 15050: loss = 2.5174\n",
      "Iteration 15060: loss = 2.4520\n",
      "Iteration 15070: loss = 2.6128\n",
      "Iteration 15080: loss = 2.4347\n",
      "Iteration 15090: loss = 2.6949\n",
      "Iteration 15100: loss = 2.2574\n",
      "Iteration 15110: loss = 2.8878\n",
      "Iteration 15120: loss = 2.6979\n",
      "Iteration 15130: loss = 2.4484\n",
      "Iteration 15140: loss = 2.9013\n",
      "Iteration 15150: loss = 2.9084\n",
      "Iteration 15160: loss = 2.5770\n",
      "Iteration 15170: loss = 2.5060\n",
      "Iteration 15180: loss = 2.6746\n",
      "Iteration 15190: loss = 2.5535\n",
      "Iteration 15200: loss = 2.5820\n",
      "Iteration 15210: loss = 2.5570\n",
      "Iteration 15220: loss = 2.2921\n",
      "Iteration 15230: loss = 2.7536\n",
      "Iteration 15240: loss = 2.3338\n",
      "Iteration 15250: loss = 2.6565\n",
      "Iteration 15260: loss = 2.6253\n",
      "Iteration 15270: loss = 2.9473\n",
      "Iteration 15280: loss = 2.6879\n",
      "Iteration 15290: loss = 2.5989\n",
      "Iteration 15300: loss = 2.4206\n",
      "Iteration 15310: loss = 2.4276\n",
      "Iteration 15320: loss = 2.4442\n",
      "Iteration 15330: loss = 2.6020\n",
      "Iteration 15340: loss = 2.9136\n",
      "Iteration 15350: loss = 2.2230\n",
      "Iteration 15360: loss = 2.7864\n",
      "Iteration 15370: loss = 2.3697\n",
      "Iteration 15380: loss = 2.6598\n",
      "Iteration 15390: loss = 2.6124\n",
      "Iteration 15400: loss = 2.2473\n",
      "Iteration 15410: loss = 2.4572\n",
      "Iteration 15420: loss = 2.4944\n",
      "Iteration 15430: loss = 2.7163\n",
      "Iteration 15440: loss = 2.6291\n",
      "Iteration 15450: loss = 2.6650\n",
      "Iteration 15460: loss = 2.4208\n",
      "Iteration 15470: loss = 2.3585\n",
      "Iteration 15480: loss = 2.8137\n",
      "Iteration 15490: loss = 2.4542\n",
      "Iteration 15500: loss = 2.9442\n",
      "Iteration 15510: loss = 2.6340\n",
      "Iteration 15520: loss = 2.5701\n",
      "Iteration 15530: loss = 2.4878\n",
      "Iteration 15540: loss = 2.2582\n",
      "Iteration 15550: loss = 2.2391\n",
      "Iteration 15560: loss = 2.3811\n",
      "Iteration 15570: loss = 3.0329\n",
      "Iteration 15580: loss = 2.2834\n",
      "Iteration 15590: loss = 2.9292\n",
      "Iteration 15600: loss = 2.8123\n",
      "Iteration 15610: loss = 2.5336\n",
      "Iteration 15620: loss = 2.1782\n",
      "Iteration 15630: loss = 2.2849\n",
      "Iteration 15640: loss = 2.5680\n",
      "Iteration 15650: loss = 2.3180\n",
      "Iteration 15660: loss = 2.3623\n",
      "Iteration 15670: loss = 2.4390\n",
      "Iteration 15680: loss = 2.4119\n",
      "Iteration 15690: loss = 2.5057\n",
      "Iteration 15700: loss = 2.8043\n",
      "Iteration 15710: loss = 2.2938\n",
      "Iteration 15720: loss = 2.4148\n",
      "Iteration 15730: loss = 2.4483\n",
      "Iteration 15740: loss = 2.8355\n",
      "Iteration 15750: loss = 2.5521\n",
      "Iteration 15760: loss = 2.6118\n",
      "Iteration 15770: loss = 2.9579\n",
      "Iteration 15780: loss = 2.7532\n",
      "Iteration 15790: loss = 2.7711\n",
      "Iteration 15800: loss = 2.2219\n",
      "Iteration 15810: loss = 2.8080\n",
      "Iteration 15820: loss = 2.2855\n",
      "Iteration 15830: loss = 2.5151\n",
      "Iteration 15840: loss = 2.5762\n",
      "Iteration 15850: loss = 2.6587\n",
      "Iteration 15860: loss = 2.3173\n",
      "Iteration 15870: loss = 2.5804\n",
      "Iteration 15880: loss = 2.7186\n",
      "Iteration 15890: loss = 2.3874\n",
      "Iteration 15900: loss = 2.3234\n",
      "Iteration 15910: loss = 2.3661\n",
      "Iteration 15920: loss = 3.0659\n",
      "Iteration 15930: loss = 2.3223\n",
      "Iteration 15940: loss = 2.9326\n",
      "Iteration 15950: loss = 3.0840\n",
      "Iteration 15960: loss = 3.0329\n",
      "Iteration 15970: loss = 2.7729\n",
      "Iteration 15980: loss = 3.0879\n",
      "Iteration 15990: loss = 2.8195\n",
      "Iteration 16000: loss = 2.8524\n",
      "Iteration 16010: loss = 2.7741\n",
      "Iteration 16020: loss = 2.6076\n",
      "Iteration 16030: loss = 2.3673\n",
      "Iteration 16040: loss = 2.4292\n",
      "Iteration 16050: loss = 2.4661\n",
      "Iteration 16060: loss = 2.6754\n",
      "Iteration 16070: loss = 2.4603\n",
      "Iteration 16080: loss = 2.2700\n",
      "Iteration 16090: loss = 2.7846\n",
      "Iteration 16100: loss = 2.5119\n",
      "Iteration 16110: loss = 2.4088\n",
      "Iteration 16120: loss = 2.3882\n",
      "Iteration 16130: loss = 2.3977\n",
      "Iteration 16140: loss = 2.8273\n",
      "Iteration 16150: loss = 2.8518\n",
      "Iteration 16160: loss = 2.6216\n",
      "Iteration 16170: loss = 2.5322\n",
      "Iteration 16180: loss = 3.0419\n",
      "Iteration 16190: loss = 2.5308\n",
      "Iteration 16200: loss = 2.6740\n",
      "Iteration 16210: loss = 2.5140\n",
      "Iteration 16220: loss = 2.4825\n",
      "Iteration 16230: loss = 2.3773\n",
      "Iteration 16240: loss = 2.3692\n",
      "Iteration 16250: loss = 2.6875\n",
      "Iteration 16260: loss = 2.8086\n",
      "Iteration 16270: loss = 2.5196\n",
      "Iteration 16280: loss = 2.3516\n",
      "Iteration 16290: loss = 2.3468\n",
      "Iteration 16300: loss = 2.5752\n",
      "Iteration 16310: loss = 2.9048\n",
      "Iteration 16320: loss = 2.1835\n",
      "Iteration 16330: loss = 3.2380\n",
      "Iteration 16340: loss = 2.5741\n",
      "Iteration 16350: loss = 2.6136\n",
      "Iteration 16360: loss = 2.6028\n",
      "Iteration 16370: loss = 2.4015\n",
      "Iteration 16380: loss = 2.2440\n",
      "Iteration 16390: loss = 2.2301\n",
      "Iteration 16400: loss = 2.2408\n",
      "Iteration 16410: loss = 3.0104\n",
      "Iteration 16420: loss = 2.6815\n",
      "Iteration 16430: loss = 2.4759\n",
      "Iteration 16440: loss = 2.6653\n",
      "Iteration 16450: loss = 2.3328\n",
      "Iteration 16460: loss = 2.4716\n",
      "Iteration 16470: loss = 2.3631\n",
      "Iteration 16480: loss = 3.0072\n",
      "Iteration 16490: loss = 2.4588\n",
      "Iteration 16500: loss = 3.1038\n",
      "Iteration 16510: loss = 2.0763\n",
      "Iteration 16520: loss = 2.9873\n",
      "Iteration 16530: loss = 2.3897\n",
      "Iteration 16540: loss = 2.2448\n",
      "Iteration 16550: loss = 2.7276\n",
      "Iteration 16560: loss = 2.8379\n",
      "Iteration 16570: loss = 2.2657\n",
      "Iteration 16580: loss = 3.0115\n",
      "Iteration 16590: loss = 2.6355\n",
      "Iteration 16600: loss = 2.4123\n",
      "Iteration 16610: loss = 2.7427\n",
      "Iteration 16620: loss = 2.4015\n",
      "Iteration 16630: loss = 2.9336\n",
      "Iteration 16640: loss = 2.4420\n",
      "Iteration 16650: loss = 2.8754\n",
      "Iteration 16660: loss = 2.5097\n",
      "Iteration 16670: loss = 2.5304\n",
      "Iteration 16680: loss = 2.5278\n",
      "Iteration 16690: loss = 2.4640\n",
      "Iteration 16700: loss = 2.3575\n",
      "Iteration 16710: loss = 2.4484\n",
      "Iteration 16720: loss = 2.6180\n",
      "Iteration 16730: loss = 2.6380\n",
      "Iteration 16740: loss = 3.0568\n",
      "Iteration 16750: loss = 2.7493\n",
      "Iteration 16760: loss = 2.5081\n",
      "Iteration 16770: loss = 2.2789\n",
      "Iteration 16780: loss = 2.5206\n",
      "Iteration 16790: loss = 2.6794\n",
      "Iteration 16800: loss = 2.8963\n",
      "Iteration 16810: loss = 2.4767\n",
      "Iteration 16820: loss = 2.8477\n",
      "Iteration 16830: loss = 2.6126\n",
      "Iteration 16840: loss = 2.1777\n",
      "Iteration 16850: loss = 2.5038\n",
      "Iteration 16860: loss = 2.6441\n",
      "Iteration 16870: loss = 2.9537\n",
      "Iteration 16880: loss = 2.6230\n",
      "Iteration 16890: loss = 2.5080\n",
      "Iteration 16900: loss = 2.7368\n",
      "Iteration 16910: loss = 2.4562\n",
      "Iteration 16920: loss = 2.4769\n",
      "Iteration 16930: loss = 2.6658\n",
      "Iteration 16940: loss = 2.2057\n",
      "Iteration 16950: loss = 2.7557\n",
      "Iteration 16960: loss = 2.5572\n",
      "Iteration 16970: loss = 2.2491\n",
      "Iteration 16980: loss = 2.6121\n",
      "Iteration 16990: loss = 2.6954\n",
      "Iteration 17000: loss = 2.2726\n",
      "Iteration 17010: loss = 2.8711\n",
      "Iteration 17020: loss = 2.4184\n",
      "Iteration 17030: loss = 2.6517\n",
      "Iteration 17040: loss = 2.6438\n",
      "Iteration 17050: loss = 3.3895\n",
      "Iteration 17060: loss = 2.5690\n",
      "Iteration 17070: loss = 2.4450\n",
      "Iteration 17080: loss = 2.4162\n",
      "Iteration 17090: loss = 2.5940\n",
      "Iteration 17100: loss = 2.6425\n",
      "Iteration 17110: loss = 2.6165\n",
      "Iteration 17120: loss = 2.9578\n",
      "Iteration 17130: loss = 2.6104\n",
      "Iteration 17140: loss = 2.3612\n",
      "Iteration 17150: loss = 2.3834\n",
      "Iteration 17160: loss = 2.3535\n",
      "Iteration 17170: loss = 2.5666\n",
      "Iteration 17180: loss = 2.7232\n",
      "Iteration 17190: loss = 2.3346\n",
      "Iteration 17200: loss = 2.3005\n",
      "Iteration 17210: loss = 2.4048\n",
      "Iteration 17220: loss = 2.7308\n",
      "Iteration 17230: loss = 2.9567\n",
      "Iteration 17240: loss = 2.3505\n",
      "Iteration 17250: loss = 2.3277\n",
      "Iteration 17260: loss = 2.6885\n",
      "Iteration 17270: loss = 2.5334\n",
      "Iteration 17280: loss = 3.4305\n",
      "Iteration 17290: loss = 2.9498\n",
      "Iteration 17300: loss = 2.5058\n",
      "Iteration 17310: loss = 2.4693\n",
      "Iteration 17320: loss = 2.6178\n",
      "Iteration 17330: loss = 2.4375\n",
      "Iteration 17340: loss = 2.5118\n",
      "Iteration 17350: loss = 2.5595\n",
      "Iteration 17360: loss = 2.9596\n",
      "Iteration 17370: loss = 2.3921\n",
      "Iteration 17380: loss = 2.4544\n",
      "Iteration 17390: loss = 2.5119\n",
      "Iteration 17400: loss = 2.5624\n",
      "Iteration 17410: loss = 2.9047\n",
      "Iteration 17420: loss = 2.6932\n",
      "Iteration 17430: loss = 2.5781\n",
      "Iteration 17440: loss = 2.5967\n",
      "Iteration 17450: loss = 2.3515\n",
      "Iteration 17460: loss = 2.5372\n",
      "Iteration 17470: loss = 2.7040\n",
      "Iteration 17480: loss = 2.6816\n",
      "Iteration 17490: loss = 2.8882\n",
      "Iteration 17500: loss = 2.4149\n",
      "Iteration 17510: loss = 2.5161\n",
      "Iteration 17520: loss = 2.6208\n",
      "Iteration 17530: loss = 2.7680\n",
      "Iteration 17540: loss = 2.7072\n",
      "Iteration 17550: loss = 2.7556\n",
      "Iteration 17560: loss = 2.5122\n",
      "Iteration 17570: loss = 2.4707\n",
      "Iteration 17580: loss = 2.5312\n",
      "Iteration 17590: loss = 2.6242\n",
      "Iteration 17600: loss = 2.3403\n",
      "Iteration 17610: loss = 2.6055\n",
      "Iteration 17620: loss = 2.6241\n",
      "Iteration 17630: loss = 2.5050\n",
      "Iteration 17640: loss = 2.8007\n",
      "Iteration 17650: loss = 2.9537\n",
      "Iteration 17660: loss = 2.5149\n",
      "Iteration 17670: loss = 2.2543\n",
      "Iteration 17680: loss = 2.6309\n",
      "Iteration 17690: loss = 2.8092\n",
      "Iteration 17700: loss = 2.7771\n",
      "Iteration 17710: loss = 2.4420\n",
      "Iteration 17720: loss = 3.0045\n",
      "Iteration 17730: loss = 2.2942\n",
      "Iteration 17740: loss = 2.7902\n",
      "Iteration 17750: loss = 2.6626\n",
      "Iteration 17760: loss = 2.5479\n",
      "Iteration 17770: loss = 2.6497\n",
      "Iteration 17780: loss = 2.8691\n",
      "Iteration 17790: loss = 2.8725\n",
      "Iteration 17800: loss = 2.5840\n",
      "Iteration 17810: loss = 2.5248\n",
      "Iteration 17820: loss = 2.4728\n",
      "Iteration 17830: loss = 2.2043\n",
      "Iteration 17840: loss = 2.4116\n",
      "Iteration 17850: loss = 2.5303\n",
      "Iteration 17860: loss = 2.5140\n",
      "Iteration 17870: loss = 2.5700\n",
      "Iteration 17880: loss = 2.7905\n",
      "Iteration 17890: loss = 3.0607\n",
      "Iteration 17900: loss = 2.6827\n",
      "Iteration 17910: loss = 2.7411\n",
      "Iteration 17920: loss = 3.0260\n",
      "Iteration 17930: loss = 2.6483\n",
      "Iteration 17940: loss = 2.3535\n",
      "Iteration 17950: loss = 2.3025\n",
      "Iteration 17960: loss = 2.5750\n",
      "Iteration 17970: loss = 3.0273\n",
      "Iteration 17980: loss = 2.5980\n",
      "Iteration 17990: loss = 2.7901\n",
      "Iteration 18000: loss = 2.5018\n",
      "Iteration 18010: loss = 2.4506\n",
      "Iteration 18020: loss = 2.5145\n",
      "Iteration 18030: loss = 2.6199\n",
      "Iteration 18040: loss = 2.8304\n",
      "Iteration 18050: loss = 2.4535\n",
      "Iteration 18060: loss = 2.7840\n",
      "Iteration 18070: loss = 2.7473\n",
      "Iteration 18080: loss = 2.5333\n",
      "Iteration 18090: loss = 2.8174\n",
      "Iteration 18100: loss = 2.8009\n",
      "Iteration 18110: loss = 3.1135\n",
      "Iteration 18120: loss = 2.6409\n",
      "Iteration 18130: loss = 2.4325\n",
      "Iteration 18140: loss = 1.9245\n",
      "Iteration 18150: loss = 2.4276\n",
      "Iteration 18160: loss = 2.5113\n",
      "Iteration 18170: loss = 2.9435\n",
      "Iteration 18180: loss = 2.6603\n",
      "Iteration 18190: loss = 2.2498\n",
      "Iteration 18200: loss = 2.7872\n",
      "Iteration 18210: loss = 2.3954\n",
      "Iteration 18220: loss = 2.3812\n",
      "Iteration 18230: loss = 2.8134\n",
      "Iteration 18240: loss = 2.4981\n",
      "Iteration 18250: loss = 2.7684\n",
      "Iteration 18260: loss = 2.9630\n",
      "Iteration 18270: loss = 2.4195\n",
      "Iteration 18280: loss = 2.2889\n",
      "Iteration 18290: loss = 3.0638\n",
      "Iteration 18300: loss = 2.9273\n",
      "Iteration 18310: loss = 2.4982\n",
      "Iteration 18320: loss = 2.4516\n",
      "Iteration 18330: loss = 2.6657\n",
      "Iteration 18340: loss = 2.5853\n",
      "Iteration 18350: loss = 2.8272\n",
      "Iteration 18360: loss = 2.2870\n",
      "Iteration 18370: loss = 2.5517\n",
      "Iteration 18380: loss = 2.3144\n",
      "Iteration 18390: loss = 2.6764\n",
      "Iteration 18400: loss = 2.4606\n",
      "Iteration 18410: loss = 2.5098\n",
      "Iteration 18420: loss = 2.5635\n",
      "Iteration 18430: loss = 2.5125\n",
      "Iteration 18440: loss = 2.7212\n",
      "Iteration 18450: loss = 2.5950\n",
      "Iteration 18460: loss = 2.5888\n",
      "Iteration 18470: loss = 2.6434\n",
      "Iteration 18480: loss = 2.4115\n",
      "Iteration 18490: loss = 2.5249\n",
      "Iteration 18500: loss = 2.6865\n",
      "Iteration 18510: loss = 2.5597\n",
      "Iteration 18520: loss = 2.6264\n",
      "Iteration 18530: loss = 2.1759\n",
      "Iteration 18540: loss = 2.2405\n",
      "Iteration 18550: loss = 2.6980\n",
      "Iteration 18560: loss = 2.5692\n",
      "Iteration 18570: loss = 2.4153\n",
      "Iteration 18580: loss = 2.5037\n",
      "Iteration 18590: loss = 2.4394\n",
      "Iteration 18600: loss = 2.4800\n",
      "Iteration 18610: loss = 2.5471\n",
      "Iteration 18620: loss = 2.6646\n",
      "Iteration 18630: loss = 2.3535\n",
      "Iteration 18640: loss = 2.7328\n",
      "Iteration 18650: loss = 2.4355\n",
      "Iteration 18660: loss = 2.6990\n",
      "Iteration 18670: loss = 2.3826\n",
      "Iteration 18680: loss = 2.6862\n",
      "Iteration 18690: loss = 2.2438\n",
      "Iteration 18700: loss = 2.9312\n",
      "Iteration 18710: loss = 3.0533\n",
      "Iteration 18720: loss = 3.1599\n",
      "Iteration 18730: loss = 2.5368\n",
      "Iteration 18740: loss = 2.5627\n",
      "Iteration 18750: loss = 2.5948\n",
      "Iteration 18760: loss = 2.8984\n",
      "Iteration 18770: loss = 2.8373\n",
      "Iteration 18780: loss = 2.6734\n",
      "Iteration 18790: loss = 2.4840\n",
      "Iteration 18800: loss = 2.8892\n",
      "Iteration 18810: loss = 2.7691\n",
      "Iteration 18820: loss = 2.9868\n",
      "Iteration 18830: loss = 2.5869\n",
      "Iteration 18840: loss = 2.7070\n",
      "Iteration 18850: loss = 2.4913\n",
      "Iteration 18860: loss = 2.6359\n",
      "Iteration 18870: loss = 2.4495\n",
      "Iteration 18880: loss = 2.9301\n",
      "Iteration 18890: loss = 2.5422\n",
      "Iteration 18900: loss = 2.3738\n",
      "Iteration 18910: loss = 2.6157\n",
      "Iteration 18920: loss = 2.6704\n",
      "Iteration 18930: loss = 2.6258\n",
      "Iteration 18940: loss = 2.6291\n",
      "Iteration 18950: loss = 3.1418\n",
      "Iteration 18960: loss = 2.7360\n",
      "Iteration 18970: loss = 2.4881\n",
      "Iteration 18980: loss = 2.2900\n",
      "Iteration 18990: loss = 2.7492\n",
      "Iteration 19000: loss = 2.5081\n",
      "Iteration 19010: loss = 2.5505\n",
      "Iteration 19020: loss = 2.7413\n",
      "Iteration 19030: loss = 2.3481\n",
      "Iteration 19040: loss = 2.5265\n",
      "Iteration 19050: loss = 2.4255\n",
      "Iteration 19060: loss = 2.7637\n",
      "Iteration 19070: loss = 2.5319\n",
      "Iteration 19080: loss = 2.3221\n",
      "Iteration 19090: loss = 2.7219\n",
      "Iteration 19100: loss = 2.7626\n",
      "Iteration 19110: loss = 2.6546\n",
      "Iteration 19120: loss = 2.9245\n",
      "Iteration 19130: loss = 2.6166\n",
      "Iteration 19140: loss = 2.6840\n",
      "Iteration 19150: loss = 2.4984\n",
      "Iteration 19160: loss = 2.6012\n",
      "Iteration 19170: loss = 2.6762\n",
      "Iteration 19180: loss = 2.5227\n",
      "Iteration 19190: loss = 2.8185\n",
      "Iteration 19200: loss = 2.7398\n",
      "Iteration 19210: loss = 2.4076\n",
      "Iteration 19220: loss = 2.3687\n",
      "Iteration 19230: loss = 2.3201\n",
      "Iteration 19240: loss = 2.5222\n",
      "Iteration 19250: loss = 2.5623\n",
      "Iteration 19260: loss = 2.2375\n",
      "Iteration 19270: loss = 2.3685\n",
      "Iteration 19280: loss = 2.2958\n",
      "Iteration 19290: loss = 2.6015\n",
      "Iteration 19300: loss = 2.6434\n",
      "Iteration 19310: loss = 2.8877\n",
      "Iteration 19320: loss = 3.1041\n",
      "Iteration 19330: loss = 2.5473\n",
      "Iteration 19340: loss = 2.4031\n",
      "Iteration 19350: loss = 2.5469\n",
      "Iteration 19360: loss = 2.4214\n",
      "Iteration 19370: loss = 2.5076\n",
      "Iteration 19380: loss = 2.7335\n",
      "Iteration 19390: loss = 2.2908\n",
      "Iteration 19400: loss = 2.4623\n",
      "Iteration 19410: loss = 2.7991\n",
      "Iteration 19420: loss = 2.5478\n",
      "Iteration 19430: loss = 2.8976\n",
      "Iteration 19440: loss = 2.4310\n",
      "Iteration 19450: loss = 2.6715\n",
      "Iteration 19460: loss = 2.4912\n",
      "Iteration 19470: loss = 2.8326\n",
      "Iteration 19480: loss = 2.2538\n",
      "Iteration 19490: loss = 2.3833\n",
      "Iteration 19500: loss = 2.3092\n",
      "Iteration 19510: loss = 2.6244\n",
      "Iteration 19520: loss = 2.8183\n",
      "Iteration 19530: loss = 2.5699\n",
      "Iteration 19540: loss = 2.3279\n",
      "Iteration 19550: loss = 3.0574\n",
      "Iteration 19560: loss = 2.2494\n",
      "Iteration 19570: loss = 2.7408\n",
      "Iteration 19580: loss = 2.5231\n",
      "Iteration 19590: loss = 2.3420\n",
      "Iteration 19600: loss = 2.4991\n",
      "Iteration 19610: loss = 2.6502\n",
      "Iteration 19620: loss = 2.8507\n",
      "Iteration 19630: loss = 2.4920\n",
      "Iteration 19640: loss = 2.2747\n",
      "Iteration 19650: loss = 2.5065\n",
      "Iteration 19660: loss = 2.5271\n",
      "Iteration 19670: loss = 2.4132\n",
      "Iteration 19680: loss = 2.5572\n",
      "Iteration 19690: loss = 2.8748\n",
      "Iteration 19700: loss = 2.6248\n",
      "Iteration 19710: loss = 2.4816\n",
      "Iteration 19720: loss = 2.4925\n",
      "Iteration 19730: loss = 2.5706\n",
      "Iteration 19740: loss = 2.7759\n",
      "Iteration 19750: loss = 2.7270\n",
      "Iteration 19760: loss = 2.6300\n",
      "Iteration 19770: loss = 2.4522\n",
      "Iteration 19780: loss = 2.5134\n",
      "Iteration 19790: loss = 2.4775\n",
      "Iteration 19800: loss = 2.7031\n",
      "Iteration 19810: loss = 2.7517\n",
      "Iteration 19820: loss = 2.5177\n",
      "Iteration 19830: loss = 2.6187\n",
      "Iteration 19840: loss = 2.7139\n",
      "Iteration 19850: loss = 2.5226\n",
      "Iteration 19860: loss = 2.6039\n",
      "Iteration 19870: loss = 2.8191\n",
      "Iteration 19880: loss = 2.6585\n",
      "Iteration 19890: loss = 2.5909\n",
      "Iteration 19900: loss = 2.5731\n",
      "Iteration 19910: loss = 2.5701\n",
      "Iteration 19920: loss = 2.5152\n",
      "Iteration 19930: loss = 2.5557\n",
      "Iteration 19940: loss = 2.3620\n",
      "Iteration 19950: loss = 2.7115\n",
      "Iteration 19960: loss = 2.4049\n",
      "Iteration 19970: loss = 2.8723\n",
      "Iteration 19980: loss = 2.5797\n",
      "Iteration 19990: loss = 2.7205\n",
      "Iteration 20000: loss = 2.6709\n",
      "Iteration 20010: loss = 2.5028\n",
      "Iteration 20020: loss = 2.8300\n",
      "Iteration 20030: loss = 2.5402\n",
      "Iteration 20040: loss = 2.4662\n",
      "Iteration 20050: loss = 2.6481\n",
      "Iteration 20060: loss = 2.9411\n",
      "Iteration 20070: loss = 2.5579\n",
      "Iteration 20080: loss = 2.4179\n",
      "Iteration 20090: loss = 2.3045\n",
      "Iteration 20100: loss = 2.6454\n",
      "Iteration 20110: loss = 2.6064\n",
      "Iteration 20120: loss = 2.4738\n",
      "Iteration 20130: loss = 2.5246\n",
      "Iteration 20140: loss = 2.4348\n",
      "Iteration 20150: loss = 2.4444\n",
      "Iteration 20160: loss = 2.7061\n",
      "Iteration 20170: loss = 2.6127\n",
      "Iteration 20180: loss = 2.5597\n",
      "Iteration 20190: loss = 2.5480\n",
      "Iteration 20200: loss = 2.3541\n",
      "Iteration 20210: loss = 2.4596\n",
      "Iteration 20220: loss = 2.3747\n",
      "Iteration 20230: loss = 2.5886\n",
      "Iteration 20240: loss = 2.5943\n",
      "Iteration 20250: loss = 2.8243\n",
      "Iteration 20260: loss = 2.4597\n",
      "Iteration 20270: loss = 2.6882\n",
      "Iteration 20280: loss = 2.1118\n",
      "Iteration 20290: loss = 2.6093\n",
      "Iteration 20300: loss = 2.3335\n",
      "Iteration 20310: loss = 2.2299\n",
      "Iteration 20320: loss = 2.3809\n",
      "Iteration 20330: loss = 2.8708\n",
      "Iteration 20340: loss = 2.3907\n",
      "Iteration 20350: loss = 2.3496\n",
      "Iteration 20360: loss = 2.5650\n",
      "Iteration 20370: loss = 2.4305\n",
      "Iteration 20380: loss = 2.3003\n",
      "Iteration 20390: loss = 2.7102\n",
      "Iteration 20400: loss = 2.6918\n",
      "Iteration 20410: loss = 2.7227\n",
      "Iteration 20420: loss = 2.5861\n",
      "Iteration 20430: loss = 2.6884\n",
      "Iteration 20440: loss = 2.6237\n",
      "Iteration 20450: loss = 2.4845\n",
      "Iteration 20460: loss = 2.9764\n",
      "Iteration 20470: loss = 3.0397\n",
      "Iteration 20480: loss = 2.3865\n",
      "Iteration 20490: loss = 2.7607\n",
      "Iteration 20500: loss = 2.3093\n",
      "Iteration 20510: loss = 2.5220\n",
      "Iteration 20520: loss = 2.5044\n",
      "Iteration 20530: loss = 2.7725\n",
      "Iteration 20540: loss = 2.7122\n",
      "Iteration 20550: loss = 2.6342\n",
      "Iteration 20560: loss = 3.0516\n",
      "Iteration 20570: loss = 2.7172\n",
      "Iteration 20580: loss = 2.4812\n",
      "Iteration 20590: loss = 2.3446\n",
      "Iteration 20600: loss = 2.5490\n",
      "Iteration 20610: loss = 2.3142\n",
      "Iteration 20620: loss = 2.6509\n",
      "Iteration 20630: loss = 2.6547\n",
      "Iteration 20640: loss = 2.7341\n",
      "Iteration 20650: loss = 2.6867\n",
      "Iteration 20660: loss = 2.3647\n",
      "Iteration 20670: loss = 2.9079\n",
      "Iteration 20680: loss = 2.4907\n",
      "Iteration 20690: loss = 2.6743\n",
      "Iteration 20700: loss = 2.6651\n",
      "Iteration 20710: loss = 2.6763\n",
      "Iteration 20720: loss = 2.5676\n",
      "Iteration 20730: loss = 2.6216\n",
      "Iteration 20740: loss = 2.4661\n",
      "Iteration 20750: loss = 2.3524\n",
      "Iteration 20760: loss = 2.5241\n",
      "Iteration 20770: loss = 3.0388\n",
      "Iteration 20780: loss = 2.5545\n",
      "Iteration 20790: loss = 2.3469\n",
      "Iteration 20800: loss = 2.3607\n",
      "Iteration 20810: loss = 2.4398\n",
      "Iteration 20820: loss = 2.1791\n",
      "Iteration 20830: loss = 2.9815\n",
      "Iteration 20840: loss = 2.5093\n",
      "Iteration 20850: loss = 2.7365\n",
      "Iteration 20860: loss = 2.2093\n",
      "Iteration 20870: loss = 2.3312\n",
      "Iteration 20880: loss = 2.5948\n",
      "Iteration 20890: loss = 2.1973\n",
      "Iteration 20900: loss = 2.6261\n",
      "Iteration 20910: loss = 2.2450\n",
      "Iteration 20920: loss = 2.5991\n",
      "Iteration 20930: loss = 2.6359\n",
      "Iteration 20940: loss = 2.4514\n",
      "Iteration 20950: loss = 2.5630\n",
      "Iteration 20960: loss = 2.4465\n",
      "Iteration 20970: loss = 2.7770\n",
      "Iteration 20980: loss = 2.2112\n",
      "Iteration 20990: loss = 2.2370\n",
      "Iteration 21000: loss = 2.4419\n",
      "Iteration 21010: loss = 3.0522\n",
      "Iteration 21020: loss = 2.5685\n",
      "Iteration 21030: loss = 2.3717\n",
      "Iteration 21040: loss = 2.4949\n",
      "Iteration 21050: loss = 2.7448\n",
      "Iteration 21060: loss = 2.2192\n",
      "Iteration 21070: loss = 2.2642\n",
      "Iteration 21080: loss = 2.3912\n",
      "Iteration 21090: loss = 2.5187\n",
      "Iteration 21100: loss = 2.4175\n",
      "Iteration 21110: loss = 2.6067\n",
      "Iteration 21120: loss = 2.5376\n",
      "Iteration 21130: loss = 2.2842\n",
      "Iteration 21140: loss = 2.5416\n",
      "Iteration 21150: loss = 2.5284\n",
      "Iteration 21160: loss = 2.0559\n",
      "Iteration 21170: loss = 2.3508\n",
      "Iteration 21180: loss = 2.5744\n",
      "Iteration 21190: loss = 2.2553\n",
      "Iteration 21200: loss = 2.5538\n",
      "Iteration 21210: loss = 3.0685\n",
      "Iteration 21220: loss = 2.5459\n",
      "Iteration 21230: loss = 2.3003\n",
      "Iteration 21240: loss = 2.5493\n",
      "Iteration 21250: loss = 2.5626\n",
      "Iteration 21260: loss = 2.9890\n",
      "Iteration 21270: loss = 2.4176\n",
      "Iteration 21280: loss = 2.8700\n",
      "Iteration 21290: loss = 2.8430\n",
      "Iteration 21300: loss = 3.2729\n",
      "Iteration 21310: loss = 2.6727\n",
      "Iteration 21320: loss = 2.7724\n",
      "Iteration 21330: loss = 2.2754\n",
      "Iteration 21340: loss = 2.6196\n",
      "Iteration 21350: loss = 2.8090\n",
      "Iteration 21360: loss = 2.4095\n",
      "Iteration 21370: loss = 2.8588\n",
      "Iteration 21380: loss = 2.3808\n",
      "Iteration 21390: loss = 2.2563\n",
      "Iteration 21400: loss = 2.2697\n",
      "Iteration 21410: loss = 2.1295\n",
      "Iteration 21420: loss = 2.5822\n",
      "Iteration 21430: loss = 2.8426\n",
      "Iteration 21440: loss = 2.7225\n",
      "Iteration 21450: loss = 2.7761\n",
      "Iteration 21460: loss = 2.5545\n",
      "Iteration 21470: loss = 2.8625\n",
      "Iteration 21480: loss = 2.4696\n",
      "Iteration 21490: loss = 2.2474\n",
      "Iteration 21500: loss = 2.6673\n",
      "Iteration 21510: loss = 2.6435\n",
      "Iteration 21520: loss = 2.8524\n",
      "Iteration 21530: loss = 2.8099\n",
      "Iteration 21540: loss = 2.3306\n",
      "Iteration 21550: loss = 2.4392\n",
      "Iteration 21560: loss = 2.3059\n",
      "Iteration 21570: loss = 2.5175\n",
      "Iteration 21580: loss = 2.6133\n",
      "Iteration 21590: loss = 2.3121\n",
      "Iteration 21600: loss = 2.6294\n",
      "Iteration 21610: loss = 2.5604\n",
      "Iteration 21620: loss = 2.5116\n",
      "Iteration 21630: loss = 2.5044\n",
      "Iteration 21640: loss = 2.0364\n",
      "Iteration 21650: loss = 2.5049\n",
      "Iteration 21660: loss = 2.3837\n",
      "Iteration 21670: loss = 2.5311\n",
      "Iteration 21680: loss = 2.5042\n",
      "Iteration 21690: loss = 2.7499\n",
      "Iteration 21700: loss = 3.2289\n",
      "Iteration 21710: loss = 2.1793\n",
      "Iteration 21720: loss = 2.2546\n",
      "Iteration 21730: loss = 2.5888\n",
      "Iteration 21740: loss = 2.7242\n",
      "Iteration 21750: loss = 2.8494\n",
      "Iteration 21760: loss = 2.0662\n",
      "Iteration 21770: loss = 2.8950\n",
      "Iteration 21780: loss = 3.2310\n",
      "Iteration 21790: loss = 2.7181\n",
      "Iteration 21800: loss = 2.5586\n",
      "Iteration 21810: loss = 3.0240\n",
      "Iteration 21820: loss = 2.4088\n",
      "Iteration 21830: loss = 2.5557\n",
      "Iteration 21840: loss = 3.0307\n",
      "Iteration 21850: loss = 2.8325\n",
      "Iteration 21860: loss = 2.6365\n",
      "Iteration 21870: loss = 2.4636\n",
      "Iteration 21880: loss = 2.3684\n",
      "Iteration 21890: loss = 2.5388\n",
      "Iteration 21900: loss = 2.2900\n",
      "Iteration 21910: loss = 2.6215\n",
      "Iteration 21920: loss = 2.4489\n",
      "Iteration 21930: loss = 2.2231\n",
      "Iteration 21940: loss = 3.0072\n",
      "Iteration 21950: loss = 2.4365\n",
      "Iteration 21960: loss = 2.2839\n",
      "Iteration 21970: loss = 2.5278\n",
      "Iteration 21980: loss = 2.7333\n",
      "Iteration 21990: loss = 2.3312\n",
      "Iteration 22000: loss = 2.7218\n",
      "Iteration 22010: loss = 2.7176\n",
      "Iteration 22020: loss = 2.4472\n",
      "Iteration 22030: loss = 2.6275\n",
      "Iteration 22040: loss = 2.3202\n",
      "Iteration 22050: loss = 2.5915\n",
      "Iteration 22060: loss = 2.6747\n",
      "Iteration 22070: loss = 2.5969\n",
      "Iteration 22080: loss = 2.5805\n",
      "Iteration 22090: loss = 2.7358\n",
      "Iteration 22100: loss = 2.5024\n",
      "Iteration 22110: loss = 2.4995\n",
      "Iteration 22120: loss = 2.6804\n",
      "Iteration 22130: loss = 2.5078\n",
      "Iteration 22140: loss = 2.4321\n",
      "Iteration 22150: loss = 2.1858\n",
      "Iteration 22160: loss = 2.4137\n",
      "Iteration 22170: loss = 2.5497\n",
      "Iteration 22180: loss = 2.8658\n",
      "Iteration 22190: loss = 2.7798\n",
      "Iteration 22200: loss = 2.0920\n",
      "Iteration 22210: loss = 2.4970\n",
      "Iteration 22220: loss = 2.5260\n",
      "Iteration 22230: loss = 2.6013\n",
      "Iteration 22240: loss = 2.9036\n",
      "Iteration 22250: loss = 2.1534\n",
      "Iteration 22260: loss = 2.4335\n",
      "Iteration 22270: loss = 2.7714\n",
      "Iteration 22280: loss = 3.2445\n",
      "Iteration 22290: loss = 2.2943\n",
      "Iteration 22300: loss = 2.3978\n",
      "Iteration 22310: loss = 2.8440\n",
      "Iteration 22320: loss = 2.4643\n",
      "Iteration 22330: loss = 2.5936\n",
      "Iteration 22340: loss = 2.6692\n",
      "Iteration 22350: loss = 2.8330\n",
      "Iteration 22360: loss = 2.6506\n",
      "Iteration 22370: loss = 2.6187\n",
      "Iteration 22380: loss = 2.2331\n",
      "Iteration 22390: loss = 2.4422\n",
      "Iteration 22400: loss = 2.5088\n",
      "Iteration 22410: loss = 2.4859\n",
      "Iteration 22420: loss = 2.5822\n",
      "Iteration 22430: loss = 2.5499\n",
      "Iteration 22440: loss = 2.7855\n",
      "Iteration 22450: loss = 2.8422\n",
      "Iteration 22460: loss = 2.5949\n",
      "Iteration 22470: loss = 2.6758\n",
      "Iteration 22480: loss = 2.5932\n",
      "Iteration 22490: loss = 2.8589\n",
      "Iteration 22500: loss = 2.2089\n",
      "Iteration 22510: loss = 2.8622\n",
      "Iteration 22520: loss = 2.3516\n",
      "Iteration 22530: loss = 2.7633\n",
      "Iteration 22540: loss = 2.5517\n",
      "Iteration 22550: loss = 2.4709\n",
      "Iteration 22560: loss = 2.0590\n",
      "Iteration 22570: loss = 2.6841\n",
      "Iteration 22580: loss = 2.6107\n",
      "Iteration 22590: loss = 2.1750\n",
      "Iteration 22600: loss = 2.5339\n",
      "Iteration 22610: loss = 2.6494\n",
      "Iteration 22620: loss = 2.5809\n",
      "Iteration 22630: loss = 2.5219\n",
      "Iteration 22640: loss = 2.8436\n",
      "Iteration 22650: loss = 3.0491\n",
      "Iteration 22660: loss = 2.4855\n",
      "Iteration 22670: loss = 2.5839\n",
      "Iteration 22680: loss = 2.2755\n",
      "Iteration 22690: loss = 2.5833\n",
      "Iteration 22700: loss = 2.2282\n",
      "Iteration 22710: loss = 2.7099\n",
      "Iteration 22720: loss = 2.6551\n",
      "Iteration 22730: loss = 2.4307\n",
      "Iteration 22740: loss = 2.2927\n",
      "Iteration 22750: loss = 2.6748\n",
      "Iteration 22760: loss = 2.5267\n",
      "Iteration 22770: loss = 2.9402\n",
      "Iteration 22780: loss = 2.8341\n",
      "Iteration 22790: loss = 3.0239\n",
      "Iteration 22800: loss = 2.7354\n",
      "Iteration 22810: loss = 2.7328\n",
      "Iteration 22820: loss = 2.7169\n",
      "Iteration 22830: loss = 3.1079\n",
      "Iteration 22840: loss = 2.3740\n",
      "Iteration 22850: loss = 2.2194\n",
      "Iteration 22860: loss = 2.5389\n",
      "Iteration 22870: loss = 2.6898\n",
      "Iteration 22880: loss = 2.5232\n",
      "Iteration 22890: loss = 2.3857\n",
      "Iteration 22900: loss = 2.5163\n",
      "Iteration 22910: loss = 2.5112\n",
      "Iteration 22920: loss = 2.3535\n",
      "Iteration 22930: loss = 2.5910\n",
      "Iteration 22940: loss = 2.5070\n",
      "Iteration 22950: loss = 2.3606\n",
      "Iteration 22960: loss = 2.4958\n",
      "Iteration 22970: loss = 2.6807\n",
      "Iteration 22980: loss = 2.3878\n",
      "Iteration 22990: loss = 2.5974\n",
      "Iteration 23000: loss = 2.2816\n",
      "Iteration 23010: loss = 2.7861\n",
      "Iteration 23020: loss = 2.1530\n",
      "Iteration 23030: loss = 2.4834\n",
      "Iteration 23040: loss = 2.1158\n",
      "Iteration 23050: loss = 2.6055\n",
      "Iteration 23060: loss = 2.1528\n",
      "Iteration 23070: loss = 2.3726\n",
      "Iteration 23080: loss = 2.3539\n",
      "Iteration 23090: loss = 2.6455\n",
      "Iteration 23100: loss = 3.0314\n",
      "Iteration 23110: loss = 2.8281\n",
      "Iteration 23120: loss = 2.4005\n",
      "Iteration 23130: loss = 2.5850\n",
      "Iteration 23140: loss = 2.3536\n",
      "Iteration 23150: loss = 3.0754\n",
      "Iteration 23160: loss = 2.5951\n",
      "Iteration 23170: loss = 2.5482\n",
      "Iteration 23180: loss = 2.5707\n",
      "Iteration 23190: loss = 2.9993\n",
      "Iteration 23200: loss = 2.8227\n",
      "Iteration 23210: loss = 2.5631\n",
      "Iteration 23220: loss = 2.4043\n",
      "Iteration 23230: loss = 2.5751\n",
      "Iteration 23240: loss = 3.3807\n",
      "Iteration 23250: loss = 2.5701\n",
      "Iteration 23260: loss = 2.8974\n",
      "Iteration 23270: loss = 2.3195\n",
      "Iteration 23280: loss = 2.3786\n",
      "Iteration 23290: loss = 2.3811\n",
      "Iteration 23300: loss = 2.3208\n",
      "Iteration 23310: loss = 2.6928\n",
      "Iteration 23320: loss = 2.6702\n",
      "Iteration 23330: loss = 2.9416\n",
      "Iteration 23340: loss = 2.3923\n",
      "Iteration 23350: loss = 2.3070\n",
      "Iteration 23360: loss = 2.7586\n",
      "Iteration 23370: loss = 2.6624\n",
      "Iteration 23380: loss = 2.7863\n",
      "Iteration 23390: loss = 2.8275\n",
      "Iteration 23400: loss = 1.8897\n",
      "Iteration 23410: loss = 2.4178\n",
      "Iteration 23420: loss = 2.3895\n",
      "Iteration 23430: loss = 2.1176\n",
      "Iteration 23440: loss = 2.2070\n",
      "Iteration 23450: loss = 2.5402\n",
      "Iteration 23460: loss = 2.9975\n",
      "Iteration 23470: loss = 2.3397\n",
      "Iteration 23480: loss = 2.0263\n",
      "Iteration 23490: loss = 2.8878\n",
      "Iteration 23500: loss = 2.7132\n",
      "Iteration 23510: loss = 2.5034\n",
      "Iteration 23520: loss = 2.3427\n",
      "Iteration 23530: loss = 2.8878\n",
      "Iteration 23540: loss = 2.6742\n",
      "Iteration 23550: loss = 2.8901\n",
      "Iteration 23560: loss = 2.6547\n",
      "Iteration 23570: loss = 2.8839\n",
      "Iteration 23580: loss = 2.5976\n",
      "Iteration 23590: loss = 2.5673\n",
      "Iteration 23600: loss = 2.2346\n",
      "Iteration 23610: loss = 2.7220\n",
      "Iteration 23620: loss = 2.7652\n",
      "Iteration 23630: loss = 2.8065\n",
      "Iteration 23640: loss = 2.6443\n",
      "Iteration 23650: loss = 2.7721\n",
      "Iteration 23660: loss = 2.0800\n",
      "Iteration 23670: loss = 2.2591\n",
      "Iteration 23680: loss = 2.8214\n",
      "Iteration 23690: loss = 2.2806\n",
      "Iteration 23700: loss = 2.4182\n",
      "Iteration 23710: loss = 2.3205\n",
      "Iteration 23720: loss = 2.6104\n",
      "Iteration 23730: loss = 2.4032\n",
      "Iteration 23740: loss = 2.4063\n",
      "Iteration 23750: loss = 2.7182\n",
      "Iteration 23760: loss = 2.5357\n",
      "Iteration 23770: loss = 2.1786\n",
      "Iteration 23780: loss = 2.5174\n",
      "Iteration 23790: loss = 2.5012\n",
      "Iteration 23800: loss = 2.4821\n",
      "Iteration 23810: loss = 2.5490\n",
      "Iteration 23820: loss = 2.6305\n",
      "Iteration 23830: loss = 2.7377\n",
      "Iteration 23840: loss = 2.5391\n",
      "Iteration 23850: loss = 2.6897\n",
      "Iteration 23860: loss = 2.2914\n",
      "Iteration 23870: loss = 2.8894\n",
      "Iteration 23880: loss = 2.7989\n",
      "Iteration 23890: loss = 2.5863\n",
      "Iteration 23900: loss = 2.3809\n",
      "Iteration 23910: loss = 2.1773\n",
      "Iteration 23920: loss = 2.4564\n",
      "Iteration 23930: loss = 2.6607\n",
      "Iteration 23940: loss = 2.9762\n",
      "Iteration 23950: loss = 2.3033\n",
      "Iteration 23960: loss = 2.6054\n",
      "Iteration 23970: loss = 2.5667\n",
      "Iteration 23980: loss = 2.6003\n",
      "Iteration 23990: loss = 2.7477\n",
      "Iteration 24000: loss = 2.4898\n",
      "Iteration 24010: loss = 2.2970\n",
      "Iteration 24020: loss = 2.9287\n",
      "Iteration 24030: loss = 2.6092\n",
      "Iteration 24040: loss = 2.3971\n",
      "Iteration 24050: loss = 2.4278\n",
      "Iteration 24060: loss = 2.5449\n",
      "Iteration 24070: loss = 2.2290\n",
      "Iteration 24080: loss = 2.6355\n",
      "Iteration 24090: loss = 2.4032\n",
      "Iteration 24100: loss = 2.6395\n",
      "Iteration 24110: loss = 2.5823\n",
      "Iteration 24120: loss = 2.7959\n",
      "Iteration 24130: loss = 2.7619\n",
      "Iteration 24140: loss = 2.8584\n",
      "Iteration 24150: loss = 3.0752\n",
      "Iteration 24160: loss = 3.0573\n",
      "Iteration 24170: loss = 2.5642\n",
      "Iteration 24180: loss = 2.7352\n",
      "Iteration 24190: loss = 2.4874\n",
      "Iteration 24200: loss = 2.3501\n",
      "Iteration 24210: loss = 2.3135\n",
      "Iteration 24220: loss = 2.1615\n",
      "Iteration 24230: loss = 2.9329\n",
      "Iteration 24240: loss = 2.2420\n",
      "Iteration 24250: loss = 2.2628\n",
      "Iteration 24260: loss = 2.4518\n",
      "Iteration 24270: loss = 2.6926\n",
      "Iteration 24280: loss = 2.4985\n",
      "Iteration 24290: loss = 2.6008\n",
      "Iteration 24300: loss = 2.2950\n",
      "Iteration 24310: loss = 2.5709\n",
      "Iteration 24320: loss = 2.5908\n",
      "Iteration 24330: loss = 2.2869\n",
      "Iteration 24340: loss = 2.6314\n",
      "Iteration 24350: loss = 2.6004\n",
      "Iteration 24360: loss = 2.3321\n",
      "Iteration 24370: loss = 2.4153\n",
      "Iteration 24380: loss = 2.2673\n",
      "Iteration 24390: loss = 2.6487\n",
      "Iteration 24400: loss = 2.8321\n",
      "Iteration 24410: loss = 2.8031\n",
      "Iteration 24420: loss = 2.8630\n",
      "Iteration 24430: loss = 2.6780\n",
      "Iteration 24440: loss = 2.7620\n",
      "Iteration 24450: loss = 2.8440\n",
      "Iteration 24460: loss = 2.6021\n",
      "Iteration 24470: loss = 2.3040\n",
      "Iteration 24480: loss = 2.5826\n",
      "Iteration 24490: loss = 2.7558\n",
      "Iteration 24500: loss = 2.2104\n",
      "Iteration 24510: loss = 2.5155\n",
      "Iteration 24520: loss = 2.5512\n",
      "Iteration 24530: loss = 2.5794\n",
      "Iteration 24540: loss = 2.5255\n",
      "Iteration 24550: loss = 2.5367\n",
      "Iteration 24560: loss = 2.5707\n",
      "Iteration 24570: loss = 2.9345\n",
      "Iteration 24580: loss = 2.6532\n",
      "Iteration 24590: loss = 2.5384\n",
      "Iteration 24600: loss = 2.1209\n",
      "Iteration 24610: loss = 2.5076\n",
      "Iteration 24620: loss = 2.4010\n",
      "Iteration 24630: loss = 2.5621\n",
      "Iteration 24640: loss = 2.6203\n",
      "Iteration 24650: loss = 2.4614\n",
      "Iteration 24660: loss = 2.7313\n",
      "Iteration 24670: loss = 2.5541\n",
      "Iteration 24680: loss = 2.5617\n",
      "Iteration 24690: loss = 2.4639\n",
      "Iteration 24700: loss = 2.0258\n",
      "Iteration 24710: loss = 2.5579\n",
      "Iteration 24720: loss = 2.0087\n",
      "Iteration 24730: loss = 2.9139\n",
      "Iteration 24740: loss = 2.7182\n",
      "Iteration 24750: loss = 2.3960\n",
      "Iteration 24760: loss = 2.4799\n",
      "Iteration 24770: loss = 2.7198\n",
      "Iteration 24780: loss = 2.5843\n",
      "Iteration 24790: loss = 2.2227\n",
      "Iteration 24800: loss = 2.4038\n",
      "Iteration 24810: loss = 2.4692\n",
      "Iteration 24820: loss = 3.1432\n",
      "Iteration 24830: loss = 3.1378\n",
      "Iteration 24840: loss = 2.4164\n",
      "Iteration 24850: loss = 2.5613\n",
      "Iteration 24860: loss = 2.8109\n",
      "Iteration 24870: loss = 2.6016\n",
      "Iteration 24880: loss = 2.6499\n",
      "Iteration 24890: loss = 2.7421\n",
      "Iteration 24900: loss = 2.4487\n",
      "Iteration 24910: loss = 2.2521\n",
      "Iteration 24920: loss = 2.6738\n",
      "Iteration 24930: loss = 2.5637\n",
      "Iteration 24940: loss = 2.3676\n",
      "Iteration 24950: loss = 2.8088\n",
      "Iteration 24960: loss = 2.5788\n",
      "Iteration 24970: loss = 2.5095\n",
      "Iteration 24980: loss = 2.4883\n",
      "Iteration 24990: loss = 2.6908\n",
      "Iteration 25000: loss = 2.7457\n",
      "Iteration 25010: loss = 2.9053\n",
      "Iteration 25020: loss = 2.3884\n",
      "Iteration 25030: loss = 2.9352\n",
      "Iteration 25040: loss = 2.5369\n",
      "Iteration 25050: loss = 2.4009\n",
      "Iteration 25060: loss = 2.6287\n",
      "Iteration 25070: loss = 2.6203\n",
      "Iteration 25080: loss = 2.5003\n",
      "Iteration 25090: loss = 2.8278\n",
      "Iteration 25100: loss = 2.2021\n",
      "Iteration 25110: loss = 2.1101\n",
      "Iteration 25120: loss = 2.1215\n",
      "Iteration 25130: loss = 2.6147\n",
      "Iteration 25140: loss = 2.5475\n",
      "Iteration 25150: loss = 2.3689\n",
      "Iteration 25160: loss = 2.5767\n",
      "Iteration 25170: loss = 2.4844\n",
      "Iteration 25180: loss = 2.6262\n",
      "Iteration 25190: loss = 2.4928\n",
      "Iteration 25200: loss = 2.3489\n",
      "Iteration 25210: loss = 2.6573\n",
      "Iteration 25220: loss = 2.5397\n",
      "Iteration 25230: loss = 2.1704\n",
      "Iteration 25240: loss = 2.6094\n",
      "Iteration 25250: loss = 2.9079\n",
      "Iteration 25260: loss = 2.4948\n",
      "Iteration 25270: loss = 2.4500\n",
      "Iteration 25280: loss = 2.3277\n",
      "Iteration 25290: loss = 2.3059\n",
      "Iteration 25300: loss = 2.1584\n",
      "Iteration 25310: loss = 2.7907\n",
      "Iteration 25320: loss = 2.5212\n",
      "Iteration 25330: loss = 2.2175\n",
      "Iteration 25340: loss = 2.4309\n",
      "Iteration 25350: loss = 2.6084\n",
      "Iteration 25360: loss = 2.6549\n",
      "Iteration 25370: loss = 2.3954\n",
      "Iteration 25380: loss = 2.9505\n",
      "Iteration 25390: loss = 2.5033\n",
      "Iteration 25400: loss = 2.3611\n",
      "Iteration 25410: loss = 2.8753\n",
      "Iteration 25420: loss = 2.2523\n",
      "Iteration 25430: loss = 2.9193\n",
      "Iteration 25440: loss = 2.7002\n",
      "Iteration 25450: loss = 2.1760\n",
      "Iteration 25460: loss = 2.5023\n",
      "Iteration 25470: loss = 2.6249\n",
      "Iteration 25480: loss = 2.5185\n",
      "Iteration 25490: loss = 2.5644\n",
      "Iteration 25500: loss = 2.3620\n",
      "Iteration 25510: loss = 2.5680\n",
      "Iteration 25520: loss = 2.9435\n",
      "Iteration 25530: loss = 2.4298\n",
      "Iteration 25540: loss = 2.8844\n",
      "Iteration 25550: loss = 2.1581\n",
      "Iteration 25560: loss = 2.7102\n",
      "Iteration 25570: loss = 2.6551\n",
      "Iteration 25580: loss = 2.5463\n",
      "Iteration 25590: loss = 2.2872\n",
      "Iteration 25600: loss = 2.1997\n",
      "Iteration 25610: loss = 2.1926\n",
      "Iteration 25620: loss = 2.7746\n",
      "Iteration 25630: loss = 2.8535\n",
      "Iteration 25640: loss = 2.0074\n",
      "Iteration 25650: loss = 2.5129\n",
      "Iteration 25660: loss = 2.1241\n",
      "Iteration 25670: loss = 2.5035\n",
      "Iteration 25680: loss = 2.4030\n",
      "Iteration 25690: loss = 2.8537\n",
      "Iteration 25700: loss = 2.3182\n",
      "Iteration 25710: loss = 2.5955\n",
      "Iteration 25720: loss = 2.2618\n",
      "Iteration 25730: loss = 2.4366\n",
      "Iteration 25740: loss = 2.1457\n",
      "Iteration 25750: loss = 2.5594\n",
      "Iteration 25760: loss = 2.7286\n",
      "Iteration 25770: loss = 2.4600\n",
      "Iteration 25780: loss = 2.6925\n",
      "Iteration 25790: loss = 2.6114\n",
      "Iteration 25800: loss = 2.3028\n",
      "Iteration 25810: loss = 2.3814\n",
      "Iteration 25820: loss = 2.5667\n",
      "Iteration 25830: loss = 2.1856\n",
      "Iteration 25840: loss = 2.4390\n",
      "Iteration 25850: loss = 2.6533\n",
      "Iteration 25860: loss = 2.8011\n",
      "Iteration 25870: loss = 2.7439\n",
      "Iteration 25880: loss = 2.4048\n",
      "Iteration 25890: loss = 2.6418\n",
      "Iteration 25900: loss = 2.8469\n",
      "Iteration 25910: loss = 2.6520\n",
      "Iteration 25920: loss = 2.4189\n",
      "Iteration 25930: loss = 2.7485\n",
      "Iteration 25940: loss = 2.8159\n",
      "Iteration 25950: loss = 2.1539\n",
      "Iteration 25960: loss = 2.7310\n",
      "Iteration 25970: loss = 2.1469\n",
      "Iteration 25980: loss = 2.5271\n",
      "Iteration 25990: loss = 2.5784\n",
      "Iteration 26000: loss = 2.5191\n",
      "Iteration 26010: loss = 2.5708\n",
      "Iteration 26020: loss = 2.4553\n",
      "Iteration 26030: loss = 2.8865\n",
      "Iteration 26040: loss = 3.1896\n",
      "Iteration 26050: loss = 2.4551\n",
      "Iteration 26060: loss = 2.6904\n",
      "Iteration 26070: loss = 2.5411\n",
      "Iteration 26080: loss = 2.1133\n",
      "Iteration 26090: loss = 2.4471\n",
      "Iteration 26100: loss = 2.4237\n",
      "Iteration 26110: loss = 2.3914\n",
      "Iteration 26120: loss = 2.4015\n",
      "Iteration 26130: loss = 2.3877\n",
      "Iteration 26140: loss = 2.5563\n",
      "Iteration 26150: loss = 2.7377\n",
      "Iteration 26160: loss = 2.5255\n",
      "Iteration 26170: loss = 2.5858\n",
      "Iteration 26180: loss = 2.4870\n",
      "Iteration 26190: loss = 2.5356\n",
      "Iteration 26200: loss = 2.5752\n",
      "Iteration 26210: loss = 2.6098\n",
      "Iteration 26220: loss = 2.3169\n",
      "Iteration 26230: loss = 2.9450\n",
      "Iteration 26240: loss = 2.8220\n",
      "Iteration 26250: loss = 2.7378\n",
      "Iteration 26260: loss = 2.4461\n",
      "Iteration 26270: loss = 2.3583\n",
      "Iteration 26280: loss = 2.2942\n",
      "Iteration 26290: loss = 2.6625\n",
      "Iteration 26300: loss = 2.6077\n",
      "Iteration 26310: loss = 2.3837\n",
      "Iteration 26320: loss = 2.4091\n",
      "Iteration 26330: loss = 2.2957\n",
      "Iteration 26340: loss = 2.5041\n",
      "Iteration 26350: loss = 2.7738\n",
      "Iteration 26360: loss = 2.7705\n",
      "Iteration 26370: loss = 2.7652\n",
      "Iteration 26380: loss = 2.4513\n",
      "Iteration 26390: loss = 2.5293\n",
      "Iteration 26400: loss = 2.6612\n",
      "Iteration 26410: loss = 2.1539\n",
      "Iteration 26420: loss = 2.6878\n",
      "Iteration 26430: loss = 2.5908\n",
      "Iteration 26440: loss = 2.5033\n",
      "Iteration 26450: loss = 2.7175\n",
      "Iteration 26460: loss = 2.5095\n",
      "Iteration 26470: loss = 2.5256\n",
      "Iteration 26480: loss = 2.4058\n",
      "Iteration 26490: loss = 2.5725\n",
      "Iteration 26500: loss = 2.5672\n",
      "Iteration 26510: loss = 3.0046\n",
      "Iteration 26520: loss = 2.4136\n",
      "Iteration 26530: loss = 2.2758\n",
      "Iteration 26540: loss = 2.3964\n",
      "Iteration 26550: loss = 2.5341\n",
      "Iteration 26560: loss = 2.7213\n",
      "Iteration 26570: loss = 2.6160\n",
      "Iteration 26580: loss = 2.4299\n",
      "Iteration 26590: loss = 2.9872\n",
      "Iteration 26600: loss = 2.2970\n",
      "Iteration 26610: loss = 2.3312\n",
      "Iteration 26620: loss = 2.9657\n",
      "Iteration 26630: loss = 2.1142\n",
      "Iteration 26640: loss = 2.4938\n",
      "Iteration 26650: loss = 2.3572\n",
      "Iteration 26660: loss = 2.5327\n",
      "Iteration 26670: loss = 2.6121\n",
      "Iteration 26680: loss = 2.2962\n",
      "Iteration 26690: loss = 3.0208\n",
      "Iteration 26700: loss = 2.4623\n",
      "Iteration 26710: loss = 2.4896\n",
      "Iteration 26720: loss = 2.7240\n",
      "Iteration 26730: loss = 2.6355\n",
      "Iteration 26740: loss = 2.4997\n",
      "Iteration 26750: loss = 2.5463\n",
      "Iteration 26760: loss = 2.2300\n",
      "Iteration 26770: loss = 2.6118\n",
      "Iteration 26780: loss = 2.2673\n",
      "Iteration 26790: loss = 2.3411\n",
      "Iteration 26800: loss = 2.6793\n",
      "Iteration 26810: loss = 2.1415\n",
      "Iteration 26820: loss = 2.6472\n",
      "Iteration 26830: loss = 2.3025\n",
      "Iteration 26840: loss = 2.4269\n",
      "Iteration 26850: loss = 2.5732\n",
      "Iteration 26860: loss = 2.6851\n",
      "Iteration 26870: loss = 2.5990\n",
      "Iteration 26880: loss = 2.2860\n",
      "Iteration 26890: loss = 2.3578\n",
      "Iteration 26900: loss = 2.2910\n",
      "Iteration 26910: loss = 2.5616\n",
      "Iteration 26920: loss = 2.4912\n",
      "Iteration 26930: loss = 2.5524\n",
      "Iteration 26940: loss = 2.3107\n",
      "Iteration 26950: loss = 2.4492\n",
      "Iteration 26960: loss = 2.5357\n",
      "Iteration 26970: loss = 2.4890\n",
      "Iteration 26980: loss = 2.1832\n",
      "Iteration 26990: loss = 2.2898\n",
      "Iteration 27000: loss = 2.3578\n",
      "Iteration 27010: loss = 2.1138\n",
      "Iteration 27020: loss = 2.7930\n",
      "Iteration 27030: loss = 2.7790\n",
      "Iteration 27040: loss = 2.3399\n",
      "Iteration 27050: loss = 2.7656\n",
      "Iteration 27060: loss = 2.4416\n",
      "Iteration 27070: loss = 2.1195\n",
      "Iteration 27080: loss = 2.7577\n",
      "Iteration 27090: loss = 2.3097\n",
      "Iteration 27100: loss = 2.3626\n",
      "Iteration 27110: loss = 2.0883\n",
      "Iteration 27120: loss = 2.7979\n",
      "Iteration 27130: loss = 2.7563\n",
      "Iteration 27140: loss = 2.3673\n",
      "Iteration 27150: loss = 2.7118\n",
      "Iteration 27160: loss = 2.3017\n",
      "Iteration 27170: loss = 2.4697\n",
      "Iteration 27180: loss = 3.3109\n",
      "Iteration 27190: loss = 2.4227\n",
      "Iteration 27200: loss = 2.6148\n",
      "Iteration 27210: loss = 2.5586\n",
      "Iteration 27220: loss = 2.4751\n",
      "Iteration 27230: loss = 2.4171\n",
      "Iteration 27240: loss = 2.6254\n",
      "Iteration 27250: loss = 2.7372\n",
      "Iteration 27260: loss = 2.5294\n",
      "Iteration 27270: loss = 2.6280\n",
      "Iteration 27280: loss = 2.6166\n",
      "Iteration 27290: loss = 2.5267\n",
      "Iteration 27300: loss = 2.4250\n",
      "Iteration 27310: loss = 2.4276\n",
      "Iteration 27320: loss = 2.6130\n",
      "Iteration 27330: loss = 2.8333\n",
      "Iteration 27340: loss = 2.0547\n",
      "Iteration 27350: loss = 2.3964\n",
      "Iteration 27360: loss = 2.5831\n",
      "Iteration 27370: loss = 2.8156\n",
      "Iteration 27380: loss = 2.1908\n",
      "Iteration 27390: loss = 2.8114\n",
      "Iteration 27400: loss = 2.4343\n",
      "Iteration 27410: loss = 2.6759\n",
      "Iteration 27420: loss = 2.6961\n",
      "Iteration 27430: loss = 2.8937\n",
      "Iteration 27440: loss = 2.5258\n",
      "Iteration 27450: loss = 2.4746\n",
      "Iteration 27460: loss = 2.7285\n",
      "Iteration 27470: loss = 2.4353\n",
      "Iteration 27480: loss = 2.5498\n",
      "Iteration 27490: loss = 2.2331\n",
      "Iteration 27500: loss = 2.2564\n",
      "Iteration 27510: loss = 2.3068\n",
      "Iteration 27520: loss = 2.5666\n",
      "Iteration 27530: loss = 2.5491\n",
      "Iteration 27540: loss = 2.4450\n",
      "Iteration 27550: loss = 2.7773\n",
      "Iteration 27560: loss = 2.5696\n",
      "Iteration 27570: loss = 2.9955\n",
      "Iteration 27580: loss = 2.4181\n",
      "Iteration 27590: loss = 2.1665\n",
      "Iteration 27600: loss = 2.2846\n",
      "Iteration 27610: loss = 2.6376\n",
      "Iteration 27620: loss = 2.5531\n",
      "Iteration 27630: loss = 3.0914\n",
      "Iteration 27640: loss = 2.2613\n",
      "Iteration 27650: loss = 2.4039\n",
      "Iteration 27660: loss = 2.0429\n",
      "Iteration 27670: loss = 2.3984\n",
      "Iteration 27680: loss = 2.4233\n",
      "Iteration 27690: loss = 2.2546\n",
      "Iteration 27700: loss = 2.0909\n",
      "Iteration 27710: loss = 2.4113\n",
      "Iteration 27720: loss = 2.4037\n",
      "Iteration 27730: loss = 2.3528\n",
      "Iteration 27740: loss = 2.4416\n",
      "Iteration 27750: loss = 2.3000\n",
      "Iteration 27760: loss = 2.3227\n",
      "Iteration 27770: loss = 2.5143\n",
      "Iteration 27780: loss = 3.0879\n",
      "Iteration 27790: loss = 2.4905\n",
      "Iteration 27800: loss = 2.6115\n",
      "Iteration 27810: loss = 2.4802\n",
      "Iteration 27820: loss = 2.3268\n",
      "Iteration 27830: loss = 2.4036\n",
      "Iteration 27840: loss = 2.3739\n",
      "Iteration 27850: loss = 2.3627\n",
      "Iteration 27860: loss = 3.0383\n",
      "Iteration 27870: loss = 2.8060\n",
      "Iteration 27880: loss = 2.3076\n",
      "Iteration 27890: loss = 2.4692\n",
      "Iteration 27900: loss = 2.6492\n",
      "Iteration 27910: loss = 2.7106\n",
      "Iteration 27920: loss = 2.3736\n",
      "Iteration 27930: loss = 2.6521\n",
      "Iteration 27940: loss = 2.5019\n",
      "Iteration 27950: loss = 2.2348\n",
      "Iteration 27960: loss = 2.4129\n",
      "Iteration 27970: loss = 2.6480\n",
      "Iteration 27980: loss = 2.3553\n",
      "Iteration 27990: loss = 3.0374\n",
      "Iteration 28000: loss = 2.7281\n",
      "Iteration 28010: loss = 2.7902\n",
      "Iteration 28020: loss = 2.3271\n",
      "Iteration 28030: loss = 2.3863\n",
      "Iteration 28040: loss = 2.1004\n",
      "Iteration 28050: loss = 2.9464\n",
      "Iteration 28060: loss = 2.5139\n",
      "Iteration 28070: loss = 2.5411\n",
      "Iteration 28080: loss = 2.2672\n",
      "Iteration 28090: loss = 2.3690\n",
      "Iteration 28100: loss = 2.7003\n",
      "Iteration 28110: loss = 2.4369\n",
      "Iteration 28120: loss = 2.2391\n",
      "Iteration 28130: loss = 2.9356\n",
      "Iteration 28140: loss = 2.6598\n",
      "Iteration 28150: loss = 2.5412\n",
      "Iteration 28160: loss = 2.7011\n",
      "Iteration 28170: loss = 2.5535\n",
      "Iteration 28180: loss = 2.3905\n",
      "Iteration 28190: loss = 2.5485\n",
      "Iteration 28200: loss = 2.7207\n",
      "Iteration 28210: loss = 2.1121\n",
      "Iteration 28220: loss = 2.9448\n",
      "Iteration 28230: loss = 2.6828\n",
      "Iteration 28240: loss = 3.0812\n",
      "Iteration 28250: loss = 3.3911\n",
      "Iteration 28260: loss = 2.6903\n",
      "Iteration 28270: loss = 2.3876\n",
      "Iteration 28280: loss = 1.9566\n",
      "Iteration 28290: loss = 2.7800\n",
      "Iteration 28300: loss = 2.4380\n",
      "Iteration 28310: loss = 2.4251\n",
      "Iteration 28320: loss = 2.6197\n",
      "Iteration 28330: loss = 2.7759\n",
      "Iteration 28340: loss = 2.5253\n",
      "Iteration 28350: loss = 2.3362\n",
      "Iteration 28360: loss = 2.2807\n",
      "Iteration 28370: loss = 2.7527\n",
      "Iteration 28380: loss = 2.7922\n",
      "Iteration 28390: loss = 2.8516\n",
      "Iteration 28400: loss = 2.6955\n",
      "Iteration 28410: loss = 2.6585\n",
      "Iteration 28420: loss = 2.4110\n",
      "Iteration 28430: loss = 2.5584\n",
      "Iteration 28440: loss = 2.5594\n",
      "Iteration 28450: loss = 2.3359\n",
      "Iteration 28460: loss = 2.5131\n",
      "Iteration 28470: loss = 2.5135\n",
      "Iteration 28480: loss = 3.1405\n",
      "Iteration 28490: loss = 2.9578\n",
      "Iteration 28500: loss = 2.2947\n",
      "Iteration 28510: loss = 2.6601\n",
      "Iteration 28520: loss = 2.3933\n",
      "Iteration 28530: loss = 2.4707\n",
      "Iteration 28540: loss = 2.7019\n",
      "Iteration 28550: loss = 2.7244\n",
      "Iteration 28560: loss = 2.3538\n",
      "Iteration 28570: loss = 2.3036\n",
      "Iteration 28580: loss = 2.4306\n",
      "Iteration 28590: loss = 2.5844\n",
      "Iteration 28600: loss = 2.5728\n",
      "Iteration 28610: loss = 2.2066\n",
      "Iteration 28620: loss = 2.6558\n",
      "Iteration 28630: loss = 2.1469\n",
      "Iteration 28640: loss = 2.6392\n",
      "Iteration 28650: loss = 2.6252\n",
      "Iteration 28660: loss = 2.3838\n",
      "Iteration 28670: loss = 2.1978\n",
      "Iteration 28680: loss = 2.7698\n",
      "Iteration 28690: loss = 2.2539\n",
      "Iteration 28700: loss = 2.4546\n",
      "Iteration 28710: loss = 2.2371\n",
      "Iteration 28720: loss = 2.2185\n",
      "Iteration 28730: loss = 2.7297\n",
      "Iteration 28740: loss = 2.2280\n",
      "Iteration 28750: loss = 2.6284\n",
      "Iteration 28760: loss = 2.4495\n",
      "Iteration 28770: loss = 2.4040\n",
      "Iteration 28780: loss = 2.2916\n",
      "Iteration 28790: loss = 2.6348\n",
      "Iteration 28800: loss = 3.0830\n",
      "Iteration 28810: loss = 2.5579\n",
      "Iteration 28820: loss = 2.7157\n",
      "Iteration 28830: loss = 2.8474\n",
      "Iteration 28840: loss = 2.5916\n",
      "Iteration 28850: loss = 2.2498\n",
      "Iteration 28860: loss = 2.4955\n",
      "Iteration 28870: loss = 2.5416\n",
      "Iteration 28880: loss = 2.3777\n",
      "Iteration 28890: loss = 2.3963\n",
      "Iteration 28900: loss = 2.3513\n",
      "Iteration 28910: loss = 2.2124\n",
      "Iteration 28920: loss = 2.3600\n",
      "Iteration 28930: loss = 2.5848\n",
      "Iteration 28940: loss = 2.5201\n",
      "Iteration 28950: loss = 2.6085\n",
      "Iteration 28960: loss = 2.5858\n",
      "Iteration 28970: loss = 2.4924\n",
      "Iteration 28980: loss = 2.5578\n",
      "Iteration 28990: loss = 2.2234\n",
      "Iteration 29000: loss = 2.5805\n",
      "Iteration 29010: loss = 2.7419\n",
      "Iteration 29020: loss = 2.6663\n",
      "Iteration 29030: loss = 2.7064\n",
      "Iteration 29040: loss = 2.3119\n",
      "Iteration 29050: loss = 2.0532\n",
      "Iteration 29060: loss = 2.5468\n",
      "Iteration 29070: loss = 2.1690\n",
      "Iteration 29080: loss = 2.6307\n",
      "Iteration 29090: loss = 2.5305\n",
      "Iteration 29100: loss = 2.3910\n",
      "Iteration 29110: loss = 2.5788\n",
      "Iteration 29120: loss = 2.9501\n",
      "Iteration 29130: loss = 2.4969\n",
      "Iteration 29140: loss = 2.5880\n",
      "Iteration 29150: loss = 2.7846\n",
      "Iteration 29160: loss = 2.2146\n",
      "Iteration 29170: loss = 2.6890\n",
      "Iteration 29180: loss = 2.7620\n",
      "Iteration 29190: loss = 2.5249\n",
      "Iteration 29200: loss = 2.5013\n",
      "Iteration 29210: loss = 2.9638\n",
      "Iteration 29220: loss = 2.3299\n",
      "Iteration 29230: loss = 2.3170\n",
      "Iteration 29240: loss = 2.3728\n",
      "Iteration 29250: loss = 2.1460\n",
      "Iteration 29260: loss = 2.4306\n",
      "Iteration 29270: loss = 2.8905\n",
      "Iteration 29280: loss = 3.0374\n",
      "Iteration 29290: loss = 2.9667\n",
      "Iteration 29300: loss = 2.8050\n",
      "Iteration 29310: loss = 2.3818\n",
      "Iteration 29320: loss = 2.6890\n",
      "Iteration 29330: loss = 2.7361\n",
      "Iteration 29340: loss = 2.8122\n",
      "Iteration 29350: loss = 2.5102\n",
      "Iteration 29360: loss = 2.3613\n",
      "Iteration 29370: loss = 2.3936\n",
      "Iteration 29380: loss = 2.2801\n",
      "Iteration 29390: loss = 2.4755\n",
      "Iteration 29400: loss = 2.5672\n",
      "Iteration 29410: loss = 2.4924\n",
      "Iteration 29420: loss = 2.6156\n",
      "Iteration 29430: loss = 2.6979\n",
      "Iteration 29440: loss = 2.8441\n",
      "Iteration 29450: loss = 2.7755\n",
      "Iteration 29460: loss = 2.9811\n",
      "Iteration 29470: loss = 2.2598\n",
      "Iteration 29480: loss = 2.7411\n",
      "Iteration 29490: loss = 2.7831\n",
      "Iteration 29500: loss = 2.6547\n",
      "Iteration 29510: loss = 2.3592\n",
      "Iteration 29520: loss = 2.2716\n",
      "Iteration 29530: loss = 2.7258\n",
      "Iteration 29540: loss = 2.6389\n",
      "Iteration 29550: loss = 2.3399\n",
      "Iteration 29560: loss = 2.6268\n",
      "Iteration 29570: loss = 2.5227\n",
      "Iteration 29580: loss = 2.3610\n",
      "Iteration 29590: loss = 2.8192\n",
      "Iteration 29600: loss = 2.4895\n",
      "Iteration 29610: loss = 2.2732\n",
      "Iteration 29620: loss = 2.9310\n",
      "Iteration 29630: loss = 2.6641\n",
      "Iteration 29640: loss = 2.4201\n",
      "Iteration 29650: loss = 2.3843\n",
      "Iteration 29660: loss = 3.0693\n",
      "Iteration 29670: loss = 2.8066\n",
      "Iteration 29680: loss = 2.4030\n",
      "Iteration 29690: loss = 2.2906\n",
      "Iteration 29700: loss = 2.3643\n",
      "Iteration 29710: loss = 2.7210\n",
      "Iteration 29720: loss = 2.8505\n",
      "Iteration 29730: loss = 2.6379\n",
      "Iteration 29740: loss = 2.5909\n",
      "Iteration 29750: loss = 2.6030\n",
      "Iteration 29760: loss = 2.5262\n",
      "Iteration 29770: loss = 2.7338\n",
      "Iteration 29780: loss = 2.4203\n",
      "Iteration 29790: loss = 2.4576\n",
      "Iteration 29800: loss = 2.7153\n",
      "Iteration 29810: loss = 2.6404\n",
      "Iteration 29820: loss = 2.4303\n",
      "Iteration 29830: loss = 2.7941\n",
      "Iteration 29840: loss = 2.3717\n",
      "Iteration 29850: loss = 2.7380\n",
      "Iteration 29860: loss = 2.5173\n",
      "Iteration 29870: loss = 2.4460\n",
      "Iteration 29880: loss = 2.5070\n",
      "Iteration 29890: loss = 2.6042\n",
      "Iteration 29900: loss = 2.6871\n",
      "Iteration 29910: loss = 2.5502\n",
      "Iteration 29920: loss = 2.6029\n",
      "Iteration 29930: loss = 2.9138\n",
      "Iteration 29940: loss = 2.8060\n",
      "Iteration 29950: loss = 2.3805\n",
      "Iteration 29960: loss = 2.7763\n",
      "Iteration 29970: loss = 3.0724\n",
      "Iteration 29980: loss = 2.3747\n",
      "Iteration 29990: loss = 2.6267\n",
      "Iteration 30000: loss = 2.4589\n",
      "Iteration 30010: loss = 2.8051\n",
      "Iteration 30020: loss = 2.6491\n",
      "Iteration 30030: loss = 2.9497\n",
      "Iteration 30040: loss = 2.2707\n",
      "Iteration 30050: loss = 2.5476\n",
      "Iteration 30060: loss = 2.4454\n",
      "Iteration 30070: loss = 2.1677\n",
      "Iteration 30080: loss = 2.3790\n",
      "Iteration 30090: loss = 2.4308\n",
      "Iteration 30100: loss = 2.7794\n",
      "Iteration 30110: loss = 2.2136\n",
      "Iteration 30120: loss = 2.5843\n",
      "Iteration 30130: loss = 2.3656\n",
      "Iteration 30140: loss = 2.1413\n",
      "Iteration 30150: loss = 2.4052\n",
      "Iteration 30160: loss = 2.3189\n",
      "Iteration 30170: loss = 2.6232\n",
      "Iteration 30180: loss = 2.5069\n",
      "Iteration 30190: loss = 2.5163\n",
      "Iteration 30200: loss = 2.5543\n",
      "Iteration 30210: loss = 2.3755\n",
      "Iteration 30220: loss = 3.1000\n",
      "Iteration 30230: loss = 2.8234\n",
      "Iteration 30240: loss = 2.8322\n",
      "Iteration 30250: loss = 2.4970\n",
      "Iteration 30260: loss = 3.1106\n",
      "Iteration 30270: loss = 2.4852\n",
      "Iteration 30280: loss = 2.6276\n",
      "Iteration 30290: loss = 2.5202\n",
      "Iteration 30300: loss = 2.5621\n",
      "Iteration 30310: loss = 2.4639\n",
      "Iteration 30320: loss = 2.2879\n",
      "Iteration 30330: loss = 2.5792\n",
      "Iteration 30340: loss = 2.6044\n",
      "Iteration 30350: loss = 2.1350\n",
      "Iteration 30360: loss = 2.4601\n",
      "Iteration 30370: loss = 2.7460\n",
      "Iteration 30380: loss = 2.3226\n",
      "Iteration 30390: loss = 2.8925\n",
      "Iteration 30400: loss = 2.6827\n",
      "Iteration 30410: loss = 2.6771\n",
      "Iteration 30420: loss = 2.1248\n",
      "Iteration 30430: loss = 2.4016\n",
      "Iteration 30440: loss = 2.7590\n",
      "Iteration 30450: loss = 2.2802\n",
      "Iteration 30460: loss = 2.6648\n",
      "Iteration 30470: loss = 2.7697\n",
      "Iteration 30480: loss = 2.4391\n",
      "Iteration 30490: loss = 2.5131\n",
      "Iteration 30500: loss = 3.0759\n",
      "Iteration 30510: loss = 2.9684\n",
      "Iteration 30520: loss = 2.6036\n",
      "Iteration 30530: loss = 2.8161\n",
      "Iteration 30540: loss = 2.5596\n",
      "Iteration 30550: loss = 2.4708\n",
      "Iteration 30560: loss = 2.8368\n",
      "Iteration 30570: loss = 2.7312\n",
      "Iteration 30580: loss = 3.1675\n",
      "Iteration 30590: loss = 2.7146\n",
      "Iteration 30600: loss = 2.3179\n",
      "Iteration 30610: loss = 2.5572\n",
      "Iteration 30620: loss = 2.5785\n",
      "Iteration 30630: loss = 2.5043\n",
      "Iteration 30640: loss = 2.1413\n",
      "Iteration 30650: loss = 2.5225\n",
      "Iteration 30660: loss = 2.7324\n",
      "Iteration 30670: loss = 2.8749\n",
      "Iteration 30680: loss = 2.6639\n",
      "Iteration 30690: loss = 2.6658\n",
      "Iteration 30700: loss = 2.4265\n",
      "Iteration 30710: loss = 2.9794\n",
      "Iteration 30720: loss = 2.5578\n",
      "Iteration 30730: loss = 2.4468\n",
      "Iteration 30740: loss = 2.8704\n",
      "Iteration 30750: loss = 2.5857\n",
      "Iteration 30760: loss = 2.8153\n",
      "Iteration 30770: loss = 2.5823\n",
      "Iteration 30780: loss = 2.7394\n",
      "Iteration 30790: loss = 2.6134\n",
      "Iteration 30800: loss = 2.7901\n",
      "Iteration 30810: loss = 2.9576\n",
      "Iteration 30820: loss = 3.0251\n",
      "Iteration 30830: loss = 2.6553\n",
      "Iteration 30840: loss = 2.6820\n",
      "Iteration 30850: loss = 2.5106\n",
      "Iteration 30860: loss = 2.5372\n",
      "Iteration 30870: loss = 2.9123\n",
      "Iteration 30880: loss = 2.5424\n",
      "Iteration 30890: loss = 3.0044\n",
      "Iteration 30900: loss = 2.7450\n",
      "Iteration 30910: loss = 2.4868\n",
      "Iteration 30920: loss = 2.6593\n",
      "Iteration 30930: loss = 2.3348\n",
      "Iteration 30940: loss = 2.6393\n",
      "Iteration 30950: loss = 2.4192\n",
      "Iteration 30960: loss = 2.4815\n",
      "Iteration 30970: loss = 2.6044\n",
      "Iteration 30980: loss = 2.6355\n",
      "Iteration 30990: loss = 2.2169\n",
      "Iteration 31000: loss = 2.5000\n",
      "Iteration 31010: loss = 2.3456\n",
      "Iteration 31020: loss = 2.6104\n",
      "Iteration 31030: loss = 2.9885\n",
      "Iteration 31040: loss = 2.6800\n",
      "Iteration 31050: loss = 2.5795\n",
      "Iteration 31060: loss = 2.7817\n",
      "Iteration 31070: loss = 2.2307\n",
      "Iteration 31080: loss = 2.6585\n",
      "Iteration 31090: loss = 2.7955\n",
      "Iteration 31100: loss = 2.3461\n",
      "Iteration 31110: loss = 2.3353\n",
      "Iteration 31120: loss = 2.2456\n",
      "Iteration 31130: loss = 2.2927\n",
      "Iteration 31140: loss = 2.3352\n",
      "Iteration 31150: loss = 2.6738\n",
      "Iteration 31160: loss = 2.2955\n",
      "Iteration 31170: loss = 2.5939\n",
      "Iteration 31180: loss = 2.6163\n",
      "Iteration 31190: loss = 2.8209\n",
      "Iteration 31200: loss = 2.4128\n",
      "Iteration 31210: loss = 2.5916\n",
      "Iteration 31220: loss = 2.4213\n",
      "Iteration 31230: loss = 2.6671\n",
      "Iteration 31240: loss = 2.6172\n",
      "Iteration 31250: loss = 2.3221\n",
      "Iteration 31260: loss = 2.5873\n",
      "Iteration 31270: loss = 2.4761\n",
      "Iteration 31280: loss = 2.3284\n",
      "Iteration 31290: loss = 2.3054\n",
      "Iteration 31300: loss = 2.5828\n",
      "Iteration 31310: loss = 2.5423\n",
      "Iteration 31320: loss = 2.3511\n",
      "Iteration 31330: loss = 2.5201\n",
      "Iteration 31340: loss = 2.5590\n",
      "Iteration 31350: loss = 2.7512\n",
      "Iteration 31360: loss = 2.1906\n",
      "Iteration 31370: loss = 2.9943\n",
      "Iteration 31380: loss = 2.5227\n",
      "Iteration 31390: loss = 2.3262\n",
      "Iteration 31400: loss = 2.5851\n",
      "Iteration 31410: loss = 2.3631\n",
      "Iteration 31420: loss = 2.5515\n",
      "Iteration 31430: loss = 2.3872\n",
      "Iteration 31440: loss = 2.1662\n",
      "Iteration 31450: loss = 2.8100\n",
      "Iteration 31460: loss = 2.2079\n",
      "Iteration 31470: loss = 2.4974\n",
      "Iteration 31480: loss = 2.8174\n",
      "Iteration 31490: loss = 2.4670\n",
      "Iteration 31500: loss = 2.0890\n",
      "Iteration 31510: loss = 2.7300\n",
      "Iteration 31520: loss = 2.4796\n",
      "Iteration 31530: loss = 2.5122\n",
      "Iteration 31540: loss = 2.2850\n",
      "Iteration 31550: loss = 3.0444\n",
      "Iteration 31560: loss = 2.8760\n",
      "Iteration 31570: loss = 2.2683\n",
      "Iteration 31580: loss = 2.8550\n",
      "Iteration 31590: loss = 2.5140\n",
      "Iteration 31600: loss = 2.4230\n",
      "Iteration 31610: loss = 2.7328\n",
      "Iteration 31620: loss = 2.4307\n",
      "Iteration 31630: loss = 2.1293\n",
      "Iteration 31640: loss = 2.6732\n",
      "Iteration 31650: loss = 2.4186\n",
      "Iteration 31660: loss = 2.7079\n",
      "Iteration 31670: loss = 2.6813\n",
      "Iteration 31680: loss = 2.4467\n",
      "Iteration 31690: loss = 2.5998\n",
      "Iteration 31700: loss = 2.7699\n",
      "Iteration 31710: loss = 2.7033\n",
      "Iteration 31720: loss = 2.8483\n",
      "Iteration 31730: loss = 2.6981\n",
      "Iteration 31740: loss = 2.4962\n",
      "Iteration 31750: loss = 2.8006\n",
      "Iteration 31760: loss = 2.4275\n",
      "Iteration 31770: loss = 2.4631\n",
      "Iteration 31780: loss = 2.6209\n",
      "Iteration 31790: loss = 2.2480\n",
      "Iteration 31800: loss = 2.2176\n",
      "Iteration 31810: loss = 2.7321\n",
      "Iteration 31820: loss = 2.3970\n",
      "Iteration 31830: loss = 2.7236\n",
      "Iteration 31840: loss = 2.5205\n",
      "Iteration 31850: loss = 2.3019\n",
      "Iteration 31860: loss = 2.5989\n",
      "Iteration 31870: loss = 3.1151\n",
      "Iteration 31880: loss = 2.2079\n",
      "Iteration 31890: loss = 2.5078\n",
      "Iteration 31900: loss = 2.3259\n",
      "Iteration 31910: loss = 2.5644\n",
      "Iteration 31920: loss = 2.4829\n",
      "Iteration 31930: loss = 2.7221\n",
      "Iteration 31940: loss = 2.6378\n",
      "Iteration 31950: loss = 2.6386\n",
      "Iteration 31960: loss = 2.3649\n",
      "Iteration 31970: loss = 2.4541\n",
      "Iteration 31980: loss = 2.1600\n",
      "Iteration 31990: loss = 2.6486\n",
      "Iteration 32000: loss = 2.8782\n",
      "Iteration 32010: loss = 2.9532\n",
      "Iteration 32020: loss = 2.5833\n",
      "Iteration 32030: loss = 2.8205\n",
      "Iteration 32040: loss = 2.7324\n",
      "Iteration 32050: loss = 2.6116\n",
      "Iteration 32060: loss = 2.9819\n",
      "Iteration 32070: loss = 2.3808\n",
      "Iteration 32080: loss = 2.1282\n",
      "Iteration 32090: loss = 2.4203\n",
      "Iteration 32100: loss = 2.3718\n",
      "Iteration 32110: loss = 2.7775\n",
      "Iteration 32120: loss = 2.2392\n",
      "Iteration 32130: loss = 2.4391\n",
      "Iteration 32140: loss = 2.8368\n",
      "Iteration 32150: loss = 2.5802\n",
      "Iteration 32160: loss = 2.4293\n",
      "Iteration 32170: loss = 2.7457\n",
      "Iteration 32180: loss = 2.3991\n",
      "Iteration 32190: loss = 2.6013\n",
      "Iteration 32200: loss = 2.3575\n",
      "Iteration 32210: loss = 2.9631\n",
      "Iteration 32220: loss = 2.0560\n",
      "Iteration 32230: loss = 2.5248\n",
      "Iteration 32240: loss = 2.5924\n",
      "Iteration 32250: loss = 2.1415\n",
      "Iteration 32260: loss = 2.6269\n",
      "Iteration 32270: loss = 2.9086\n",
      "Iteration 32280: loss = 2.5428\n",
      "Iteration 32290: loss = 2.3998\n",
      "Iteration 32300: loss = 2.5394\n",
      "Iteration 32310: loss = 2.3220\n",
      "Iteration 32320: loss = 2.4224\n",
      "Iteration 32330: loss = 2.2986\n",
      "Iteration 32340: loss = 2.4535\n",
      "Iteration 32350: loss = 2.3909\n",
      "Iteration 32360: loss = 2.6884\n",
      "Iteration 32370: loss = 2.5874\n",
      "Iteration 32380: loss = 1.9515\n",
      "Iteration 32390: loss = 2.5731\n",
      "Iteration 32400: loss = 2.5596\n",
      "Iteration 32410: loss = 2.5687\n",
      "Iteration 32420: loss = 2.5183\n",
      "Iteration 32430: loss = 2.3080\n",
      "Iteration 32440: loss = 2.9603\n",
      "Iteration 32450: loss = 2.4837\n",
      "Iteration 32460: loss = 2.4091\n",
      "Iteration 32470: loss = 2.6006\n",
      "Iteration 32480: loss = 2.3744\n",
      "Iteration 32490: loss = 2.7526\n",
      "Iteration 32500: loss = 2.6118\n",
      "Iteration 32510: loss = 2.4606\n",
      "Iteration 32520: loss = 2.6067\n",
      "Iteration 32530: loss = 2.5684\n",
      "Iteration 32540: loss = 2.5501\n",
      "Iteration 32550: loss = 2.6014\n",
      "Iteration 32560: loss = 2.3271\n",
      "Iteration 32570: loss = 2.8039\n",
      "Iteration 32580: loss = 2.8499\n",
      "Iteration 32590: loss = 2.6729\n",
      "Iteration 32600: loss = 2.5308\n",
      "Iteration 32610: loss = 2.6164\n",
      "Iteration 32620: loss = 2.5690\n",
      "Iteration 32630: loss = 2.7451\n",
      "Iteration 32640: loss = 2.5591\n",
      "Iteration 32650: loss = 2.8237\n",
      "Iteration 32660: loss = 2.3776\n",
      "Iteration 32670: loss = 3.2763\n",
      "Iteration 32680: loss = 2.4308\n",
      "Iteration 32690: loss = 2.4063\n",
      "Iteration 32700: loss = 2.5121\n",
      "Iteration 32710: loss = 2.6916\n",
      "Iteration 32720: loss = 2.2060\n",
      "Iteration 32730: loss = 2.6754\n",
      "Iteration 32740: loss = 2.6469\n",
      "Iteration 32750: loss = 2.4428\n",
      "Iteration 32760: loss = 2.7601\n",
      "Iteration 32770: loss = 2.3936\n",
      "Iteration 32780: loss = 2.2315\n",
      "Iteration 32790: loss = 2.7482\n",
      "Iteration 32800: loss = 2.4770\n",
      "Iteration 32810: loss = 2.6928\n",
      "Iteration 32820: loss = 2.9302\n",
      "Iteration 32830: loss = 2.8959\n",
      "Iteration 32840: loss = 2.1868\n",
      "Iteration 32850: loss = 2.4266\n",
      "Iteration 32860: loss = 2.9924\n",
      "Iteration 32870: loss = 2.4995\n",
      "Iteration 32880: loss = 3.0320\n",
      "Iteration 32890: loss = 2.8072\n",
      "Iteration 32900: loss = 2.1815\n",
      "Iteration 32910: loss = 2.5041\n",
      "Iteration 32920: loss = 2.0345\n",
      "Iteration 32930: loss = 2.9104\n",
      "Iteration 32940: loss = 2.2944\n",
      "Iteration 32950: loss = 2.3523\n",
      "Iteration 32960: loss = 2.1837\n",
      "Iteration 32970: loss = 2.8860\n",
      "Iteration 32980: loss = 2.7385\n",
      "Iteration 32990: loss = 2.7747\n",
      "Iteration 33000: loss = 2.4522\n",
      "Iteration 33010: loss = 2.3837\n",
      "Iteration 33020: loss = 2.6819\n",
      "Iteration 33030: loss = 2.5603\n",
      "Iteration 33040: loss = 2.3894\n",
      "Iteration 33050: loss = 2.5642\n",
      "Iteration 33060: loss = 2.6673\n",
      "Iteration 33070: loss = 1.9693\n",
      "Iteration 33080: loss = 2.2155\n",
      "Iteration 33090: loss = 2.4135\n",
      "Iteration 33100: loss = 2.7975\n",
      "Iteration 33110: loss = 2.5610\n",
      "Iteration 33120: loss = 2.8116\n",
      "Iteration 33130: loss = 2.3789\n",
      "Iteration 33140: loss = 2.2565\n",
      "Iteration 33150: loss = 2.0690\n",
      "Iteration 33160: loss = 2.4218\n",
      "Iteration 33170: loss = 2.6996\n",
      "Iteration 33180: loss = 2.6807\n",
      "Iteration 33190: loss = 2.3662\n",
      "Iteration 33200: loss = 2.4242\n",
      "Iteration 33210: loss = 2.2823\n",
      "Iteration 33220: loss = 2.1811\n",
      "Iteration 33230: loss = 2.1535\n",
      "Iteration 33240: loss = 2.6796\n",
      "Iteration 33250: loss = 2.3786\n",
      "Iteration 33260: loss = 2.2961\n",
      "Iteration 33270: loss = 2.1587\n",
      "Iteration 33280: loss = 2.8073\n",
      "Iteration 33290: loss = 2.8521\n",
      "Iteration 33300: loss = 2.4845\n",
      "Iteration 33310: loss = 2.7765\n",
      "Iteration 33320: loss = 2.5620\n",
      "Iteration 33330: loss = 2.0476\n",
      "Iteration 33340: loss = 2.9656\n",
      "Iteration 33350: loss = 2.8796\n",
      "Iteration 33360: loss = 2.5292\n",
      "Iteration 33370: loss = 2.4690\n",
      "Iteration 33380: loss = 2.4330\n",
      "Iteration 33390: loss = 2.6030\n",
      "Iteration 33400: loss = 2.6153\n",
      "Iteration 33410: loss = 2.4158\n",
      "Iteration 33420: loss = 2.3494\n",
      "Iteration 33430: loss = 2.1341\n",
      "Iteration 33440: loss = 2.5093\n",
      "Iteration 33450: loss = 2.9651\n",
      "Iteration 33460: loss = 2.5647\n",
      "Iteration 33470: loss = 2.7812\n",
      "Iteration 33480: loss = 2.2596\n",
      "Iteration 33490: loss = 2.0576\n",
      "Iteration 33500: loss = 2.5600\n",
      "Iteration 33510: loss = 2.4374\n",
      "Iteration 33520: loss = 2.5414\n",
      "Iteration 33530: loss = 2.4902\n",
      "Iteration 33540: loss = 2.9557\n",
      "Iteration 33550: loss = 2.5935\n",
      "Iteration 33560: loss = 2.4479\n",
      "Iteration 33570: loss = 2.4790\n",
      "Iteration 33580: loss = 2.5798\n",
      "Iteration 33590: loss = 2.4841\n",
      "Iteration 33600: loss = 2.6105\n",
      "Iteration 33610: loss = 2.7380\n",
      "Iteration 33620: loss = 2.4508\n",
      "Iteration 33630: loss = 2.4638\n",
      "Iteration 33640: loss = 2.5201\n",
      "Iteration 33650: loss = 2.5672\n",
      "Iteration 33660: loss = 2.2642\n",
      "Iteration 33670: loss = 2.6217\n",
      "Iteration 33680: loss = 2.2708\n",
      "Iteration 33690: loss = 2.4652\n",
      "Iteration 33700: loss = 2.3138\n",
      "Iteration 33710: loss = 2.2676\n",
      "Iteration 33720: loss = 2.5421\n",
      "Iteration 33730: loss = 2.5063\n",
      "Iteration 33740: loss = 2.4893\n",
      "Iteration 33750: loss = 2.8360\n",
      "Iteration 33760: loss = 2.7350\n",
      "Iteration 33770: loss = 2.4299\n",
      "Iteration 33780: loss = 2.3362\n",
      "Iteration 33790: loss = 2.2946\n",
      "Iteration 33800: loss = 2.5838\n",
      "Iteration 33810: loss = 2.4495\n",
      "Iteration 33820: loss = 2.9060\n",
      "Iteration 33830: loss = 2.8909\n",
      "Iteration 33840: loss = 2.2863\n",
      "Iteration 33850: loss = 2.6916\n",
      "Iteration 33860: loss = 2.2907\n",
      "Iteration 33870: loss = 2.3187\n",
      "Iteration 33880: loss = 2.9919\n",
      "Iteration 33890: loss = 2.5614\n",
      "Iteration 33900: loss = 2.4220\n",
      "Iteration 33910: loss = 2.6147\n",
      "Iteration 33920: loss = 2.3495\n",
      "Iteration 33930: loss = 2.4629\n",
      "Iteration 33940: loss = 2.4944\n",
      "Iteration 33950: loss = 2.4702\n",
      "Iteration 33960: loss = 2.6135\n",
      "Iteration 33970: loss = 2.6409\n",
      "Iteration 33980: loss = 2.2244\n",
      "Iteration 33990: loss = 2.2002\n",
      "Iteration 34000: loss = 2.5379\n",
      "Iteration 34010: loss = 2.2054\n",
      "Iteration 34020: loss = 2.6734\n",
      "Iteration 34030: loss = 2.6034\n",
      "Iteration 34040: loss = 2.6116\n",
      "Iteration 34050: loss = 2.3558\n",
      "Iteration 34060: loss = 2.0593\n",
      "Iteration 34070: loss = 2.6025\n",
      "Iteration 34080: loss = 2.3142\n",
      "Iteration 34090: loss = 2.2892\n",
      "Iteration 34100: loss = 2.4805\n",
      "Iteration 34110: loss = 2.5429\n",
      "Iteration 34120: loss = 2.6146\n",
      "Iteration 34130: loss = 2.2914\n",
      "Iteration 34140: loss = 2.2735\n",
      "Iteration 34150: loss = 2.8225\n",
      "Iteration 34160: loss = 2.4395\n",
      "Iteration 34170: loss = 2.5227\n",
      "Iteration 34180: loss = 2.2834\n",
      "Iteration 34190: loss = 2.7647\n",
      "Iteration 34200: loss = 2.1471\n",
      "Iteration 34210: loss = 3.0158\n",
      "Iteration 34220: loss = 2.5056\n",
      "Iteration 34230: loss = 2.4171\n",
      "Iteration 34240: loss = 2.6654\n",
      "Iteration 34250: loss = 2.8815\n",
      "Iteration 34260: loss = 2.5832\n",
      "Iteration 34270: loss = 2.4558\n",
      "Iteration 34280: loss = 2.5627\n",
      "Iteration 34290: loss = 2.5392\n",
      "Iteration 34300: loss = 2.5889\n",
      "Iteration 34310: loss = 2.7425\n",
      "Iteration 34320: loss = 2.1169\n",
      "Iteration 34330: loss = 2.4457\n",
      "Iteration 34340: loss = 2.5742\n",
      "Iteration 34350: loss = 2.6723\n",
      "Iteration 34360: loss = 2.6745\n",
      "Iteration 34370: loss = 2.5076\n",
      "Iteration 34380: loss = 2.4584\n",
      "Iteration 34390: loss = 2.4177\n",
      "Iteration 34400: loss = 2.4797\n",
      "Iteration 34410: loss = 2.7070\n",
      "Iteration 34420: loss = 2.4471\n",
      "Iteration 34430: loss = 2.3444\n",
      "Iteration 34440: loss = 2.3812\n",
      "Iteration 34450: loss = 2.9125\n",
      "Iteration 34460: loss = 2.8002\n",
      "Iteration 34470: loss = 2.5374\n",
      "Iteration 34480: loss = 2.4015\n",
      "Iteration 34490: loss = 2.6742\n",
      "Iteration 34500: loss = 2.7139\n",
      "Iteration 34510: loss = 2.3769\n",
      "Iteration 34520: loss = 2.3106\n",
      "Iteration 34530: loss = 2.4871\n",
      "Iteration 34540: loss = 2.2290\n",
      "Iteration 34550: loss = 2.8878\n",
      "Iteration 34560: loss = 2.2695\n",
      "Iteration 34570: loss = 2.4398\n",
      "Iteration 34580: loss = 2.4736\n",
      "Iteration 34590: loss = 2.4194\n",
      "Iteration 34600: loss = 2.5115\n",
      "Iteration 34610: loss = 2.1356\n",
      "Iteration 34620: loss = 2.6087\n",
      "Iteration 34630: loss = 2.6590\n",
      "Iteration 34640: loss = 2.2639\n",
      "Iteration 34650: loss = 2.3092\n",
      "Iteration 34660: loss = 2.7208\n",
      "Iteration 34670: loss = 2.3619\n",
      "Iteration 34680: loss = 2.3175\n",
      "Iteration 34690: loss = 2.5494\n",
      "Iteration 34700: loss = 2.4840\n",
      "Iteration 34710: loss = 2.3557\n",
      "Iteration 34720: loss = 2.5845\n",
      "Iteration 34730: loss = 2.4808\n",
      "Iteration 34740: loss = 2.5457\n",
      "Iteration 34750: loss = 2.1505\n",
      "Iteration 34760: loss = 2.7093\n",
      "Iteration 34770: loss = 2.4384\n",
      "Iteration 34780: loss = 2.8997\n",
      "Iteration 34790: loss = 2.5519\n",
      "Iteration 34800: loss = 2.3758\n",
      "Iteration 34810: loss = 2.4877\n",
      "Iteration 34820: loss = 2.7495\n",
      "Iteration 34830: loss = 3.0606\n",
      "Iteration 34840: loss = 2.1834\n",
      "Iteration 34850: loss = 2.2290\n",
      "Iteration 34860: loss = 3.0198\n",
      "Iteration 34870: loss = 2.2372\n",
      "Iteration 34880: loss = 2.5932\n",
      "Iteration 34890: loss = 2.1440\n",
      "Iteration 34900: loss = 2.0223\n",
      "Iteration 34910: loss = 2.7629\n",
      "Iteration 34920: loss = 2.8057\n",
      "Iteration 34930: loss = 2.2573\n",
      "Iteration 34940: loss = 2.1540\n",
      "Iteration 34950: loss = 2.4906\n",
      "Iteration 34960: loss = 2.4265\n",
      "Iteration 34970: loss = 2.5311\n",
      "Iteration 34980: loss = 2.5725\n",
      "Iteration 34990: loss = 2.7181\n",
      "Iteration 35000: loss = 2.7132\n",
      "Iteration 35010: loss = 2.7536\n",
      "Iteration 35020: loss = 2.4537\n",
      "Iteration 35030: loss = 2.7107\n",
      "Iteration 35040: loss = 2.8618\n",
      "Iteration 35050: loss = 2.8380\n",
      "Iteration 35060: loss = 2.7758\n",
      "Iteration 35070: loss = 2.5473\n",
      "Iteration 35080: loss = 2.8563\n",
      "Iteration 35090: loss = 2.1098\n",
      "Iteration 35100: loss = 2.2697\n",
      "Iteration 35110: loss = 2.7848\n",
      "Iteration 35120: loss = 2.8310\n",
      "Iteration 35130: loss = 2.2627\n",
      "Iteration 35140: loss = 2.8409\n",
      "Iteration 35150: loss = 2.3809\n",
      "Iteration 35160: loss = 2.7159\n",
      "Iteration 35170: loss = 2.6573\n",
      "Iteration 35180: loss = 2.4846\n",
      "Iteration 35190: loss = 2.4264\n",
      "Iteration 35200: loss = 2.6454\n",
      "Iteration 35210: loss = 2.7749\n",
      "Iteration 35220: loss = 2.5204\n",
      "Iteration 35230: loss = 2.7812\n",
      "Iteration 35240: loss = 2.7525\n",
      "Iteration 35250: loss = 2.2538\n",
      "Iteration 35260: loss = 2.7980\n",
      "Iteration 35270: loss = 2.5357\n",
      "Iteration 35280: loss = 2.7436\n",
      "Iteration 35290: loss = 2.4831\n",
      "Iteration 35300: loss = 2.1976\n",
      "Iteration 35310: loss = 2.4184\n",
      "Iteration 35320: loss = 2.7762\n",
      "Iteration 35330: loss = 2.3338\n",
      "Iteration 35340: loss = 2.8253\n",
      "Iteration 35350: loss = 3.0005\n",
      "Iteration 35360: loss = 2.8436\n",
      "Iteration 35370: loss = 2.3325\n",
      "Iteration 35380: loss = 2.3044\n",
      "Iteration 35390: loss = 2.8569\n",
      "Iteration 35400: loss = 2.4385\n",
      "Iteration 35410: loss = 2.2003\n",
      "Iteration 35420: loss = 2.5848\n",
      "Iteration 35430: loss = 2.5597\n",
      "Iteration 35440: loss = 2.2585\n",
      "Iteration 35450: loss = 2.3075\n",
      "Iteration 35460: loss = 2.2570\n",
      "Iteration 35470: loss = 2.3760\n",
      "Iteration 35480: loss = 2.6649\n",
      "Iteration 35490: loss = 2.4434\n",
      "Iteration 35500: loss = 2.6969\n",
      "Iteration 35510: loss = 2.4668\n",
      "Iteration 35520: loss = 2.3201\n",
      "Iteration 35530: loss = 2.3634\n",
      "Iteration 35540: loss = 2.9324\n",
      "Iteration 35550: loss = 2.3870\n",
      "Iteration 35560: loss = 2.9510\n",
      "Iteration 35570: loss = 2.6799\n",
      "Iteration 35580: loss = 2.9641\n",
      "Iteration 35590: loss = 2.6438\n",
      "Iteration 35600: loss = 2.3534\n",
      "Iteration 35610: loss = 2.4910\n",
      "Iteration 35620: loss = 2.4346\n",
      "Iteration 35630: loss = 2.7024\n",
      "Iteration 35640: loss = 2.3951\n",
      "Iteration 35650: loss = 2.3975\n",
      "Iteration 35660: loss = 2.4972\n",
      "Iteration 35670: loss = 2.5618\n",
      "Iteration 35680: loss = 2.8202\n",
      "Iteration 35690: loss = 2.4124\n",
      "Iteration 35700: loss = 2.5649\n",
      "Iteration 35710: loss = 2.5788\n",
      "Iteration 35720: loss = 2.6007\n",
      "Iteration 35730: loss = 2.7390\n",
      "Iteration 35740: loss = 2.0131\n",
      "Iteration 35750: loss = 2.3945\n",
      "Iteration 35760: loss = 2.3789\n",
      "Iteration 35770: loss = 2.2038\n",
      "Iteration 35780: loss = 2.6102\n",
      "Iteration 35790: loss = 2.3415\n",
      "Iteration 35800: loss = 2.5543\n",
      "Iteration 35810: loss = 2.1443\n",
      "Iteration 35820: loss = 2.6292\n",
      "Iteration 35830: loss = 2.2630\n",
      "Iteration 35840: loss = 2.4921\n",
      "Iteration 35850: loss = 2.6003\n",
      "Iteration 35860: loss = 2.7838\n",
      "Iteration 35870: loss = 2.6562\n",
      "Iteration 35880: loss = 2.1420\n",
      "Iteration 35890: loss = 2.6377\n",
      "Iteration 35900: loss = 2.4120\n",
      "Iteration 35910: loss = 2.6706\n",
      "Iteration 35920: loss = 2.3605\n",
      "Iteration 35930: loss = 2.6155\n",
      "Iteration 35940: loss = 2.4840\n",
      "Iteration 35950: loss = 2.6140\n",
      "Iteration 35960: loss = 2.4536\n",
      "Iteration 35970: loss = 2.8402\n",
      "Iteration 35980: loss = 2.3210\n",
      "Iteration 35990: loss = 2.5579\n",
      "Iteration 36000: loss = 2.4116\n",
      "Iteration 36010: loss = 2.3996\n",
      "Iteration 36020: loss = 2.6706\n",
      "Iteration 36030: loss = 1.9890\n",
      "Iteration 36040: loss = 2.6286\n",
      "Iteration 36050: loss = 2.4551\n",
      "Iteration 36060: loss = 3.0301\n",
      "Iteration 36070: loss = 2.5365\n",
      "Iteration 36080: loss = 2.1419\n",
      "Iteration 36090: loss = 2.3023\n",
      "Iteration 36100: loss = 2.8192\n",
      "Iteration 36110: loss = 2.3791\n",
      "Iteration 36120: loss = 2.5235\n",
      "Iteration 36130: loss = 2.7503\n",
      "Iteration 36140: loss = 2.2566\n",
      "Iteration 36150: loss = 2.7664\n",
      "Iteration 36160: loss = 2.1577\n",
      "Iteration 36170: loss = 2.3490\n",
      "Iteration 36180: loss = 2.2767\n",
      "Iteration 36190: loss = 2.4263\n",
      "Iteration 36200: loss = 2.8430\n",
      "Iteration 36210: loss = 2.4194\n",
      "Iteration 36220: loss = 2.7622\n",
      "Iteration 36230: loss = 2.7234\n",
      "Iteration 36240: loss = 2.4931\n",
      "Iteration 36250: loss = 2.2190\n",
      "Iteration 36260: loss = 2.3354\n",
      "Iteration 36270: loss = 2.2109\n",
      "Iteration 36280: loss = 2.4574\n",
      "Iteration 36290: loss = 2.3613\n",
      "Iteration 36300: loss = 2.6674\n",
      "Iteration 36310: loss = 2.2933\n",
      "Iteration 36320: loss = 2.5955\n",
      "Iteration 36330: loss = 2.3057\n",
      "Iteration 36340: loss = 2.5148\n",
      "Iteration 36350: loss = 2.3955\n",
      "Iteration 36360: loss = 2.3870\n",
      "Iteration 36370: loss = 2.6041\n",
      "Iteration 36380: loss = 2.8594\n",
      "Iteration 36390: loss = 2.4630\n",
      "Iteration 36400: loss = 2.5654\n",
      "Iteration 36410: loss = 2.6216\n",
      "Iteration 36420: loss = 2.6918\n",
      "Iteration 36430: loss = 2.2424\n",
      "Iteration 36440: loss = 2.4787\n",
      "Iteration 36450: loss = 2.8158\n",
      "Iteration 36460: loss = 2.3784\n",
      "Iteration 36470: loss = 2.2220\n",
      "Iteration 36480: loss = 2.8257\n",
      "Iteration 36490: loss = 2.2341\n",
      "Iteration 36500: loss = 2.5915\n",
      "Iteration 36510: loss = 2.5578\n",
      "Iteration 36520: loss = 2.5024\n",
      "Iteration 36530: loss = 2.2018\n",
      "Iteration 36540: loss = 2.3802\n",
      "Iteration 36550: loss = 2.4084\n",
      "Iteration 36560: loss = 1.9327\n",
      "Iteration 36570: loss = 2.9782\n",
      "Iteration 36580: loss = 2.6645\n",
      "Iteration 36590: loss = 2.2927\n",
      "Iteration 36600: loss = 2.1858\n",
      "Iteration 36610: loss = 2.5235\n",
      "Iteration 36620: loss = 2.6142\n",
      "Iteration 36630: loss = 2.6039\n",
      "Iteration 36640: loss = 2.0146\n",
      "Iteration 36650: loss = 2.5633\n",
      "Iteration 36660: loss = 2.5139\n",
      "Iteration 36670: loss = 2.3448\n",
      "Iteration 36680: loss = 2.7864\n",
      "Iteration 36690: loss = 2.2869\n",
      "Iteration 36700: loss = 2.3630\n",
      "Iteration 36710: loss = 2.6619\n",
      "Iteration 36720: loss = 2.1587\n",
      "Iteration 36730: loss = 2.0926\n",
      "Iteration 36740: loss = 2.3636\n",
      "Iteration 36750: loss = 2.6048\n",
      "Iteration 36760: loss = 2.6185\n",
      "Iteration 36770: loss = 2.3277\n",
      "Iteration 36780: loss = 2.5778\n",
      "Iteration 36790: loss = 2.5292\n",
      "Iteration 36800: loss = 2.6595\n",
      "Iteration 36810: loss = 2.8062\n",
      "Iteration 36820: loss = 2.3178\n",
      "Iteration 36830: loss = 2.5988\n",
      "Iteration 36840: loss = 2.2404\n",
      "Iteration 36850: loss = 2.3444\n",
      "Iteration 36860: loss = 2.5425\n",
      "Iteration 36870: loss = 2.4783\n",
      "Iteration 36880: loss = 2.4944\n",
      "Iteration 36890: loss = 2.6449\n",
      "Iteration 36900: loss = 2.2694\n",
      "Iteration 36910: loss = 2.4423\n",
      "Iteration 36920: loss = 2.1255\n",
      "Iteration 36930: loss = 2.6089\n",
      "Iteration 36940: loss = 2.4257\n",
      "Iteration 36950: loss = 2.4382\n",
      "Iteration 36960: loss = 2.7238\n",
      "Iteration 36970: loss = 2.4808\n",
      "Iteration 36980: loss = 2.5276\n",
      "Iteration 36990: loss = 2.6917\n",
      "Iteration 37000: loss = 2.3711\n",
      "Iteration 37010: loss = 2.6218\n",
      "Iteration 37020: loss = 2.6200\n",
      "Iteration 37030: loss = 2.3530\n",
      "Iteration 37040: loss = 2.3834\n",
      "Iteration 37050: loss = 2.2207\n",
      "Iteration 37060: loss = 2.4323\n",
      "Iteration 37070: loss = 2.6820\n",
      "Iteration 37080: loss = 2.5280\n",
      "Iteration 37090: loss = 2.5765\n",
      "Iteration 37100: loss = 2.4334\n",
      "Iteration 37110: loss = 2.9876\n",
      "Iteration 37120: loss = 2.6945\n",
      "Iteration 37130: loss = 2.3316\n",
      "Iteration 37140: loss = 2.5911\n",
      "Iteration 37150: loss = 2.6965\n",
      "Iteration 37160: loss = 2.4465\n",
      "Iteration 37170: loss = 2.3750\n",
      "Iteration 37180: loss = 2.2720\n",
      "Iteration 37190: loss = 2.3931\n",
      "Iteration 37200: loss = 2.7926\n",
      "Iteration 37210: loss = 2.4742\n",
      "Iteration 37220: loss = 2.6802\n",
      "Iteration 37230: loss = 2.7366\n",
      "Iteration 37240: loss = 2.4245\n",
      "Iteration 37250: loss = 2.6462\n",
      "Iteration 37260: loss = 2.2162\n",
      "Iteration 37270: loss = 2.4092\n",
      "Iteration 37280: loss = 2.7198\n",
      "Iteration 37290: loss = 2.4960\n",
      "Iteration 37300: loss = 2.5261\n",
      "Iteration 37310: loss = 2.4052\n",
      "Iteration 37320: loss = 2.5528\n",
      "Iteration 37330: loss = 2.0608\n",
      "Iteration 37340: loss = 2.6936\n",
      "Iteration 37350: loss = 2.6412\n",
      "Iteration 37360: loss = 2.5512\n",
      "Iteration 37370: loss = 2.7168\n",
      "Iteration 37380: loss = 2.8701\n",
      "Iteration 37390: loss = 2.3723\n",
      "Iteration 37400: loss = 2.1777\n",
      "Iteration 37410: loss = 2.5337\n",
      "Iteration 37420: loss = 2.4458\n",
      "Iteration 37430: loss = 2.9018\n",
      "Iteration 37440: loss = 2.5300\n",
      "Iteration 37450: loss = 2.3205\n",
      "Iteration 37460: loss = 2.7044\n",
      "Iteration 37470: loss = 2.4062\n",
      "Iteration 37480: loss = 2.4395\n",
      "Iteration 37490: loss = 2.3701\n",
      "Iteration 37500: loss = 2.5012\n",
      "Iteration 37510: loss = 2.5100\n",
      "Iteration 37520: loss = 2.5476\n",
      "Iteration 37530: loss = 2.3970\n",
      "Iteration 37540: loss = 2.1606\n",
      "Iteration 37550: loss = 2.4569\n",
      "Iteration 37560: loss = 2.6642\n",
      "Iteration 37570: loss = 2.1749\n",
      "Iteration 37580: loss = 2.5284\n",
      "Iteration 37590: loss = 2.5383\n",
      "Iteration 37600: loss = 2.5951\n",
      "Iteration 37610: loss = 2.5130\n",
      "Iteration 37620: loss = 2.7025\n",
      "Iteration 37630: loss = 2.4744\n",
      "Iteration 37640: loss = 2.5140\n",
      "Iteration 37650: loss = 2.3458\n",
      "Iteration 37660: loss = 2.7827\n",
      "Iteration 37670: loss = 2.3407\n",
      "Iteration 37680: loss = 2.6547\n",
      "Iteration 37690: loss = 2.5117\n",
      "Iteration 37700: loss = 2.5242\n",
      "Iteration 37710: loss = 2.6174\n",
      "Iteration 37720: loss = 2.3749\n",
      "Iteration 37730: loss = 2.3730\n",
      "Iteration 37740: loss = 2.7830\n",
      "Iteration 37750: loss = 2.4421\n",
      "Iteration 37760: loss = 2.3069\n",
      "Iteration 37770: loss = 2.7389\n",
      "Iteration 37780: loss = 2.4402\n",
      "Iteration 37790: loss = 2.1548\n",
      "Iteration 37800: loss = 2.6098\n",
      "Iteration 37810: loss = 2.8667\n",
      "Iteration 37820: loss = 2.3023\n",
      "Iteration 37830: loss = 2.4062\n",
      "Iteration 37840: loss = 3.1249\n",
      "Iteration 37850: loss = 2.2697\n",
      "Iteration 37860: loss = 2.7381\n",
      "Iteration 37870: loss = 2.7368\n",
      "Iteration 37880: loss = 2.5098\n",
      "Iteration 37890: loss = 2.5923\n",
      "Iteration 37900: loss = 2.8918\n",
      "Iteration 37910: loss = 2.6099\n",
      "Iteration 37920: loss = 2.5199\n",
      "Iteration 37930: loss = 2.3744\n",
      "Iteration 37940: loss = 2.1909\n",
      "Iteration 37950: loss = 2.9815\n",
      "Iteration 37960: loss = 2.4174\n",
      "Iteration 37970: loss = 2.4577\n",
      "Iteration 37980: loss = 2.5516\n",
      "Iteration 37990: loss = 2.6427\n",
      "Iteration 38000: loss = 2.2900\n",
      "Iteration 38010: loss = 2.2634\n",
      "Iteration 38020: loss = 2.2084\n",
      "Iteration 38030: loss = 2.4112\n",
      "Iteration 38040: loss = 2.6747\n",
      "Iteration 38050: loss = 2.6174\n",
      "Iteration 38060: loss = 2.4977\n",
      "Iteration 38070: loss = 2.3768\n",
      "Iteration 38080: loss = 2.4309\n",
      "Iteration 38090: loss = 2.7719\n",
      "Iteration 38100: loss = 2.5660\n",
      "Iteration 38110: loss = 2.3896\n",
      "Iteration 38120: loss = 2.7709\n",
      "Iteration 38130: loss = 2.6904\n",
      "Iteration 38140: loss = 2.7932\n",
      "Iteration 38150: loss = 2.3077\n",
      "Iteration 38160: loss = 1.9708\n",
      "Iteration 38170: loss = 2.5471\n",
      "Iteration 38180: loss = 3.0212\n",
      "Iteration 38190: loss = 2.4625\n",
      "Iteration 38200: loss = 2.4342\n",
      "Iteration 38210: loss = 2.5568\n",
      "Iteration 38220: loss = 2.1391\n",
      "Iteration 38230: loss = 2.5755\n",
      "Iteration 38240: loss = 2.3918\n",
      "Iteration 38250: loss = 2.5121\n",
      "Iteration 38260: loss = 2.7353\n",
      "Iteration 38270: loss = 2.6400\n",
      "Iteration 38280: loss = 2.3271\n",
      "Iteration 38290: loss = 2.4101\n",
      "Iteration 38300: loss = 2.6288\n",
      "Iteration 38310: loss = 2.3615\n",
      "Iteration 38320: loss = 2.5002\n",
      "Iteration 38330: loss = 2.4904\n",
      "Iteration 38340: loss = 2.8357\n",
      "Iteration 38350: loss = 2.4459\n",
      "Iteration 38360: loss = 2.3138\n",
      "Iteration 38370: loss = 2.4410\n",
      "Iteration 38380: loss = 2.5565\n",
      "Iteration 38390: loss = 2.3167\n",
      "Iteration 38400: loss = 2.4511\n",
      "Iteration 38410: loss = 2.6983\n",
      "Iteration 38420: loss = 2.4021\n",
      "Iteration 38430: loss = 2.2766\n",
      "Iteration 38440: loss = 2.2201\n",
      "Iteration 38450: loss = 2.5302\n",
      "Iteration 38460: loss = 2.8473\n",
      "Iteration 38470: loss = 2.4117\n",
      "Iteration 38480: loss = 2.5903\n",
      "Iteration 38490: loss = 2.2908\n",
      "Iteration 38500: loss = 2.6817\n",
      "Iteration 38510: loss = 2.4798\n",
      "Iteration 38520: loss = 2.7033\n",
      "Iteration 38530: loss = 2.7075\n",
      "Iteration 38540: loss = 2.5091\n",
      "Iteration 38550: loss = 2.6266\n",
      "Iteration 38560: loss = 2.7486\n",
      "Iteration 38570: loss = 2.7224\n",
      "Iteration 38580: loss = 2.2683\n",
      "Iteration 38590: loss = 2.4772\n",
      "Iteration 38600: loss = 2.9372\n",
      "Iteration 38610: loss = 2.7192\n",
      "Iteration 38620: loss = 2.8863\n",
      "Iteration 38630: loss = 2.5536\n",
      "Iteration 38640: loss = 2.7761\n",
      "Iteration 38650: loss = 2.4055\n",
      "Iteration 38660: loss = 2.5072\n",
      "Iteration 38670: loss = 2.5941\n",
      "Iteration 38680: loss = 2.7579\n",
      "Iteration 38690: loss = 2.6546\n",
      "Iteration 38700: loss = 2.3590\n",
      "Iteration 38710: loss = 2.6271\n",
      "Iteration 38720: loss = 2.5111\n",
      "Iteration 38730: loss = 2.6878\n",
      "Iteration 38740: loss = 2.2290\n",
      "Iteration 38750: loss = 2.7595\n",
      "Iteration 38760: loss = 2.3228\n",
      "Iteration 38770: loss = 2.3028\n",
      "Iteration 38780: loss = 2.5947\n",
      "Iteration 38790: loss = 2.6707\n",
      "Iteration 38800: loss = 2.9793\n",
      "Iteration 38810: loss = 2.7836\n",
      "Iteration 38820: loss = 2.3067\n",
      "Iteration 38830: loss = 2.6452\n",
      "Iteration 38840: loss = 2.8501\n",
      "Iteration 38850: loss = 2.6674\n",
      "Iteration 38860: loss = 2.2187\n",
      "Iteration 38870: loss = 2.6652\n",
      "Iteration 38880: loss = 1.7800\n",
      "Iteration 38890: loss = 2.3160\n",
      "Iteration 38900: loss = 2.3738\n",
      "Iteration 38910: loss = 2.7994\n",
      "Iteration 38920: loss = 2.2950\n",
      "Iteration 38930: loss = 2.6889\n",
      "Iteration 38940: loss = 2.7579\n",
      "Iteration 38950: loss = 2.4623\n",
      "Iteration 38960: loss = 2.6625\n",
      "Iteration 38970: loss = 2.7273\n",
      "Iteration 38980: loss = 2.4854\n",
      "Iteration 38990: loss = 2.1103\n",
      "Iteration 39000: loss = 2.0723\n",
      "Iteration 39010: loss = 2.5609\n",
      "Iteration 39020: loss = 2.5782\n",
      "Iteration 39030: loss = 2.3280\n",
      "Iteration 39040: loss = 2.4364\n",
      "Iteration 39050: loss = 2.4289\n",
      "Iteration 39060: loss = 2.5807\n",
      "Iteration 39070: loss = 2.3760\n",
      "Iteration 39080: loss = 2.7981\n",
      "Iteration 39090: loss = 2.4161\n",
      "Iteration 39100: loss = 2.6022\n",
      "Iteration 39110: loss = 2.1204\n",
      "Iteration 39120: loss = 2.3726\n",
      "Iteration 39130: loss = 2.9341\n",
      "Iteration 39140: loss = 2.5577\n",
      "Iteration 39150: loss = 2.3587\n",
      "Iteration 39160: loss = 2.2214\n",
      "Iteration 39170: loss = 2.2486\n",
      "Iteration 39180: loss = 2.6280\n",
      "Iteration 39190: loss = 2.3007\n",
      "Iteration 39200: loss = 2.6349\n",
      "Iteration 39210: loss = 2.3204\n",
      "Iteration 39220: loss = 2.3427\n",
      "Iteration 39230: loss = 2.7226\n",
      "Iteration 39240: loss = 2.4846\n",
      "Iteration 39250: loss = 2.5647\n",
      "Iteration 39260: loss = 2.6871\n",
      "Iteration 39270: loss = 2.4788\n",
      "Iteration 39280: loss = 2.3267\n",
      "Iteration 39290: loss = 2.0912\n",
      "Iteration 39300: loss = 2.4417\n",
      "Iteration 39310: loss = 2.4078\n",
      "Iteration 39320: loss = 2.7203\n",
      "Iteration 39330: loss = 2.0999\n",
      "Iteration 39340: loss = 2.5538\n",
      "Iteration 39350: loss = 2.3786\n",
      "Iteration 39360: loss = 2.2214\n",
      "Iteration 39370: loss = 2.4132\n",
      "Iteration 39380: loss = 2.5688\n",
      "Iteration 39390: loss = 2.3916\n",
      "Iteration 39400: loss = 1.9808\n",
      "Iteration 39410: loss = 2.4093\n",
      "Iteration 39420: loss = 2.4550\n",
      "Iteration 39430: loss = 2.8360\n",
      "Iteration 39440: loss = 2.2424\n",
      "Iteration 39450: loss = 2.3225\n",
      "Iteration 39460: loss = 2.7829\n",
      "Iteration 39470: loss = 2.0011\n",
      "Iteration 39480: loss = 2.5130\n",
      "Iteration 39490: loss = 2.2090\n",
      "Iteration 39500: loss = 2.7202\n",
      "Iteration 39510: loss = 2.7060\n",
      "Iteration 39520: loss = 2.5392\n",
      "Iteration 39530: loss = 2.4324\n",
      "Iteration 39540: loss = 2.2980\n",
      "Iteration 39550: loss = 2.5234\n",
      "Iteration 39560: loss = 2.6535\n",
      "Iteration 39570: loss = 2.4639\n",
      "Iteration 39580: loss = 2.6455\n",
      "Iteration 39590: loss = 2.6949\n",
      "Iteration 39600: loss = 2.5795\n",
      "Iteration 39610: loss = 2.5815\n",
      "Iteration 39620: loss = 2.2383\n",
      "Iteration 39630: loss = 2.5030\n",
      "Iteration 39640: loss = 3.0014\n",
      "Iteration 39650: loss = 2.4633\n",
      "Iteration 39660: loss = 2.3749\n",
      "Iteration 39670: loss = 2.5049\n",
      "Iteration 39680: loss = 2.2626\n",
      "Iteration 39690: loss = 2.6929\n",
      "Iteration 39700: loss = 2.7983\n",
      "Iteration 39710: loss = 2.3569\n",
      "Iteration 39720: loss = 2.5237\n",
      "Iteration 39730: loss = 2.5478\n",
      "Iteration 39740: loss = 2.8910\n",
      "Iteration 39750: loss = 2.5681\n",
      "Iteration 39760: loss = 2.4639\n",
      "Iteration 39770: loss = 2.4842\n",
      "Iteration 39780: loss = 2.5228\n",
      "Iteration 39790: loss = 2.7182\n",
      "Iteration 39800: loss = 2.1517\n",
      "Iteration 39810: loss = 2.2263\n",
      "Iteration 39820: loss = 2.6975\n",
      "Iteration 39830: loss = 2.6094\n",
      "Iteration 39840: loss = 2.5875\n",
      "Iteration 39850: loss = 2.5734\n",
      "Iteration 39860: loss = 2.1152\n",
      "Iteration 39870: loss = 2.4845\n",
      "Iteration 39880: loss = 2.5062\n",
      "Iteration 39890: loss = 2.6855\n",
      "Iteration 39900: loss = 2.5976\n",
      "Iteration 39910: loss = 2.5602\n",
      "Iteration 39920: loss = 2.4472\n",
      "Iteration 39930: loss = 2.4971\n",
      "Iteration 39940: loss = 2.4077\n",
      "Iteration 39950: loss = 2.3664\n",
      "Iteration 39960: loss = 2.6543\n",
      "Iteration 39970: loss = 2.2333\n",
      "Iteration 39980: loss = 2.8670\n",
      "Iteration 39990: loss = 2.7456\n",
      "Iteration 40000: loss = 2.6765\n",
      "Iteration 40010: loss = 2.5454\n",
      "Iteration 40020: loss = 2.5211\n",
      "Iteration 40030: loss = 2.1391\n",
      "Iteration 40040: loss = 2.5183\n",
      "Iteration 40050: loss = 2.6186\n",
      "Iteration 40060: loss = 2.4351\n",
      "Iteration 40070: loss = 2.5162\n",
      "Iteration 40080: loss = 2.6277\n",
      "Iteration 40090: loss = 2.6955\n",
      "Iteration 40100: loss = 2.5939\n",
      "Iteration 40110: loss = 2.5111\n",
      "Iteration 40120: loss = 2.4204\n",
      "Iteration 40130: loss = 2.7275\n",
      "Iteration 40140: loss = 2.3121\n",
      "Iteration 40150: loss = 2.3740\n",
      "Iteration 40160: loss = 2.3724\n",
      "Iteration 40170: loss = 2.4399\n",
      "Iteration 40180: loss = 2.7127\n",
      "Iteration 40190: loss = 2.6085\n",
      "Iteration 40200: loss = 2.3337\n",
      "Iteration 40210: loss = 2.7610\n",
      "Iteration 40220: loss = 2.2209\n",
      "Iteration 40230: loss = 2.5533\n",
      "Iteration 40240: loss = 2.2893\n",
      "Iteration 40250: loss = 2.5808\n",
      "Iteration 40260: loss = 2.2777\n",
      "Iteration 40270: loss = 2.3825\n",
      "Iteration 40280: loss = 2.3663\n",
      "Iteration 40290: loss = 2.1989\n",
      "Iteration 40300: loss = 2.0498\n",
      "Iteration 40310: loss = 2.5859\n",
      "Iteration 40320: loss = 2.9124\n",
      "Iteration 40330: loss = 2.6252\n",
      "Iteration 40340: loss = 2.7558\n",
      "Iteration 40350: loss = 2.3979\n",
      "Iteration 40360: loss = 2.8298\n",
      "Iteration 40370: loss = 2.4073\n",
      "Iteration 40380: loss = 2.7305\n",
      "Iteration 40390: loss = 2.4119\n",
      "Iteration 40400: loss = 2.4192\n",
      "Iteration 40410: loss = 2.5506\n",
      "Iteration 40420: loss = 2.1509\n",
      "Iteration 40430: loss = 2.2678\n",
      "Iteration 40440: loss = 2.3302\n",
      "Iteration 40450: loss = 2.5480\n",
      "Iteration 40460: loss = 2.4551\n",
      "Iteration 40470: loss = 2.4801\n",
      "Iteration 40480: loss = 2.4503\n",
      "Iteration 40490: loss = 2.4390\n",
      "Iteration 40500: loss = 2.6459\n",
      "Iteration 40510: loss = 2.5302\n",
      "Iteration 40520: loss = 2.4483\n",
      "Iteration 40530: loss = 2.4649\n",
      "Iteration 40540: loss = 2.7918\n",
      "Iteration 40550: loss = 3.1132\n",
      "Iteration 40560: loss = 2.4873\n",
      "Iteration 40570: loss = 2.3497\n",
      "Iteration 40580: loss = 2.3108\n",
      "Iteration 40590: loss = 2.6010\n",
      "Iteration 40600: loss = 2.6507\n",
      "Iteration 40610: loss = 2.6584\n",
      "Iteration 40620: loss = 2.0926\n",
      "Iteration 40630: loss = 2.4530\n",
      "Iteration 40640: loss = 3.2022\n",
      "Iteration 40650: loss = 2.8886\n",
      "Iteration 40660: loss = 2.7443\n",
      "Iteration 40670: loss = 2.6622\n",
      "Iteration 40680: loss = 2.6019\n",
      "Iteration 40690: loss = 2.7346\n",
      "Iteration 40700: loss = 2.1652\n",
      "Iteration 40710: loss = 2.6417\n",
      "Iteration 40720: loss = 2.5012\n",
      "Iteration 40730: loss = 2.4349\n",
      "Iteration 40740: loss = 2.3600\n",
      "Iteration 40750: loss = 2.3942\n",
      "Iteration 40760: loss = 2.0754\n",
      "Iteration 40770: loss = 2.6704\n",
      "Iteration 40780: loss = 2.5066\n",
      "Iteration 40790: loss = 2.2502\n",
      "Iteration 40800: loss = 2.3452\n",
      "Iteration 40810: loss = 2.7000\n",
      "Iteration 40820: loss = 2.2258\n",
      "Iteration 40830: loss = 2.4301\n",
      "Iteration 40840: loss = 2.7393\n",
      "Iteration 40850: loss = 2.3824\n",
      "Iteration 40860: loss = 2.3492\n",
      "Iteration 40870: loss = 2.2801\n",
      "Iteration 40880: loss = 2.6063\n",
      "Iteration 40890: loss = 2.8694\n",
      "Iteration 40900: loss = 2.9161\n",
      "Iteration 40910: loss = 2.3977\n",
      "Iteration 40920: loss = 2.4541\n",
      "Iteration 40930: loss = 2.5005\n",
      "Iteration 40940: loss = 2.4607\n",
      "Iteration 40950: loss = 2.6769\n",
      "Iteration 40960: loss = 2.0838\n",
      "Iteration 40970: loss = 2.7295\n",
      "Iteration 40980: loss = 2.6276\n",
      "Iteration 40990: loss = 2.5127\n",
      "Iteration 41000: loss = 3.0505\n",
      "Iteration 41010: loss = 2.5487\n",
      "Iteration 41020: loss = 2.6457\n",
      "Iteration 41030: loss = 2.3434\n",
      "Iteration 41040: loss = 2.7756\n",
      "Iteration 41050: loss = 2.7503\n",
      "Iteration 41060: loss = 2.4692\n",
      "Iteration 41070: loss = 2.5441\n",
      "Iteration 41080: loss = 2.3042\n",
      "Iteration 41090: loss = 2.5474\n",
      "Iteration 41100: loss = 2.7499\n",
      "Iteration 41110: loss = 2.2075\n",
      "Iteration 41120: loss = 2.1759\n",
      "Iteration 41130: loss = 2.6056\n",
      "Iteration 41140: loss = 2.2941\n",
      "Iteration 41150: loss = 2.2463\n",
      "Iteration 41160: loss = 2.7349\n",
      "Iteration 41170: loss = 3.0226\n",
      "Iteration 41180: loss = 2.7523\n",
      "Iteration 41190: loss = 2.8191\n",
      "Iteration 41200: loss = 2.3980\n",
      "Iteration 41210: loss = 2.2975\n",
      "Iteration 41220: loss = 2.4286\n",
      "Iteration 41230: loss = 2.6867\n",
      "Iteration 41240: loss = 2.6323\n",
      "Iteration 41250: loss = 2.6069\n",
      "Iteration 41260: loss = 2.5358\n",
      "Iteration 41270: loss = 2.5432\n",
      "Iteration 41280: loss = 2.2708\n",
      "Iteration 41290: loss = 2.6341\n",
      "Iteration 41300: loss = 2.6029\n",
      "Iteration 41310: loss = 2.2394\n",
      "Iteration 41320: loss = 2.7742\n",
      "Iteration 41330: loss = 2.5757\n",
      "Iteration 41340: loss = 2.1468\n",
      "Iteration 41350: loss = 2.2598\n",
      "Iteration 41360: loss = 2.9417\n",
      "Iteration 41370: loss = 2.3255\n",
      "Iteration 41380: loss = 2.4053\n",
      "Iteration 41390: loss = 2.7183\n",
      "Iteration 41400: loss = 2.2783\n",
      "Iteration 41410: loss = 2.0845\n",
      "Iteration 41420: loss = 2.8861\n",
      "Iteration 41430: loss = 2.7622\n",
      "Iteration 41440: loss = 2.0822\n",
      "Iteration 41450: loss = 2.3582\n",
      "Iteration 41460: loss = 2.4753\n",
      "Iteration 41470: loss = 2.7442\n",
      "Iteration 41480: loss = 2.4074\n",
      "Iteration 41490: loss = 2.4806\n",
      "Iteration 41500: loss = 2.5193\n",
      "Iteration 41510: loss = 2.3718\n",
      "Iteration 41520: loss = 2.5864\n",
      "Iteration 41530: loss = 2.6874\n",
      "Iteration 41540: loss = 2.7506\n",
      "Iteration 41550: loss = 2.2703\n",
      "Iteration 41560: loss = 2.5924\n",
      "Iteration 41570: loss = 2.4857\n",
      "Iteration 41580: loss = 2.6885\n",
      "Iteration 41590: loss = 2.5131\n",
      "Iteration 41600: loss = 2.8950\n",
      "Iteration 41610: loss = 2.6443\n",
      "Iteration 41620: loss = 2.6928\n",
      "Iteration 41630: loss = 2.4503\n",
      "Iteration 41640: loss = 2.5990\n",
      "Iteration 41650: loss = 2.2735\n",
      "Iteration 41660: loss = 2.6693\n",
      "Iteration 41670: loss = 2.3169\n",
      "Iteration 41680: loss = 2.4814\n",
      "Iteration 41690: loss = 2.6931\n",
      "Iteration 41700: loss = 2.3317\n",
      "Iteration 41710: loss = 2.0811\n",
      "Iteration 41720: loss = 2.4725\n",
      "Iteration 41730: loss = 2.3236\n",
      "Iteration 41740: loss = 2.3134\n",
      "Iteration 41750: loss = 2.2409\n",
      "Iteration 41760: loss = 2.2539\n",
      "Iteration 41770: loss = 2.1524\n",
      "Iteration 41780: loss = 2.4632\n",
      "Iteration 41790: loss = 2.2450\n",
      "Iteration 41800: loss = 2.3172\n",
      "Iteration 41810: loss = 2.5336\n",
      "Iteration 41820: loss = 2.2096\n",
      "Iteration 41830: loss = 2.2909\n",
      "Iteration 41840: loss = 2.3508\n",
      "Iteration 41850: loss = 2.4640\n",
      "Iteration 41860: loss = 2.5077\n",
      "Iteration 41870: loss = 2.5904\n",
      "Iteration 41880: loss = 2.2987\n",
      "Iteration 41890: loss = 2.8984\n",
      "Iteration 41900: loss = 2.1316\n",
      "Iteration 41910: loss = 2.4920\n",
      "Iteration 41920: loss = 2.4617\n",
      "Iteration 41930: loss = 2.2183\n",
      "Iteration 41940: loss = 2.3489\n",
      "Iteration 41950: loss = 2.5132\n",
      "Iteration 41960: loss = 2.4436\n",
      "Iteration 41970: loss = 2.5276\n",
      "Iteration 41980: loss = 2.6027\n",
      "Iteration 41990: loss = 2.2431\n",
      "Iteration 42000: loss = 2.6964\n",
      "Iteration 42010: loss = 2.8448\n",
      "Iteration 42020: loss = 2.2757\n",
      "Iteration 42030: loss = 2.4833\n",
      "Iteration 42040: loss = 2.1340\n",
      "Iteration 42050: loss = 2.5272\n",
      "Iteration 42060: loss = 2.4265\n",
      "Iteration 42070: loss = 2.8551\n",
      "Iteration 42080: loss = 2.5378\n",
      "Iteration 42090: loss = 1.9106\n",
      "Iteration 42100: loss = 2.7456\n",
      "Iteration 42110: loss = 2.7685\n",
      "Iteration 42120: loss = 2.3999\n",
      "Iteration 42130: loss = 2.4980\n",
      "Iteration 42140: loss = 2.1783\n",
      "Iteration 42150: loss = 2.3354\n",
      "Iteration 42160: loss = 2.2942\n",
      "Iteration 42170: loss = 2.4595\n",
      "Iteration 42180: loss = 2.0401\n",
      "Iteration 42190: loss = 2.5851\n",
      "Iteration 42200: loss = 2.4671\n",
      "Iteration 42210: loss = 2.2397\n",
      "Iteration 42220: loss = 2.3067\n",
      "Iteration 42230: loss = 2.4689\n",
      "Iteration 42240: loss = 2.5829\n",
      "Iteration 42250: loss = 2.5673\n",
      "Iteration 42260: loss = 2.4312\n",
      "Iteration 42270: loss = 2.3209\n",
      "Iteration 42280: loss = 2.1181\n",
      "Iteration 42290: loss = 2.8103\n",
      "Iteration 42300: loss = 2.1219\n",
      "Iteration 42310: loss = 2.3998\n",
      "Iteration 42320: loss = 2.5901\n",
      "Iteration 42330: loss = 2.5593\n",
      "Iteration 42340: loss = 2.3999\n",
      "Iteration 42350: loss = 2.2251\n",
      "Iteration 42360: loss = 2.6902\n",
      "Iteration 42370: loss = 2.5274\n",
      "Iteration 42380: loss = 2.3277\n",
      "Iteration 42390: loss = 2.3789\n",
      "Iteration 42400: loss = 2.4511\n",
      "Iteration 42410: loss = 3.0592\n",
      "Iteration 42420: loss = 2.6643\n",
      "Iteration 42430: loss = 2.4111\n",
      "Iteration 42440: loss = 2.6144\n",
      "Iteration 42450: loss = 2.5558\n",
      "Iteration 42460: loss = 2.6811\n",
      "Iteration 42470: loss = 2.3814\n",
      "Iteration 42480: loss = 2.9495\n",
      "Iteration 42490: loss = 2.8954\n",
      "Iteration 42500: loss = 2.4623\n",
      "Iteration 42510: loss = 2.4118\n",
      "Iteration 42520: loss = 2.5066\n",
      "Iteration 42530: loss = 2.2099\n",
      "Iteration 42540: loss = 2.5773\n",
      "Iteration 42550: loss = 2.8178\n",
      "Iteration 42560: loss = 2.4593\n",
      "Iteration 42570: loss = 2.2921\n",
      "Iteration 42580: loss = 2.0974\n",
      "Iteration 42590: loss = 2.6848\n",
      "Iteration 42600: loss = 2.4212\n",
      "Iteration 42610: loss = 2.3051\n",
      "Iteration 42620: loss = 2.8009\n",
      "Iteration 42630: loss = 2.4980\n",
      "Iteration 42640: loss = 2.2067\n",
      "Iteration 42650: loss = 2.4879\n",
      "Iteration 42660: loss = 2.3660\n",
      "Iteration 42670: loss = 2.1636\n",
      "Iteration 42680: loss = 2.2870\n",
      "Iteration 42690: loss = 2.5409\n",
      "Iteration 42700: loss = 2.3213\n",
      "Iteration 42710: loss = 2.4648\n",
      "Iteration 42720: loss = 2.6448\n",
      "Iteration 42730: loss = 2.8227\n",
      "Iteration 42740: loss = 2.8318\n",
      "Iteration 42750: loss = 2.5039\n",
      "Iteration 42760: loss = 1.9827\n",
      "Iteration 42770: loss = 2.1800\n",
      "Iteration 42780: loss = 2.4432\n",
      "Iteration 42790: loss = 2.2514\n",
      "Iteration 42800: loss = 2.8862\n",
      "Iteration 42810: loss = 2.2113\n",
      "Iteration 42820: loss = 2.6552\n",
      "Iteration 42830: loss = 2.6251\n",
      "Iteration 42840: loss = 2.8099\n",
      "Iteration 42850: loss = 2.1074\n",
      "Iteration 42860: loss = 2.4215\n",
      "Iteration 42870: loss = 2.3085\n",
      "Iteration 42880: loss = 2.7009\n",
      "Iteration 42890: loss = 2.3809\n",
      "Iteration 42900: loss = 2.7698\n",
      "Iteration 42910: loss = 2.6474\n",
      "Iteration 42920: loss = 2.4757\n",
      "Iteration 42930: loss = 2.6048\n",
      "Iteration 42940: loss = 2.7758\n",
      "Iteration 42950: loss = 2.4966\n",
      "Iteration 42960: loss = 2.6503\n",
      "Iteration 42970: loss = 2.3755\n",
      "Iteration 42980: loss = 2.6849\n",
      "Iteration 42990: loss = 2.7607\n",
      "Iteration 43000: loss = 2.4958\n",
      "Iteration 43010: loss = 2.6838\n",
      "Iteration 43020: loss = 2.4184\n",
      "Iteration 43030: loss = 2.3787\n",
      "Iteration 43040: loss = 2.3908\n",
      "Iteration 43050: loss = 2.0247\n",
      "Iteration 43060: loss = 2.5235\n",
      "Iteration 43070: loss = 2.6936\n",
      "Iteration 43080: loss = 2.3810\n",
      "Iteration 43090: loss = 2.3717\n",
      "Iteration 43100: loss = 2.3723\n",
      "Iteration 43110: loss = 2.3316\n",
      "Iteration 43120: loss = 2.6899\n",
      "Iteration 43130: loss = 2.6331\n",
      "Iteration 43140: loss = 2.5304\n",
      "Iteration 43150: loss = 2.1088\n",
      "Iteration 43160: loss = 2.6163\n",
      "Iteration 43170: loss = 2.5672\n",
      "Iteration 43180: loss = 2.5698\n",
      "Iteration 43190: loss = 2.5551\n",
      "Iteration 43200: loss = 3.0219\n",
      "Iteration 43210: loss = 2.1820\n",
      "Iteration 43220: loss = 2.4433\n",
      "Iteration 43230: loss = 2.2011\n",
      "Iteration 43240: loss = 2.3158\n",
      "Iteration 43250: loss = 2.2465\n",
      "Iteration 43260: loss = 2.8100\n",
      "Iteration 43270: loss = 2.3653\n",
      "Iteration 43280: loss = 2.4374\n",
      "Iteration 43290: loss = 2.0681\n",
      "Iteration 43300: loss = 2.3671\n",
      "Iteration 43310: loss = 2.4451\n",
      "Iteration 43320: loss = 2.3469\n",
      "Iteration 43330: loss = 2.5118\n",
      "Iteration 43340: loss = 2.5881\n",
      "Iteration 43350: loss = 2.6687\n",
      "Iteration 43360: loss = 2.8678\n",
      "Iteration 43370: loss = 2.4582\n",
      "Iteration 43380: loss = 2.5365\n",
      "Iteration 43390: loss = 2.8341\n",
      "Iteration 43400: loss = 2.6370\n",
      "Iteration 43410: loss = 2.5827\n",
      "Iteration 43420: loss = 2.7360\n",
      "Iteration 43430: loss = 2.5297\n",
      "Iteration 43440: loss = 2.1730\n",
      "Iteration 43450: loss = 2.5901\n",
      "Iteration 43460: loss = 2.0244\n",
      "Iteration 43470: loss = 2.8764\n",
      "Iteration 43480: loss = 2.2941\n",
      "Iteration 43490: loss = 2.4000\n",
      "Iteration 43500: loss = 2.1246\n",
      "Iteration 43510: loss = 2.5461\n",
      "Iteration 43520: loss = 2.4602\n",
      "Iteration 43530: loss = 2.4732\n",
      "Iteration 43540: loss = 2.2750\n",
      "Iteration 43550: loss = 2.4772\n",
      "Iteration 43560: loss = 2.4510\n",
      "Iteration 43570: loss = 2.9797\n",
      "Iteration 43580: loss = 2.7954\n",
      "Iteration 43590: loss = 2.7182\n",
      "Iteration 43600: loss = 2.8240\n",
      "Iteration 43610: loss = 2.5584\n",
      "Iteration 43620: loss = 2.8443\n",
      "Iteration 43630: loss = 2.5015\n",
      "Iteration 43640: loss = 3.0076\n",
      "Iteration 43650: loss = 2.3956\n",
      "Iteration 43660: loss = 2.7160\n",
      "Iteration 43670: loss = 2.3572\n",
      "Iteration 43680: loss = 2.3839\n",
      "Iteration 43690: loss = 2.4346\n",
      "Iteration 43700: loss = 2.6408\n",
      "Iteration 43710: loss = 2.8339\n",
      "Iteration 43720: loss = 2.2842\n",
      "Iteration 43730: loss = 2.3781\n",
      "Iteration 43740: loss = 3.0528\n",
      "Iteration 43750: loss = 2.8078\n",
      "Iteration 43760: loss = 2.4375\n",
      "Iteration 43770: loss = 2.5791\n",
      "Iteration 43780: loss = 2.7319\n",
      "Iteration 43790: loss = 2.4948\n",
      "Iteration 43800: loss = 2.2820\n",
      "Iteration 43810: loss = 2.5016\n",
      "Iteration 43820: loss = 2.6854\n",
      "Iteration 43830: loss = 2.4328\n",
      "Iteration 43840: loss = 2.5474\n",
      "Iteration 43850: loss = 2.0192\n",
      "Iteration 43860: loss = 2.4110\n",
      "Iteration 43870: loss = 2.3698\n",
      "Iteration 43880: loss = 2.2939\n",
      "Iteration 43890: loss = 2.5893\n",
      "Iteration 43900: loss = 2.4970\n",
      "Iteration 43910: loss = 2.1528\n",
      "Iteration 43920: loss = 2.3386\n",
      "Iteration 43930: loss = 2.2408\n",
      "Iteration 43940: loss = 3.2515\n",
      "Iteration 43950: loss = 2.5939\n",
      "Iteration 43960: loss = 2.6731\n",
      "Iteration 43970: loss = 2.2787\n",
      "Iteration 43980: loss = 2.3430\n",
      "Iteration 43990: loss = 2.7640\n",
      "Iteration 44000: loss = 2.8311\n",
      "Iteration 44010: loss = 2.3662\n",
      "Iteration 44020: loss = 2.6889\n",
      "Iteration 44030: loss = 2.3220\n",
      "Iteration 44040: loss = 2.5460\n",
      "Iteration 44050: loss = 2.7804\n",
      "Iteration 44060: loss = 2.5129\n",
      "Iteration 44070: loss = 2.4173\n",
      "Iteration 44080: loss = 2.3121\n",
      "Iteration 44090: loss = 2.3093\n",
      "Iteration 44100: loss = 2.3852\n",
      "Iteration 44110: loss = 2.6689\n",
      "Iteration 44120: loss = 2.4338\n",
      "Iteration 44130: loss = 2.5569\n",
      "Iteration 44140: loss = 2.6774\n",
      "Iteration 44150: loss = 2.6780\n",
      "Iteration 44160: loss = 2.3737\n",
      "Iteration 44170: loss = 2.9836\n",
      "Iteration 44180: loss = 2.5799\n",
      "Iteration 44190: loss = 2.4225\n",
      "Iteration 44200: loss = 2.4346\n",
      "Iteration 44210: loss = 2.3637\n",
      "Iteration 44220: loss = 2.7280\n",
      "Iteration 44230: loss = 2.5969\n",
      "Iteration 44240: loss = 2.6456\n",
      "Iteration 44250: loss = 2.3494\n",
      "Iteration 44260: loss = 2.2100\n",
      "Iteration 44270: loss = 2.3223\n",
      "Iteration 44280: loss = 2.7322\n",
      "Iteration 44290: loss = 2.2123\n",
      "Iteration 44300: loss = 2.4210\n",
      "Iteration 44310: loss = 2.8985\n",
      "Iteration 44320: loss = 2.6608\n",
      "Iteration 44330: loss = 3.0400\n",
      "Iteration 44340: loss = 2.4389\n",
      "Iteration 44350: loss = 2.2775\n",
      "Iteration 44360: loss = 2.3154\n",
      "Iteration 44370: loss = 2.5756\n",
      "Iteration 44380: loss = 2.3379\n",
      "Iteration 44390: loss = 2.4107\n",
      "Iteration 44400: loss = 2.4149\n",
      "Iteration 44410: loss = 2.6078\n",
      "Iteration 44420: loss = 2.5631\n",
      "Iteration 44430: loss = 2.5587\n",
      "Iteration 44440: loss = 2.8955\n",
      "Iteration 44450: loss = 2.6234\n",
      "Iteration 44460: loss = 2.7829\n",
      "Iteration 44470: loss = 2.0602\n",
      "Iteration 44480: loss = 2.6811\n",
      "Iteration 44490: loss = 2.6247\n",
      "Iteration 44500: loss = 2.8197\n",
      "Iteration 44510: loss = 2.5022\n",
      "Iteration 44520: loss = 2.4264\n",
      "Iteration 44530: loss = 2.3671\n",
      "Iteration 44540: loss = 2.6335\n",
      "Iteration 44550: loss = 2.5150\n",
      "Iteration 44560: loss = 2.6794\n",
      "Iteration 44570: loss = 2.2304\n",
      "Iteration 44580: loss = 2.5697\n",
      "Iteration 44590: loss = 2.5250\n",
      "Iteration 44600: loss = 2.7605\n",
      "Iteration 44610: loss = 2.4904\n",
      "Iteration 44620: loss = 2.6664\n",
      "Iteration 44630: loss = 2.1032\n",
      "Iteration 44640: loss = 2.4107\n",
      "Iteration 44650: loss = 2.7066\n",
      "Iteration 44660: loss = 2.3916\n",
      "Iteration 44670: loss = 2.3260\n",
      "Iteration 44680: loss = 2.2748\n",
      "Iteration 44690: loss = 2.8508\n",
      "Iteration 44700: loss = 2.4910\n",
      "Iteration 44710: loss = 2.5860\n",
      "Iteration 44720: loss = 2.8182\n",
      "Iteration 44730: loss = 2.8243\n",
      "Iteration 44740: loss = 2.6439\n",
      "Iteration 44750: loss = 2.4510\n",
      "Iteration 44760: loss = 2.8162\n",
      "Iteration 44770: loss = 2.3061\n",
      "Iteration 44780: loss = 2.7430\n",
      "Iteration 44790: loss = 2.4592\n",
      "Iteration 44800: loss = 2.2540\n",
      "Iteration 44810: loss = 2.6998\n",
      "Iteration 44820: loss = 2.0838\n",
      "Iteration 44830: loss = 2.3800\n",
      "Iteration 44840: loss = 2.5376\n",
      "Iteration 44850: loss = 2.3740\n",
      "Iteration 44860: loss = 2.2030\n",
      "Iteration 44870: loss = 2.2611\n",
      "Iteration 44880: loss = 2.4875\n",
      "Iteration 44890: loss = 2.6409\n",
      "Iteration 44900: loss = 2.4745\n",
      "Iteration 44910: loss = 2.4975\n",
      "Iteration 44920: loss = 2.6633\n",
      "Iteration 44930: loss = 2.3998\n",
      "Iteration 44940: loss = 3.0526\n",
      "Iteration 44950: loss = 2.5396\n",
      "Iteration 44960: loss = 2.6101\n",
      "Iteration 44970: loss = 2.4316\n",
      "Iteration 44980: loss = 2.5164\n",
      "Iteration 44990: loss = 2.2627\n",
      "Iteration 45000: loss = 2.4940\n",
      "Iteration 45010: loss = 2.5408\n",
      "Iteration 45020: loss = 2.3446\n",
      "Iteration 45030: loss = 2.8458\n",
      "Iteration 45040: loss = 2.4833\n",
      "Iteration 45050: loss = 2.4135\n",
      "Iteration 45060: loss = 2.4495\n",
      "Iteration 45070: loss = 2.4444\n",
      "Iteration 45080: loss = 2.4735\n",
      "Iteration 45090: loss = 2.4372\n",
      "Iteration 45100: loss = 2.3532\n",
      "Iteration 45110: loss = 2.4541\n",
      "Iteration 45120: loss = 2.5354\n",
      "Iteration 45130: loss = 2.4570\n",
      "Iteration 45140: loss = 2.5767\n",
      "Iteration 45150: loss = 2.6013\n",
      "Iteration 45160: loss = 2.4805\n",
      "Iteration 45170: loss = 2.1165\n",
      "Iteration 45180: loss = 2.6209\n",
      "Iteration 45190: loss = 2.6637\n",
      "Iteration 45200: loss = 2.3029\n",
      "Iteration 45210: loss = 2.6032\n",
      "Iteration 45220: loss = 2.3763\n",
      "Iteration 45230: loss = 2.5786\n",
      "Iteration 45240: loss = 2.3902\n",
      "Iteration 45250: loss = 2.5707\n",
      "Iteration 45260: loss = 2.5576\n",
      "Iteration 45270: loss = 2.5566\n",
      "Iteration 45280: loss = 2.5817\n",
      "Iteration 45290: loss = 2.6814\n",
      "Iteration 45300: loss = 2.5028\n",
      "Iteration 45310: loss = 2.2731\n",
      "Iteration 45320: loss = 2.1196\n",
      "Iteration 45330: loss = 2.7127\n",
      "Iteration 45340: loss = 2.6182\n",
      "Iteration 45350: loss = 2.7406\n",
      "Iteration 45360: loss = 2.4403\n",
      "Iteration 45370: loss = 2.3675\n",
      "Iteration 45380: loss = 2.4619\n",
      "Iteration 45390: loss = 2.5477\n",
      "Iteration 45400: loss = 2.2675\n",
      "Iteration 45410: loss = 2.2319\n",
      "Iteration 45420: loss = 2.3778\n",
      "Iteration 45430: loss = 2.6707\n",
      "Iteration 45440: loss = 2.4284\n",
      "Iteration 45450: loss = 2.4690\n",
      "Iteration 45460: loss = 2.7679\n",
      "Iteration 45470: loss = 2.5006\n",
      "Iteration 45480: loss = 2.0244\n",
      "Iteration 45490: loss = 2.2501\n",
      "Iteration 45500: loss = 2.7098\n",
      "Iteration 45510: loss = 2.2855\n",
      "Iteration 45520: loss = 2.5737\n",
      "Iteration 45530: loss = 2.6328\n",
      "Iteration 45540: loss = 2.4582\n",
      "Iteration 45550: loss = 2.5164\n",
      "Iteration 45560: loss = 2.5120\n",
      "Iteration 45570: loss = 2.5484\n",
      "Iteration 45580: loss = 2.4301\n",
      "Iteration 45590: loss = 2.5741\n",
      "Iteration 45600: loss = 2.6819\n",
      "Iteration 45610: loss = 2.0166\n",
      "Iteration 45620: loss = 2.2122\n",
      "Iteration 45630: loss = 2.3252\n",
      "Iteration 45640: loss = 2.4751\n",
      "Iteration 45650: loss = 2.7415\n",
      "Iteration 45660: loss = 2.6552\n",
      "Iteration 45670: loss = 2.3282\n",
      "Iteration 45680: loss = 2.4690\n",
      "Iteration 45690: loss = 2.6497\n",
      "Iteration 45700: loss = 2.2856\n",
      "Iteration 45710: loss = 1.9861\n",
      "Iteration 45720: loss = 2.3028\n",
      "Iteration 45730: loss = 2.3257\n",
      "Iteration 45740: loss = 2.6900\n",
      "Iteration 45750: loss = 2.5407\n",
      "Iteration 45760: loss = 2.8400\n",
      "Iteration 45770: loss = 2.6949\n",
      "Iteration 45780: loss = 2.2929\n",
      "Iteration 45790: loss = 2.1597\n",
      "Iteration 45800: loss = 2.4698\n",
      "Iteration 45810: loss = 2.6196\n",
      "Iteration 45820: loss = 2.6741\n",
      "Iteration 45830: loss = 2.8517\n",
      "Iteration 45840: loss = 2.2547\n",
      "Iteration 45850: loss = 2.2132\n",
      "Iteration 45860: loss = 2.5543\n",
      "Iteration 45870: loss = 2.4442\n",
      "Iteration 45880: loss = 2.2980\n",
      "Iteration 45890: loss = 2.7127\n",
      "Iteration 45900: loss = 2.4832\n",
      "Iteration 45910: loss = 2.6631\n",
      "Iteration 45920: loss = 2.1896\n",
      "Iteration 45930: loss = 2.5856\n",
      "Iteration 45940: loss = 2.5654\n",
      "Iteration 45950: loss = 2.7756\n",
      "Iteration 45960: loss = 2.1039\n",
      "Iteration 45970: loss = 2.3953\n",
      "Iteration 45980: loss = 2.6949\n",
      "Iteration 45990: loss = 2.4826\n",
      "Iteration 46000: loss = 2.5422\n",
      "Iteration 46010: loss = 2.5664\n",
      "Iteration 46020: loss = 2.4035\n",
      "Iteration 46030: loss = 2.3758\n",
      "Iteration 46040: loss = 2.6257\n",
      "Iteration 46050: loss = 2.4173\n",
      "Iteration 46060: loss = 2.6637\n",
      "Iteration 46070: loss = 2.7326\n",
      "Iteration 46080: loss = 2.5806\n",
      "Iteration 46090: loss = 2.4393\n",
      "Iteration 46100: loss = 2.8996\n",
      "Iteration 46110: loss = 2.7720\n",
      "Iteration 46120: loss = 2.3057\n",
      "Iteration 46130: loss = 2.2665\n",
      "Iteration 46140: loss = 2.4920\n",
      "Iteration 46150: loss = 2.4804\n",
      "Iteration 46160: loss = 2.4658\n",
      "Iteration 46170: loss = 2.5582\n",
      "Iteration 46180: loss = 2.2381\n",
      "Iteration 46190: loss = 2.4188\n",
      "Iteration 46200: loss = 2.8825\n",
      "Iteration 46210: loss = 2.1850\n",
      "Iteration 46220: loss = 2.2815\n",
      "Iteration 46230: loss = 2.7900\n",
      "Iteration 46240: loss = 2.4758\n",
      "Iteration 46250: loss = 2.3376\n",
      "Iteration 46260: loss = 2.4646\n",
      "Iteration 46270: loss = 2.5075\n",
      "Iteration 46280: loss = 2.5253\n",
      "Iteration 46290: loss = 2.6290\n",
      "Iteration 46300: loss = 2.7029\n",
      "Iteration 46310: loss = 2.5610\n",
      "Iteration 46320: loss = 2.6406\n",
      "Iteration 46330: loss = 2.1281\n",
      "Iteration 46340: loss = 2.2853\n",
      "Iteration 46350: loss = 2.3324\n",
      "Iteration 46360: loss = 2.4884\n",
      "Iteration 46370: loss = 2.1946\n",
      "Iteration 46380: loss = 2.3087\n",
      "Iteration 46390: loss = 2.1150\n",
      "Iteration 46400: loss = 2.5162\n",
      "Iteration 46410: loss = 2.4692\n",
      "Iteration 46420: loss = 2.2789\n",
      "Iteration 46430: loss = 2.2852\n",
      "Iteration 46440: loss = 2.5889\n",
      "Iteration 46450: loss = 2.2238\n",
      "Iteration 46460: loss = 2.2411\n",
      "Iteration 46470: loss = 2.2262\n",
      "Iteration 46480: loss = 2.4719\n",
      "Iteration 46490: loss = 3.0127\n",
      "Iteration 46500: loss = 2.3421\n",
      "Iteration 46510: loss = 2.3677\n",
      "Iteration 46520: loss = 2.5218\n",
      "Iteration 46530: loss = 2.4044\n",
      "Iteration 46540: loss = 2.8402\n",
      "Iteration 46550: loss = 2.1727\n",
      "Iteration 46560: loss = 2.5857\n",
      "Iteration 46570: loss = 2.6026\n",
      "Iteration 46580: loss = 2.5826\n",
      "Iteration 46590: loss = 2.4069\n",
      "Iteration 46600: loss = 2.8288\n",
      "Iteration 46610: loss = 2.1955\n",
      "Iteration 46620: loss = 2.3771\n",
      "Iteration 46630: loss = 2.6276\n",
      "Iteration 46640: loss = 2.5266\n",
      "Iteration 46650: loss = 2.3079\n",
      "Iteration 46660: loss = 2.4917\n",
      "Iteration 46670: loss = 2.3274\n",
      "Iteration 46680: loss = 2.5991\n",
      "Iteration 46690: loss = 2.4359\n",
      "Iteration 46700: loss = 2.8897\n",
      "Iteration 46710: loss = 2.5019\n",
      "Iteration 46720: loss = 2.4436\n",
      "Iteration 46730: loss = 2.0546\n",
      "Iteration 46740: loss = 2.7704\n",
      "Iteration 46750: loss = 2.5558\n",
      "Iteration 46760: loss = 2.3466\n",
      "Iteration 46770: loss = 2.5284\n",
      "Iteration 46780: loss = 1.9485\n",
      "Iteration 46790: loss = 2.6233\n",
      "Iteration 46800: loss = 1.8435\n",
      "Iteration 46810: loss = 2.6305\n",
      "Iteration 46820: loss = 2.4648\n",
      "Iteration 46830: loss = 2.3674\n",
      "Iteration 46840: loss = 2.3672\n",
      "Iteration 46850: loss = 2.3986\n",
      "Iteration 46860: loss = 2.5734\n",
      "Iteration 46870: loss = 2.2607\n",
      "Iteration 46880: loss = 2.6957\n",
      "Iteration 46890: loss = 2.6403\n",
      "Iteration 46900: loss = 2.2276\n",
      "Iteration 46910: loss = 2.3278\n",
      "Iteration 46920: loss = 2.6178\n",
      "Iteration 46930: loss = 2.9709\n",
      "Iteration 46940: loss = 2.4178\n",
      "Iteration 46950: loss = 2.8373\n",
      "Iteration 46960: loss = 2.4097\n",
      "Iteration 46970: loss = 2.9496\n",
      "Iteration 46980: loss = 2.3395\n",
      "Iteration 46990: loss = 2.2294\n",
      "Iteration 47000: loss = 2.1132\n",
      "Iteration 47010: loss = 2.3415\n",
      "Iteration 47020: loss = 2.7379\n",
      "Iteration 47030: loss = 2.7144\n",
      "Iteration 47040: loss = 2.4215\n",
      "Iteration 47050: loss = 2.4637\n",
      "Iteration 47060: loss = 2.3687\n",
      "Iteration 47070: loss = 2.5736\n",
      "Iteration 47080: loss = 2.5649\n",
      "Iteration 47090: loss = 2.3862\n",
      "Iteration 47100: loss = 2.6202\n",
      "Iteration 47110: loss = 2.5343\n",
      "Iteration 47120: loss = 2.8572\n",
      "Iteration 47130: loss = 2.7810\n",
      "Iteration 47140: loss = 2.3659\n",
      "Iteration 47150: loss = 2.2190\n",
      "Iteration 47160: loss = 2.3648\n",
      "Iteration 47170: loss = 2.2414\n",
      "Iteration 47180: loss = 2.8764\n",
      "Iteration 47190: loss = 2.5689\n",
      "Iteration 47200: loss = 2.6691\n",
      "Iteration 47210: loss = 2.5593\n",
      "Iteration 47220: loss = 2.3505\n",
      "Iteration 47230: loss = 2.5216\n",
      "Iteration 47240: loss = 3.1911\n",
      "Iteration 47250: loss = 2.3777\n",
      "Iteration 47260: loss = 2.7517\n",
      "Iteration 47270: loss = 2.6214\n",
      "Iteration 47280: loss = 2.4762\n",
      "Iteration 47290: loss = 2.3477\n",
      "Iteration 47300: loss = 2.7532\n",
      "Iteration 47310: loss = 2.1428\n",
      "Iteration 47320: loss = 2.5578\n",
      "Iteration 47330: loss = 2.6983\n",
      "Iteration 47340: loss = 2.3184\n",
      "Iteration 47350: loss = 2.2909\n",
      "Iteration 47360: loss = 2.2079\n",
      "Iteration 47370: loss = 2.3243\n",
      "Iteration 47380: loss = 2.6294\n",
      "Iteration 47390: loss = 2.5507\n",
      "Iteration 47400: loss = 2.5059\n",
      "Iteration 47410: loss = 2.6687\n",
      "Iteration 47420: loss = 2.4396\n",
      "Iteration 47430: loss = 2.6549\n",
      "Iteration 47440: loss = 3.2051\n",
      "Iteration 47450: loss = 2.4640\n",
      "Iteration 47460: loss = 2.1339\n",
      "Iteration 47470: loss = 2.3720\n",
      "Iteration 47480: loss = 2.2482\n",
      "Iteration 47490: loss = 2.1897\n",
      "Iteration 47500: loss = 2.4066\n",
      "Iteration 47510: loss = 2.5827\n",
      "Iteration 47520: loss = 2.8034\n",
      "Iteration 47530: loss = 2.7934\n",
      "Iteration 47540: loss = 2.0353\n",
      "Iteration 47550: loss = 2.6403\n",
      "Iteration 47560: loss = 2.2901\n",
      "Iteration 47570: loss = 2.4946\n",
      "Iteration 47580: loss = 2.1580\n",
      "Iteration 47590: loss = 2.1596\n",
      "Iteration 47600: loss = 2.0514\n",
      "Iteration 47610: loss = 2.6527\n",
      "Iteration 47620: loss = 2.1696\n",
      "Iteration 47630: loss = 2.6784\n",
      "Iteration 47640: loss = 2.2286\n",
      "Iteration 47650: loss = 2.2331\n",
      "Iteration 47660: loss = 2.3796\n",
      "Iteration 47670: loss = 2.8877\n",
      "Iteration 47680: loss = 2.3496\n",
      "Iteration 47690: loss = 2.3287\n",
      "Iteration 47700: loss = 2.6419\n",
      "Iteration 47710: loss = 2.7986\n",
      "Iteration 47720: loss = 2.7132\n",
      "Iteration 47730: loss = 2.3041\n",
      "Iteration 47740: loss = 2.0922\n",
      "Iteration 47750: loss = 2.2762\n",
      "Iteration 47760: loss = 2.4791\n",
      "Iteration 47770: loss = 2.6116\n",
      "Iteration 47780: loss = 2.5463\n",
      "Iteration 47790: loss = 2.3867\n",
      "Iteration 47800: loss = 2.8629\n",
      "Iteration 47810: loss = 2.0429\n",
      "Iteration 47820: loss = 2.6758\n",
      "Iteration 47830: loss = 2.7550\n",
      "Iteration 47840: loss = 2.5067\n",
      "Iteration 47850: loss = 2.4602\n",
      "Iteration 47860: loss = 2.4089\n",
      "Iteration 47870: loss = 2.4197\n",
      "Iteration 47880: loss = 2.7973\n",
      "Iteration 47890: loss = 2.2421\n",
      "Iteration 47900: loss = 2.3278\n",
      "Iteration 47910: loss = 2.5581\n",
      "Iteration 47920: loss = 2.7134\n",
      "Iteration 47930: loss = 2.2326\n",
      "Iteration 47940: loss = 2.1034\n",
      "Iteration 47950: loss = 2.2458\n",
      "Iteration 47960: loss = 2.6410\n",
      "Iteration 47970: loss = 2.7662\n",
      "Iteration 47980: loss = 2.2390\n",
      "Iteration 47990: loss = 2.0425\n",
      "Iteration 48000: loss = 2.1251\n",
      "Iteration 48010: loss = 2.3953\n",
      "Iteration 48020: loss = 2.7209\n",
      "Iteration 48030: loss = 2.4361\n",
      "Iteration 48040: loss = 2.1739\n",
      "Iteration 48050: loss = 2.5942\n",
      "Iteration 48060: loss = 2.2725\n",
      "Iteration 48070: loss = 2.5709\n",
      "Iteration 48080: loss = 2.6883\n",
      "Iteration 48090: loss = 2.8054\n",
      "Iteration 48100: loss = 2.3912\n",
      "Iteration 48110: loss = 2.1028\n",
      "Iteration 48120: loss = 2.8256\n",
      "Iteration 48130: loss = 3.0159\n",
      "Iteration 48140: loss = 2.4669\n",
      "Iteration 48150: loss = 2.5780\n",
      "Iteration 48160: loss = 2.7459\n",
      "Iteration 48170: loss = 2.5084\n",
      "Iteration 48180: loss = 2.7283\n",
      "Iteration 48190: loss = 2.4351\n",
      "Iteration 48200: loss = 2.1360\n",
      "Iteration 48210: loss = 2.6936\n",
      "Iteration 48220: loss = 2.1342\n",
      "Iteration 48230: loss = 2.7746\n",
      "Iteration 48240: loss = 2.5572\n",
      "Iteration 48250: loss = 2.6637\n",
      "Iteration 48260: loss = 2.7309\n",
      "Iteration 48270: loss = 2.8536\n",
      "Iteration 48280: loss = 2.0813\n",
      "Iteration 48290: loss = 2.6892\n",
      "Iteration 48300: loss = 2.1553\n",
      "Iteration 48310: loss = 2.3499\n",
      "Iteration 48320: loss = 2.6507\n",
      "Iteration 48330: loss = 2.2308\n",
      "Iteration 48340: loss = 2.8307\n",
      "Iteration 48350: loss = 2.1478\n",
      "Iteration 48360: loss = 2.7252\n",
      "Iteration 48370: loss = 2.1073\n",
      "Iteration 48380: loss = 2.6402\n",
      "Iteration 48390: loss = 2.3414\n",
      "Iteration 48400: loss = 2.1327\n",
      "Iteration 48410: loss = 2.2947\n",
      "Iteration 48420: loss = 2.3956\n",
      "Iteration 48430: loss = 2.6291\n",
      "Iteration 48440: loss = 2.7128\n",
      "Iteration 48450: loss = 2.6173\n",
      "Iteration 48460: loss = 2.8375\n",
      "Iteration 48470: loss = 2.8882\n",
      "Iteration 48480: loss = 2.7113\n",
      "Iteration 48490: loss = 2.7007\n",
      "Iteration 48500: loss = 2.4103\n",
      "Iteration 48510: loss = 2.5867\n",
      "Iteration 48520: loss = 2.5082\n",
      "Iteration 48530: loss = 3.0983\n",
      "Iteration 48540: loss = 2.1167\n",
      "Iteration 48550: loss = 2.2173\n",
      "Iteration 48560: loss = 2.2652\n",
      "Iteration 48570: loss = 2.3856\n",
      "Iteration 48580: loss = 2.1295\n",
      "Iteration 48590: loss = 2.7589\n",
      "Iteration 48600: loss = 2.3096\n",
      "Iteration 48610: loss = 2.4096\n",
      "Iteration 48620: loss = 2.4119\n",
      "Iteration 48630: loss = 2.2018\n",
      "Iteration 48640: loss = 2.1324\n",
      "Iteration 48650: loss = 2.6998\n",
      "Iteration 48660: loss = 2.6275\n",
      "Iteration 48670: loss = 2.2456\n",
      "Iteration 48680: loss = 2.3475\n",
      "Iteration 48690: loss = 2.2807\n",
      "Iteration 48700: loss = 2.4733\n",
      "Iteration 48710: loss = 2.3024\n",
      "Iteration 48720: loss = 2.8582\n",
      "Iteration 48730: loss = 2.5875\n",
      "Iteration 48740: loss = 2.3145\n",
      "Iteration 48750: loss = 2.6317\n",
      "Iteration 48760: loss = 2.4795\n",
      "Iteration 48770: loss = 2.7497\n",
      "Iteration 48780: loss = 2.5814\n",
      "Iteration 48790: loss = 2.6330\n",
      "Iteration 48800: loss = 2.5355\n",
      "Iteration 48810: loss = 2.2550\n",
      "Iteration 48820: loss = 2.1931\n",
      "Iteration 48830: loss = 2.3457\n",
      "Iteration 48840: loss = 2.2670\n",
      "Iteration 48850: loss = 2.3850\n",
      "Iteration 48860: loss = 2.7138\n",
      "Iteration 48870: loss = 1.8932\n",
      "Iteration 48880: loss = 2.7282\n",
      "Iteration 48890: loss = 2.4608\n",
      "Iteration 48900: loss = 2.6719\n",
      "Iteration 48910: loss = 2.4872\n",
      "Iteration 48920: loss = 2.7158\n",
      "Iteration 48930: loss = 2.7061\n",
      "Iteration 48940: loss = 2.8631\n",
      "Iteration 48950: loss = 2.3146\n",
      "Iteration 48960: loss = 2.5203\n",
      "Iteration 48970: loss = 2.3964\n",
      "Iteration 48980: loss = 2.2167\n",
      "Iteration 48990: loss = 2.6942\n",
      "Iteration 49000: loss = 2.2390\n",
      "Iteration 49010: loss = 2.7483\n",
      "Iteration 49020: loss = 2.6135\n",
      "Iteration 49030: loss = 2.4596\n",
      "Iteration 49040: loss = 2.9568\n",
      "Iteration 49050: loss = 2.5707\n",
      "Iteration 49060: loss = 2.5915\n",
      "Iteration 49070: loss = 2.6992\n",
      "Iteration 49080: loss = 2.2207\n",
      "Iteration 49090: loss = 2.3104\n",
      "Iteration 49100: loss = 2.1961\n",
      "Iteration 49110: loss = 2.5597\n",
      "Iteration 49120: loss = 2.2607\n",
      "Iteration 49130: loss = 2.4774\n",
      "Iteration 49140: loss = 2.4011\n",
      "Iteration 49150: loss = 2.7074\n",
      "Iteration 49160: loss = 2.4104\n",
      "Iteration 49170: loss = 2.2448\n",
      "Iteration 49180: loss = 2.1056\n",
      "Iteration 49190: loss = 2.2446\n",
      "Iteration 49200: loss = 2.7939\n",
      "Iteration 49210: loss = 2.6496\n",
      "Iteration 49220: loss = 2.8786\n",
      "Iteration 49230: loss = 2.6135\n",
      "Iteration 49240: loss = 2.7646\n",
      "Iteration 49250: loss = 2.5149\n",
      "Iteration 49260: loss = 2.4514\n",
      "Iteration 49270: loss = 2.6546\n",
      "Iteration 49280: loss = 2.1574\n",
      "Iteration 49290: loss = 2.6840\n",
      "Iteration 49300: loss = 2.3866\n",
      "Iteration 49310: loss = 2.5510\n",
      "Iteration 49320: loss = 2.6639\n",
      "Iteration 49330: loss = 2.6499\n",
      "Iteration 49340: loss = 2.7015\n",
      "Iteration 49350: loss = 2.3764\n",
      "Iteration 49360: loss = 2.2449\n",
      "Iteration 49370: loss = 2.7334\n",
      "Iteration 49380: loss = 2.3598\n",
      "Iteration 49390: loss = 2.5419\n",
      "Iteration 49400: loss = 2.5814\n",
      "Iteration 49410: loss = 2.4488\n",
      "Iteration 49420: loss = 2.6739\n",
      "Iteration 49430: loss = 2.5911\n",
      "Iteration 49440: loss = 2.0454\n",
      "Iteration 49450: loss = 2.0304\n",
      "Iteration 49460: loss = 2.2376\n",
      "Iteration 49470: loss = 2.8061\n",
      "Iteration 49480: loss = 2.8443\n",
      "Iteration 49490: loss = 2.2349\n",
      "Iteration 49500: loss = 2.6013\n",
      "Iteration 49510: loss = 2.7070\n",
      "Iteration 49520: loss = 2.6746\n",
      "Iteration 49530: loss = 2.3236\n",
      "Iteration 49540: loss = 2.4012\n",
      "Iteration 49550: loss = 2.6793\n",
      "Iteration 49560: loss = 2.3152\n",
      "Iteration 49570: loss = 2.5683\n",
      "Iteration 49580: loss = 2.1707\n",
      "Iteration 49590: loss = 2.6680\n",
      "Iteration 49600: loss = 2.4586\n",
      "Iteration 49610: loss = 2.5823\n",
      "Iteration 49620: loss = 2.4100\n",
      "Iteration 49630: loss = 2.3483\n",
      "Iteration 49640: loss = 2.5220\n",
      "Iteration 49650: loss = 2.3944\n",
      "Iteration 49660: loss = 3.1226\n",
      "Iteration 49670: loss = 2.5011\n",
      "Iteration 49680: loss = 2.6025\n",
      "Iteration 49690: loss = 2.6903\n",
      "Iteration 49700: loss = 2.0626\n",
      "Iteration 49710: loss = 2.7612\n",
      "Iteration 49720: loss = 2.5592\n",
      "Iteration 49730: loss = 2.6066\n",
      "Iteration 49740: loss = 2.8267\n",
      "Iteration 49750: loss = 2.6918\n",
      "Iteration 49760: loss = 2.5028\n",
      "Iteration 49770: loss = 2.4184\n",
      "Iteration 49780: loss = 2.6394\n",
      "Iteration 49790: loss = 2.4749\n",
      "Iteration 49800: loss = 2.5692\n",
      "Iteration 49810: loss = 2.2627\n",
      "Iteration 49820: loss = 2.5750\n",
      "Iteration 49830: loss = 2.3615\n",
      "Iteration 49840: loss = 2.7426\n",
      "Iteration 49850: loss = 2.5796\n",
      "Iteration 49860: loss = 2.5641\n",
      "Iteration 49870: loss = 2.5537\n",
      "Iteration 49880: loss = 2.6348\n",
      "Iteration 49890: loss = 2.3788\n",
      "Iteration 49900: loss = 2.7120\n",
      "Iteration 49910: loss = 2.6932\n",
      "Iteration 49920: loss = 2.0068\n",
      "Iteration 49930: loss = 2.7827\n",
      "Iteration 49940: loss = 2.4165\n",
      "Iteration 49950: loss = 2.6226\n",
      "Iteration 49960: loss = 2.5570\n",
      "Iteration 49970: loss = 2.2100\n",
      "Iteration 49980: loss = 2.6736\n",
      "Iteration 49990: loss = 2.2234\n",
      "Iteration 50000: loss = 2.3836\n",
      "Iteration 50010: loss = 2.3456\n",
      "Iteration 50020: loss = 2.1964\n",
      "Iteration 50030: loss = 2.2561\n",
      "Iteration 50040: loss = 2.4775\n",
      "Iteration 50050: loss = 2.6983\n",
      "Iteration 50060: loss = 2.5903\n",
      "Iteration 50070: loss = 2.1625\n",
      "Iteration 50080: loss = 2.0572\n",
      "Iteration 50090: loss = 2.2551\n",
      "Iteration 50100: loss = 2.7312\n",
      "Iteration 50110: loss = 2.7367\n",
      "Iteration 50120: loss = 2.8262\n",
      "Iteration 50130: loss = 2.5759\n",
      "Iteration 50140: loss = 2.4731\n",
      "Iteration 50150: loss = 2.5906\n",
      "Iteration 50160: loss = 2.7925\n",
      "Iteration 50170: loss = 2.0347\n",
      "Iteration 50180: loss = 2.6590\n",
      "Iteration 50190: loss = 2.2544\n",
      "Iteration 50200: loss = 2.3349\n",
      "Iteration 50210: loss = 2.1742\n",
      "Iteration 50220: loss = 2.2885\n",
      "Iteration 50230: loss = 2.7569\n",
      "Iteration 50240: loss = 2.5954\n",
      "Iteration 50250: loss = 2.1085\n",
      "Iteration 50260: loss = 2.1760\n",
      "Iteration 50270: loss = 2.3445\n",
      "Iteration 50280: loss = 2.2037\n",
      "Iteration 50290: loss = 2.5181\n",
      "Iteration 50300: loss = 2.3625\n",
      "Iteration 50310: loss = 2.3582\n",
      "Iteration 50320: loss = 2.3475\n",
      "Iteration 50330: loss = 2.5781\n",
      "Iteration 50340: loss = 2.2754\n",
      "Iteration 50350: loss = 2.6179\n",
      "Iteration 50360: loss = 2.5039\n",
      "Iteration 50370: loss = 2.4759\n",
      "Iteration 50380: loss = 2.6019\n",
      "Iteration 50390: loss = 2.3652\n",
      "Iteration 50400: loss = 2.5459\n",
      "Iteration 50410: loss = 2.3678\n",
      "Iteration 50420: loss = 2.2177\n",
      "Iteration 50430: loss = 2.3745\n",
      "Iteration 50440: loss = 2.9698\n",
      "Iteration 50450: loss = 2.5315\n",
      "Iteration 50460: loss = 2.3106\n",
      "Iteration 50470: loss = 2.6029\n",
      "Iteration 50480: loss = 2.4375\n",
      "Iteration 50490: loss = 2.7067\n",
      "Iteration 50500: loss = 2.3868\n",
      "Iteration 50510: loss = 2.5101\n",
      "Iteration 50520: loss = 2.5335\n",
      "Iteration 50530: loss = 2.5177\n",
      "Iteration 50540: loss = 2.3193\n",
      "Iteration 50550: loss = 2.5358\n",
      "Iteration 50560: loss = 2.3869\n",
      "Iteration 50570: loss = 2.5717\n",
      "Iteration 50580: loss = 2.4368\n",
      "Iteration 50590: loss = 2.5112\n",
      "Iteration 50600: loss = 2.6709\n",
      "Iteration 50610: loss = 2.1786\n",
      "Iteration 50620: loss = 2.6019\n",
      "Iteration 50630: loss = 2.1909\n",
      "Iteration 50640: loss = 2.5761\n",
      "Iteration 50650: loss = 2.6744\n",
      "Iteration 50660: loss = 2.3559\n",
      "Iteration 50670: loss = 2.2019\n",
      "Iteration 50680: loss = 2.4538\n",
      "Iteration 50690: loss = 2.3482\n",
      "Iteration 50700: loss = 2.4030\n",
      "Iteration 50710: loss = 2.6212\n",
      "Iteration 50720: loss = 2.7435\n",
      "Iteration 50730: loss = 2.5329\n",
      "Iteration 50740: loss = 2.7171\n",
      "Iteration 50750: loss = 2.5125\n",
      "Iteration 50760: loss = 2.2027\n",
      "Iteration 50770: loss = 2.7047\n",
      "Iteration 50780: loss = 2.6397\n",
      "Iteration 50790: loss = 2.5746\n",
      "Iteration 50800: loss = 2.2262\n",
      "Iteration 50810: loss = 2.3968\n",
      "Iteration 50820: loss = 2.5720\n",
      "Iteration 50830: loss = 3.1959\n",
      "Iteration 50840: loss = 2.2673\n",
      "Iteration 50850: loss = 2.4937\n",
      "Iteration 50860: loss = 2.4791\n",
      "Iteration 50870: loss = 2.1886\n",
      "Iteration 50880: loss = 2.7686\n",
      "Iteration 50890: loss = 2.5558\n",
      "Iteration 50900: loss = 2.3644\n",
      "Iteration 50910: loss = 2.4531\n",
      "Iteration 50920: loss = 2.4423\n",
      "Iteration 50930: loss = 2.4927\n",
      "Iteration 50940: loss = 2.7484\n",
      "Iteration 50950: loss = 2.3225\n",
      "Iteration 50960: loss = 2.6869\n",
      "Iteration 50970: loss = 2.5467\n",
      "Iteration 50980: loss = 2.2821\n",
      "Iteration 50990: loss = 2.5587\n",
      "Iteration 51000: loss = 2.5202\n",
      "Iteration 51010: loss = 2.6432\n",
      "Iteration 51020: loss = 2.4756\n",
      "Iteration 51030: loss = 2.2916\n",
      "Iteration 51040: loss = 2.3683\n",
      "Iteration 51050: loss = 2.5823\n",
      "Iteration 51060: loss = 2.4252\n",
      "Iteration 51070: loss = 2.3259\n",
      "Iteration 51080: loss = 2.5251\n",
      "Iteration 51090: loss = 2.4011\n",
      "Iteration 51100: loss = 2.8044\n",
      "Iteration 51110: loss = 2.3380\n",
      "Iteration 51120: loss = 2.4320\n",
      "Iteration 51130: loss = 2.7216\n",
      "Iteration 51140: loss = 2.7226\n",
      "Iteration 51150: loss = 2.5487\n",
      "Iteration 51160: loss = 2.2393\n",
      "Iteration 51170: loss = 2.5805\n",
      "Iteration 51180: loss = 2.3328\n",
      "Iteration 51190: loss = 2.1245\n",
      "Iteration 51200: loss = 2.4251\n",
      "Iteration 51210: loss = 2.2145\n",
      "Iteration 51220: loss = 2.5227\n",
      "Iteration 51230: loss = 2.2620\n",
      "Iteration 51240: loss = 2.5133\n",
      "Iteration 51250: loss = 2.4639\n",
      "Iteration 51260: loss = 2.5189\n",
      "Iteration 51270: loss = 2.3255\n",
      "Iteration 51280: loss = 2.4979\n",
      "Iteration 51290: loss = 2.5090\n",
      "Iteration 51300: loss = 2.4120\n",
      "Iteration 51310: loss = 2.7377\n",
      "Iteration 51320: loss = 2.3413\n",
      "Iteration 51330: loss = 2.1864\n",
      "Iteration 51340: loss = 2.6026\n",
      "Iteration 51350: loss = 2.6887\n",
      "Iteration 51360: loss = 2.5030\n",
      "Iteration 51370: loss = 2.5429\n",
      "Iteration 51380: loss = 3.2745\n",
      "Iteration 51390: loss = 2.7031\n",
      "Iteration 51400: loss = 2.1875\n",
      "Iteration 51410: loss = 2.3260\n",
      "Iteration 51420: loss = 2.6274\n",
      "Iteration 51430: loss = 2.3197\n",
      "Iteration 51440: loss = 2.2801\n",
      "Iteration 51450: loss = 2.2584\n",
      "Iteration 51460: loss = 2.4763\n",
      "Iteration 51470: loss = 2.5025\n",
      "Iteration 51480: loss = 2.2807\n",
      "Iteration 51490: loss = 2.4502\n",
      "Iteration 51500: loss = 2.3331\n",
      "Iteration 51510: loss = 2.7622\n",
      "Iteration 51520: loss = 2.2863\n",
      "Iteration 51530: loss = 2.3100\n",
      "Iteration 51540: loss = 2.6429\n",
      "Iteration 51550: loss = 2.5504\n",
      "Iteration 51560: loss = 2.2143\n",
      "Iteration 51570: loss = 2.1607\n",
      "Iteration 51580: loss = 2.6070\n",
      "Iteration 51590: loss = 2.6982\n",
      "Iteration 51600: loss = 2.5386\n",
      "Iteration 51610: loss = 2.6600\n",
      "Iteration 51620: loss = 2.4042\n",
      "Iteration 51630: loss = 2.6263\n",
      "Iteration 51640: loss = 2.6663\n",
      "Iteration 51650: loss = 2.4494\n",
      "Iteration 51660: loss = 2.6259\n",
      "Iteration 51670: loss = 2.3581\n",
      "Iteration 51680: loss = 2.3025\n",
      "Iteration 51690: loss = 2.4867\n",
      "Iteration 51700: loss = 2.3710\n",
      "Iteration 51710: loss = 2.4323\n",
      "Iteration 51720: loss = 2.2757\n",
      "Iteration 51730: loss = 2.3895\n",
      "Iteration 51740: loss = 2.4274\n",
      "Iteration 51750: loss = 2.6185\n",
      "Iteration 51760: loss = 2.4205\n",
      "Iteration 51770: loss = 2.7059\n",
      "Iteration 51780: loss = 2.5308\n",
      "Iteration 51790: loss = 2.4742\n",
      "Iteration 51800: loss = 2.1188\n",
      "Iteration 51810: loss = 2.4800\n",
      "Iteration 51820: loss = 2.2228\n",
      "Iteration 51830: loss = 2.3742\n",
      "Iteration 51840: loss = 2.3592\n",
      "Iteration 51850: loss = 2.3994\n",
      "Iteration 51860: loss = 2.1419\n",
      "Iteration 51870: loss = 2.4340\n",
      "Iteration 51880: loss = 2.8669\n",
      "Iteration 51890: loss = 2.5698\n",
      "Iteration 51900: loss = 2.7894\n",
      "Iteration 51910: loss = 2.7061\n",
      "Iteration 51920: loss = 2.1382\n",
      "Iteration 51930: loss = 2.5811\n",
      "Iteration 51940: loss = 2.6489\n",
      "Iteration 51950: loss = 2.3680\n",
      "Iteration 51960: loss = 2.5067\n",
      "Iteration 51970: loss = 2.0569\n",
      "Iteration 51980: loss = 2.4302\n",
      "Iteration 51990: loss = 2.3593\n",
      "Iteration 52000: loss = 2.6583\n",
      "Iteration 52010: loss = 2.4716\n",
      "Iteration 52020: loss = 2.7385\n",
      "Iteration 52030: loss = 2.4925\n",
      "Iteration 52040: loss = 2.6418\n",
      "Iteration 52050: loss = 2.5037\n",
      "Iteration 52060: loss = 2.6325\n",
      "Iteration 52070: loss = 2.3564\n",
      "Iteration 52080: loss = 1.9635\n",
      "Iteration 52090: loss = 2.5494\n",
      "Iteration 52100: loss = 3.0502\n",
      "Iteration 52110: loss = 2.2602\n",
      "Iteration 52120: loss = 2.4609\n",
      "Iteration 52130: loss = 2.3002\n",
      "Iteration 52140: loss = 2.1928\n",
      "Iteration 52150: loss = 2.3258\n",
      "Iteration 52160: loss = 2.8915\n",
      "Iteration 52170: loss = 2.5713\n",
      "Iteration 52180: loss = 2.2552\n",
      "Iteration 52190: loss = 2.5219\n",
      "Iteration 52200: loss = 2.9433\n",
      "Iteration 52210: loss = 2.1768\n",
      "Iteration 52220: loss = 2.4867\n",
      "Iteration 52230: loss = 2.4655\n",
      "Iteration 52240: loss = 2.3769\n",
      "Iteration 52250: loss = 2.6457\n",
      "Iteration 52260: loss = 2.3342\n",
      "Iteration 52270: loss = 2.3350\n",
      "Iteration 52280: loss = 2.4963\n",
      "Iteration 52290: loss = 2.1811\n",
      "Iteration 52300: loss = 2.4691\n",
      "Iteration 52310: loss = 2.6889\n",
      "Iteration 52320: loss = 2.2112\n",
      "Iteration 52330: loss = 2.5680\n",
      "Iteration 52340: loss = 2.3946\n",
      "Iteration 52350: loss = 2.6457\n",
      "Iteration 52360: loss = 2.5869\n",
      "Iteration 52370: loss = 2.5848\n",
      "Iteration 52380: loss = 2.3563\n",
      "Iteration 52390: loss = 2.3888\n",
      "Iteration 52400: loss = 2.2939\n",
      "Iteration 52410: loss = 2.2907\n",
      "Iteration 52420: loss = 2.1863\n",
      "Iteration 52430: loss = 2.4297\n",
      "Iteration 52440: loss = 2.1474\n",
      "Iteration 52450: loss = 2.4434\n",
      "Iteration 52460: loss = 2.4148\n",
      "Iteration 52470: loss = 2.4387\n",
      "Iteration 52480: loss = 2.6844\n",
      "Iteration 52490: loss = 2.6497\n",
      "Iteration 52500: loss = 2.7327\n",
      "Iteration 52510: loss = 2.3838\n",
      "Iteration 52520: loss = 2.5456\n",
      "Iteration 52530: loss = 2.1808\n",
      "Iteration 52540: loss = 2.5887\n",
      "Iteration 52550: loss = 2.4201\n",
      "Iteration 52560: loss = 2.2253\n",
      "Iteration 52570: loss = 2.9865\n",
      "Iteration 52580: loss = 2.5520\n",
      "Iteration 52590: loss = 2.6262\n",
      "Iteration 52600: loss = 2.8519\n",
      "Iteration 52610: loss = 2.4187\n",
      "Iteration 52620: loss = 2.6329\n",
      "Iteration 52630: loss = 2.2881\n",
      "Iteration 52640: loss = 2.3488\n",
      "Iteration 52650: loss = 2.7558\n",
      "Iteration 52660: loss = 2.5969\n",
      "Iteration 52670: loss = 2.3471\n",
      "Iteration 52680: loss = 2.3651\n",
      "Iteration 52690: loss = 2.3160\n",
      "Iteration 52700: loss = 2.7201\n",
      "Iteration 52710: loss = 2.2388\n",
      "Iteration 52720: loss = 2.2088\n",
      "Iteration 52730: loss = 2.4468\n",
      "Iteration 52740: loss = 2.3357\n",
      "Iteration 52750: loss = 2.2777\n",
      "Iteration 52760: loss = 2.3967\n",
      "Iteration 52770: loss = 1.9998\n",
      "Iteration 52780: loss = 2.3776\n",
      "Iteration 52790: loss = 2.3512\n",
      "Iteration 52800: loss = 2.3045\n",
      "Iteration 52810: loss = 2.5586\n",
      "Iteration 52820: loss = 2.5453\n",
      "Iteration 52830: loss = 2.6233\n",
      "Iteration 52840: loss = 2.5362\n",
      "Iteration 52850: loss = 2.5520\n",
      "Iteration 52860: loss = 2.6593\n",
      "Iteration 52870: loss = 2.0981\n",
      "Iteration 52880: loss = 2.3620\n",
      "Iteration 52890: loss = 2.7110\n",
      "Iteration 52900: loss = 2.2362\n",
      "Iteration 52910: loss = 2.6160\n",
      "Iteration 52920: loss = 2.1977\n",
      "Iteration 52930: loss = 2.6323\n",
      "Iteration 52940: loss = 2.3228\n",
      "Iteration 52950: loss = 2.4314\n",
      "Iteration 52960: loss = 2.2816\n",
      "Iteration 52970: loss = 2.6102\n",
      "Iteration 52980: loss = 2.5308\n",
      "Iteration 52990: loss = 2.2311\n",
      "Iteration 53000: loss = 2.4148\n",
      "Iteration 53010: loss = 2.8012\n",
      "Iteration 53020: loss = 2.5752\n",
      "Iteration 53030: loss = 2.7027\n",
      "Iteration 53040: loss = 2.6181\n",
      "Iteration 53050: loss = 2.3674\n",
      "Iteration 53060: loss = 2.4965\n",
      "Iteration 53070: loss = 2.7450\n",
      "Iteration 53080: loss = 2.7291\n",
      "Iteration 53090: loss = 3.2981\n",
      "Iteration 53100: loss = 2.2522\n",
      "Iteration 53110: loss = 2.5844\n",
      "Iteration 53120: loss = 2.2577\n",
      "Iteration 53130: loss = 2.5103\n",
      "Iteration 53140: loss = 2.4375\n",
      "Iteration 53150: loss = 3.0735\n",
      "Iteration 53160: loss = 2.6152\n",
      "Iteration 53170: loss = 2.5899\n",
      "Iteration 53180: loss = 2.0734\n",
      "Iteration 53190: loss = 2.1639\n",
      "Iteration 53200: loss = 2.1523\n",
      "Iteration 53210: loss = 2.4315\n",
      "Iteration 53220: loss = 2.5489\n",
      "Iteration 53230: loss = 2.7287\n",
      "Iteration 53240: loss = 2.4691\n",
      "Iteration 53250: loss = 2.5100\n",
      "Iteration 53260: loss = 2.2830\n",
      "Iteration 53270: loss = 2.3926\n",
      "Iteration 53280: loss = 2.3987\n",
      "Iteration 53290: loss = 2.2866\n",
      "Iteration 53300: loss = 2.3679\n",
      "Iteration 53310: loss = 2.5540\n",
      "Iteration 53320: loss = 2.1874\n",
      "Iteration 53330: loss = 2.5641\n",
      "Iteration 53340: loss = 2.5086\n",
      "Iteration 53350: loss = 2.1678\n",
      "Iteration 53360: loss = 2.6956\n",
      "Iteration 53370: loss = 2.5336\n",
      "Iteration 53380: loss = 2.5975\n",
      "Iteration 53390: loss = 2.3998\n",
      "Iteration 53400: loss = 2.4316\n",
      "Iteration 53410: loss = 2.6542\n",
      "Iteration 53420: loss = 2.8702\n",
      "Iteration 53430: loss = 2.4240\n",
      "Iteration 53440: loss = 2.2735\n",
      "Iteration 53450: loss = 2.3222\n",
      "Iteration 53460: loss = 2.3943\n",
      "Iteration 53470: loss = 2.7518\n",
      "Iteration 53480: loss = 2.6014\n",
      "Iteration 53490: loss = 2.4865\n",
      "Iteration 53500: loss = 2.5060\n",
      "Iteration 53510: loss = 2.1674\n",
      "Iteration 53520: loss = 2.3501\n",
      "Iteration 53530: loss = 2.6877\n",
      "Iteration 53540: loss = 2.8403\n",
      "Iteration 53550: loss = 2.4721\n",
      "Iteration 53560: loss = 2.1541\n",
      "Iteration 53570: loss = 2.5061\n",
      "Iteration 53580: loss = 2.8199\n",
      "Iteration 53590: loss = 2.2887\n",
      "Iteration 53600: loss = 2.5429\n",
      "Iteration 53610: loss = 2.5240\n",
      "Iteration 53620: loss = 2.5386\n",
      "Iteration 53630: loss = 2.5959\n",
      "Iteration 53640: loss = 2.0687\n",
      "Iteration 53650: loss = 2.6671\n",
      "Iteration 53660: loss = 2.0359\n",
      "Iteration 53670: loss = 2.6049\n",
      "Iteration 53680: loss = 2.1134\n",
      "Iteration 53690: loss = 2.3958\n",
      "Iteration 53700: loss = 2.3860\n",
      "Iteration 53710: loss = 2.3683\n",
      "Iteration 53720: loss = 2.1477\n",
      "Iteration 53730: loss = 2.6731\n",
      "Iteration 53740: loss = 2.3118\n",
      "Iteration 53750: loss = 2.6446\n",
      "Iteration 53760: loss = 2.3497\n",
      "Iteration 53770: loss = 2.2535\n",
      "Iteration 53780: loss = 2.4892\n",
      "Iteration 53790: loss = 2.2970\n",
      "Iteration 53800: loss = 2.3561\n",
      "Iteration 53810: loss = 2.4220\n",
      "Iteration 53820: loss = 2.4123\n",
      "Iteration 53830: loss = 2.4212\n",
      "Iteration 53840: loss = 2.2057\n",
      "Iteration 53850: loss = 2.2308\n",
      "Iteration 53860: loss = 2.5082\n",
      "Iteration 53870: loss = 2.4378\n",
      "Iteration 53880: loss = 2.7114\n",
      "Iteration 53890: loss = 2.6245\n",
      "Iteration 53900: loss = 2.3868\n",
      "Iteration 53910: loss = 2.8428\n",
      "Iteration 53920: loss = 2.3038\n",
      "Iteration 53930: loss = 2.5616\n",
      "Iteration 53940: loss = 2.4083\n",
      "Iteration 53950: loss = 2.3792\n",
      "Iteration 53960: loss = 2.6707\n",
      "Iteration 53970: loss = 2.3466\n",
      "Iteration 53980: loss = 2.4697\n",
      "Iteration 53990: loss = 2.3173\n",
      "Iteration 54000: loss = 1.9966\n",
      "Iteration 54010: loss = 2.8181\n",
      "Iteration 54020: loss = 2.2572\n",
      "Iteration 54030: loss = 2.5729\n",
      "Iteration 54040: loss = 2.2785\n",
      "Iteration 54050: loss = 2.1528\n",
      "Iteration 54060: loss = 2.2964\n",
      "Iteration 54070: loss = 2.4698\n",
      "Iteration 54080: loss = 2.7356\n",
      "Iteration 54090: loss = 2.1510\n",
      "Iteration 54100: loss = 2.3735\n",
      "Iteration 54110: loss = 2.6502\n",
      "Iteration 54120: loss = 2.6265\n",
      "Iteration 54130: loss = 2.0093\n",
      "Iteration 54140: loss = 2.2002\n",
      "Iteration 54150: loss = 2.6280\n",
      "Iteration 54160: loss = 2.2622\n",
      "Iteration 54170: loss = 2.3707\n",
      "Iteration 54180: loss = 2.3808\n",
      "Iteration 54190: loss = 2.3972\n",
      "Iteration 54200: loss = 2.5193\n",
      "Iteration 54210: loss = 2.7734\n",
      "Iteration 54220: loss = 2.4902\n",
      "Iteration 54230: loss = 2.2801\n",
      "Iteration 54240: loss = 2.6064\n",
      "Iteration 54250: loss = 2.1811\n",
      "Iteration 54260: loss = 3.1787\n",
      "Iteration 54270: loss = 2.4718\n",
      "Iteration 54280: loss = 2.9374\n",
      "Iteration 54290: loss = 2.5359\n",
      "Iteration 54300: loss = 2.6091\n",
      "Iteration 54310: loss = 2.2529\n",
      "Iteration 54320: loss = 1.9100\n",
      "Iteration 54330: loss = 2.9138\n",
      "Iteration 54340: loss = 2.3641\n",
      "Iteration 54350: loss = 2.3896\n",
      "Iteration 54360: loss = 1.9530\n",
      "Iteration 54370: loss = 2.4812\n",
      "Iteration 54380: loss = 2.7156\n",
      "Iteration 54390: loss = 2.4167\n",
      "Iteration 54400: loss = 2.4547\n",
      "Iteration 54410: loss = 2.5647\n",
      "Iteration 54420: loss = 2.4493\n",
      "Iteration 54430: loss = 2.6033\n",
      "Iteration 54440: loss = 2.5366\n",
      "Iteration 54450: loss = 2.5891\n",
      "Iteration 54460: loss = 2.8062\n",
      "Iteration 54470: loss = 2.4291\n",
      "Iteration 54480: loss = 2.4297\n",
      "Iteration 54490: loss = 2.6847\n",
      "Iteration 54500: loss = 2.5379\n",
      "Iteration 54510: loss = 2.4375\n",
      "Iteration 54520: loss = 2.6184\n",
      "Iteration 54530: loss = 3.0894\n",
      "Iteration 54540: loss = 2.3126\n",
      "Iteration 54550: loss = 2.0989\n",
      "Iteration 54560: loss = 2.6269\n",
      "Iteration 54570: loss = 2.3907\n",
      "Iteration 54580: loss = 2.5144\n",
      "Iteration 54590: loss = 2.7800\n",
      "Iteration 54600: loss = 2.0372\n",
      "Iteration 54610: loss = 2.4207\n",
      "Iteration 54620: loss = 2.3343\n",
      "Iteration 54630: loss = 2.3320\n",
      "Iteration 54640: loss = 2.7548\n",
      "Iteration 54650: loss = 2.6243\n",
      "Iteration 54660: loss = 2.4151\n",
      "Iteration 54670: loss = 2.5476\n",
      "Iteration 54680: loss = 2.4080\n",
      "Iteration 54690: loss = 2.1553\n",
      "Iteration 54700: loss = 2.5004\n",
      "Iteration 54710: loss = 2.5312\n",
      "Iteration 54720: loss = 2.8106\n",
      "Iteration 54730: loss = 2.2381\n",
      "Iteration 54740: loss = 2.5380\n",
      "Iteration 54750: loss = 2.7262\n",
      "Iteration 54760: loss = 2.6117\n",
      "Iteration 54770: loss = 2.3278\n",
      "Iteration 54780: loss = 2.3586\n",
      "Iteration 54790: loss = 2.4929\n",
      "Iteration 54800: loss = 2.5289\n",
      "Iteration 54810: loss = 2.2402\n",
      "Iteration 54820: loss = 2.6044\n",
      "Iteration 54830: loss = 2.3936\n",
      "Iteration 54840: loss = 2.3878\n",
      "Iteration 54850: loss = 2.4968\n",
      "Iteration 54860: loss = 2.3709\n",
      "Iteration 54870: loss = 2.6564\n",
      "Iteration 54880: loss = 2.3851\n",
      "Iteration 54890: loss = 2.2200\n",
      "Iteration 54900: loss = 2.5404\n",
      "Iteration 54910: loss = 2.5069\n",
      "Iteration 54920: loss = 2.5445\n",
      "Iteration 54930: loss = 2.5210\n",
      "Iteration 54940: loss = 2.5401\n",
      "Iteration 54950: loss = 2.2595\n",
      "Iteration 54960: loss = 2.2811\n",
      "Iteration 54970: loss = 2.9775\n",
      "Iteration 54980: loss = 2.5165\n",
      "Iteration 54990: loss = 2.4712\n",
      "Iteration 55000: loss = 2.2576\n",
      "Iteration 55010: loss = 2.3420\n",
      "Iteration 55020: loss = 2.4403\n",
      "Iteration 55030: loss = 2.3652\n",
      "Iteration 55040: loss = 2.7140\n",
      "Iteration 55050: loss = 2.5522\n",
      "Iteration 55060: loss = 2.2160\n",
      "Iteration 55070: loss = 2.4718\n",
      "Iteration 55080: loss = 2.5333\n",
      "Iteration 55090: loss = 2.3129\n",
      "Iteration 55100: loss = 2.5223\n",
      "Iteration 55110: loss = 2.4346\n",
      "Iteration 55120: loss = 2.6881\n",
      "Iteration 55130: loss = 2.2109\n",
      "Iteration 55140: loss = 2.2948\n",
      "Iteration 55150: loss = 2.0779\n",
      "Iteration 55160: loss = 2.3741\n",
      "Iteration 55170: loss = 2.4310\n",
      "Iteration 55180: loss = 2.0872\n",
      "Iteration 55190: loss = 2.4056\n",
      "Iteration 55200: loss = 2.1821\n",
      "Iteration 55210: loss = 2.4481\n",
      "Iteration 55220: loss = 2.7140\n",
      "Iteration 55230: loss = 2.4371\n",
      "Iteration 55240: loss = 1.8642\n",
      "Iteration 55250: loss = 2.2793\n",
      "Iteration 55260: loss = 2.6152\n",
      "Iteration 55270: loss = 2.6227\n",
      "Iteration 55280: loss = 2.3730\n",
      "Iteration 55290: loss = 2.1834\n",
      "Iteration 55300: loss = 2.6464\n",
      "Iteration 55310: loss = 2.3584\n",
      "Iteration 55320: loss = 2.0660\n",
      "Iteration 55330: loss = 2.3097\n",
      "Iteration 55340: loss = 2.7723\n",
      "Iteration 55350: loss = 2.5367\n",
      "Iteration 55360: loss = 2.2202\n",
      "Iteration 55370: loss = 2.5520\n",
      "Iteration 55380: loss = 2.1826\n",
      "Iteration 55390: loss = 2.4979\n",
      "Iteration 55400: loss = 2.8499\n",
      "Iteration 55410: loss = 2.7541\n",
      "Iteration 55420: loss = 2.4745\n",
      "Iteration 55430: loss = 2.3451\n",
      "Iteration 55440: loss = 1.9491\n",
      "Iteration 55450: loss = 2.6459\n",
      "Iteration 55460: loss = 2.4773\n",
      "Iteration 55470: loss = 2.1454\n",
      "Iteration 55480: loss = 2.9193\n",
      "Iteration 55490: loss = 2.4363\n",
      "Iteration 55500: loss = 2.6414\n",
      "Iteration 55510: loss = 2.0535\n",
      "Iteration 55520: loss = 2.4797\n",
      "Iteration 55530: loss = 2.3051\n",
      "Iteration 55540: loss = 2.4863\n",
      "Iteration 55550: loss = 2.3790\n",
      "Iteration 55560: loss = 2.3842\n",
      "Iteration 55570: loss = 2.3949\n",
      "Iteration 55580: loss = 2.6868\n",
      "Iteration 55590: loss = 2.3641\n",
      "Iteration 55600: loss = 2.1710\n",
      "Iteration 55610: loss = 2.3640\n",
      "Iteration 55620: loss = 2.2629\n",
      "Iteration 55630: loss = 2.7107\n",
      "Iteration 55640: loss = 2.8204\n",
      "Iteration 55650: loss = 2.7213\n",
      "Iteration 55660: loss = 2.4943\n",
      "Iteration 55670: loss = 2.2182\n",
      "Iteration 55680: loss = 2.5651\n",
      "Iteration 55690: loss = 2.4521\n",
      "Iteration 55700: loss = 2.7036\n",
      "Iteration 55710: loss = 2.5806\n",
      "Iteration 55720: loss = 2.5887\n",
      "Iteration 55730: loss = 2.4887\n",
      "Iteration 55740: loss = 2.6545\n",
      "Iteration 55750: loss = 2.4049\n",
      "Iteration 55760: loss = 2.8665\n",
      "Iteration 55770: loss = 2.5169\n",
      "Iteration 55780: loss = 2.1404\n",
      "Iteration 55790: loss = 2.6304\n",
      "Iteration 55800: loss = 2.4028\n",
      "Iteration 55810: loss = 2.4210\n",
      "Iteration 55820: loss = 2.5048\n",
      "Iteration 55830: loss = 2.8200\n",
      "Iteration 55840: loss = 2.1394\n",
      "Iteration 55850: loss = 2.6183\n",
      "Iteration 55860: loss = 2.2204\n",
      "Iteration 55870: loss = 2.7187\n",
      "Iteration 55880: loss = 2.3932\n",
      "Iteration 55890: loss = 2.5095\n",
      "Iteration 55900: loss = 2.4779\n",
      "Iteration 55910: loss = 2.1614\n",
      "Iteration 55920: loss = 2.3693\n",
      "Iteration 55930: loss = 2.5059\n",
      "Iteration 55940: loss = 2.6825\n",
      "Iteration 55950: loss = 2.5832\n",
      "Iteration 55960: loss = 2.3399\n",
      "Iteration 55970: loss = 2.6019\n",
      "Iteration 55980: loss = 2.4392\n",
      "Iteration 55990: loss = 2.8031\n",
      "Iteration 56000: loss = 2.6654\n",
      "Iteration 56010: loss = 2.4805\n",
      "Iteration 56020: loss = 2.3565\n",
      "Iteration 56030: loss = 1.9736\n",
      "Iteration 56040: loss = 2.5589\n",
      "Iteration 56050: loss = 2.5686\n",
      "Iteration 56060: loss = 2.2105\n",
      "Iteration 56070: loss = 2.7047\n",
      "Iteration 56080: loss = 2.1633\n",
      "Iteration 56090: loss = 2.1368\n",
      "Iteration 56100: loss = 2.9616\n",
      "Iteration 56110: loss = 2.3284\n",
      "Iteration 56120: loss = 2.4242\n",
      "Iteration 56130: loss = 2.4801\n",
      "Iteration 56140: loss = 2.7069\n",
      "Iteration 56150: loss = 2.7430\n",
      "Iteration 56160: loss = 2.4330\n",
      "Iteration 56170: loss = 2.2532\n",
      "Iteration 56180: loss = 2.3553\n",
      "Iteration 56190: loss = 2.3297\n",
      "Iteration 56200: loss = 2.5934\n",
      "Iteration 56210: loss = 2.6203\n",
      "Iteration 56220: loss = 2.7952\n",
      "Iteration 56230: loss = 2.6157\n",
      "Iteration 56240: loss = 2.1896\n",
      "Iteration 56250: loss = 2.8394\n",
      "Iteration 56260: loss = 2.5218\n",
      "Iteration 56270: loss = 2.3871\n",
      "Iteration 56280: loss = 2.3369\n",
      "Iteration 56290: loss = 2.6356\n",
      "Iteration 56300: loss = 2.1724\n",
      "Iteration 56310: loss = 2.6146\n",
      "Iteration 56320: loss = 2.5713\n",
      "Iteration 56330: loss = 2.5713\n",
      "Iteration 56340: loss = 2.8548\n",
      "Iteration 56350: loss = 2.4466\n",
      "Iteration 56360: loss = 2.5565\n",
      "Iteration 56370: loss = 2.6838\n",
      "Iteration 56380: loss = 2.3662\n",
      "Iteration 56390: loss = 2.2139\n",
      "Iteration 56400: loss = 2.8446\n",
      "Iteration 56410: loss = 2.4494\n",
      "Iteration 56420: loss = 2.3792\n",
      "Iteration 56430: loss = 2.3711\n",
      "Iteration 56440: loss = 2.6485\n",
      "Iteration 56450: loss = 2.7685\n",
      "Iteration 56460: loss = 2.6124\n",
      "Iteration 56470: loss = 2.1959\n",
      "Iteration 56480: loss = 2.4615\n",
      "Iteration 56490: loss = 2.3186\n",
      "Iteration 56500: loss = 2.1737\n",
      "Iteration 56510: loss = 1.9275\n",
      "Iteration 56520: loss = 2.3916\n",
      "Iteration 56530: loss = 2.3077\n",
      "Iteration 56540: loss = 2.5875\n",
      "Iteration 56550: loss = 2.6588\n",
      "Iteration 56560: loss = 2.5426\n",
      "Iteration 56570: loss = 2.5985\n",
      "Iteration 56580: loss = 2.5246\n",
      "Iteration 56590: loss = 2.6208\n",
      "Iteration 56600: loss = 2.8147\n",
      "Iteration 56610: loss = 2.3700\n",
      "Iteration 56620: loss = 2.2411\n",
      "Iteration 56630: loss = 2.4402\n",
      "Iteration 56640: loss = 2.6367\n",
      "Iteration 56650: loss = 2.2163\n",
      "Iteration 56660: loss = 2.1932\n",
      "Iteration 56670: loss = 2.2180\n",
      "Iteration 56680: loss = 2.5983\n",
      "Iteration 56690: loss = 2.4823\n",
      "Iteration 56700: loss = 2.6846\n",
      "Iteration 56710: loss = 2.3609\n",
      "Iteration 56720: loss = 2.3752\n",
      "Iteration 56730: loss = 2.6651\n",
      "Iteration 56740: loss = 2.8388\n",
      "Iteration 56750: loss = 2.4816\n",
      "Iteration 56760: loss = 2.2224\n",
      "Iteration 56770: loss = 2.8446\n",
      "Iteration 56780: loss = 2.9062\n",
      "Iteration 56790: loss = 2.4781\n",
      "Iteration 56800: loss = 2.7672\n",
      "Iteration 56810: loss = 2.3872\n",
      "Iteration 56820: loss = 2.3004\n",
      "Iteration 56830: loss = 2.3787\n",
      "Iteration 56840: loss = 2.6644\n",
      "Iteration 56850: loss = 2.5126\n",
      "Iteration 56860: loss = 2.8369\n",
      "Iteration 56870: loss = 2.4285\n",
      "Iteration 56880: loss = 2.4975\n",
      "Iteration 56890: loss = 2.1405\n",
      "Iteration 56900: loss = 2.6421\n",
      "Iteration 56910: loss = 2.2663\n",
      "Iteration 56920: loss = 2.4081\n",
      "Iteration 56930: loss = 2.7258\n",
      "Iteration 56940: loss = 2.3141\n",
      "Iteration 56950: loss = 2.1828\n",
      "Iteration 56960: loss = 2.1119\n",
      "Iteration 56970: loss = 2.2692\n",
      "Iteration 56980: loss = 2.6526\n",
      "Iteration 56990: loss = 2.2785\n",
      "Iteration 57000: loss = 2.6565\n",
      "Iteration 57010: loss = 2.6295\n",
      "Iteration 57020: loss = 2.2042\n",
      "Iteration 57030: loss = 2.6029\n",
      "Iteration 57040: loss = 2.3764\n",
      "Iteration 57050: loss = 2.2392\n",
      "Iteration 57060: loss = 2.7245\n",
      "Iteration 57070: loss = 2.3982\n",
      "Iteration 57080: loss = 2.4740\n",
      "Iteration 57090: loss = 2.6340\n",
      "Iteration 57100: loss = 2.4285\n",
      "Iteration 57110: loss = 2.1763\n",
      "Iteration 57120: loss = 2.6999\n",
      "Iteration 57130: loss = 2.0812\n",
      "Iteration 57140: loss = 2.1264\n",
      "Iteration 57150: loss = 2.4173\n",
      "Iteration 57160: loss = 2.5678\n",
      "Iteration 57170: loss = 2.4576\n",
      "Iteration 57180: loss = 2.7157\n",
      "Iteration 57190: loss = 2.4563\n",
      "Iteration 57200: loss = 2.5702\n",
      "Iteration 57210: loss = 2.1220\n",
      "Iteration 57220: loss = 2.5158\n",
      "Iteration 57230: loss = 1.9838\n",
      "Iteration 57240: loss = 2.7489\n",
      "Iteration 57250: loss = 2.7834\n",
      "Iteration 57260: loss = 2.7308\n",
      "Iteration 57270: loss = 2.3568\n",
      "Iteration 57280: loss = 2.1764\n",
      "Iteration 57290: loss = 2.2178\n",
      "Iteration 57300: loss = 2.5159\n",
      "Iteration 57310: loss = 2.6617\n",
      "Iteration 57320: loss = 2.6059\n",
      "Iteration 57330: loss = 2.5691\n",
      "Iteration 57340: loss = 2.1285\n",
      "Iteration 57350: loss = 2.7610\n",
      "Iteration 57360: loss = 2.7562\n",
      "Iteration 57370: loss = 2.9797\n",
      "Iteration 57380: loss = 2.8827\n",
      "Iteration 57390: loss = 2.4633\n",
      "Iteration 57400: loss = 2.4696\n",
      "Iteration 57410: loss = 2.6211\n",
      "Iteration 57420: loss = 2.5151\n",
      "Iteration 57430: loss = 2.3187\n",
      "Iteration 57440: loss = 2.2845\n",
      "Iteration 57450: loss = 2.6733\n",
      "Iteration 57460: loss = 2.8473\n",
      "Iteration 57470: loss = 2.2219\n",
      "Iteration 57480: loss = 2.6585\n",
      "Iteration 57490: loss = 2.3128\n",
      "Iteration 57500: loss = 2.6626\n",
      "Iteration 57510: loss = 2.4986\n",
      "Iteration 57520: loss = 2.5824\n",
      "Iteration 57530: loss = 2.4625\n",
      "Iteration 57540: loss = 2.3186\n",
      "Iteration 57550: loss = 2.5128\n",
      "Iteration 57560: loss = 2.1286\n",
      "Iteration 57570: loss = 2.5029\n",
      "Iteration 57580: loss = 2.5059\n",
      "Iteration 57590: loss = 2.2985\n",
      "Iteration 57600: loss = 2.5000\n",
      "Iteration 57610: loss = 2.5027\n",
      "Iteration 57620: loss = 2.3337\n",
      "Iteration 57630: loss = 2.3156\n",
      "Iteration 57640: loss = 2.3380\n",
      "Iteration 57650: loss = 2.8240\n",
      "Iteration 57660: loss = 2.2671\n",
      "Iteration 57670: loss = 2.6601\n",
      "Iteration 57680: loss = 2.7024\n",
      "Iteration 57690: loss = 2.0070\n",
      "Iteration 57700: loss = 2.4707\n",
      "Iteration 57710: loss = 2.4004\n",
      "Iteration 57720: loss = 2.2639\n",
      "Iteration 57730: loss = 2.4935\n",
      "Iteration 57740: loss = 2.1697\n",
      "Iteration 57750: loss = 2.5927\n",
      "Iteration 57760: loss = 2.7299\n",
      "Iteration 57770: loss = 2.3084\n",
      "Iteration 57780: loss = 2.4244\n",
      "Iteration 57790: loss = 2.7715\n",
      "Iteration 57800: loss = 2.5894\n",
      "Iteration 57810: loss = 2.4744\n",
      "Iteration 57820: loss = 2.2739\n",
      "Iteration 57830: loss = 2.4970\n",
      "Iteration 57840: loss = 2.5279\n",
      "Iteration 57850: loss = 2.4812\n",
      "Iteration 57860: loss = 2.5226\n",
      "Iteration 57870: loss = 2.1215\n",
      "Iteration 57880: loss = 2.5512\n",
      "Iteration 57890: loss = 2.7087\n",
      "Iteration 57900: loss = 2.7672\n",
      "Iteration 57910: loss = 2.5699\n",
      "Iteration 57920: loss = 2.2402\n",
      "Iteration 57930: loss = 2.4975\n",
      "Iteration 57940: loss = 2.2769\n",
      "Iteration 57950: loss = 2.6357\n",
      "Iteration 57960: loss = 2.9125\n",
      "Iteration 57970: loss = 2.7418\n",
      "Iteration 57980: loss = 2.2822\n",
      "Iteration 57990: loss = 2.3350\n",
      "Iteration 58000: loss = 2.0881\n",
      "Iteration 58010: loss = 2.5072\n",
      "Iteration 58020: loss = 2.2221\n",
      "Iteration 58030: loss = 2.1940\n",
      "Iteration 58040: loss = 2.8369\n",
      "Iteration 58050: loss = 2.3560\n",
      "Iteration 58060: loss = 2.6055\n",
      "Iteration 58070: loss = 2.6700\n",
      "Iteration 58080: loss = 2.3023\n",
      "Iteration 58090: loss = 2.5384\n",
      "Iteration 58100: loss = 2.3831\n",
      "Iteration 58110: loss = 2.8451\n",
      "Iteration 58120: loss = 2.7985\n",
      "Iteration 58130: loss = 2.1465\n",
      "Iteration 58140: loss = 2.3337\n",
      "Iteration 58150: loss = 2.0533\n",
      "Iteration 58160: loss = 2.4873\n",
      "Iteration 58170: loss = 2.1238\n",
      "Iteration 58180: loss = 2.2524\n",
      "Iteration 58190: loss = 2.5546\n",
      "Iteration 58200: loss = 2.3074\n",
      "Iteration 58210: loss = 2.4727\n",
      "Iteration 58220: loss = 2.9073\n",
      "Iteration 58230: loss = 2.3592\n",
      "Iteration 58240: loss = 2.3549\n",
      "Iteration 58250: loss = 2.5465\n",
      "Iteration 58260: loss = 2.6920\n",
      "Iteration 58270: loss = 2.4899\n",
      "Iteration 58280: loss = 2.6041\n",
      "Iteration 58290: loss = 2.3796\n",
      "Iteration 58300: loss = 2.4732\n",
      "Iteration 58310: loss = 2.3341\n",
      "Iteration 58320: loss = 2.3259\n",
      "Iteration 58330: loss = 2.2803\n",
      "Iteration 58340: loss = 2.4616\n",
      "Iteration 58350: loss = 2.4058\n",
      "Iteration 58360: loss = 2.2657\n",
      "Iteration 58370: loss = 2.1676\n",
      "Iteration 58380: loss = 2.4536\n",
      "Iteration 58390: loss = 2.2679\n",
      "Iteration 58400: loss = 2.0599\n",
      "Iteration 58410: loss = 2.1058\n",
      "Iteration 58420: loss = 2.1046\n",
      "Iteration 58430: loss = 2.5912\n",
      "Iteration 58440: loss = 2.8067\n",
      "Iteration 58450: loss = 2.3169\n",
      "Iteration 58460: loss = 2.6659\n",
      "Iteration 58470: loss = 2.4405\n",
      "Iteration 58480: loss = 2.1958\n",
      "Iteration 58490: loss = 2.5723\n",
      "Iteration 58500: loss = 2.3297\n",
      "Iteration 58510: loss = 2.7935\n",
      "Iteration 58520: loss = 2.4061\n",
      "Iteration 58530: loss = 2.3661\n",
      "Iteration 58540: loss = 2.4896\n",
      "Iteration 58550: loss = 2.2905\n",
      "Iteration 58560: loss = 2.7843\n",
      "Iteration 58570: loss = 2.5448\n",
      "Iteration 58580: loss = 2.0512\n",
      "Iteration 58590: loss = 2.4384\n",
      "Iteration 58600: loss = 2.7676\n",
      "Iteration 58610: loss = 2.5423\n",
      "Iteration 58620: loss = 2.5822\n",
      "Iteration 58630: loss = 2.0698\n",
      "Iteration 58640: loss = 2.4649\n",
      "Iteration 58650: loss = 2.7016\n",
      "Iteration 58660: loss = 2.2193\n",
      "Iteration 58670: loss = 2.3945\n",
      "Iteration 58680: loss = 2.5365\n",
      "Iteration 58690: loss = 2.5352\n",
      "Iteration 58700: loss = 2.5471\n",
      "Iteration 58710: loss = 3.1420\n",
      "Iteration 58720: loss = 2.4939\n",
      "Iteration 58730: loss = 2.3895\n",
      "Iteration 58740: loss = 2.1416\n",
      "Iteration 58750: loss = 2.6009\n",
      "Iteration 58760: loss = 2.4515\n",
      "Iteration 58770: loss = 2.5654\n",
      "Iteration 58780: loss = 2.4895\n",
      "Iteration 58790: loss = 2.5941\n",
      "Iteration 58800: loss = 2.4624\n",
      "Iteration 58810: loss = 2.3813\n",
      "Iteration 58820: loss = 2.5817\n",
      "Iteration 58830: loss = 2.8019\n",
      "Iteration 58840: loss = 2.3884\n",
      "Iteration 58850: loss = 2.4551\n",
      "Iteration 58860: loss = 2.3803\n",
      "Iteration 58870: loss = 2.6609\n",
      "Iteration 58880: loss = 2.7135\n",
      "Iteration 58890: loss = 2.3563\n",
      "Iteration 58900: loss = 2.6171\n",
      "Iteration 58910: loss = 2.9844\n",
      "Iteration 58920: loss = 2.3787\n",
      "Iteration 58930: loss = 2.3690\n",
      "Iteration 58940: loss = 2.6516\n",
      "Iteration 58950: loss = 2.4263\n",
      "Iteration 58960: loss = 2.6748\n",
      "Iteration 58970: loss = 2.5995\n",
      "Iteration 58980: loss = 2.2563\n",
      "Iteration 58990: loss = 2.2803\n",
      "Iteration 59000: loss = 2.4950\n",
      "Iteration 59010: loss = 2.8565\n",
      "Iteration 59020: loss = 2.8476\n",
      "Iteration 59030: loss = 2.1463\n",
      "Iteration 59040: loss = 2.1279\n",
      "Iteration 59050: loss = 2.6266\n",
      "Iteration 59060: loss = 2.6921\n",
      "Iteration 59070: loss = 2.6176\n",
      "Iteration 59080: loss = 2.4878\n",
      "Iteration 59090: loss = 2.7034\n",
      "Iteration 59100: loss = 2.2151\n",
      "Iteration 59110: loss = 2.7628\n",
      "Iteration 59120: loss = 2.5410\n",
      "Iteration 59130: loss = 2.1273\n",
      "Iteration 59140: loss = 2.3499\n",
      "Iteration 59150: loss = 2.3402\n",
      "Iteration 59160: loss = 2.4618\n",
      "Iteration 59170: loss = 2.5279\n",
      "Iteration 59180: loss = 2.5312\n",
      "Iteration 59190: loss = 2.5863\n",
      "Iteration 59200: loss = 2.2378\n",
      "Iteration 59210: loss = 2.6499\n",
      "Iteration 59220: loss = 2.3185\n",
      "Iteration 59230: loss = 3.0192\n",
      "Iteration 59240: loss = 2.3854\n",
      "Iteration 59250: loss = 2.7031\n",
      "Iteration 59260: loss = 2.1545\n",
      "Iteration 59270: loss = 2.5199\n",
      "Iteration 59280: loss = 2.6062\n",
      "Iteration 59290: loss = 2.4246\n",
      "Iteration 59300: loss = 2.3859\n",
      "Iteration 59310: loss = 2.5496\n",
      "Iteration 59320: loss = 2.6507\n",
      "Iteration 59330: loss = 2.1404\n",
      "Iteration 59340: loss = 2.3402\n",
      "Iteration 59350: loss = 2.2381\n",
      "Iteration 59360: loss = 2.6920\n",
      "Iteration 59370: loss = 2.6798\n",
      "Iteration 59380: loss = 2.3672\n",
      "Iteration 59390: loss = 2.8534\n",
      "Iteration 59400: loss = 2.8495\n",
      "Iteration 59410: loss = 2.8192\n",
      "Iteration 59420: loss = 2.8694\n",
      "Iteration 59430: loss = 2.4382\n",
      "Iteration 59440: loss = 2.5766\n",
      "Iteration 59450: loss = 2.4418\n",
      "Iteration 59460: loss = 2.6259\n",
      "Iteration 59470: loss = 2.4857\n",
      "Iteration 59480: loss = 2.4056\n",
      "Iteration 59490: loss = 2.2379\n",
      "Iteration 59500: loss = 2.4862\n",
      "Iteration 59510: loss = 2.0626\n",
      "Iteration 59520: loss = 2.3223\n",
      "Iteration 59530: loss = 2.7135\n",
      "Iteration 59540: loss = 2.1085\n",
      "Iteration 59550: loss = 2.6921\n",
      "Iteration 59560: loss = 2.8039\n",
      "Iteration 59570: loss = 2.2639\n",
      "Iteration 59580: loss = 2.5778\n",
      "Iteration 59590: loss = 2.5696\n",
      "Iteration 59600: loss = 2.3776\n",
      "Iteration 59610: loss = 2.3292\n",
      "Iteration 59620: loss = 2.3284\n",
      "Iteration 59630: loss = 2.4168\n",
      "Iteration 59640: loss = 2.6952\n",
      "Iteration 59650: loss = 2.7353\n",
      "Iteration 59660: loss = 2.6106\n",
      "Iteration 59670: loss = 2.1542\n",
      "Iteration 59680: loss = 2.4952\n",
      "Iteration 59690: loss = 2.6174\n",
      "Iteration 59700: loss = 2.3245\n",
      "Iteration 59710: loss = 2.0669\n",
      "Iteration 59720: loss = 2.4616\n",
      "Iteration 59730: loss = 2.6180\n",
      "Iteration 59740: loss = 2.3652\n",
      "Iteration 59750: loss = 2.5594\n",
      "Iteration 59760: loss = 2.6585\n",
      "Iteration 59770: loss = 2.2224\n",
      "Iteration 59780: loss = 2.5687\n",
      "Iteration 59790: loss = 2.8880\n",
      "Iteration 59800: loss = 2.5507\n",
      "Iteration 59810: loss = 2.5818\n",
      "Iteration 59820: loss = 2.5482\n",
      "Iteration 59830: loss = 2.5103\n",
      "Iteration 59840: loss = 2.5828\n",
      "Iteration 59850: loss = 2.4545\n",
      "Iteration 59860: loss = 2.4636\n",
      "Iteration 59870: loss = 2.8878\n",
      "Iteration 59880: loss = 2.3674\n",
      "Iteration 59890: loss = 2.3652\n",
      "Iteration 59900: loss = 2.2734\n",
      "Iteration 59910: loss = 2.3544\n",
      "Iteration 59920: loss = 2.2876\n",
      "Iteration 59930: loss = 2.7521\n",
      "Iteration 59940: loss = 2.5594\n",
      "Iteration 59950: loss = 2.8194\n",
      "Iteration 59960: loss = 2.3949\n",
      "Iteration 59970: loss = 2.0302\n",
      "Iteration 59980: loss = 2.5234\n",
      "Iteration 59990: loss = 2.2458\n",
      "Iteration 60000: loss = 2.4963\n",
      "Iteration 60010: loss = 2.6211\n",
      "Iteration 60020: loss = 2.8965\n",
      "Iteration 60030: loss = 2.5569\n",
      "Iteration 60040: loss = 2.6202\n",
      "Iteration 60050: loss = 2.4283\n",
      "Iteration 60060: loss = 2.5301\n",
      "Iteration 60070: loss = 2.6527\n",
      "Iteration 60080: loss = 2.1847\n",
      "Iteration 60090: loss = 2.6163\n",
      "Iteration 60100: loss = 2.5287\n",
      "Iteration 60110: loss = 2.8629\n",
      "Iteration 60120: loss = 2.6037\n",
      "Iteration 60130: loss = 2.1815\n",
      "Iteration 60140: loss = 2.6768\n",
      "Iteration 60150: loss = 2.6072\n",
      "Iteration 60160: loss = 2.3488\n",
      "Iteration 60170: loss = 2.5677\n",
      "Iteration 60180: loss = 2.6176\n",
      "Iteration 60190: loss = 2.3492\n",
      "Iteration 60200: loss = 2.6849\n",
      "Iteration 60210: loss = 2.1208\n",
      "Iteration 60220: loss = 2.3871\n",
      "Iteration 60230: loss = 2.4301\n",
      "Iteration 60240: loss = 2.6825\n",
      "Iteration 60250: loss = 2.8880\n",
      "Iteration 60260: loss = 2.2771\n",
      "Iteration 60270: loss = 2.3946\n",
      "Iteration 60280: loss = 2.5796\n",
      "Iteration 60290: loss = 2.5407\n",
      "Iteration 60300: loss = 2.3853\n",
      "Iteration 60310: loss = 2.7309\n",
      "Iteration 60320: loss = 2.4233\n",
      "Iteration 60330: loss = 2.5818\n",
      "Iteration 60340: loss = 2.1825\n",
      "Iteration 60350: loss = 2.4960\n",
      "Iteration 60360: loss = 2.1518\n",
      "Iteration 60370: loss = 2.3459\n",
      "Iteration 60380: loss = 2.5974\n",
      "Iteration 60390: loss = 2.4945\n",
      "Iteration 60400: loss = 2.5808\n",
      "Iteration 60410: loss = 2.4562\n",
      "Iteration 60420: loss = 2.9304\n",
      "Iteration 60430: loss = 2.2182\n",
      "Iteration 60440: loss = 2.5624\n",
      "Iteration 60450: loss = 2.8098\n",
      "Iteration 60460: loss = 2.4002\n",
      "Iteration 60470: loss = 2.0915\n",
      "Iteration 60480: loss = 2.4355\n",
      "Iteration 60490: loss = 2.1854\n",
      "Iteration 60500: loss = 2.7102\n",
      "Iteration 60510: loss = 2.5759\n",
      "Iteration 60520: loss = 2.0404\n",
      "Iteration 60530: loss = 2.5299\n",
      "Iteration 60540: loss = 2.3763\n",
      "Iteration 60550: loss = 2.6183\n",
      "Iteration 60560: loss = 2.5962\n",
      "Iteration 60570: loss = 2.7361\n",
      "Iteration 60580: loss = 2.6341\n",
      "Iteration 60590: loss = 2.5520\n",
      "Iteration 60600: loss = 2.7925\n",
      "Iteration 60610: loss = 2.5293\n",
      "Iteration 60620: loss = 2.8355\n",
      "Iteration 60630: loss = 2.3263\n",
      "Iteration 60640: loss = 2.1503\n",
      "Iteration 60650: loss = 2.3315\n",
      "Iteration 60660: loss = 2.1739\n",
      "Iteration 60670: loss = 2.5948\n",
      "Iteration 60680: loss = 2.9560\n",
      "Iteration 60690: loss = 2.3398\n",
      "Iteration 60700: loss = 2.1696\n",
      "Iteration 60710: loss = 2.4620\n",
      "Iteration 60720: loss = 2.5352\n",
      "Iteration 60730: loss = 2.6857\n",
      "Iteration 60740: loss = 2.6420\n",
      "Iteration 60750: loss = 2.3767\n",
      "Iteration 60760: loss = 2.2611\n",
      "Iteration 60770: loss = 2.2763\n",
      "Iteration 60780: loss = 2.5671\n",
      "Iteration 60790: loss = 2.3773\n",
      "Iteration 60800: loss = 2.6967\n",
      "Iteration 60810: loss = 2.4617\n",
      "Iteration 60820: loss = 2.4690\n",
      "Iteration 60830: loss = 2.5317\n",
      "Iteration 60840: loss = 2.6069\n",
      "Iteration 60850: loss = 2.5451\n",
      "Iteration 60860: loss = 2.2689\n",
      "Iteration 60870: loss = 2.7106\n",
      "Iteration 60880: loss = 2.7110\n",
      "Iteration 60890: loss = 3.1167\n",
      "Iteration 60900: loss = 2.2992\n",
      "Iteration 60910: loss = 2.1555\n",
      "Iteration 60920: loss = 2.5124\n",
      "Iteration 60930: loss = 2.3382\n",
      "Iteration 60940: loss = 2.5738\n",
      "Iteration 60950: loss = 2.6480\n",
      "Iteration 60960: loss = 2.4270\n",
      "Iteration 60970: loss = 2.3156\n",
      "Iteration 60980: loss = 2.2109\n",
      "Iteration 60990: loss = 2.7342\n",
      "Iteration 61000: loss = 2.6201\n",
      "Iteration 61010: loss = 2.1329\n",
      "Iteration 61020: loss = 2.5241\n",
      "Iteration 61030: loss = 2.9621\n",
      "Iteration 61040: loss = 2.7673\n",
      "Iteration 61050: loss = 2.4280\n",
      "Iteration 61060: loss = 2.1804\n",
      "Iteration 61070: loss = 2.2419\n",
      "Iteration 61080: loss = 2.8267\n",
      "Iteration 61090: loss = 2.3846\n",
      "Iteration 61100: loss = 2.1652\n",
      "Iteration 61110: loss = 2.3289\n",
      "Iteration 61120: loss = 2.5819\n",
      "Iteration 61130: loss = 2.5338\n",
      "Iteration 61140: loss = 2.6047\n",
      "Iteration 61150: loss = 2.2536\n",
      "Iteration 61160: loss = 2.2349\n",
      "Iteration 61170: loss = 2.4044\n",
      "Iteration 61180: loss = 2.4621\n",
      "Iteration 61190: loss = 2.4613\n",
      "Iteration 61200: loss = 2.4366\n",
      "Iteration 61210: loss = 2.6558\n",
      "Iteration 61220: loss = 2.8957\n",
      "Iteration 61230: loss = 2.5242\n",
      "Iteration 61240: loss = 1.9236\n",
      "Iteration 61250: loss = 2.6492\n",
      "Iteration 61260: loss = 2.2850\n",
      "Iteration 61270: loss = 2.1234\n",
      "Iteration 61280: loss = 2.5814\n",
      "Iteration 61290: loss = 2.6249\n",
      "Iteration 61300: loss = 2.9269\n",
      "Iteration 61310: loss = 2.0822\n",
      "Iteration 61320: loss = 2.2211\n",
      "Iteration 61330: loss = 2.5866\n",
      "Iteration 61340: loss = 2.9545\n",
      "Iteration 61350: loss = 2.6202\n",
      "Iteration 61360: loss = 2.2283\n",
      "Iteration 61370: loss = 2.5234\n",
      "Iteration 61380: loss = 2.4894\n",
      "Iteration 61390: loss = 2.6457\n",
      "Iteration 61400: loss = 2.4193\n",
      "Iteration 61410: loss = 2.0893\n",
      "Iteration 61420: loss = 2.3595\n",
      "Iteration 61430: loss = 2.2979\n",
      "Iteration 61440: loss = 2.6434\n",
      "Iteration 61450: loss = 2.4379\n",
      "Iteration 61460: loss = 2.4961\n",
      "Iteration 61470: loss = 2.6392\n",
      "Iteration 61480: loss = 2.6258\n",
      "Iteration 61490: loss = 1.8976\n",
      "Iteration 61500: loss = 2.3876\n",
      "Iteration 61510: loss = 2.6242\n",
      "Iteration 61520: loss = 2.3604\n",
      "Iteration 61530: loss = 2.2292\n",
      "Iteration 61540: loss = 2.5218\n",
      "Iteration 61550: loss = 2.5658\n",
      "Iteration 61560: loss = 2.5092\n",
      "Iteration 61570: loss = 2.5542\n",
      "Iteration 61580: loss = 2.4633\n",
      "Iteration 61590: loss = 2.5631\n",
      "Iteration 61600: loss = 2.2705\n",
      "Iteration 61610: loss = 2.7705\n",
      "Iteration 61620: loss = 2.5550\n",
      "Iteration 61630: loss = 2.5357\n",
      "Iteration 61640: loss = 2.1550\n",
      "Iteration 61650: loss = 2.4150\n",
      "Iteration 61660: loss = 2.8986\n",
      "Iteration 61670: loss = 2.3820\n",
      "Iteration 61680: loss = 2.4962\n",
      "Iteration 61690: loss = 2.5740\n",
      "Iteration 61700: loss = 2.2407\n",
      "Iteration 61710: loss = 2.6114\n",
      "Iteration 61720: loss = 2.7459\n",
      "Iteration 61730: loss = 2.6208\n",
      "Iteration 61740: loss = 2.9762\n",
      "Iteration 61750: loss = 2.5782\n",
      "Iteration 61760: loss = 2.8220\n",
      "Iteration 61770: loss = 2.2636\n",
      "Iteration 61780: loss = 2.7488\n",
      "Iteration 61790: loss = 2.4672\n",
      "Iteration 61800: loss = 2.2916\n",
      "Iteration 61810: loss = 2.3351\n",
      "Iteration 61820: loss = 2.9606\n",
      "Iteration 61830: loss = 2.2577\n",
      "Iteration 61840: loss = 2.6083\n",
      "Iteration 61850: loss = 2.5540\n",
      "Iteration 61860: loss = 2.7182\n",
      "Iteration 61870: loss = 2.0678\n",
      "Iteration 61880: loss = 2.4436\n",
      "Iteration 61890: loss = 2.6522\n",
      "Iteration 61900: loss = 3.0841\n",
      "Iteration 61910: loss = 2.6285\n",
      "Iteration 61920: loss = 2.4806\n",
      "Iteration 61930: loss = 2.4722\n",
      "Iteration 61940: loss = 2.4160\n",
      "Iteration 61950: loss = 2.7219\n",
      "Iteration 61960: loss = 2.2994\n",
      "Iteration 61970: loss = 2.4611\n",
      "Iteration 61980: loss = 2.5832\n",
      "Iteration 61990: loss = 2.5309\n",
      "Iteration 62000: loss = 2.4313\n",
      "Iteration 62010: loss = 2.5887\n",
      "Iteration 62020: loss = 2.4751\n",
      "Iteration 62030: loss = 2.4695\n",
      "Iteration 62040: loss = 2.3597\n",
      "Iteration 62050: loss = 2.3515\n",
      "Iteration 62060: loss = 2.5699\n",
      "Iteration 62070: loss = 2.5240\n",
      "Iteration 62080: loss = 2.3109\n",
      "Iteration 62090: loss = 3.3029\n",
      "Iteration 62100: loss = 2.5939\n",
      "Iteration 62110: loss = 2.4978\n",
      "Iteration 62120: loss = 2.8665\n",
      "Iteration 62130: loss = 2.8400\n",
      "Iteration 62140: loss = 2.2884\n",
      "Iteration 62150: loss = 2.1633\n",
      "Iteration 62160: loss = 2.2473\n",
      "Iteration 62170: loss = 2.5019\n",
      "Iteration 62180: loss = 2.3201\n",
      "Iteration 62190: loss = 2.3887\n",
      "Iteration 62200: loss = 2.4022\n",
      "Iteration 62210: loss = 2.7573\n",
      "Iteration 62220: loss = 2.8130\n",
      "Iteration 62230: loss = 2.5984\n",
      "Iteration 62240: loss = 2.5986\n",
      "Iteration 62250: loss = 2.5621\n",
      "Iteration 62260: loss = 2.4569\n",
      "Iteration 62270: loss = 2.7895\n",
      "Iteration 62280: loss = 2.4849\n",
      "Iteration 62290: loss = 2.6953\n",
      "Iteration 62300: loss = 2.2739\n",
      "Iteration 62310: loss = 2.2660\n",
      "Iteration 62320: loss = 2.5278\n",
      "Iteration 62330: loss = 3.0248\n",
      "Iteration 62340: loss = 2.2650\n",
      "Iteration 62350: loss = 2.2875\n",
      "Iteration 62360: loss = 2.5087\n",
      "Iteration 62370: loss = 2.2911\n",
      "Iteration 62380: loss = 2.6933\n",
      "Iteration 62390: loss = 2.1472\n",
      "Iteration 62400: loss = 2.3806\n",
      "Iteration 62410: loss = 2.5300\n",
      "Iteration 62420: loss = 2.0693\n",
      "Iteration 62430: loss = 2.5284\n",
      "Iteration 62440: loss = 2.4787\n",
      "Iteration 62450: loss = 2.5414\n",
      "Iteration 62460: loss = 2.7203\n",
      "Iteration 62470: loss = 2.2048\n",
      "Iteration 62480: loss = 2.1187\n",
      "Iteration 62490: loss = 2.3280\n",
      "Iteration 62500: loss = 2.5519\n",
      "Iteration 62510: loss = 2.5539\n",
      "Iteration 62520: loss = 2.3663\n",
      "Iteration 62530: loss = 2.3164\n",
      "Iteration 62540: loss = 2.4787\n",
      "Iteration 62550: loss = 2.4980\n",
      "Iteration 62560: loss = 2.7311\n",
      "Iteration 62570: loss = 2.4756\n",
      "Iteration 62580: loss = 1.8968\n",
      "Iteration 62590: loss = 2.1331\n",
      "Iteration 62600: loss = 2.2382\n",
      "Iteration 62610: loss = 2.6061\n",
      "Iteration 62620: loss = 2.0665\n",
      "Iteration 62630: loss = 2.1577\n",
      "Iteration 62640: loss = 2.2517\n",
      "Iteration 62650: loss = 2.8636\n",
      "Iteration 62660: loss = 2.2135\n",
      "Iteration 62670: loss = 2.4023\n",
      "Iteration 62680: loss = 2.5411\n",
      "Iteration 62690: loss = 2.7271\n",
      "Iteration 62700: loss = 2.6870\n",
      "Iteration 62710: loss = 2.5681\n",
      "Iteration 62720: loss = 2.3656\n",
      "Iteration 62730: loss = 1.9388\n",
      "Iteration 62740: loss = 2.3493\n",
      "Iteration 62750: loss = 2.4192\n",
      "Iteration 62760: loss = 2.4202\n",
      "Iteration 62770: loss = 2.8508\n",
      "Iteration 62780: loss = 2.3537\n",
      "Iteration 62790: loss = 2.5569\n",
      "Iteration 62800: loss = 2.6205\n",
      "Iteration 62810: loss = 2.4261\n",
      "Iteration 62820: loss = 2.6455\n",
      "Iteration 62830: loss = 2.2816\n",
      "Iteration 62840: loss = 2.3319\n",
      "Iteration 62850: loss = 2.4845\n",
      "Iteration 62860: loss = 2.4355\n",
      "Iteration 62870: loss = 2.0880\n",
      "Iteration 62880: loss = 2.4285\n",
      "Iteration 62890: loss = 2.5449\n",
      "Iteration 62900: loss = 2.4014\n",
      "Iteration 62910: loss = 2.3162\n",
      "Iteration 62920: loss = 2.4296\n",
      "Iteration 62930: loss = 2.2583\n",
      "Iteration 62940: loss = 2.6245\n",
      "Iteration 62950: loss = 2.5822\n",
      "Iteration 62960: loss = 2.5261\n",
      "Iteration 62970: loss = 2.8238\n",
      "Iteration 62980: loss = 2.0378\n",
      "Iteration 62990: loss = 2.3990\n",
      "Iteration 63000: loss = 2.3014\n",
      "Iteration 63010: loss = 2.4669\n",
      "Iteration 63020: loss = 2.8213\n",
      "Iteration 63030: loss = 2.4142\n",
      "Iteration 63040: loss = 2.4019\n",
      "Iteration 63050: loss = 1.9937\n",
      "Iteration 63060: loss = 2.4033\n",
      "Iteration 63070: loss = 2.2542\n",
      "Iteration 63080: loss = 2.7241\n",
      "Iteration 63090: loss = 2.3611\n",
      "Iteration 63100: loss = 2.3591\n",
      "Iteration 63110: loss = 2.6932\n",
      "Iteration 63120: loss = 2.2238\n",
      "Iteration 63130: loss = 2.1672\n",
      "Iteration 63140: loss = 2.3521\n",
      "Iteration 63150: loss = 2.5871\n",
      "Iteration 63160: loss = 2.4286\n",
      "Iteration 63170: loss = 2.3777\n",
      "Iteration 63180: loss = 2.4711\n",
      "Iteration 63190: loss = 2.4400\n",
      "Iteration 63200: loss = 2.5564\n",
      "Iteration 63210: loss = 2.1058\n",
      "Iteration 63220: loss = 2.7938\n",
      "Iteration 63230: loss = 2.7334\n",
      "Iteration 63240: loss = 2.4773\n",
      "Iteration 63250: loss = 2.4392\n",
      "Iteration 63260: loss = 2.0175\n",
      "Iteration 63270: loss = 1.8947\n",
      "Iteration 63280: loss = 2.8585\n",
      "Iteration 63290: loss = 2.7428\n",
      "Iteration 63300: loss = 2.5705\n",
      "Iteration 63310: loss = 2.6162\n",
      "Iteration 63320: loss = 2.3429\n",
      "Iteration 63330: loss = 2.3804\n",
      "Iteration 63340: loss = 2.5611\n",
      "Iteration 63350: loss = 2.4311\n",
      "Iteration 63360: loss = 2.4381\n",
      "Iteration 63370: loss = 2.4740\n",
      "Iteration 63380: loss = 2.5085\n",
      "Iteration 63390: loss = 2.8089\n",
      "Iteration 63400: loss = 2.4382\n",
      "Iteration 63410: loss = 2.6691\n",
      "Iteration 63420: loss = 2.7921\n",
      "Iteration 63430: loss = 2.2543\n",
      "Iteration 63440: loss = 2.3404\n",
      "Iteration 63450: loss = 2.4314\n",
      "Iteration 63460: loss = 2.5307\n",
      "Iteration 63470: loss = 2.2965\n",
      "Iteration 63480: loss = 2.6280\n",
      "Iteration 63490: loss = 2.6631\n",
      "Iteration 63500: loss = 2.0321\n",
      "Iteration 63510: loss = 2.2910\n",
      "Iteration 63520: loss = 2.7069\n",
      "Iteration 63530: loss = 2.4643\n",
      "Iteration 63540: loss = 2.4636\n",
      "Iteration 63550: loss = 2.2121\n",
      "Iteration 63560: loss = 2.1589\n",
      "Iteration 63570: loss = 2.3159\n",
      "Iteration 63580: loss = 2.7098\n",
      "Iteration 63590: loss = 2.4982\n",
      "Iteration 63600: loss = 2.3746\n",
      "Iteration 63610: loss = 2.6697\n",
      "Iteration 63620: loss = 2.1401\n",
      "Iteration 63630: loss = 2.1869\n",
      "Iteration 63640: loss = 2.5827\n",
      "Iteration 63650: loss = 2.6261\n",
      "Iteration 63660: loss = 2.3218\n",
      "Iteration 63670: loss = 2.6821\n",
      "Iteration 63680: loss = 3.0379\n",
      "Iteration 63690: loss = 2.7881\n",
      "Iteration 63700: loss = 2.7110\n",
      "Iteration 63710: loss = 2.2762\n",
      "Iteration 63720: loss = 2.3656\n",
      "Iteration 63730: loss = 2.4743\n",
      "Iteration 63740: loss = 2.4285\n",
      "Iteration 63750: loss = 2.4407\n",
      "Iteration 63760: loss = 2.9615\n",
      "Iteration 63770: loss = 2.5966\n",
      "Iteration 63780: loss = 2.3748\n",
      "Iteration 63790: loss = 2.8052\n",
      "Iteration 63800: loss = 2.3031\n",
      "Iteration 63810: loss = 2.5881\n",
      "Iteration 63820: loss = 2.5609\n",
      "Iteration 63830: loss = 2.7744\n",
      "Iteration 63840: loss = 2.5876\n",
      "Iteration 63850: loss = 2.1655\n",
      "Iteration 63860: loss = 2.5633\n",
      "Iteration 63870: loss = 2.5546\n",
      "Iteration 63880: loss = 2.5033\n",
      "Iteration 63890: loss = 2.2561\n",
      "Iteration 63900: loss = 3.1963\n",
      "Iteration 63910: loss = 2.0532\n",
      "Iteration 63920: loss = 2.7705\n",
      "Iteration 63930: loss = 1.9111\n",
      "Iteration 63940: loss = 2.7882\n",
      "Iteration 63950: loss = 2.2612\n",
      "Iteration 63960: loss = 2.7028\n",
      "Iteration 63970: loss = 2.8376\n",
      "Iteration 63980: loss = 2.4242\n",
      "Iteration 63990: loss = 2.6215\n",
      "Iteration 64000: loss = 2.7255\n",
      "Iteration 64010: loss = 2.6061\n",
      "Iteration 64020: loss = 2.4489\n",
      "Iteration 64030: loss = 2.4439\n",
      "Iteration 64040: loss = 2.4449\n",
      "Iteration 64050: loss = 2.3042\n",
      "Iteration 64060: loss = 2.8844\n",
      "Iteration 64070: loss = 2.4596\n",
      "Iteration 64080: loss = 2.3820\n",
      "Iteration 64090: loss = 2.3898\n",
      "Iteration 64100: loss = 2.3623\n",
      "Iteration 64110: loss = 2.3168\n",
      "Iteration 64120: loss = 2.6343\n",
      "Iteration 64130: loss = 2.3342\n",
      "Iteration 64140: loss = 2.5732\n",
      "Iteration 64150: loss = 2.5371\n",
      "Iteration 64160: loss = 2.3835\n",
      "Iteration 64170: loss = 2.8963\n",
      "Iteration 64180: loss = 2.3314\n",
      "Iteration 64190: loss = 2.2787\n",
      "Iteration 64200: loss = 2.5123\n",
      "Iteration 64210: loss = 2.4060\n",
      "Iteration 64220: loss = 2.4258\n",
      "Iteration 64230: loss = 2.2077\n",
      "Iteration 64240: loss = 2.5156\n",
      "Iteration 64250: loss = 2.4182\n",
      "Iteration 64260: loss = 2.2316\n",
      "Iteration 64270: loss = 2.7415\n",
      "Iteration 64280: loss = 2.2831\n",
      "Iteration 64290: loss = 2.6451\n",
      "Iteration 64300: loss = 2.8104\n",
      "Iteration 64310: loss = 2.4932\n",
      "Iteration 64320: loss = 2.3977\n",
      "Iteration 64330: loss = 2.2132\n",
      "Iteration 64340: loss = 2.2017\n",
      "Iteration 64350: loss = 2.3743\n",
      "Iteration 64360: loss = 2.7480\n",
      "Iteration 64370: loss = 2.5646\n",
      "Iteration 64380: loss = 2.4242\n",
      "Iteration 64390: loss = 2.8114\n",
      "Iteration 64400: loss = 2.2924\n",
      "Iteration 64410: loss = 2.1340\n",
      "Iteration 64420: loss = 3.1063\n",
      "Iteration 64430: loss = 2.6544\n",
      "Iteration 64440: loss = 2.4057\n",
      "Iteration 64450: loss = 2.5757\n",
      "Iteration 64460: loss = 2.7372\n",
      "Iteration 64470: loss = 2.5790\n",
      "Iteration 64480: loss = 2.4036\n",
      "Iteration 64490: loss = 2.4801\n",
      "Iteration 64500: loss = 2.2157\n",
      "Iteration 64510: loss = 2.1942\n",
      "Iteration 64520: loss = 2.3831\n",
      "Iteration 64530: loss = 2.2145\n",
      "Iteration 64540: loss = 2.0284\n",
      "Iteration 64550: loss = 2.6473\n",
      "Iteration 64560: loss = 2.2624\n",
      "Iteration 64570: loss = 2.2152\n",
      "Iteration 64580: loss = 2.3613\n",
      "Iteration 64590: loss = 2.5192\n",
      "Iteration 64600: loss = 2.5666\n",
      "Iteration 64610: loss = 2.7701\n",
      "Iteration 64620: loss = 2.4715\n",
      "Iteration 64630: loss = 2.5473\n",
      "Iteration 64640: loss = 2.1624\n",
      "Iteration 64650: loss = 2.5254\n",
      "Iteration 64660: loss = 2.4156\n",
      "Iteration 64670: loss = 2.5195\n",
      "Iteration 64680: loss = 2.1650\n",
      "Iteration 64690: loss = 2.3698\n",
      "Iteration 64700: loss = 2.3173\n",
      "Iteration 64710: loss = 2.3512\n",
      "Iteration 64720: loss = 2.3361\n",
      "Iteration 64730: loss = 2.5070\n",
      "Iteration 64740: loss = 2.5929\n",
      "Iteration 64750: loss = 2.5535\n",
      "Iteration 64760: loss = 2.6886\n",
      "Iteration 64770: loss = 2.3172\n",
      "Iteration 64780: loss = 2.0698\n",
      "Iteration 64790: loss = 2.3768\n",
      "Iteration 64800: loss = 2.2081\n",
      "Iteration 64810: loss = 2.5924\n",
      "Iteration 64820: loss = 2.3874\n",
      "Iteration 64830: loss = 2.6170\n",
      "Iteration 64840: loss = 2.3719\n",
      "Iteration 64850: loss = 2.5106\n",
      "Iteration 64860: loss = 2.4417\n",
      "Iteration 64870: loss = 2.4547\n",
      "Iteration 64880: loss = 2.6498\n",
      "Iteration 64890: loss = 2.4072\n",
      "Iteration 64900: loss = 2.6641\n",
      "Iteration 64910: loss = 2.2516\n",
      "Iteration 64920: loss = 2.1980\n",
      "Iteration 64930: loss = 2.1074\n",
      "Iteration 64940: loss = 2.2513\n",
      "Iteration 64950: loss = 2.4357\n",
      "Iteration 64960: loss = 2.4213\n",
      "Iteration 64970: loss = 2.3629\n",
      "Iteration 64980: loss = 2.2763\n",
      "Iteration 64990: loss = 2.3386\n",
      "Iteration 65000: loss = 2.5561\n",
      "Iteration 65010: loss = 2.1309\n",
      "Iteration 65020: loss = 2.7406\n",
      "Iteration 65030: loss = 2.4653\n",
      "Iteration 65040: loss = 2.3523\n",
      "Iteration 65050: loss = 2.8473\n",
      "Iteration 65060: loss = 2.2193\n",
      "Iteration 65070: loss = 2.5578\n",
      "Iteration 65080: loss = 2.6666\n",
      "Iteration 65090: loss = 2.7192\n",
      "Iteration 65100: loss = 2.4878\n",
      "Iteration 65110: loss = 2.2560\n",
      "Iteration 65120: loss = 3.0335\n",
      "Iteration 65130: loss = 2.3526\n",
      "Iteration 65140: loss = 2.3751\n",
      "Iteration 65150: loss = 2.6498\n",
      "Iteration 65160: loss = 2.8570\n",
      "Iteration 65170: loss = 2.6184\n",
      "Iteration 65180: loss = 2.5312\n",
      "Iteration 65190: loss = 2.9128\n",
      "Iteration 65200: loss = 2.3140\n",
      "Iteration 65210: loss = 2.2566\n",
      "Iteration 65220: loss = 2.2157\n",
      "Iteration 65230: loss = 2.5554\n",
      "Iteration 65240: loss = 2.1737\n",
      "Iteration 65250: loss = 2.6777\n",
      "Iteration 65260: loss = 2.8941\n",
      "Iteration 65270: loss = 2.6774\n",
      "Iteration 65280: loss = 2.2044\n",
      "Iteration 65290: loss = 2.6358\n",
      "Iteration 65300: loss = 2.0779\n",
      "Iteration 65310: loss = 2.6333\n",
      "Iteration 65320: loss = 2.5868\n",
      "Iteration 65330: loss = 2.6945\n",
      "Iteration 65340: loss = 2.4107\n",
      "Iteration 65350: loss = 2.4158\n",
      "Iteration 65360: loss = 2.3928\n",
      "Iteration 65370: loss = 2.2413\n",
      "Iteration 65380: loss = 2.3435\n",
      "Iteration 65390: loss = 2.5508\n",
      "Iteration 65400: loss = 2.3984\n",
      "Iteration 65410: loss = 2.3242\n",
      "Iteration 65420: loss = 2.3421\n",
      "Iteration 65430: loss = 2.5447\n",
      "Iteration 65440: loss = 2.7023\n",
      "Iteration 65450: loss = 2.5841\n",
      "Iteration 65460: loss = 2.4751\n",
      "Iteration 65470: loss = 2.4850\n",
      "Iteration 65480: loss = 2.7409\n",
      "Iteration 65490: loss = 2.4320\n",
      "Iteration 65500: loss = 2.4782\n",
      "Iteration 65510: loss = 2.7874\n",
      "Iteration 65520: loss = 2.4743\n",
      "Iteration 65530: loss = 2.2115\n",
      "Iteration 65540: loss = 2.4331\n",
      "Iteration 65550: loss = 2.3955\n",
      "Iteration 65560: loss = 2.4497\n",
      "Iteration 65570: loss = 2.7996\n",
      "Iteration 65580: loss = 2.6022\n",
      "Iteration 65590: loss = 2.5237\n",
      "Iteration 65600: loss = 2.2799\n",
      "Iteration 65610: loss = 2.6288\n",
      "Iteration 65620: loss = 2.4730\n",
      "Iteration 65630: loss = 2.2457\n",
      "Iteration 65640: loss = 2.2084\n",
      "Iteration 65650: loss = 2.1885\n",
      "Iteration 65660: loss = 2.7499\n",
      "Iteration 65670: loss = 2.1453\n",
      "Iteration 65680: loss = 2.3992\n",
      "Iteration 65690: loss = 2.1290\n",
      "Iteration 65700: loss = 2.2837\n",
      "Iteration 65710: loss = 2.4619\n",
      "Iteration 65720: loss = 3.1084\n",
      "Iteration 65730: loss = 2.6811\n",
      "Iteration 65740: loss = 2.1499\n",
      "Iteration 65750: loss = 2.4961\n",
      "Iteration 65760: loss = 2.6295\n",
      "Iteration 65770: loss = 2.4296\n",
      "Iteration 65780: loss = 2.7198\n",
      "Iteration 65790: loss = 2.5597\n",
      "Iteration 65800: loss = 2.7535\n",
      "Iteration 65810: loss = 2.1080\n",
      "Iteration 65820: loss = 2.7511\n",
      "Iteration 65830: loss = 2.5479\n",
      "Iteration 65840: loss = 2.3380\n",
      "Iteration 65850: loss = 2.2756\n",
      "Iteration 65860: loss = 2.3437\n",
      "Iteration 65870: loss = 2.4916\n",
      "Iteration 65880: loss = 2.2777\n",
      "Iteration 65890: loss = 2.6741\n",
      "Iteration 65900: loss = 2.1742\n",
      "Iteration 65910: loss = 2.4028\n",
      "Iteration 65920: loss = 2.3904\n",
      "Iteration 65930: loss = 2.4505\n",
      "Iteration 65940: loss = 2.4610\n",
      "Iteration 65950: loss = 2.0853\n",
      "Iteration 65960: loss = 2.8423\n",
      "Iteration 65970: loss = 2.6188\n",
      "Iteration 65980: loss = 2.7595\n",
      "Iteration 65990: loss = 2.4092\n",
      "Iteration 66000: loss = 2.4702\n",
      "Iteration 66010: loss = 2.5592\n",
      "Iteration 66020: loss = 2.5394\n",
      "Iteration 66030: loss = 2.2473\n",
      "Iteration 66040: loss = 2.4787\n",
      "Iteration 66050: loss = 2.2532\n",
      "Iteration 66060: loss = 2.5119\n",
      "Iteration 66070: loss = 2.2719\n",
      "Iteration 66080: loss = 2.3247\n",
      "Iteration 66090: loss = 2.3972\n",
      "Iteration 66100: loss = 2.7321\n",
      "Iteration 66110: loss = 2.4427\n",
      "Iteration 66120: loss = 2.2246\n",
      "Iteration 66130: loss = 2.3063\n",
      "Iteration 66140: loss = 2.5014\n",
      "Iteration 66150: loss = 2.4350\n",
      "Iteration 66160: loss = 2.3426\n",
      "Iteration 66170: loss = 2.7559\n",
      "Iteration 66180: loss = 2.2851\n",
      "Iteration 66190: loss = 2.4590\n",
      "Iteration 66200: loss = 2.2846\n",
      "Iteration 66210: loss = 2.5304\n",
      "Iteration 66220: loss = 2.3069\n",
      "Iteration 66230: loss = 2.3480\n",
      "Iteration 66240: loss = 2.3108\n",
      "Iteration 66250: loss = 2.4833\n",
      "Iteration 66260: loss = 2.2441\n",
      "Iteration 66270: loss = 2.2891\n",
      "Iteration 66280: loss = 2.6682\n",
      "Iteration 66290: loss = 2.2049\n",
      "Iteration 66300: loss = 2.6781\n",
      "Iteration 66310: loss = 2.7161\n",
      "Iteration 66320: loss = 1.8330\n",
      "Iteration 66330: loss = 2.7947\n",
      "Iteration 66340: loss = 2.6200\n",
      "Iteration 66350: loss = 2.4444\n",
      "Iteration 66360: loss = 2.6020\n",
      "Iteration 66370: loss = 2.7652\n",
      "Iteration 66380: loss = 2.6200\n",
      "Iteration 66390: loss = 2.9088\n",
      "Iteration 66400: loss = 2.7739\n",
      "Iteration 66410: loss = 2.4875\n",
      "Iteration 66420: loss = 2.5011\n",
      "Iteration 66430: loss = 2.5225\n",
      "Iteration 66440: loss = 2.4972\n",
      "Iteration 66450: loss = 2.9826\n",
      "Iteration 66460: loss = 2.2272\n",
      "Iteration 66470: loss = 2.3635\n",
      "Iteration 66480: loss = 2.4378\n",
      "Iteration 66490: loss = 2.4873\n",
      "Iteration 66500: loss = 2.1923\n",
      "Iteration 66510: loss = 2.4294\n",
      "Iteration 66520: loss = 2.3465\n",
      "Iteration 66530: loss = 2.6283\n",
      "Iteration 66540: loss = 2.2627\n",
      "Iteration 66550: loss = 2.1437\n",
      "Iteration 66560: loss = 2.5181\n",
      "Iteration 66570: loss = 2.6953\n",
      "Iteration 66580: loss = 2.4087\n",
      "Iteration 66590: loss = 2.2631\n",
      "Iteration 66600: loss = 2.3271\n",
      "Iteration 66610: loss = 2.2369\n",
      "Iteration 66620: loss = 2.8253\n",
      "Iteration 66630: loss = 2.8967\n",
      "Iteration 66640: loss = 2.5214\n",
      "Iteration 66650: loss = 2.2988\n",
      "Iteration 66660: loss = 2.5709\n",
      "Iteration 66670: loss = 2.4518\n",
      "Iteration 66680: loss = 2.3612\n",
      "Iteration 66690: loss = 2.3483\n",
      "Iteration 66700: loss = 2.3799\n",
      "Iteration 66710: loss = 2.4511\n",
      "Iteration 66720: loss = 2.4335\n",
      "Iteration 66730: loss = 2.1517\n",
      "Iteration 66740: loss = 2.5740\n",
      "Iteration 66750: loss = 2.7260\n",
      "Iteration 66760: loss = 2.6084\n",
      "Iteration 66770: loss = 2.5088\n",
      "Iteration 66780: loss = 2.5040\n",
      "Iteration 66790: loss = 2.4936\n",
      "Iteration 66800: loss = 2.2516\n",
      "Iteration 66810: loss = 2.5945\n",
      "Iteration 66820: loss = 2.4542\n",
      "Iteration 66830: loss = 1.7340\n",
      "Iteration 66840: loss = 2.4718\n",
      "Iteration 66850: loss = 2.3751\n",
      "Iteration 66860: loss = 2.4779\n",
      "Iteration 66870: loss = 2.2821\n",
      "Iteration 66880: loss = 2.8285\n",
      "Iteration 66890: loss = 2.3699\n",
      "Iteration 66900: loss = 2.5430\n",
      "Iteration 66910: loss = 2.6812\n",
      "Iteration 66920: loss = 2.4015\n",
      "Iteration 66930: loss = 2.6338\n",
      "Iteration 66940: loss = 2.5694\n",
      "Iteration 66950: loss = 2.2945\n",
      "Iteration 66960: loss = 2.9821\n",
      "Iteration 66970: loss = 2.6229\n",
      "Iteration 66980: loss = 2.5260\n",
      "Iteration 66990: loss = 2.3457\n",
      "Iteration 67000: loss = 2.3222\n",
      "Iteration 67010: loss = 2.3299\n",
      "Iteration 67020: loss = 2.8810\n",
      "Iteration 67030: loss = 2.4184\n",
      "Iteration 67040: loss = 3.3303\n",
      "Iteration 67050: loss = 2.5951\n",
      "Iteration 67060: loss = 2.3985\n",
      "Iteration 67070: loss = 2.6593\n",
      "Iteration 67080: loss = 2.4637\n",
      "Iteration 67090: loss = 2.5734\n",
      "Iteration 67100: loss = 2.1379\n",
      "Iteration 67110: loss = 2.2711\n",
      "Iteration 67120: loss = 2.7153\n",
      "Iteration 67130: loss = 2.4169\n",
      "Iteration 67140: loss = 2.2161\n",
      "Iteration 67150: loss = 2.5809\n",
      "Iteration 67160: loss = 2.0939\n",
      "Iteration 67170: loss = 2.4007\n",
      "Iteration 67180: loss = 2.6206\n",
      "Iteration 67190: loss = 2.5582\n",
      "Iteration 67200: loss = 2.1622\n",
      "Iteration 67210: loss = 2.5938\n",
      "Iteration 67220: loss = 2.2880\n",
      "Iteration 67230: loss = 2.3907\n",
      "Iteration 67240: loss = 2.2277\n",
      "Iteration 67250: loss = 2.2562\n",
      "Iteration 67260: loss = 1.9537\n",
      "Iteration 67270: loss = 2.6218\n",
      "Iteration 67280: loss = 2.2380\n",
      "Iteration 67290: loss = 2.3710\n",
      "Iteration 67300: loss = 2.8826\n",
      "Iteration 67310: loss = 2.4875\n",
      "Iteration 67320: loss = 2.3361\n",
      "Iteration 67330: loss = 2.2645\n",
      "Iteration 67340: loss = 2.5236\n",
      "Iteration 67350: loss = 2.6733\n",
      "Iteration 67360: loss = 2.6980\n",
      "Iteration 67370: loss = 2.4328\n",
      "Iteration 67380: loss = 2.4227\n",
      "Iteration 67390: loss = 2.4120\n",
      "Iteration 67400: loss = 2.3482\n",
      "Iteration 67410: loss = 2.6690\n",
      "Iteration 67420: loss = 2.8016\n",
      "Iteration 67430: loss = 2.3835\n",
      "Iteration 67440: loss = 2.4014\n",
      "Iteration 67450: loss = 2.4184\n",
      "Iteration 67460: loss = 2.8075\n",
      "Iteration 67470: loss = 2.5387\n",
      "Iteration 67480: loss = 2.4346\n",
      "Iteration 67490: loss = 2.4326\n",
      "Iteration 67500: loss = 2.3255\n",
      "Iteration 67510: loss = 2.7905\n",
      "Iteration 67520: loss = 2.2426\n",
      "Iteration 67530: loss = 2.1683\n",
      "Iteration 67540: loss = 2.3548\n",
      "Iteration 67550: loss = 2.2996\n",
      "Iteration 67560: loss = 2.6567\n",
      "Iteration 67570: loss = 2.7675\n",
      "Iteration 67580: loss = 2.3747\n",
      "Iteration 67590: loss = 2.3762\n",
      "Iteration 67600: loss = 2.6040\n",
      "Iteration 67610: loss = 2.7748\n",
      "Iteration 67620: loss = 2.5729\n",
      "Iteration 67630: loss = 2.5098\n",
      "Iteration 67640: loss = 2.0916\n",
      "Iteration 67650: loss = 2.7515\n",
      "Iteration 67660: loss = 2.6556\n",
      "Iteration 67670: loss = 2.4720\n",
      "Iteration 67680: loss = 2.7826\n",
      "Iteration 67690: loss = 2.6006\n",
      "Iteration 67700: loss = 2.7922\n",
      "Iteration 67710: loss = 2.5012\n",
      "Iteration 67720: loss = 2.0557\n",
      "Iteration 67730: loss = 2.4548\n",
      "Iteration 67740: loss = 3.1048\n",
      "Iteration 67750: loss = 2.5191\n",
      "Iteration 67760: loss = 2.5051\n",
      "Iteration 67770: loss = 2.6701\n",
      "Iteration 67780: loss = 2.3427\n",
      "Iteration 67790: loss = 2.0152\n",
      "Iteration 67800: loss = 2.2615\n",
      "Iteration 67810: loss = 2.4164\n",
      "Iteration 67820: loss = 3.0137\n",
      "Iteration 67830: loss = 2.4117\n",
      "Iteration 67840: loss = 2.1279\n",
      "Iteration 67850: loss = 2.3600\n",
      "Iteration 67860: loss = 2.5784\n",
      "Iteration 67870: loss = 2.5914\n",
      "Iteration 67880: loss = 2.5790\n",
      "Iteration 67890: loss = 2.0295\n",
      "Iteration 67900: loss = 2.5629\n",
      "Iteration 67910: loss = 2.4731\n",
      "Iteration 67920: loss = 2.1039\n",
      "Iteration 67930: loss = 2.6287\n",
      "Iteration 67940: loss = 2.2367\n",
      "Iteration 67950: loss = 2.7829\n",
      "Iteration 67960: loss = 2.7826\n",
      "Iteration 67970: loss = 2.3946\n",
      "Iteration 67980: loss = 2.7550\n",
      "Iteration 67990: loss = 2.6816\n",
      "Iteration 68000: loss = 2.5695\n",
      "Iteration 68010: loss = 2.4611\n",
      "Iteration 68020: loss = 2.7722\n",
      "Iteration 68030: loss = 2.4328\n",
      "Iteration 68040: loss = 2.4289\n",
      "Iteration 68050: loss = 2.5698\n",
      "Iteration 68060: loss = 2.4508\n",
      "Iteration 68070: loss = 2.3673\n",
      "Iteration 68080: loss = 2.4775\n",
      "Iteration 68090: loss = 2.4887\n",
      "Iteration 68100: loss = 2.7639\n",
      "Iteration 68110: loss = 2.4593\n",
      "Iteration 68120: loss = 2.4955\n",
      "Iteration 68130: loss = 2.4273\n",
      "Iteration 68140: loss = 2.3898\n",
      "Iteration 68150: loss = 2.5337\n",
      "Iteration 68160: loss = 2.3337\n",
      "Iteration 68170: loss = 2.2515\n",
      "Iteration 68180: loss = 2.4939\n",
      "Iteration 68190: loss = 2.0469\n",
      "Iteration 68200: loss = 2.4810\n",
      "Iteration 68210: loss = 2.4771\n",
      "Iteration 68220: loss = 2.2515\n",
      "Iteration 68230: loss = 2.3670\n",
      "Iteration 68240: loss = 2.3406\n",
      "Iteration 68250: loss = 2.5290\n",
      "Iteration 68260: loss = 2.0716\n",
      "Iteration 68270: loss = 2.5855\n",
      "Iteration 68280: loss = 2.4936\n",
      "Iteration 68290: loss = 2.5203\n",
      "Iteration 68300: loss = 2.3645\n",
      "Iteration 68310: loss = 2.2700\n",
      "Iteration 68320: loss = 2.6699\n",
      "Iteration 68330: loss = 2.1939\n",
      "Iteration 68340: loss = 2.7279\n",
      "Iteration 68350: loss = 2.0819\n",
      "Iteration 68360: loss = 2.3958\n",
      "Iteration 68370: loss = 2.4571\n",
      "Iteration 68380: loss = 2.4509\n",
      "Iteration 68390: loss = 2.5921\n",
      "Iteration 68400: loss = 2.3712\n",
      "Iteration 68410: loss = 2.7512\n",
      "Iteration 68420: loss = 2.6604\n",
      "Iteration 68430: loss = 2.1907\n",
      "Iteration 68440: loss = 2.3055\n",
      "Iteration 68450: loss = 2.5419\n",
      "Iteration 68460: loss = 2.8043\n",
      "Iteration 68470: loss = 2.3202\n",
      "Iteration 68480: loss = 2.4475\n",
      "Iteration 68490: loss = 2.5913\n",
      "Iteration 68500: loss = 2.1505\n",
      "Iteration 68510: loss = 2.3270\n",
      "Iteration 68520: loss = 2.4329\n",
      "Iteration 68530: loss = 2.4868\n",
      "Iteration 68540: loss = 2.2193\n",
      "Iteration 68550: loss = 2.4359\n",
      "Iteration 68560: loss = 2.5568\n",
      "Iteration 68570: loss = 2.3451\n",
      "Iteration 68580: loss = 2.3381\n",
      "Iteration 68590: loss = 2.5143\n",
      "Iteration 68600: loss = 2.5334\n",
      "Iteration 68610: loss = 2.5902\n",
      "Iteration 68620: loss = 2.4930\n",
      "Iteration 68630: loss = 2.4499\n",
      "Iteration 68640: loss = 2.6563\n",
      "Iteration 68650: loss = 2.5255\n",
      "Iteration 68660: loss = 2.3550\n",
      "Iteration 68670: loss = 2.6630\n",
      "Iteration 68680: loss = 2.6127\n",
      "Iteration 68690: loss = 2.2489\n",
      "Iteration 68700: loss = 2.4422\n",
      "Iteration 68710: loss = 2.2718\n",
      "Iteration 68720: loss = 2.4282\n",
      "Iteration 68730: loss = 2.2439\n",
      "Iteration 68740: loss = 2.1021\n",
      "Iteration 68750: loss = 2.1429\n",
      "Iteration 68760: loss = 2.3529\n",
      "Iteration 68770: loss = 2.6565\n",
      "Iteration 68780: loss = 2.4191\n",
      "Iteration 68790: loss = 2.0496\n",
      "Iteration 68800: loss = 2.7517\n",
      "Iteration 68810: loss = 2.3900\n",
      "Iteration 68820: loss = 2.1556\n",
      "Iteration 68830: loss = 2.8255\n",
      "Iteration 68840: loss = 2.3733\n",
      "Iteration 68850: loss = 2.3675\n",
      "Iteration 68860: loss = 2.1589\n",
      "Iteration 68870: loss = 2.5676\n",
      "Iteration 68880: loss = 2.2644\n",
      "Iteration 68890: loss = 2.5142\n",
      "Iteration 68900: loss = 2.6084\n",
      "Iteration 68910: loss = 2.2222\n",
      "Iteration 68920: loss = 2.2477\n",
      "Iteration 68930: loss = 2.4825\n",
      "Iteration 68940: loss = 2.1230\n",
      "Iteration 68950: loss = 2.4343\n",
      "Iteration 68960: loss = 2.3328\n",
      "Iteration 68970: loss = 2.8472\n",
      "Iteration 68980: loss = 2.4375\n",
      "Iteration 68990: loss = 2.6563\n",
      "Iteration 69000: loss = 2.2986\n",
      "Iteration 69010: loss = 2.6748\n",
      "Iteration 69020: loss = 2.4535\n",
      "Iteration 69030: loss = 2.6462\n",
      "Iteration 69040: loss = 2.5188\n",
      "Iteration 69050: loss = 2.2220\n",
      "Iteration 69060: loss = 2.2368\n",
      "Iteration 69070: loss = 2.6648\n",
      "Iteration 69080: loss = 2.4496\n",
      "Iteration 69090: loss = 2.9699\n",
      "Iteration 69100: loss = 2.8633\n",
      "Iteration 69110: loss = 2.5365\n",
      "Iteration 69120: loss = 2.5103\n",
      "Iteration 69130: loss = 2.4972\n",
      "Iteration 69140: loss = 2.9651\n",
      "Iteration 69150: loss = 2.3546\n",
      "Iteration 69160: loss = 2.1500\n",
      "Iteration 69170: loss = 2.5370\n",
      "Iteration 69180: loss = 3.1108\n",
      "Iteration 69190: loss = 2.4090\n",
      "Iteration 69200: loss = 2.1054\n",
      "Iteration 69210: loss = 2.6764\n",
      "Iteration 69220: loss = 2.4025\n",
      "Iteration 69230: loss = 2.3876\n",
      "Iteration 69240: loss = 2.7029\n",
      "Iteration 69250: loss = 2.6193\n",
      "Iteration 69260: loss = 2.3304\n",
      "Iteration 69270: loss = 2.5080\n",
      "Iteration 69280: loss = 2.1772\n",
      "Iteration 69290: loss = 2.5519\n",
      "Iteration 69300: loss = 2.3581\n",
      "Iteration 69310: loss = 2.6960\n",
      "Iteration 69320: loss = 2.2415\n",
      "Iteration 69330: loss = 2.1624\n",
      "Iteration 69340: loss = 2.4591\n",
      "Iteration 69350: loss = 2.5884\n",
      "Iteration 69360: loss = 2.3893\n",
      "Iteration 69370: loss = 2.5215\n",
      "Iteration 69380: loss = 2.8411\n",
      "Iteration 69390: loss = 2.3847\n",
      "Iteration 69400: loss = 2.4915\n",
      "Iteration 69410: loss = 2.2785\n",
      "Iteration 69420: loss = 2.3211\n",
      "Iteration 69430: loss = 2.4209\n",
      "Iteration 69440: loss = 2.3768\n",
      "Iteration 69450: loss = 2.2032\n",
      "Iteration 69460: loss = 2.1766\n",
      "Iteration 69470: loss = 2.0667\n",
      "Iteration 69480: loss = 2.4041\n",
      "Iteration 69490: loss = 2.9158\n",
      "Iteration 69500: loss = 2.2091\n",
      "Iteration 69510: loss = 2.3119\n",
      "Iteration 69520: loss = 2.1466\n",
      "Iteration 69530: loss = 2.3767\n",
      "Iteration 69540: loss = 2.0146\n",
      "Iteration 69550: loss = 2.3572\n",
      "Iteration 69560: loss = 2.3191\n",
      "Iteration 69570: loss = 2.6039\n",
      "Iteration 69580: loss = 2.5363\n",
      "Iteration 69590: loss = 2.5968\n",
      "Iteration 69600: loss = 2.7187\n",
      "Iteration 69610: loss = 2.3618\n",
      "Iteration 69620: loss = 2.4216\n",
      "Iteration 69630: loss = 2.6706\n",
      "Iteration 69640: loss = 2.6247\n",
      "Iteration 69650: loss = 2.2606\n",
      "Iteration 69660: loss = 2.7179\n",
      "Iteration 69670: loss = 2.4761\n",
      "Iteration 69680: loss = 2.5336\n",
      "Iteration 69690: loss = 2.2657\n",
      "Iteration 69700: loss = 2.5170\n",
      "Iteration 69710: loss = 2.4701\n",
      "Iteration 69720: loss = 2.3498\n",
      "Iteration 69730: loss = 2.4018\n",
      "Iteration 69740: loss = 2.6910\n",
      "Iteration 69750: loss = 2.7697\n",
      "Iteration 69760: loss = 2.4744\n",
      "Iteration 69770: loss = 2.3962\n",
      "Iteration 69780: loss = 2.4516\n",
      "Iteration 69790: loss = 2.5287\n",
      "Iteration 69800: loss = 2.5604\n",
      "Iteration 69810: loss = 2.7524\n",
      "Iteration 69820: loss = 2.1429\n",
      "Iteration 69830: loss = 2.3411\n",
      "Iteration 69840: loss = 2.4377\n",
      "Iteration 69850: loss = 2.7374\n",
      "Iteration 69860: loss = 2.2828\n",
      "Iteration 69870: loss = 1.9936\n",
      "Iteration 69880: loss = 2.2431\n",
      "Iteration 69890: loss = 2.2139\n",
      "Iteration 69900: loss = 2.1569\n",
      "Iteration 69910: loss = 2.3937\n",
      "Iteration 69920: loss = 2.1103\n",
      "Iteration 69930: loss = 2.4239\n",
      "Iteration 69940: loss = 2.4969\n",
      "Iteration 69950: loss = 2.8225\n",
      "Iteration 69960: loss = 2.5726\n",
      "Iteration 69970: loss = 2.4813\n",
      "Iteration 69980: loss = 2.4524\n",
      "Iteration 69990: loss = 2.2089\n",
      "Iteration 70000: loss = 2.3548\n",
      "Iteration 70010: loss = 2.3396\n",
      "Iteration 70020: loss = 3.0424\n",
      "Iteration 70030: loss = 2.3835\n",
      "Iteration 70040: loss = 2.1210\n",
      "Iteration 70050: loss = 2.2482\n",
      "Iteration 70060: loss = 2.1722\n",
      "Iteration 70070: loss = 2.6117\n",
      "Iteration 70080: loss = 2.5032\n",
      "Iteration 70090: loss = 2.2095\n",
      "Iteration 70100: loss = 2.5316\n",
      "Iteration 70110: loss = 2.6032\n",
      "Iteration 70120: loss = 2.7196\n",
      "Iteration 70130: loss = 2.6988\n",
      "Iteration 70140: loss = 2.6413\n",
      "Iteration 70150: loss = 2.5210\n",
      "Iteration 70160: loss = 2.3890\n",
      "Iteration 70170: loss = 2.7424\n",
      "Iteration 70180: loss = 2.3687\n",
      "Iteration 70190: loss = 2.6903\n",
      "Iteration 70200: loss = 2.5059\n",
      "Iteration 70210: loss = 2.4213\n",
      "Iteration 70220: loss = 2.5482\n",
      "Iteration 70230: loss = 2.4830\n",
      "Iteration 70240: loss = 2.5832\n",
      "Iteration 70250: loss = 2.7841\n",
      "Iteration 70260: loss = 2.5823\n",
      "Iteration 70270: loss = 2.2674\n",
      "Iteration 70280: loss = 2.4999\n",
      "Iteration 70290: loss = 2.2984\n",
      "Iteration 70300: loss = 2.1527\n",
      "Iteration 70310: loss = 2.4640\n",
      "Iteration 70320: loss = 2.5247\n",
      "Iteration 70330: loss = 2.7216\n",
      "Iteration 70340: loss = 2.6305\n",
      "Iteration 70350: loss = 2.1573\n",
      "Iteration 70360: loss = 2.4992\n",
      "Iteration 70370: loss = 2.6753\n",
      "Iteration 70380: loss = 2.0244\n",
      "Iteration 70390: loss = 2.6115\n",
      "Iteration 70400: loss = 2.2275\n",
      "Iteration 70410: loss = 2.0661\n",
      "Iteration 70420: loss = 2.2292\n",
      "Iteration 70430: loss = 2.5053\n",
      "Iteration 70440: loss = 2.5104\n",
      "Iteration 70450: loss = 2.2280\n",
      "Iteration 70460: loss = 2.5802\n",
      "Iteration 70470: loss = 2.9716\n",
      "Iteration 70480: loss = 2.8137\n",
      "Iteration 70490: loss = 2.4251\n",
      "Iteration 70500: loss = 2.5412\n",
      "Iteration 70510: loss = 2.4661\n",
      "Iteration 70520: loss = 2.2740\n",
      "Iteration 70530: loss = 2.5628\n",
      "Iteration 70540: loss = 2.4391\n",
      "Iteration 70550: loss = 2.5703\n",
      "Iteration 70560: loss = 2.0792\n",
      "Iteration 70570: loss = 2.4043\n",
      "Iteration 70580: loss = 2.5424\n",
      "Iteration 70590: loss = 2.3871\n",
      "Iteration 70600: loss = 2.2509\n",
      "Iteration 70610: loss = 2.6908\n",
      "Iteration 70620: loss = 2.4018\n",
      "Iteration 70630: loss = 2.5315\n",
      "Iteration 70640: loss = 2.6744\n",
      "Iteration 70650: loss = 2.4798\n",
      "Iteration 70660: loss = 2.4669\n",
      "Iteration 70670: loss = 2.7967\n",
      "Iteration 70680: loss = 2.4043\n",
      "Iteration 70690: loss = 2.4718\n",
      "Iteration 70700: loss = 2.3884\n",
      "Iteration 70710: loss = 2.6362\n",
      "Iteration 70720: loss = 2.7699\n",
      "Iteration 70730: loss = 2.2171\n",
      "Iteration 70740: loss = 2.6922\n",
      "Iteration 70750: loss = 2.2066\n",
      "Iteration 70760: loss = 2.5134\n",
      "Iteration 70770: loss = 2.8081\n",
      "Iteration 70780: loss = 2.4818\n",
      "Iteration 70790: loss = 2.9899\n",
      "Iteration 70800: loss = 2.4116\n",
      "Iteration 70810: loss = 2.3244\n",
      "Iteration 70820: loss = 2.4942\n",
      "Iteration 70830: loss = 2.5853\n",
      "Iteration 70840: loss = 2.4854\n",
      "Iteration 70850: loss = 2.3452\n",
      "Iteration 70860: loss = 2.2763\n",
      "Iteration 70870: loss = 2.6314\n",
      "Iteration 70880: loss = 2.3217\n",
      "Iteration 70890: loss = 2.7114\n",
      "Iteration 70900: loss = 2.2342\n",
      "Iteration 70910: loss = 2.3171\n",
      "Iteration 70920: loss = 2.3863\n",
      "Iteration 70930: loss = 2.4894\n",
      "Iteration 70940: loss = 2.3767\n",
      "Iteration 70950: loss = 2.3255\n",
      "Iteration 70960: loss = 2.1663\n",
      "Iteration 70970: loss = 2.6440\n",
      "Iteration 70980: loss = 2.4275\n",
      "Iteration 70990: loss = 2.3027\n",
      "Iteration 71000: loss = 2.3741\n",
      "Iteration 71010: loss = 2.3075\n",
      "Iteration 71020: loss = 2.8565\n",
      "Iteration 71030: loss = 2.4139\n",
      "Iteration 71040: loss = 2.5657\n",
      "Iteration 71050: loss = 2.3432\n",
      "Iteration 71060: loss = 2.5838\n",
      "Iteration 71070: loss = 2.5177\n",
      "Iteration 71080: loss = 2.5442\n",
      "Iteration 71090: loss = 2.5702\n",
      "Iteration 71100: loss = 2.3757\n",
      "Iteration 71110: loss = 2.1546\n",
      "Iteration 71120: loss = 2.6277\n",
      "Iteration 71130: loss = 2.8532\n",
      "Iteration 71140: loss = 2.4003\n",
      "Iteration 71150: loss = 2.5366\n",
      "Iteration 71160: loss = 2.2048\n",
      "Iteration 71170: loss = 2.5086\n",
      "Iteration 71180: loss = 2.0663\n",
      "Iteration 71190: loss = 2.4656\n",
      "Iteration 71200: loss = 2.4171\n",
      "Iteration 71210: loss = 2.3796\n",
      "Iteration 71220: loss = 2.4807\n",
      "Iteration 71230: loss = 2.2805\n",
      "Iteration 71240: loss = 2.3055\n",
      "Iteration 71250: loss = 2.2841\n",
      "Iteration 71260: loss = 2.3145\n",
      "Iteration 71270: loss = 2.2590\n",
      "Iteration 71280: loss = 2.5246\n",
      "Iteration 71290: loss = 2.5064\n",
      "Iteration 71300: loss = 2.6809\n",
      "Iteration 71310: loss = 2.6263\n",
      "Iteration 71320: loss = 2.4194\n",
      "Iteration 71330: loss = 2.5634\n",
      "Iteration 71340: loss = 2.6001\n",
      "Iteration 71350: loss = 2.4751\n",
      "Iteration 71360: loss = 2.7897\n",
      "Iteration 71370: loss = 2.2287\n",
      "Iteration 71380: loss = 2.2660\n",
      "Iteration 71390: loss = 2.8386\n",
      "Iteration 71400: loss = 2.4901\n",
      "Iteration 71410: loss = 2.6402\n",
      "Iteration 71420: loss = 2.5950\n",
      "Iteration 71430: loss = 2.6103\n",
      "Iteration 71440: loss = 2.3569\n",
      "Iteration 71450: loss = 2.4768\n",
      "Iteration 71460: loss = 2.1261\n",
      "Iteration 71470: loss = 2.6108\n",
      "Iteration 71480: loss = 2.3005\n",
      "Iteration 71490: loss = 2.3104\n",
      "Iteration 71500: loss = 2.4871\n",
      "Iteration 71510: loss = 2.3351\n",
      "Iteration 71520: loss = 2.7880\n",
      "Iteration 71530: loss = 2.4841\n",
      "Iteration 71540: loss = 2.4516\n",
      "Iteration 71550: loss = 2.7405\n",
      "Iteration 71560: loss = 2.6717\n",
      "Iteration 71570: loss = 2.7273\n",
      "Iteration 71580: loss = 2.6674\n",
      "Iteration 71590: loss = 2.2780\n",
      "Iteration 71600: loss = 2.2481\n",
      "Iteration 71610: loss = 2.5448\n",
      "Iteration 71620: loss = 2.5189\n",
      "Iteration 71630: loss = 2.3061\n",
      "Iteration 71640: loss = 2.3939\n",
      "Iteration 71650: loss = 2.5955\n",
      "Iteration 71660: loss = 3.0342\n",
      "Iteration 71670: loss = 2.9028\n",
      "Iteration 71680: loss = 2.3581\n",
      "Iteration 71690: loss = 2.8700\n",
      "Iteration 71700: loss = 2.7742\n",
      "Iteration 71710: loss = 2.4816\n",
      "Iteration 71720: loss = 2.6054\n",
      "Iteration 71730: loss = 2.4845\n",
      "Iteration 71740: loss = 2.5742\n",
      "Iteration 71750: loss = 2.4020\n",
      "Iteration 71760: loss = 2.3462\n",
      "Iteration 71770: loss = 2.5235\n",
      "Iteration 71780: loss = 2.7148\n",
      "Iteration 71790: loss = 2.8503\n",
      "Iteration 71800: loss = 2.0848\n",
      "Iteration 71810: loss = 2.8955\n",
      "Iteration 71820: loss = 2.5111\n",
      "Iteration 71830: loss = 2.6847\n",
      "Iteration 71840: loss = 2.7284\n",
      "Iteration 71850: loss = 2.7644\n",
      "Iteration 71860: loss = 2.5712\n",
      "Iteration 71870: loss = 2.9154\n",
      "Iteration 71880: loss = 1.9674\n",
      "Iteration 71890: loss = 2.7334\n",
      "Iteration 71900: loss = 2.5762\n",
      "Iteration 71910: loss = 2.9509\n",
      "Iteration 71920: loss = 2.4229\n",
      "Iteration 71930: loss = 2.7594\n",
      "Iteration 71940: loss = 2.3324\n",
      "Iteration 71950: loss = 2.9016\n",
      "Iteration 71960: loss = 2.6206\n",
      "Iteration 71970: loss = 2.6468\n",
      "Iteration 71980: loss = 2.6745\n",
      "Iteration 71990: loss = 2.3533\n",
      "Iteration 72000: loss = 2.4188\n",
      "Iteration 72010: loss = 2.5053\n",
      "Iteration 72020: loss = 2.4358\n",
      "Iteration 72030: loss = 2.5087\n",
      "Iteration 72040: loss = 2.5300\n",
      "Iteration 72050: loss = 2.6322\n",
      "Iteration 72060: loss = 2.4256\n",
      "Iteration 72070: loss = 2.3753\n",
      "Iteration 72080: loss = 2.3219\n",
      "Iteration 72090: loss = 2.3046\n",
      "Iteration 72100: loss = 1.9643\n",
      "Iteration 72110: loss = 2.3743\n",
      "Iteration 72120: loss = 2.3872\n",
      "Iteration 72130: loss = 2.3470\n",
      "Iteration 72140: loss = 2.4683\n",
      "Iteration 72150: loss = 2.1989\n",
      "Iteration 72160: loss = 2.3656\n",
      "Iteration 72170: loss = 2.2088\n",
      "Iteration 72180: loss = 2.8781\n",
      "Iteration 72190: loss = 2.4402\n",
      "Iteration 72200: loss = 2.6641\n",
      "Iteration 72210: loss = 2.3893\n",
      "Iteration 72220: loss = 2.2800\n",
      "Iteration 72230: loss = 2.5685\n",
      "Iteration 72240: loss = 2.5183\n",
      "Iteration 72250: loss = 2.2212\n",
      "Iteration 72260: loss = 2.6743\n",
      "Iteration 72270: loss = 2.6951\n",
      "Iteration 72280: loss = 2.3174\n",
      "Iteration 72290: loss = 2.5673\n",
      "Iteration 72300: loss = 2.4891\n",
      "Iteration 72310: loss = 2.8123\n",
      "Iteration 72320: loss = 2.6201\n",
      "Iteration 72330: loss = 2.2353\n",
      "Iteration 72340: loss = 2.3640\n",
      "Iteration 72350: loss = 2.2704\n",
      "Iteration 72360: loss = 2.5851\n",
      "Iteration 72370: loss = 2.6868\n",
      "Iteration 72380: loss = 2.8220\n",
      "Iteration 72390: loss = 2.8339\n",
      "Iteration 72400: loss = 2.7776\n",
      "Iteration 72410: loss = 2.5320\n",
      "Iteration 72420: loss = 2.2048\n",
      "Iteration 72430: loss = 2.6961\n",
      "Iteration 72440: loss = 2.3474\n",
      "Iteration 72450: loss = 2.3656\n",
      "Iteration 72460: loss = 2.6251\n",
      "Iteration 72470: loss = 2.4748\n",
      "Iteration 72480: loss = 2.0060\n",
      "Iteration 72490: loss = 2.5555\n",
      "Iteration 72500: loss = 2.0907\n",
      "Iteration 72510: loss = 2.2137\n",
      "Iteration 72520: loss = 2.3595\n",
      "Iteration 72530: loss = 2.0291\n",
      "Iteration 72540: loss = 2.4633\n",
      "Iteration 72550: loss = 2.0244\n",
      "Iteration 72560: loss = 2.6336\n",
      "Iteration 72570: loss = 2.5118\n",
      "Iteration 72580: loss = 2.4595\n",
      "Iteration 72590: loss = 2.2531\n",
      "Iteration 72600: loss = 2.3299\n",
      "Iteration 72610: loss = 2.4988\n",
      "Iteration 72620: loss = 2.7121\n",
      "Iteration 72630: loss = 2.7976\n",
      "Iteration 72640: loss = 2.5891\n",
      "Iteration 72650: loss = 2.4213\n",
      "Iteration 72660: loss = 2.2777\n",
      "Iteration 72670: loss = 2.5971\n",
      "Iteration 72680: loss = 2.9314\n",
      "Iteration 72690: loss = 2.5035\n",
      "Iteration 72700: loss = 2.4952\n",
      "Iteration 72710: loss = 2.2778\n",
      "Iteration 72720: loss = 2.5033\n",
      "Iteration 72730: loss = 2.6973\n",
      "Iteration 72740: loss = 2.9054\n",
      "Iteration 72750: loss = 2.3858\n",
      "Iteration 72760: loss = 2.6276\n",
      "Iteration 72770: loss = 2.5108\n",
      "Iteration 72780: loss = 2.5404\n",
      "Iteration 72790: loss = 2.2849\n",
      "Iteration 72800: loss = 2.5031\n",
      "Iteration 72810: loss = 2.4438\n",
      "Iteration 72820: loss = 2.5994\n",
      "Iteration 72830: loss = 2.4908\n",
      "Iteration 72840: loss = 1.9762\n",
      "Iteration 72850: loss = 2.4328\n",
      "Iteration 72860: loss = 2.8539\n",
      "Iteration 72870: loss = 2.4578\n",
      "Iteration 72880: loss = 2.7315\n",
      "Iteration 72890: loss = 2.1296\n",
      "Iteration 72900: loss = 2.6927\n",
      "Iteration 72910: loss = 2.6123\n",
      "Iteration 72920: loss = 2.3515\n",
      "Iteration 72930: loss = 2.3430\n",
      "Iteration 72940: loss = 2.4641\n",
      "Iteration 72950: loss = 2.5277\n",
      "Iteration 72960: loss = 2.4210\n",
      "Iteration 72970: loss = 2.6299\n",
      "Iteration 72980: loss = 2.6984\n",
      "Iteration 72990: loss = 2.1977\n",
      "Iteration 73000: loss = 2.2839\n",
      "Iteration 73010: loss = 2.0071\n",
      "Iteration 73020: loss = 2.3831\n",
      "Iteration 73030: loss = 2.4888\n",
      "Iteration 73040: loss = 2.5008\n",
      "Iteration 73050: loss = 2.3583\n",
      "Iteration 73060: loss = 2.2863\n",
      "Iteration 73070: loss = 2.4832\n",
      "Iteration 73080: loss = 2.4579\n",
      "Iteration 73090: loss = 2.1715\n",
      "Iteration 73100: loss = 2.0295\n",
      "Iteration 73110: loss = 2.5451\n",
      "Iteration 73120: loss = 2.0531\n",
      "Iteration 73130: loss = 2.3485\n",
      "Iteration 73140: loss = 2.6290\n",
      "Iteration 73150: loss = 2.3364\n",
      "Iteration 73160: loss = 2.6646\n",
      "Iteration 73170: loss = 2.1976\n",
      "Iteration 73180: loss = 2.6960\n",
      "Iteration 73190: loss = 2.3420\n",
      "Iteration 73200: loss = 2.5931\n",
      "Iteration 73210: loss = 2.2813\n",
      "Iteration 73220: loss = 2.2920\n",
      "Iteration 73230: loss = 2.0915\n",
      "Iteration 73240: loss = 2.6140\n",
      "Iteration 73250: loss = 2.1476\n",
      "Iteration 73260: loss = 2.2148\n",
      "Iteration 73270: loss = 2.5042\n",
      "Iteration 73280: loss = 3.1393\n",
      "Iteration 73290: loss = 2.3676\n",
      "Iteration 73300: loss = 2.5344\n",
      "Iteration 73310: loss = 2.9136\n",
      "Iteration 73320: loss = 2.6143\n",
      "Iteration 73330: loss = 2.5788\n",
      "Iteration 73340: loss = 1.9587\n",
      "Iteration 73350: loss = 2.0936\n",
      "Iteration 73360: loss = 2.4689\n",
      "Iteration 73370: loss = 2.5924\n",
      "Iteration 73380: loss = 2.5166\n",
      "Iteration 73390: loss = 2.7353\n",
      "Iteration 73400: loss = 2.6367\n",
      "Iteration 73410: loss = 2.5786\n",
      "Iteration 73420: loss = 2.6371\n",
      "Iteration 73430: loss = 2.5458\n",
      "Iteration 73440: loss = 2.3007\n",
      "Iteration 73450: loss = 2.3415\n",
      "Iteration 73460: loss = 2.4970\n",
      "Iteration 73470: loss = 2.0188\n",
      "Iteration 73480: loss = 2.3481\n",
      "Iteration 73490: loss = 2.5308\n",
      "Iteration 73500: loss = 2.3983\n",
      "Iteration 73510: loss = 2.2855\n",
      "Iteration 73520: loss = 2.4714\n",
      "Iteration 73530: loss = 2.5010\n",
      "Iteration 73540: loss = 2.0578\n",
      "Iteration 73550: loss = 2.3070\n",
      "Iteration 73560: loss = 2.6852\n",
      "Iteration 73570: loss = 2.6161\n",
      "Iteration 73580: loss = 2.2604\n",
      "Iteration 73590: loss = 2.6407\n",
      "Iteration 73600: loss = 2.7045\n",
      "Iteration 73610: loss = 2.3141\n",
      "Iteration 73620: loss = 2.4609\n",
      "Iteration 73630: loss = 2.2130\n",
      "Iteration 73640: loss = 2.5069\n",
      "Iteration 73650: loss = 2.7948\n",
      "Iteration 73660: loss = 2.0919\n",
      "Iteration 73670: loss = 1.9231\n",
      "Iteration 73680: loss = 2.3528\n",
      "Iteration 73690: loss = 2.3524\n",
      "Iteration 73700: loss = 2.6337\n",
      "Iteration 73710: loss = 2.5105\n",
      "Iteration 73720: loss = 2.1110\n",
      "Iteration 73730: loss = 2.3398\n",
      "Iteration 73740: loss = 2.9638\n",
      "Iteration 73750: loss = 2.5247\n",
      "Iteration 73760: loss = 2.5433\n",
      "Iteration 73770: loss = 2.3872\n",
      "Iteration 73780: loss = 2.3978\n",
      "Iteration 73790: loss = 2.5805\n",
      "Iteration 73800: loss = 2.4614\n",
      "Iteration 73810: loss = 2.3251\n",
      "Iteration 73820: loss = 2.5940\n",
      "Iteration 73830: loss = 2.4052\n",
      "Iteration 73840: loss = 2.5872\n",
      "Iteration 73850: loss = 2.4870\n",
      "Iteration 73860: loss = 2.3195\n",
      "Iteration 73870: loss = 2.2350\n",
      "Iteration 73880: loss = 2.5655\n",
      "Iteration 73890: loss = 2.4833\n",
      "Iteration 73900: loss = 2.2603\n",
      "Iteration 73910: loss = 2.6738\n",
      "Iteration 73920: loss = 2.2863\n",
      "Iteration 73930: loss = 2.7715\n",
      "Iteration 73940: loss = 2.4168\n",
      "Iteration 73950: loss = 2.1600\n",
      "Iteration 73960: loss = 2.2130\n",
      "Iteration 73970: loss = 2.4977\n",
      "Iteration 73980: loss = 2.9968\n",
      "Iteration 73990: loss = 2.2534\n",
      "Iteration 74000: loss = 2.3877\n",
      "Iteration 74010: loss = 2.6267\n",
      "Iteration 74020: loss = 2.1651\n",
      "Iteration 74030: loss = 2.8657\n",
      "Iteration 74040: loss = 2.1619\n",
      "Iteration 74050: loss = 2.6706\n",
      "Iteration 74060: loss = 2.2113\n",
      "Iteration 74070: loss = 2.4378\n",
      "Iteration 74080: loss = 2.7705\n",
      "Iteration 74090: loss = 2.4355\n",
      "Iteration 74100: loss = 2.2465\n",
      "Iteration 74110: loss = 2.4951\n",
      "Iteration 74120: loss = 2.3705\n",
      "Iteration 74130: loss = 2.0125\n",
      "Iteration 74140: loss = 2.5120\n",
      "Iteration 74150: loss = 2.3042\n",
      "Iteration 74160: loss = 2.4735\n",
      "Iteration 74170: loss = 2.1286\n",
      "Iteration 74180: loss = 2.3581\n",
      "Iteration 74190: loss = 2.3969\n",
      "Iteration 74200: loss = 2.5041\n",
      "Iteration 74210: loss = 2.1288\n",
      "Iteration 74220: loss = 2.6402\n",
      "Iteration 74230: loss = 1.9590\n",
      "Iteration 74240: loss = 2.5777\n",
      "Iteration 74250: loss = 2.7475\n",
      "Iteration 74260: loss = 2.5890\n",
      "Iteration 74270: loss = 2.5840\n",
      "Iteration 74280: loss = 2.5164\n",
      "Iteration 74290: loss = 2.4840\n",
      "Iteration 74300: loss = 2.7226\n",
      "Iteration 74310: loss = 2.5184\n",
      "Iteration 74320: loss = 2.5069\n",
      "Iteration 74330: loss = 2.2521\n",
      "Iteration 74340: loss = 2.5919\n",
      "Iteration 74350: loss = 2.6783\n",
      "Iteration 74360: loss = 2.6493\n",
      "Iteration 74370: loss = 2.7252\n",
      "Iteration 74380: loss = 2.0851\n",
      "Iteration 74390: loss = 2.4514\n",
      "Iteration 74400: loss = 2.5400\n",
      "Iteration 74410: loss = 2.1053\n",
      "Iteration 74420: loss = 2.3218\n",
      "Iteration 74430: loss = 2.2789\n",
      "Iteration 74440: loss = 2.5312\n",
      "Iteration 74450: loss = 2.7180\n",
      "Iteration 74460: loss = 2.2273\n",
      "Iteration 74470: loss = 2.6381\n",
      "Iteration 74480: loss = 2.4608\n",
      "Iteration 74490: loss = 2.3378\n",
      "Iteration 74500: loss = 2.1527\n",
      "Iteration 74510: loss = 2.5710\n",
      "Iteration 74520: loss = 2.2404\n",
      "Iteration 74530: loss = 2.7998\n",
      "Iteration 74540: loss = 2.6342\n",
      "Iteration 74550: loss = 2.7967\n",
      "Iteration 74560: loss = 2.4131\n",
      "Iteration 74570: loss = 2.8035\n",
      "Iteration 74580: loss = 2.5502\n",
      "Iteration 74590: loss = 2.7610\n",
      "Iteration 74600: loss = 2.4670\n",
      "Iteration 74610: loss = 2.3459\n",
      "Iteration 74620: loss = 2.6381\n",
      "Iteration 74630: loss = 2.4052\n",
      "Iteration 74640: loss = 2.1793\n",
      "Iteration 74650: loss = 2.5177\n",
      "Iteration 74660: loss = 2.5154\n",
      "Iteration 74670: loss = 2.0103\n",
      "Iteration 74680: loss = 2.6082\n",
      "Iteration 74690: loss = 2.3536\n",
      "Iteration 74700: loss = 2.2911\n",
      "Iteration 74710: loss = 2.4321\n",
      "Iteration 74720: loss = 2.3553\n",
      "Iteration 74730: loss = 2.3217\n",
      "Iteration 74740: loss = 2.3278\n",
      "Iteration 74750: loss = 2.8255\n",
      "Iteration 74760: loss = 2.7680\n",
      "Iteration 74770: loss = 2.5490\n",
      "Iteration 74780: loss = 2.3299\n",
      "Iteration 74790: loss = 2.4899\n",
      "Iteration 74800: loss = 2.4824\n",
      "Iteration 74810: loss = 2.2736\n",
      "Iteration 74820: loss = 2.3920\n",
      "Iteration 74830: loss = 2.4898\n",
      "Iteration 74840: loss = 2.4944\n",
      "Iteration 74850: loss = 2.5686\n",
      "Iteration 74860: loss = 2.4430\n",
      "Iteration 74870: loss = 2.3972\n",
      "Iteration 74880: loss = 2.1190\n",
      "Iteration 74890: loss = 2.5138\n",
      "Iteration 74900: loss = 2.6495\n",
      "Iteration 74910: loss = 2.6047\n",
      "Iteration 74920: loss = 2.2312\n",
      "Iteration 74930: loss = 2.4546\n",
      "Iteration 74940: loss = 2.4053\n",
      "Iteration 74950: loss = 2.4613\n",
      "Iteration 74960: loss = 2.5062\n",
      "Iteration 74970: loss = 2.1729\n",
      "Iteration 74980: loss = 2.7673\n",
      "Iteration 74990: loss = 2.4668\n",
      "Iteration 75000: loss = 2.4251\n",
      "Iteration 75010: loss = 2.2162\n",
      "Iteration 75020: loss = 2.7415\n",
      "Iteration 75030: loss = 2.3454\n",
      "Iteration 75040: loss = 2.3297\n",
      "Iteration 75050: loss = 2.1643\n",
      "Iteration 75060: loss = 2.8118\n",
      "Iteration 75070: loss = 2.3879\n",
      "Iteration 75080: loss = 2.8327\n",
      "Iteration 75090: loss = 2.1520\n",
      "Iteration 75100: loss = 2.1437\n",
      "Iteration 75110: loss = 2.6607\n",
      "Iteration 75120: loss = 2.1288\n",
      "Iteration 75130: loss = 2.3984\n",
      "Iteration 75140: loss = 2.2354\n",
      "Iteration 75150: loss = 2.5390\n",
      "Iteration 75160: loss = 2.6606\n",
      "Iteration 75170: loss = 2.6000\n",
      "Iteration 75180: loss = 2.5468\n",
      "Iteration 75190: loss = 2.2035\n",
      "Iteration 75200: loss = 2.4502\n",
      "Iteration 75210: loss = 2.1407\n",
      "Iteration 75220: loss = 2.2147\n",
      "Iteration 75230: loss = 2.3607\n",
      "Iteration 75240: loss = 2.8373\n",
      "Iteration 75250: loss = 2.4740\n",
      "Iteration 75260: loss = 2.0338\n",
      "Iteration 75270: loss = 2.6561\n",
      "Iteration 75280: loss = 2.4732\n",
      "Iteration 75290: loss = 2.5493\n",
      "Iteration 75300: loss = 2.2739\n",
      "Iteration 75310: loss = 2.7497\n",
      "Iteration 75320: loss = 2.3001\n",
      "Iteration 75330: loss = 2.7383\n",
      "Iteration 75340: loss = 2.3726\n",
      "Iteration 75350: loss = 2.2100\n",
      "Iteration 75360: loss = 2.5368\n",
      "Iteration 75370: loss = 2.6036\n",
      "Iteration 75380: loss = 2.6163\n",
      "Iteration 75390: loss = 2.3104\n",
      "Iteration 75400: loss = 2.2830\n",
      "Iteration 75410: loss = 2.1854\n",
      "Iteration 75420: loss = 2.4651\n",
      "Iteration 75430: loss = 2.6334\n",
      "Iteration 75440: loss = 2.9279\n",
      "Iteration 75450: loss = 2.6392\n",
      "Iteration 75460: loss = 2.4627\n",
      "Iteration 75470: loss = 2.3473\n",
      "Iteration 75480: loss = 2.2237\n",
      "Iteration 75490: loss = 1.9820\n",
      "Iteration 75500: loss = 2.0821\n",
      "Iteration 75510: loss = 2.5461\n",
      "Iteration 75520: loss = 2.3274\n",
      "Iteration 75530: loss = 2.3246\n",
      "Iteration 75540: loss = 2.2938\n",
      "Iteration 75550: loss = 2.3895\n",
      "Iteration 75560: loss = 2.1303\n",
      "Iteration 75570: loss = 2.3575\n",
      "Iteration 75580: loss = 2.4045\n",
      "Iteration 75590: loss = 2.2369\n",
      "Iteration 75600: loss = 2.2952\n",
      "Iteration 75610: loss = 2.4261\n",
      "Iteration 75620: loss = 2.3704\n",
      "Iteration 75630: loss = 2.6224\n",
      "Iteration 75640: loss = 2.6839\n",
      "Iteration 75650: loss = 2.4132\n",
      "Iteration 75660: loss = 2.2586\n",
      "Iteration 75670: loss = 2.2559\n",
      "Iteration 75680: loss = 2.4313\n",
      "Iteration 75690: loss = 2.5595\n",
      "Iteration 75700: loss = 2.2448\n",
      "Iteration 75710: loss = 2.3042\n",
      "Iteration 75720: loss = 2.8256\n",
      "Iteration 75730: loss = 2.3804\n",
      "Iteration 75740: loss = 2.5032\n",
      "Iteration 75750: loss = 2.5118\n",
      "Iteration 75760: loss = 2.8913\n",
      "Iteration 75770: loss = 2.1954\n",
      "Iteration 75780: loss = 2.2726\n",
      "Iteration 75790: loss = 2.4815\n",
      "Iteration 75800: loss = 2.5099\n",
      "Iteration 75810: loss = 2.4132\n",
      "Iteration 75820: loss = 2.2994\n",
      "Iteration 75830: loss = 2.3780\n",
      "Iteration 75840: loss = 2.5858\n",
      "Iteration 75850: loss = 2.1552\n",
      "Iteration 75860: loss = 2.6400\n",
      "Iteration 75870: loss = 2.2527\n",
      "Iteration 75880: loss = 2.4362\n",
      "Iteration 75890: loss = 2.4203\n",
      "Iteration 75900: loss = 1.9304\n",
      "Iteration 75910: loss = 2.3578\n",
      "Iteration 75920: loss = 2.6073\n",
      "Iteration 75930: loss = 2.5121\n",
      "Iteration 75940: loss = 2.1192\n",
      "Iteration 75950: loss = 2.6282\n",
      "Iteration 75960: loss = 2.7863\n",
      "Iteration 75970: loss = 2.4752\n",
      "Iteration 75980: loss = 2.3935\n",
      "Iteration 75990: loss = 2.6454\n",
      "Iteration 76000: loss = 2.1838\n",
      "Iteration 76010: loss = 2.2714\n",
      "Iteration 76020: loss = 2.3748\n",
      "Iteration 76030: loss = 2.6811\n",
      "Iteration 76040: loss = 2.7926\n",
      "Iteration 76050: loss = 2.2436\n",
      "Iteration 76060: loss = 2.8135\n",
      "Iteration 76070: loss = 2.5450\n",
      "Iteration 76080: loss = 2.1611\n",
      "Iteration 76090: loss = 2.2599\n",
      "Iteration 76100: loss = 2.4668\n",
      "Iteration 76110: loss = 2.3555\n",
      "Iteration 76120: loss = 2.4779\n",
      "Iteration 76130: loss = 2.4807\n",
      "Iteration 76140: loss = 2.4165\n",
      "Iteration 76150: loss = 2.3214\n",
      "Iteration 76160: loss = 2.6271\n",
      "Iteration 76170: loss = 2.4695\n",
      "Iteration 76180: loss = 2.3851\n",
      "Iteration 76190: loss = 2.4262\n",
      "Iteration 76200: loss = 2.4273\n",
      "Iteration 76210: loss = 2.2234\n",
      "Iteration 76220: loss = 2.7442\n",
      "Iteration 76230: loss = 2.1899\n",
      "Iteration 76240: loss = 2.4303\n",
      "Iteration 76250: loss = 1.8244\n",
      "Iteration 76260: loss = 2.5748\n",
      "Iteration 76270: loss = 2.3602\n",
      "Iteration 76280: loss = 2.2857\n",
      "Iteration 76290: loss = 2.4250\n",
      "Iteration 76300: loss = 2.4302\n",
      "Iteration 76310: loss = 2.2936\n",
      "Iteration 76320: loss = 2.4877\n",
      "Iteration 76330: loss = 2.3426\n",
      "Iteration 76340: loss = 2.8565\n",
      "Iteration 76350: loss = 2.7334\n",
      "Iteration 76360: loss = 2.3034\n",
      "Iteration 76370: loss = 2.8634\n",
      "Iteration 76380: loss = 2.5980\n",
      "Iteration 76390: loss = 2.8172\n",
      "Iteration 76400: loss = 2.5362\n",
      "Iteration 76410: loss = 2.2874\n",
      "Iteration 76420: loss = 2.5616\n",
      "Iteration 76430: loss = 2.5295\n",
      "Iteration 76440: loss = 2.4640\n",
      "Iteration 76450: loss = 2.4282\n",
      "Iteration 76460: loss = 2.5962\n",
      "Iteration 76470: loss = 2.8514\n",
      "Iteration 76480: loss = 2.2542\n",
      "Iteration 76490: loss = 1.8118\n",
      "Iteration 76500: loss = 2.6542\n",
      "Iteration 76510: loss = 2.6360\n",
      "Iteration 76520: loss = 2.5796\n",
      "Iteration 76530: loss = 2.7577\n",
      "Iteration 76540: loss = 2.4396\n",
      "Iteration 76550: loss = 2.3156\n",
      "Iteration 76560: loss = 2.7407\n",
      "Iteration 76570: loss = 2.4649\n",
      "Iteration 76580: loss = 2.2298\n",
      "Iteration 76590: loss = 2.6463\n",
      "Iteration 76600: loss = 2.5401\n",
      "Iteration 76610: loss = 2.7737\n",
      "Iteration 76620: loss = 2.3939\n",
      "Iteration 76630: loss = 2.1236\n",
      "Iteration 76640: loss = 2.0690\n",
      "Iteration 76650: loss = 2.2266\n",
      "Iteration 76660: loss = 2.4020\n",
      "Iteration 76670: loss = 2.5638\n",
      "Iteration 76680: loss = 2.6567\n",
      "Iteration 76690: loss = 2.4508\n",
      "Iteration 76700: loss = 2.4734\n",
      "Iteration 76710: loss = 2.5439\n",
      "Iteration 76720: loss = 2.5725\n",
      "Iteration 76730: loss = 1.9865\n",
      "Iteration 76740: loss = 2.5749\n",
      "Iteration 76750: loss = 2.2966\n",
      "Iteration 76760: loss = 2.3500\n",
      "Iteration 76770: loss = 2.3177\n",
      "Iteration 76780: loss = 2.3489\n",
      "Iteration 76790: loss = 2.4748\n",
      "Iteration 76800: loss = 2.2963\n",
      "Iteration 76810: loss = 2.8540\n",
      "Iteration 76820: loss = 2.5111\n",
      "Iteration 76830: loss = 2.6393\n",
      "Iteration 76840: loss = 2.8184\n",
      "Iteration 76850: loss = 2.6796\n",
      "Iteration 76860: loss = 2.3980\n",
      "Iteration 76870: loss = 2.6725\n",
      "Iteration 76880: loss = 2.5737\n",
      "Iteration 76890: loss = 2.5414\n",
      "Iteration 76900: loss = 2.1880\n",
      "Iteration 76910: loss = 2.6845\n",
      "Iteration 76920: loss = 2.2713\n",
      "Iteration 76930: loss = 2.4906\n",
      "Iteration 76940: loss = 2.4570\n",
      "Iteration 76950: loss = 2.2167\n",
      "Iteration 76960: loss = 2.1625\n",
      "Iteration 76970: loss = 2.6516\n",
      "Iteration 76980: loss = 2.3705\n",
      "Iteration 76990: loss = 2.1391\n",
      "Iteration 77000: loss = 2.5567\n",
      "Iteration 77010: loss = 2.1282\n",
      "Iteration 77020: loss = 3.0469\n",
      "Iteration 77030: loss = 2.4106\n",
      "Iteration 77040: loss = 2.6527\n",
      "Iteration 77050: loss = 2.3366\n",
      "Iteration 77060: loss = 2.5086\n",
      "Iteration 77070: loss = 2.0714\n",
      "Iteration 77080: loss = 2.0886\n",
      "Iteration 77090: loss = 2.6320\n",
      "Iteration 77100: loss = 2.3737\n",
      "Iteration 77110: loss = 2.3521\n",
      "Iteration 77120: loss = 2.4772\n",
      "Iteration 77130: loss = 2.8534\n",
      "Iteration 77140: loss = 2.6231\n",
      "Iteration 77150: loss = 2.2888\n",
      "Iteration 77160: loss = 2.3151\n",
      "Iteration 77170: loss = 2.3072\n",
      "Iteration 77180: loss = 2.6853\n",
      "Iteration 77190: loss = 2.1940\n",
      "Iteration 77200: loss = 2.4405\n",
      "Iteration 77210: loss = 2.2759\n",
      "Iteration 77220: loss = 2.5316\n",
      "Iteration 77230: loss = 2.8808\n",
      "Iteration 77240: loss = 2.2841\n",
      "Iteration 77250: loss = 2.4778\n",
      "Iteration 77260: loss = 3.1298\n",
      "Iteration 77270: loss = 2.6355\n",
      "Iteration 77280: loss = 2.5420\n",
      "Iteration 77290: loss = 2.6031\n",
      "Iteration 77300: loss = 2.7055\n",
      "Iteration 77310: loss = 2.7991\n",
      "Iteration 77320: loss = 2.7784\n",
      "Iteration 77330: loss = 2.3478\n",
      "Iteration 77340: loss = 2.7400\n",
      "Iteration 77350: loss = 2.2346\n",
      "Iteration 77360: loss = 2.3937\n",
      "Iteration 77370: loss = 2.7092\n",
      "Iteration 77380: loss = 2.3963\n",
      "Iteration 77390: loss = 2.3153\n",
      "Iteration 77400: loss = 2.0312\n",
      "Iteration 77410: loss = 2.4570\n",
      "Iteration 77420: loss = 2.6271\n",
      "Iteration 77430: loss = 2.1374\n",
      "Iteration 77440: loss = 2.2274\n",
      "Iteration 77450: loss = 2.4280\n",
      "Iteration 77460: loss = 2.8030\n",
      "Iteration 77470: loss = 2.4632\n",
      "Iteration 77480: loss = 2.4664\n",
      "Iteration 77490: loss = 2.5957\n",
      "Iteration 77500: loss = 2.4677\n",
      "Iteration 77510: loss = 2.3559\n",
      "Iteration 77520: loss = 2.7446\n",
      "Iteration 77530: loss = 2.5377\n",
      "Iteration 77540: loss = 2.5928\n",
      "Iteration 77550: loss = 2.2021\n",
      "Iteration 77560: loss = 2.4291\n",
      "Iteration 77570: loss = 2.3458\n",
      "Iteration 77580: loss = 2.5468\n",
      "Iteration 77590: loss = 2.9280\n",
      "Iteration 77600: loss = 2.5290\n",
      "Iteration 77610: loss = 2.5124\n",
      "Iteration 77620: loss = 2.5188\n",
      "Iteration 77630: loss = 2.6660\n",
      "Iteration 77640: loss = 2.4272\n",
      "Iteration 77650: loss = 2.5111\n",
      "Iteration 77660: loss = 2.1899\n",
      "Iteration 77670: loss = 2.7153\n",
      "Iteration 77680: loss = 2.3358\n",
      "Iteration 77690: loss = 2.2671\n",
      "Iteration 77700: loss = 2.2610\n",
      "Iteration 77710: loss = 2.1726\n",
      "Iteration 77720: loss = 2.5833\n",
      "Iteration 77730: loss = 2.6344\n",
      "Iteration 77740: loss = 2.6215\n",
      "Iteration 77750: loss = 2.5449\n",
      "Iteration 77760: loss = 2.4291\n",
      "Iteration 77770: loss = 2.2888\n",
      "Iteration 77780: loss = 2.1637\n",
      "Iteration 77790: loss = 2.4937\n",
      "Iteration 77800: loss = 2.6568\n",
      "Iteration 77810: loss = 2.4591\n",
      "Iteration 77820: loss = 2.3604\n",
      "Iteration 77830: loss = 2.2138\n",
      "Iteration 77840: loss = 2.0062\n",
      "Iteration 77850: loss = 2.2035\n",
      "Iteration 77860: loss = 1.9513\n",
      "Iteration 77870: loss = 2.6405\n",
      "Iteration 77880: loss = 1.9893\n",
      "Iteration 77890: loss = 2.6025\n",
      "Iteration 77900: loss = 2.7706\n",
      "Iteration 77910: loss = 2.2413\n",
      "Iteration 77920: loss = 2.7869\n",
      "Iteration 77930: loss = 2.6485\n",
      "Iteration 77940: loss = 2.2313\n",
      "Iteration 77950: loss = 2.6622\n",
      "Iteration 77960: loss = 2.6598\n",
      "Iteration 77970: loss = 2.4237\n",
      "Iteration 77980: loss = 2.8770\n",
      "Iteration 77990: loss = 2.5324\n",
      "Iteration 78000: loss = 2.3746\n",
      "Iteration 78010: loss = 2.4538\n",
      "Iteration 78020: loss = 2.5908\n",
      "Iteration 78030: loss = 2.6760\n",
      "Iteration 78040: loss = 2.5780\n",
      "Iteration 78050: loss = 2.3608\n",
      "Iteration 78060: loss = 2.8986\n",
      "Iteration 78070: loss = 2.8727\n",
      "Iteration 78080: loss = 2.3299\n",
      "Iteration 78090: loss = 2.8592\n",
      "Iteration 78100: loss = 2.3489\n",
      "Iteration 78110: loss = 2.7056\n",
      "Iteration 78120: loss = 2.4846\n",
      "Iteration 78130: loss = 2.3113\n",
      "Iteration 78140: loss = 2.1811\n",
      "Iteration 78150: loss = 2.4759\n",
      "Iteration 78160: loss = 2.3679\n",
      "Iteration 78170: loss = 2.7982\n",
      "Iteration 78180: loss = 2.7116\n",
      "Iteration 78190: loss = 2.2195\n",
      "Iteration 78200: loss = 2.1477\n",
      "Iteration 78210: loss = 2.3638\n",
      "Iteration 78220: loss = 2.2151\n",
      "Iteration 78230: loss = 2.7648\n",
      "Iteration 78240: loss = 2.5908\n",
      "Iteration 78250: loss = 2.3414\n",
      "Iteration 78260: loss = 2.5117\n",
      "Iteration 78270: loss = 2.4240\n",
      "Iteration 78280: loss = 2.5163\n",
      "Iteration 78290: loss = 2.3658\n",
      "Iteration 78300: loss = 2.2710\n",
      "Iteration 78310: loss = 2.7646\n",
      "Iteration 78320: loss = 2.8282\n",
      "Iteration 78330: loss = 2.3297\n",
      "Iteration 78340: loss = 2.1977\n",
      "Iteration 78350: loss = 2.7867\n",
      "Iteration 78360: loss = 2.3346\n",
      "Iteration 78370: loss = 2.4161\n",
      "Iteration 78380: loss = 2.5502\n",
      "Iteration 78390: loss = 2.5032\n",
      "Iteration 78400: loss = 2.3891\n",
      "Iteration 78410: loss = 2.3553\n",
      "Iteration 78420: loss = 2.3626\n",
      "Iteration 78430: loss = 2.6088\n",
      "Iteration 78440: loss = 2.4286\n",
      "Iteration 78450: loss = 2.2994\n",
      "Iteration 78460: loss = 2.8062\n",
      "Iteration 78470: loss = 2.4901\n",
      "Iteration 78480: loss = 2.0404\n",
      "Iteration 78490: loss = 2.2108\n",
      "Iteration 78500: loss = 2.6436\n",
      "Iteration 78510: loss = 2.1657\n",
      "Iteration 78520: loss = 2.0786\n",
      "Iteration 78530: loss = 2.2976\n",
      "Iteration 78540: loss = 2.1471\n",
      "Iteration 78550: loss = 2.2232\n",
      "Iteration 78560: loss = 2.6034\n",
      "Iteration 78570: loss = 2.0780\n",
      "Iteration 78580: loss = 2.9724\n",
      "Iteration 78590: loss = 2.7146\n",
      "Iteration 78600: loss = 2.3151\n",
      "Iteration 78610: loss = 2.6409\n",
      "Iteration 78620: loss = 2.1702\n",
      "Iteration 78630: loss = 2.8078\n",
      "Iteration 78640: loss = 2.4621\n",
      "Iteration 78650: loss = 2.6183\n",
      "Iteration 78660: loss = 2.3854\n",
      "Iteration 78670: loss = 2.2763\n",
      "Iteration 78680: loss = 2.6048\n",
      "Iteration 78690: loss = 2.4819\n",
      "Iteration 78700: loss = 2.1743\n",
      "Iteration 78710: loss = 2.0261\n",
      "Iteration 78720: loss = 2.8547\n",
      "Iteration 78730: loss = 2.1862\n",
      "Iteration 78740: loss = 2.8619\n",
      "Iteration 78750: loss = 2.3188\n",
      "Iteration 78760: loss = 2.6251\n",
      "Iteration 78770: loss = 2.3143\n",
      "Iteration 78780: loss = 2.5850\n",
      "Iteration 78790: loss = 2.5544\n",
      "Iteration 78800: loss = 2.6676\n",
      "Iteration 78810: loss = 2.3607\n",
      "Iteration 78820: loss = 2.2973\n",
      "Iteration 78830: loss = 2.7153\n",
      "Iteration 78840: loss = 2.2531\n",
      "Iteration 78850: loss = 2.7162\n",
      "Iteration 78860: loss = 2.5805\n",
      "Iteration 78870: loss = 2.1107\n",
      "Iteration 78880: loss = 2.7440\n",
      "Iteration 78890: loss = 2.2559\n",
      "Iteration 78900: loss = 2.2985\n",
      "Iteration 78910: loss = 2.6281\n",
      "Iteration 78920: loss = 2.7002\n",
      "Iteration 78930: loss = 2.2795\n",
      "Iteration 78940: loss = 2.6393\n",
      "Iteration 78950: loss = 2.6490\n",
      "Iteration 78960: loss = 2.3582\n",
      "Iteration 78970: loss = 2.4883\n",
      "Iteration 78980: loss = 2.3683\n",
      "Iteration 78990: loss = 2.6118\n",
      "Iteration 79000: loss = 2.1357\n",
      "Iteration 79010: loss = 2.6533\n",
      "Iteration 79020: loss = 2.3759\n",
      "Iteration 79030: loss = 2.2893\n",
      "Iteration 79040: loss = 2.6945\n",
      "Iteration 79050: loss = 2.8048\n",
      "Iteration 79060: loss = 2.7016\n",
      "Iteration 79070: loss = 2.5558\n",
      "Iteration 79080: loss = 2.3846\n",
      "Iteration 79090: loss = 2.4553\n",
      "Iteration 79100: loss = 2.2437\n",
      "Iteration 79110: loss = 2.8573\n",
      "Iteration 79120: loss = 2.2669\n",
      "Iteration 79130: loss = 2.7849\n",
      "Iteration 79140: loss = 2.3091\n",
      "Iteration 79150: loss = 2.2262\n",
      "Iteration 79160: loss = 2.8064\n",
      "Iteration 79170: loss = 2.4377\n",
      "Iteration 79180: loss = 2.1348\n",
      "Iteration 79190: loss = 2.2356\n",
      "Iteration 79200: loss = 2.6331\n",
      "Iteration 79210: loss = 2.5199\n",
      "Iteration 79220: loss = 2.4786\n",
      "Iteration 79230: loss = 2.4530\n",
      "Iteration 79240: loss = 2.4832\n",
      "Iteration 79250: loss = 2.4784\n",
      "Iteration 79260: loss = 2.2936\n",
      "Iteration 79270: loss = 2.2848\n",
      "Iteration 79280: loss = 2.5293\n",
      "Iteration 79290: loss = 2.4517\n",
      "Iteration 79300: loss = 2.5416\n",
      "Iteration 79310: loss = 2.6584\n",
      "Iteration 79320: loss = 2.5144\n",
      "Iteration 79330: loss = 2.5466\n",
      "Iteration 79340: loss = 2.2939\n",
      "Iteration 79350: loss = 2.5429\n",
      "Iteration 79360: loss = 2.3250\n",
      "Iteration 79370: loss = 2.4831\n",
      "Iteration 79380: loss = 2.2589\n",
      "Iteration 79390: loss = 2.5639\n",
      "Iteration 79400: loss = 2.0025\n",
      "Iteration 79410: loss = 2.2243\n",
      "Iteration 79420: loss = 2.3784\n",
      "Iteration 79430: loss = 2.6879\n",
      "Iteration 79440: loss = 2.5010\n",
      "Iteration 79450: loss = 2.3064\n",
      "Iteration 79460: loss = 2.2213\n",
      "Iteration 79470: loss = 2.3114\n",
      "Iteration 79480: loss = 2.6757\n",
      "Iteration 79490: loss = 2.4099\n",
      "Iteration 79500: loss = 2.5858\n",
      "Iteration 79510: loss = 2.4936\n",
      "Iteration 79520: loss = 2.7254\n",
      "Iteration 79530: loss = 2.8697\n",
      "Iteration 79540: loss = 2.5987\n",
      "Iteration 79550: loss = 2.5373\n",
      "Iteration 79560: loss = 2.4054\n",
      "Iteration 79570: loss = 2.2764\n",
      "Iteration 79580: loss = 2.7116\n",
      "Iteration 79590: loss = 2.2114\n",
      "Iteration 79600: loss = 2.5678\n",
      "Iteration 79610: loss = 2.5058\n",
      "Iteration 79620: loss = 2.6572\n",
      "Iteration 79630: loss = 2.3528\n",
      "Iteration 79640: loss = 2.1312\n",
      "Iteration 79650: loss = 2.5855\n",
      "Iteration 79660: loss = 2.8328\n",
      "Iteration 79670: loss = 2.2241\n",
      "Iteration 79680: loss = 2.1971\n",
      "Iteration 79690: loss = 2.3333\n",
      "Iteration 79700: loss = 2.3253\n",
      "Iteration 79710: loss = 2.6851\n",
      "Iteration 79720: loss = 2.6437\n",
      "Iteration 79730: loss = 2.4119\n",
      "Iteration 79740: loss = 2.3052\n",
      "Iteration 79750: loss = 2.3814\n",
      "Iteration 79760: loss = 2.6834\n",
      "Iteration 79770: loss = 2.4141\n",
      "Iteration 79780: loss = 2.3556\n",
      "Iteration 79790: loss = 2.0735\n",
      "Iteration 79800: loss = 2.6897\n",
      "Iteration 79810: loss = 2.1329\n",
      "Iteration 79820: loss = 2.1265\n",
      "Iteration 79830: loss = 2.5076\n",
      "Iteration 79840: loss = 2.3544\n",
      "Iteration 79850: loss = 2.1959\n",
      "Iteration 79860: loss = 2.3933\n",
      "Iteration 79870: loss = 2.7436\n",
      "Iteration 79880: loss = 2.7900\n",
      "Iteration 79890: loss = 2.4136\n",
      "Iteration 79900: loss = 2.4920\n",
      "Iteration 79910: loss = 2.8615\n",
      "Iteration 79920: loss = 2.1806\n",
      "Iteration 79930: loss = 2.6016\n",
      "Iteration 79940: loss = 2.2866\n",
      "Iteration 79950: loss = 2.3524\n",
      "Iteration 79960: loss = 2.1736\n",
      "Iteration 79970: loss = 2.5208\n",
      "Iteration 79980: loss = 2.6718\n",
      "Iteration 79990: loss = 2.6751\n",
      "Iteration 80000: loss = 2.1721\n",
      "Iteration 80010: loss = 2.3190\n",
      "Iteration 80020: loss = 2.4315\n",
      "Iteration 80030: loss = 2.7931\n",
      "Iteration 80040: loss = 2.3387\n",
      "Iteration 80050: loss = 3.1035\n",
      "Iteration 80060: loss = 2.3597\n",
      "Iteration 80070: loss = 2.7186\n",
      "Iteration 80080: loss = 2.5495\n",
      "Iteration 80090: loss = 2.4243\n",
      "Iteration 80100: loss = 2.5123\n",
      "Iteration 80110: loss = 2.6212\n",
      "Iteration 80120: loss = 2.2836\n",
      "Iteration 80130: loss = 2.4514\n",
      "Iteration 80140: loss = 2.4304\n",
      "Iteration 80150: loss = 2.7417\n",
      "Iteration 80160: loss = 2.5709\n",
      "Iteration 80170: loss = 2.4753\n",
      "Iteration 80180: loss = 2.2861\n",
      "Iteration 80190: loss = 2.5871\n",
      "Iteration 80200: loss = 2.4589\n",
      "Iteration 80210: loss = 2.1688\n",
      "Iteration 80220: loss = 2.0085\n",
      "Iteration 80230: loss = 2.4805\n",
      "Iteration 80240: loss = 2.4538\n",
      "Iteration 80250: loss = 2.4092\n",
      "Iteration 80260: loss = 2.1722\n",
      "Iteration 80270: loss = 2.5264\n",
      "Iteration 80280: loss = 2.2797\n",
      "Iteration 80290: loss = 2.3184\n",
      "Iteration 80300: loss = 2.4873\n",
      "Iteration 80310: loss = 2.5151\n",
      "Iteration 80320: loss = 2.3655\n",
      "Iteration 80330: loss = 2.5428\n",
      "Iteration 80340: loss = 2.9722\n",
      "Iteration 80350: loss = 2.5476\n",
      "Iteration 80360: loss = 2.4357\n",
      "Iteration 80370: loss = 2.4855\n",
      "Iteration 80380: loss = 2.6238\n",
      "Iteration 80390: loss = 2.3370\n",
      "Iteration 80400: loss = 2.6037\n",
      "Iteration 80410: loss = 2.5259\n",
      "Iteration 80420: loss = 2.0694\n",
      "Iteration 80430: loss = 2.6193\n",
      "Iteration 80440: loss = 2.5526\n",
      "Iteration 80450: loss = 2.5707\n",
      "Iteration 80460: loss = 2.6384\n",
      "Iteration 80470: loss = 2.1969\n",
      "Iteration 80480: loss = 2.6655\n",
      "Iteration 80490: loss = 2.9058\n",
      "Iteration 80500: loss = 2.4292\n",
      "Iteration 80510: loss = 2.3848\n",
      "Iteration 80520: loss = 2.2200\n",
      "Iteration 80530: loss = 2.3364\n",
      "Iteration 80540: loss = 2.7483\n",
      "Iteration 80550: loss = 2.4086\n",
      "Iteration 80560: loss = 2.6436\n",
      "Iteration 80570: loss = 2.7040\n",
      "Iteration 80580: loss = 2.7085\n",
      "Iteration 80590: loss = 2.1020\n",
      "Iteration 80600: loss = 2.1140\n",
      "Iteration 80610: loss = 2.4166\n",
      "Iteration 80620: loss = 2.6604\n",
      "Iteration 80630: loss = 2.2267\n",
      "Iteration 80640: loss = 2.5288\n",
      "Iteration 80650: loss = 2.5365\n",
      "Iteration 80660: loss = 2.6653\n",
      "Iteration 80670: loss = 2.5109\n",
      "Iteration 80680: loss = 2.5749\n",
      "Iteration 80690: loss = 2.4815\n",
      "Iteration 80700: loss = 2.4417\n",
      "Iteration 80710: loss = 2.5236\n",
      "Iteration 80720: loss = 2.2142\n",
      "Iteration 80730: loss = 2.3230\n",
      "Iteration 80740: loss = 2.8460\n",
      "Iteration 80750: loss = 2.5994\n",
      "Iteration 80760: loss = 2.3400\n",
      "Iteration 80770: loss = 2.8556\n",
      "Iteration 80780: loss = 2.1352\n",
      "Iteration 80790: loss = 2.5480\n",
      "Iteration 80800: loss = 2.0723\n",
      "Iteration 80810: loss = 2.5771\n",
      "Iteration 80820: loss = 2.5491\n",
      "Iteration 80830: loss = 2.3482\n",
      "Iteration 80840: loss = 2.5009\n",
      "Iteration 80850: loss = 2.5038\n",
      "Iteration 80860: loss = 2.1824\n",
      "Iteration 80870: loss = 2.5156\n",
      "Iteration 80880: loss = 2.7102\n",
      "Iteration 80890: loss = 2.6768\n",
      "Iteration 80900: loss = 2.3961\n",
      "Iteration 80910: loss = 2.4775\n",
      "Iteration 80920: loss = 2.5235\n",
      "Iteration 80930: loss = 2.4620\n",
      "Iteration 80940: loss = 2.5995\n",
      "Iteration 80950: loss = 2.3594\n",
      "Iteration 80960: loss = 2.2077\n",
      "Iteration 80970: loss = 2.4078\n",
      "Iteration 80980: loss = 1.9529\n",
      "Iteration 80990: loss = 2.6052\n",
      "Iteration 81000: loss = 2.5663\n",
      "Iteration 81010: loss = 2.4372\n",
      "Iteration 81020: loss = 2.7211\n",
      "Iteration 81030: loss = 2.5945\n",
      "Iteration 81040: loss = 2.2283\n",
      "Iteration 81050: loss = 2.2220\n",
      "Iteration 81060: loss = 2.1036\n",
      "Iteration 81070: loss = 2.7486\n",
      "Iteration 81080: loss = 2.7791\n",
      "Iteration 81090: loss = 2.4352\n",
      "Iteration 81100: loss = 2.7025\n",
      "Iteration 81110: loss = 2.5077\n",
      "Iteration 81120: loss = 2.3200\n",
      "Iteration 81130: loss = 2.4318\n",
      "Iteration 81140: loss = 2.2415\n",
      "Iteration 81150: loss = 2.7459\n",
      "Iteration 81160: loss = 2.3700\n",
      "Iteration 81170: loss = 2.8049\n",
      "Iteration 81180: loss = 2.3938\n",
      "Iteration 81190: loss = 2.4394\n",
      "Iteration 81200: loss = 2.5208\n",
      "Iteration 81210: loss = 2.6431\n",
      "Iteration 81220: loss = 2.8639\n",
      "Iteration 81230: loss = 2.5943\n",
      "Iteration 81240: loss = 1.8905\n",
      "Iteration 81250: loss = 2.1950\n",
      "Iteration 81260: loss = 2.4969\n",
      "Iteration 81270: loss = 2.4972\n",
      "Iteration 81280: loss = 2.6471\n",
      "Iteration 81290: loss = 2.3690\n",
      "Iteration 81300: loss = 2.5002\n",
      "Iteration 81310: loss = 2.7324\n",
      "Iteration 81320: loss = 2.5659\n",
      "Iteration 81330: loss = 2.3079\n",
      "Iteration 81340: loss = 2.3375\n",
      "Iteration 81350: loss = 2.8454\n",
      "Iteration 81360: loss = 2.6265\n",
      "Iteration 81370: loss = 2.4812\n",
      "Iteration 81380: loss = 2.5784\n",
      "Iteration 81390: loss = 2.8366\n",
      "Iteration 81400: loss = 2.7106\n",
      "Iteration 81410: loss = 2.4018\n",
      "Iteration 81420: loss = 2.3280\n",
      "Iteration 81430: loss = 2.3629\n",
      "Iteration 81440: loss = 2.5903\n",
      "Iteration 81450: loss = 2.5358\n",
      "Iteration 81460: loss = 2.0793\n",
      "Iteration 81470: loss = 2.1247\n",
      "Iteration 81480: loss = 2.2618\n",
      "Iteration 81490: loss = 2.6447\n",
      "Iteration 81500: loss = 2.6562\n",
      "Iteration 81510: loss = 2.9131\n",
      "Iteration 81520: loss = 2.2974\n",
      "Iteration 81530: loss = 2.5642\n",
      "Iteration 81540: loss = 2.3586\n",
      "Iteration 81550: loss = 2.3711\n",
      "Iteration 81560: loss = 2.4703\n",
      "Iteration 81570: loss = 2.4937\n",
      "Iteration 81580: loss = 2.6151\n",
      "Iteration 81590: loss = 2.6849\n",
      "Iteration 81600: loss = 2.8197\n",
      "Iteration 81610: loss = 2.4366\n",
      "Iteration 81620: loss = 2.1335\n",
      "Iteration 81630: loss = 2.7632\n",
      "Iteration 81640: loss = 2.6987\n",
      "Iteration 81650: loss = 2.2852\n",
      "Iteration 81660: loss = 2.0893\n",
      "Iteration 81670: loss = 2.5125\n",
      "Iteration 81680: loss = 2.3754\n",
      "Iteration 81690: loss = 2.3926\n",
      "Iteration 81700: loss = 2.1872\n",
      "Iteration 81710: loss = 2.2740\n",
      "Iteration 81720: loss = 2.8761\n",
      "Iteration 81730: loss = 2.3095\n",
      "Iteration 81740: loss = 2.5010\n",
      "Iteration 81750: loss = 2.3377\n",
      "Iteration 81760: loss = 2.5976\n",
      "Iteration 81770: loss = 2.4053\n",
      "Iteration 81780: loss = 2.6691\n",
      "Iteration 81790: loss = 2.5327\n",
      "Iteration 81800: loss = 2.8204\n",
      "Iteration 81810: loss = 2.4440\n",
      "Iteration 81820: loss = 2.4520\n",
      "Iteration 81830: loss = 2.7689\n",
      "Iteration 81840: loss = 2.5072\n",
      "Iteration 81850: loss = 2.4918\n",
      "Iteration 81860: loss = 2.4488\n",
      "Iteration 81870: loss = 2.2952\n",
      "Iteration 81880: loss = 2.4365\n",
      "Iteration 81890: loss = 2.8484\n",
      "Iteration 81900: loss = 2.6141\n",
      "Iteration 81910: loss = 2.8736\n",
      "Iteration 81920: loss = 2.1128\n",
      "Iteration 81930: loss = 2.5490\n",
      "Iteration 81940: loss = 2.2949\n",
      "Iteration 81950: loss = 2.5684\n",
      "Iteration 81960: loss = 2.2341\n",
      "Iteration 81970: loss = 2.3695\n",
      "Iteration 81980: loss = 2.7441\n",
      "Iteration 81990: loss = 2.5795\n",
      "Iteration 82000: loss = 2.7008\n",
      "Iteration 82010: loss = 2.4150\n",
      "Iteration 82020: loss = 2.3723\n",
      "Iteration 82030: loss = 2.5027\n",
      "Iteration 82040: loss = 2.2556\n",
      "Iteration 82050: loss = 2.6872\n",
      "Iteration 82060: loss = 2.7249\n",
      "Iteration 82070: loss = 2.5605\n",
      "Iteration 82080: loss = 2.8084\n",
      "Iteration 82090: loss = 2.6123\n",
      "Iteration 82100: loss = 2.7274\n",
      "Iteration 82110: loss = 2.4832\n",
      "Iteration 82120: loss = 2.1307\n",
      "Iteration 82130: loss = 2.8735\n",
      "Iteration 82140: loss = 2.3652\n",
      "Iteration 82150: loss = 2.0972\n",
      "Iteration 82160: loss = 2.6159\n",
      "Iteration 82170: loss = 2.4010\n",
      "Iteration 82180: loss = 2.6279\n",
      "Iteration 82190: loss = 2.7269\n",
      "Iteration 82200: loss = 2.3619\n",
      "Iteration 82210: loss = 2.6852\n",
      "Iteration 82220: loss = 2.4354\n",
      "Iteration 82230: loss = 2.0133\n",
      "Iteration 82240: loss = 2.4082\n",
      "Iteration 82250: loss = 2.5571\n",
      "Iteration 82260: loss = 2.7591\n",
      "Iteration 82270: loss = 2.5628\n",
      "Iteration 82280: loss = 2.6564\n",
      "Iteration 82290: loss = 2.2364\n",
      "Iteration 82300: loss = 2.6271\n",
      "Iteration 82310: loss = 2.5600\n",
      "Iteration 82320: loss = 2.5300\n",
      "Iteration 82330: loss = 2.7519\n",
      "Iteration 82340: loss = 2.3414\n",
      "Iteration 82350: loss = 2.3322\n",
      "Iteration 82360: loss = 2.3977\n",
      "Iteration 82370: loss = 2.1976\n",
      "Iteration 82380: loss = 2.3605\n",
      "Iteration 82390: loss = 2.1872\n",
      "Iteration 82400: loss = 2.2613\n",
      "Iteration 82410: loss = 2.6212\n",
      "Iteration 82420: loss = 2.6657\n",
      "Iteration 82430: loss = 2.3186\n",
      "Iteration 82440: loss = 2.3691\n",
      "Iteration 82450: loss = 2.6635\n",
      "Iteration 82460: loss = 2.6239\n",
      "Iteration 82470: loss = 2.3838\n",
      "Iteration 82480: loss = 2.2937\n",
      "Iteration 82490: loss = 2.0853\n",
      "Iteration 82500: loss = 2.3745\n",
      "Iteration 82510: loss = 2.0765\n",
      "Iteration 82520: loss = 2.5069\n",
      "Iteration 82530: loss = 2.3649\n",
      "Iteration 82540: loss = 2.1123\n",
      "Iteration 82550: loss = 2.0874\n",
      "Iteration 82560: loss = 2.4530\n",
      "Iteration 82570: loss = 2.5764\n",
      "Iteration 82580: loss = 2.1139\n",
      "Iteration 82590: loss = 2.6664\n",
      "Iteration 82600: loss = 2.4642\n",
      "Iteration 82610: loss = 2.4620\n",
      "Iteration 82620: loss = 2.5300\n",
      "Iteration 82630: loss = 2.4721\n",
      "Iteration 82640: loss = 2.7464\n",
      "Iteration 82650: loss = 2.6200\n",
      "Iteration 82660: loss = 2.4626\n",
      "Iteration 82670: loss = 2.6055\n",
      "Iteration 82680: loss = 2.9013\n",
      "Iteration 82690: loss = 2.2950\n",
      "Iteration 82700: loss = 2.1793\n",
      "Iteration 82710: loss = 2.4049\n",
      "Iteration 82720: loss = 2.7669\n",
      "Iteration 82730: loss = 2.6823\n",
      "Iteration 82740: loss = 2.6316\n",
      "Iteration 82750: loss = 2.5927\n",
      "Iteration 82760: loss = 3.2403\n",
      "Iteration 82770: loss = 2.4648\n",
      "Iteration 82780: loss = 2.5481\n",
      "Iteration 82790: loss = 2.4214\n",
      "Iteration 82800: loss = 2.2018\n",
      "Iteration 82810: loss = 2.2545\n",
      "Iteration 82820: loss = 2.2554\n",
      "Iteration 82830: loss = 2.7645\n",
      "Iteration 82840: loss = 2.2705\n",
      "Iteration 82850: loss = 2.4321\n",
      "Iteration 82860: loss = 2.5829\n",
      "Iteration 82870: loss = 3.0944\n",
      "Iteration 82880: loss = 2.4122\n",
      "Iteration 82890: loss = 2.2136\n",
      "Iteration 82900: loss = 2.1518\n",
      "Iteration 82910: loss = 2.2805\n",
      "Iteration 82920: loss = 2.5370\n",
      "Iteration 82930: loss = 2.3836\n",
      "Iteration 82940: loss = 2.5247\n",
      "Iteration 82950: loss = 2.4621\n",
      "Iteration 82960: loss = 2.5902\n",
      "Iteration 82970: loss = 2.8810\n",
      "Iteration 82980: loss = 2.4835\n",
      "Iteration 82990: loss = 2.2663\n",
      "Iteration 83000: loss = 2.9181\n",
      "Iteration 83010: loss = 2.4292\n",
      "Iteration 83020: loss = 2.5685\n",
      "Iteration 83030: loss = 2.3015\n",
      "Iteration 83040: loss = 1.9755\n",
      "Iteration 83050: loss = 2.5752\n",
      "Iteration 83060: loss = 2.2557\n",
      "Iteration 83070: loss = 2.4029\n",
      "Iteration 83080: loss = 2.0846\n",
      "Iteration 83090: loss = 2.2700\n",
      "Iteration 83100: loss = 2.5348\n",
      "Iteration 83110: loss = 2.2530\n",
      "Iteration 83120: loss = 2.4711\n",
      "Iteration 83130: loss = 2.0341\n",
      "Iteration 83140: loss = 2.4407\n",
      "Iteration 83150: loss = 2.1365\n",
      "Iteration 83160: loss = 2.5049\n",
      "Iteration 83170: loss = 2.3898\n",
      "Iteration 83180: loss = 2.4489\n",
      "Iteration 83190: loss = 2.2535\n",
      "Iteration 83200: loss = 2.4606\n",
      "Iteration 83210: loss = 2.2092\n",
      "Iteration 83220: loss = 2.1624\n",
      "Iteration 83230: loss = 2.2177\n",
      "Iteration 83240: loss = 2.6382\n",
      "Iteration 83250: loss = 2.1556\n",
      "Iteration 83260: loss = 2.8164\n",
      "Iteration 83270: loss = 2.8258\n",
      "Iteration 83280: loss = 2.2129\n",
      "Iteration 83290: loss = 2.3029\n",
      "Iteration 83300: loss = 2.4630\n",
      "Iteration 83310: loss = 2.4341\n",
      "Iteration 83320: loss = 2.9169\n",
      "Iteration 83330: loss = 2.6758\n",
      "Iteration 83340: loss = 2.4910\n",
      "Iteration 83350: loss = 2.5555\n",
      "Iteration 83360: loss = 2.1204\n",
      "Iteration 83370: loss = 2.3964\n",
      "Iteration 83380: loss = 2.0789\n",
      "Iteration 83390: loss = 2.5981\n",
      "Iteration 83400: loss = 2.6552\n",
      "Iteration 83410: loss = 2.2713\n",
      "Iteration 83420: loss = 2.4211\n",
      "Iteration 83430: loss = 2.3572\n",
      "Iteration 83440: loss = 2.3446\n",
      "Iteration 83450: loss = 3.1014\n",
      "Iteration 83460: loss = 2.6791\n",
      "Iteration 83470: loss = 2.2184\n",
      "Iteration 83480: loss = 2.7910\n",
      "Iteration 83490: loss = 2.3970\n",
      "Iteration 83500: loss = 2.5298\n",
      "Iteration 83510: loss = 2.6591\n",
      "Iteration 83520: loss = 2.7257\n",
      "Iteration 83530: loss = 2.6330\n",
      "Iteration 83540: loss = 2.2264\n",
      "Iteration 83550: loss = 2.8312\n",
      "Iteration 83560: loss = 2.0647\n",
      "Iteration 83570: loss = 2.8244\n",
      "Iteration 83580: loss = 2.7535\n",
      "Iteration 83590: loss = 2.4155\n",
      "Iteration 83600: loss = 2.4687\n",
      "Iteration 83610: loss = 2.4127\n",
      "Iteration 83620: loss = 2.6920\n",
      "Iteration 83630: loss = 2.7532\n",
      "Iteration 83640: loss = 2.5045\n",
      "Iteration 83650: loss = 2.6499\n",
      "Iteration 83660: loss = 2.5007\n",
      "Iteration 83670: loss = 2.4258\n",
      "Iteration 83680: loss = 2.6506\n",
      "Iteration 83690: loss = 2.2285\n",
      "Iteration 83700: loss = 2.2043\n",
      "Iteration 83710: loss = 2.4899\n",
      "Iteration 83720: loss = 2.1031\n",
      "Iteration 83730: loss = 2.6379\n",
      "Iteration 83740: loss = 2.7486\n",
      "Iteration 83750: loss = 2.5748\n",
      "Iteration 83760: loss = 2.3397\n",
      "Iteration 83770: loss = 2.1473\n",
      "Iteration 83780: loss = 3.2448\n",
      "Iteration 83790: loss = 2.4296\n",
      "Iteration 83800: loss = 2.4434\n",
      "Iteration 83810: loss = 2.6495\n",
      "Iteration 83820: loss = 2.5592\n",
      "Iteration 83830: loss = 2.4009\n",
      "Iteration 83840: loss = 2.6166\n",
      "Iteration 83850: loss = 2.3615\n",
      "Iteration 83860: loss = 2.2492\n",
      "Iteration 83870: loss = 2.3758\n",
      "Iteration 83880: loss = 1.9679\n",
      "Iteration 83890: loss = 2.5658\n",
      "Iteration 83900: loss = 2.2003\n",
      "Iteration 83910: loss = 2.8120\n",
      "Iteration 83920: loss = 2.4550\n",
      "Iteration 83930: loss = 2.5130\n",
      "Iteration 83940: loss = 2.5478\n",
      "Iteration 83950: loss = 2.4439\n",
      "Iteration 83960: loss = 2.7511\n",
      "Iteration 83970: loss = 2.8139\n",
      "Iteration 83980: loss = 2.3489\n",
      "Iteration 83990: loss = 2.4535\n",
      "Iteration 84000: loss = 2.6811\n",
      "Iteration 84010: loss = 2.8378\n",
      "Iteration 84020: loss = 2.6648\n",
      "Iteration 84030: loss = 2.5855\n",
      "Iteration 84040: loss = 2.3077\n",
      "Iteration 84050: loss = 2.5220\n",
      "Iteration 84060: loss = 2.3359\n",
      "Iteration 84070: loss = 2.6654\n",
      "Iteration 84080: loss = 2.7668\n",
      "Iteration 84090: loss = 2.1457\n",
      "Iteration 84100: loss = 2.3085\n",
      "Iteration 84110: loss = 3.0496\n",
      "Iteration 84120: loss = 2.6539\n",
      "Iteration 84130: loss = 2.4817\n",
      "Iteration 84140: loss = 2.4475\n",
      "Iteration 84150: loss = 2.6013\n",
      "Iteration 84160: loss = 2.4315\n",
      "Iteration 84170: loss = 2.3527\n",
      "Iteration 84180: loss = 2.5408\n",
      "Iteration 84190: loss = 2.6976\n",
      "Iteration 84200: loss = 2.4541\n",
      "Iteration 84210: loss = 3.0004\n",
      "Iteration 84220: loss = 2.4452\n",
      "Iteration 84230: loss = 2.5908\n",
      "Iteration 84240: loss = 2.5051\n",
      "Iteration 84250: loss = 2.5251\n",
      "Iteration 84260: loss = 2.3718\n",
      "Iteration 84270: loss = 2.0864\n",
      "Iteration 84280: loss = 2.3030\n",
      "Iteration 84290: loss = 1.9987\n",
      "Iteration 84300: loss = 2.2850\n",
      "Iteration 84310: loss = 2.4259\n",
      "Iteration 84320: loss = 2.7834\n",
      "Iteration 84330: loss = 2.5270\n",
      "Iteration 84340: loss = 2.5966\n",
      "Iteration 84350: loss = 2.1373\n",
      "Iteration 84360: loss = 2.3507\n",
      "Iteration 84370: loss = 1.9596\n",
      "Iteration 84380: loss = 2.3442\n",
      "Iteration 84390: loss = 2.5200\n",
      "Iteration 84400: loss = 2.6350\n",
      "Iteration 84410: loss = 2.2246\n",
      "Iteration 84420: loss = 2.7143\n",
      "Iteration 84430: loss = 2.5509\n",
      "Iteration 84440: loss = 2.0761\n",
      "Iteration 84450: loss = 2.4181\n",
      "Iteration 84460: loss = 2.6432\n",
      "Iteration 84470: loss = 2.3608\n",
      "Iteration 84480: loss = 2.4685\n",
      "Iteration 84490: loss = 2.7834\n",
      "Iteration 84500: loss = 2.3368\n",
      "Iteration 84510: loss = 2.7377\n",
      "Iteration 84520: loss = 2.5328\n",
      "Iteration 84530: loss = 2.2370\n",
      "Iteration 84540: loss = 2.2807\n",
      "Iteration 84550: loss = 2.2802\n",
      "Iteration 84560: loss = 2.3640\n",
      "Iteration 84570: loss = 2.8672\n",
      "Iteration 84580: loss = 2.5625\n",
      "Iteration 84590: loss = 2.2180\n",
      "Iteration 84600: loss = 2.7398\n",
      "Iteration 84610: loss = 2.3049\n",
      "Iteration 84620: loss = 2.5284\n",
      "Iteration 84630: loss = 2.3523\n",
      "Iteration 84640: loss = 2.6321\n",
      "Iteration 84650: loss = 2.9835\n",
      "Iteration 84660: loss = 2.5327\n",
      "Iteration 84670: loss = 2.4320\n",
      "Iteration 84680: loss = 2.1639\n",
      "Iteration 84690: loss = 2.5288\n",
      "Iteration 84700: loss = 2.7886\n",
      "Iteration 84710: loss = 2.8368\n",
      "Iteration 84720: loss = 2.4260\n",
      "Iteration 84730: loss = 2.5970\n",
      "Iteration 84740: loss = 2.0378\n",
      "Iteration 84750: loss = 2.5180\n",
      "Iteration 84760: loss = 2.3271\n",
      "Iteration 84770: loss = 1.8655\n",
      "Iteration 84780: loss = 2.1053\n",
      "Iteration 84790: loss = 2.2536\n",
      "Iteration 84800: loss = 2.5999\n",
      "Iteration 84810: loss = 2.6846\n",
      "Iteration 84820: loss = 2.4363\n",
      "Iteration 84830: loss = 1.9789\n",
      "Iteration 84840: loss = 2.3401\n",
      "Iteration 84850: loss = 2.7935\n",
      "Iteration 84860: loss = 2.5933\n",
      "Iteration 84870: loss = 2.2294\n",
      "Iteration 84880: loss = 2.5885\n",
      "Iteration 84890: loss = 2.1465\n",
      "Iteration 84900: loss = 2.3341\n",
      "Iteration 84910: loss = 2.1664\n",
      "Iteration 84920: loss = 2.7383\n",
      "Iteration 84930: loss = 2.1420\n",
      "Iteration 84940: loss = 2.2609\n",
      "Iteration 84950: loss = 2.2766\n",
      "Iteration 84960: loss = 2.3669\n",
      "Iteration 84970: loss = 2.5552\n",
      "Iteration 84980: loss = 2.2879\n",
      "Iteration 84990: loss = 2.5935\n",
      "Iteration 85000: loss = 2.4777\n",
      "Iteration 85010: loss = 2.2907\n",
      "Iteration 85020: loss = 2.5739\n",
      "Iteration 85030: loss = 3.1532\n",
      "Iteration 85040: loss = 2.6034\n",
      "Iteration 85050: loss = 2.2548\n",
      "Iteration 85060: loss = 2.5237\n",
      "Iteration 85070: loss = 2.6649\n",
      "Iteration 85080: loss = 2.3816\n",
      "Iteration 85090: loss = 2.7884\n",
      "Iteration 85100: loss = 1.9133\n",
      "Iteration 85110: loss = 2.6535\n",
      "Iteration 85120: loss = 2.3734\n",
      "Iteration 85130: loss = 2.4779\n",
      "Iteration 85140: loss = 2.3265\n",
      "Iteration 85150: loss = 2.6663\n",
      "Iteration 85160: loss = 2.3625\n",
      "Iteration 85170: loss = 2.3468\n",
      "Iteration 85180: loss = 2.4370\n",
      "Iteration 85190: loss = 2.9132\n",
      "Iteration 85200: loss = 2.0109\n",
      "Iteration 85210: loss = 2.5543\n",
      "Iteration 85220: loss = 2.1162\n",
      "Iteration 85230: loss = 2.4443\n",
      "Iteration 85240: loss = 2.4455\n",
      "Iteration 85250: loss = 2.2580\n",
      "Iteration 85260: loss = 2.5500\n",
      "Iteration 85270: loss = 2.3846\n",
      "Iteration 85280: loss = 2.4063\n",
      "Iteration 85290: loss = 2.7330\n",
      "Iteration 85300: loss = 2.6735\n",
      "Iteration 85310: loss = 2.2829\n",
      "Iteration 85320: loss = 1.9456\n",
      "Iteration 85330: loss = 2.4937\n",
      "Iteration 85340: loss = 2.5366\n",
      "Iteration 85350: loss = 2.9841\n",
      "Iteration 85360: loss = 2.4283\n",
      "Iteration 85370: loss = 2.4893\n",
      "Iteration 85380: loss = 1.9619\n",
      "Iteration 85390: loss = 2.6241\n",
      "Iteration 85400: loss = 2.1031\n",
      "Iteration 85410: loss = 2.5716\n",
      "Iteration 85420: loss = 2.4313\n",
      "Iteration 85430: loss = 2.6139\n",
      "Iteration 85440: loss = 2.3254\n",
      "Iteration 85450: loss = 2.5960\n",
      "Iteration 85460: loss = 2.3213\n",
      "Iteration 85470: loss = 2.1841\n",
      "Iteration 85480: loss = 2.2713\n",
      "Iteration 85490: loss = 2.3303\n",
      "Iteration 85500: loss = 2.4981\n",
      "Iteration 85510: loss = 2.6848\n",
      "Iteration 85520: loss = 2.7913\n",
      "Iteration 85530: loss = 2.4350\n",
      "Iteration 85540: loss = 2.4044\n",
      "Iteration 85550: loss = 2.5775\n",
      "Iteration 85560: loss = 2.2809\n",
      "Iteration 85570: loss = 2.5981\n",
      "Iteration 85580: loss = 2.3728\n",
      "Iteration 85590: loss = 2.3721\n",
      "Iteration 85600: loss = 2.7558\n",
      "Iteration 85610: loss = 2.2372\n",
      "Iteration 85620: loss = 2.4986\n",
      "Iteration 85630: loss = 2.4425\n",
      "Iteration 85640: loss = 2.4134\n",
      "Iteration 85650: loss = 2.7010\n",
      "Iteration 85660: loss = 2.4739\n",
      "Iteration 85670: loss = 2.0495\n",
      "Iteration 85680: loss = 2.3236\n",
      "Iteration 85690: loss = 2.2634\n",
      "Iteration 85700: loss = 2.5426\n",
      "Iteration 85710: loss = 2.7905\n",
      "Iteration 85720: loss = 2.5609\n",
      "Iteration 85730: loss = 2.7745\n",
      "Iteration 85740: loss = 1.9868\n",
      "Iteration 85750: loss = 2.7822\n",
      "Iteration 85760: loss = 3.0239\n",
      "Iteration 85770: loss = 1.9820\n",
      "Iteration 85780: loss = 2.6143\n",
      "Iteration 85790: loss = 2.3364\n",
      "Iteration 85800: loss = 2.4424\n",
      "Iteration 85810: loss = 2.8529\n",
      "Iteration 85820: loss = 2.8365\n",
      "Iteration 85830: loss = 2.6972\n",
      "Iteration 85840: loss = 2.2922\n",
      "Iteration 85850: loss = 2.5871\n",
      "Iteration 85860: loss = 2.7346\n",
      "Iteration 85870: loss = 2.7394\n",
      "Iteration 85880: loss = 2.1653\n",
      "Iteration 85890: loss = 2.1834\n",
      "Iteration 85900: loss = 2.3581\n",
      "Iteration 85910: loss = 2.7907\n",
      "Iteration 85920: loss = 2.3099\n",
      "Iteration 85930: loss = 2.0510\n",
      "Iteration 85940: loss = 2.3694\n",
      "Iteration 85950: loss = 2.3199\n",
      "Iteration 85960: loss = 2.5565\n",
      "Iteration 85970: loss = 2.3133\n",
      "Iteration 85980: loss = 2.5790\n",
      "Iteration 85990: loss = 2.4364\n",
      "Iteration 86000: loss = 2.6357\n",
      "Iteration 86010: loss = 2.6119\n",
      "Iteration 86020: loss = 2.2184\n",
      "Iteration 86030: loss = 2.4092\n",
      "Iteration 86040: loss = 2.1748\n",
      "Iteration 86050: loss = 2.4485\n",
      "Iteration 86060: loss = 2.2968\n",
      "Iteration 86070: loss = 3.0475\n",
      "Iteration 86080: loss = 2.3118\n",
      "Iteration 86090: loss = 2.6887\n",
      "Iteration 86100: loss = 2.5433\n",
      "Iteration 86110: loss = 2.3151\n",
      "Iteration 86120: loss = 2.6071\n",
      "Iteration 86130: loss = 2.5710\n",
      "Iteration 86140: loss = 2.2003\n",
      "Iteration 86150: loss = 2.3516\n",
      "Iteration 86160: loss = 2.1646\n",
      "Iteration 86170: loss = 2.4803\n",
      "Iteration 86180: loss = 2.3638\n",
      "Iteration 86190: loss = 2.6700\n",
      "Iteration 86200: loss = 2.4102\n",
      "Iteration 86210: loss = 2.3648\n",
      "Iteration 86220: loss = 2.4860\n",
      "Iteration 86230: loss = 2.4031\n",
      "Iteration 86240: loss = 2.2445\n",
      "Iteration 86250: loss = 2.5755\n",
      "Iteration 86260: loss = 2.4266\n",
      "Iteration 86270: loss = 2.4345\n",
      "Iteration 86280: loss = 2.4580\n",
      "Iteration 86290: loss = 2.3027\n",
      "Iteration 86300: loss = 2.3845\n",
      "Iteration 86310: loss = 2.3454\n",
      "Iteration 86320: loss = 2.3307\n",
      "Iteration 86330: loss = 2.3952\n",
      "Iteration 86340: loss = 2.5754\n",
      "Iteration 86350: loss = 2.4859\n",
      "Iteration 86360: loss = 2.4888\n",
      "Iteration 86370: loss = 2.2812\n",
      "Iteration 86380: loss = 2.0817\n",
      "Iteration 86390: loss = 2.5192\n",
      "Iteration 86400: loss = 2.7849\n",
      "Iteration 86410: loss = 2.3542\n",
      "Iteration 86420: loss = 2.5004\n",
      "Iteration 86430: loss = 2.3424\n",
      "Iteration 86440: loss = 2.7098\n",
      "Iteration 86450: loss = 2.2975\n",
      "Iteration 86460: loss = 2.7455\n",
      "Iteration 86470: loss = 2.9491\n",
      "Iteration 86480: loss = 2.6936\n",
      "Iteration 86490: loss = 2.3947\n",
      "Iteration 86500: loss = 1.6766\n",
      "Iteration 86510: loss = 2.4988\n",
      "Iteration 86520: loss = 2.6778\n",
      "Iteration 86530: loss = 2.6269\n",
      "Iteration 86540: loss = 2.5961\n",
      "Iteration 86550: loss = 2.6119\n",
      "Iteration 86560: loss = 2.3499\n",
      "Iteration 86570: loss = 2.4965\n",
      "Iteration 86580: loss = 2.3553\n",
      "Iteration 86590: loss = 2.6027\n",
      "Iteration 86600: loss = 2.9751\n",
      "Iteration 86610: loss = 2.3385\n",
      "Iteration 86620: loss = 2.3619\n",
      "Iteration 86630: loss = 2.5313\n",
      "Iteration 86640: loss = 2.1309\n",
      "Iteration 86650: loss = 2.7651\n",
      "Iteration 86660: loss = 2.0688\n",
      "Iteration 86670: loss = 2.6108\n",
      "Iteration 86680: loss = 2.4630\n",
      "Iteration 86690: loss = 2.4525\n",
      "Iteration 86700: loss = 2.4907\n",
      "Iteration 86710: loss = 2.4861\n",
      "Iteration 86720: loss = 2.6998\n",
      "Iteration 86730: loss = 2.4691\n",
      "Iteration 86740: loss = 2.2793\n",
      "Iteration 86750: loss = 2.7259\n",
      "Iteration 86760: loss = 2.3779\n",
      "Iteration 86770: loss = 2.3871\n",
      "Iteration 86780: loss = 2.2923\n",
      "Iteration 86790: loss = 2.7067\n",
      "Iteration 86800: loss = 2.4529\n",
      "Iteration 86810: loss = 2.4135\n",
      "Iteration 86820: loss = 2.1781\n",
      "Iteration 86830: loss = 2.4522\n",
      "Iteration 86840: loss = 2.2962\n",
      "Iteration 86850: loss = 2.1040\n",
      "Iteration 86860: loss = 2.1035\n",
      "Iteration 86870: loss = 2.2923\n",
      "Iteration 86880: loss = 2.3909\n",
      "Iteration 86890: loss = 2.2683\n",
      "Iteration 86900: loss = 2.5484\n",
      "Iteration 86910: loss = 2.6604\n",
      "Iteration 86920: loss = 2.6469\n",
      "Iteration 86930: loss = 2.4649\n",
      "Iteration 86940: loss = 2.3781\n",
      "Iteration 86950: loss = 2.1316\n",
      "Iteration 86960: loss = 2.6277\n",
      "Iteration 86970: loss = 2.2690\n",
      "Iteration 86980: loss = 2.3160\n",
      "Iteration 86990: loss = 2.3739\n",
      "Iteration 87000: loss = 2.2027\n",
      "Iteration 87010: loss = 2.5965\n",
      "Iteration 87020: loss = 2.5946\n",
      "Iteration 87030: loss = 2.4896\n",
      "Iteration 87040: loss = 2.3837\n",
      "Iteration 87050: loss = 2.3831\n",
      "Iteration 87060: loss = 2.6655\n",
      "Iteration 87070: loss = 2.7819\n",
      "Iteration 87080: loss = 2.1155\n",
      "Iteration 87090: loss = 2.4971\n",
      "Iteration 87100: loss = 2.3765\n",
      "Iteration 87110: loss = 2.5842\n",
      "Iteration 87120: loss = 2.5550\n",
      "Iteration 87130: loss = 2.3498\n",
      "Iteration 87140: loss = 2.3207\n",
      "Iteration 87150: loss = 2.1824\n",
      "Iteration 87160: loss = 2.7564\n",
      "Iteration 87170: loss = 2.6682\n",
      "Iteration 87180: loss = 2.2901\n",
      "Iteration 87190: loss = 2.6340\n",
      "Iteration 87200: loss = 2.4353\n",
      "Iteration 87210: loss = 2.1438\n",
      "Iteration 87220: loss = 2.4246\n",
      "Iteration 87230: loss = 2.5478\n",
      "Iteration 87240: loss = 2.0655\n",
      "Iteration 87250: loss = 2.6483\n",
      "Iteration 87260: loss = 2.1223\n",
      "Iteration 87270: loss = 2.7236\n",
      "Iteration 87280: loss = 2.1862\n",
      "Iteration 87290: loss = 1.9881\n",
      "Iteration 87300: loss = 2.7504\n",
      "Iteration 87310: loss = 2.1784\n",
      "Iteration 87320: loss = 2.5331\n",
      "Iteration 87330: loss = 2.7064\n",
      "Iteration 87340: loss = 2.4296\n",
      "Iteration 87350: loss = 3.0031\n",
      "Iteration 87360: loss = 2.3881\n",
      "Iteration 87370: loss = 2.5267\n",
      "Iteration 87380: loss = 2.4683\n",
      "Iteration 87390: loss = 2.4072\n",
      "Iteration 87400: loss = 2.3774\n",
      "Iteration 87410: loss = 2.1528\n",
      "Iteration 87420: loss = 2.7487\n",
      "Iteration 87430: loss = 2.3305\n",
      "Iteration 87440: loss = 2.1779\n",
      "Iteration 87450: loss = 2.4831\n",
      "Iteration 87460: loss = 2.3612\n",
      "Iteration 87470: loss = 2.1550\n",
      "Iteration 87480: loss = 2.3814\n",
      "Iteration 87490: loss = 2.4741\n",
      "Iteration 87500: loss = 2.9243\n",
      "Iteration 87510: loss = 2.5569\n",
      "Iteration 87520: loss = 2.3469\n",
      "Iteration 87530: loss = 2.7204\n",
      "Iteration 87540: loss = 2.5768\n",
      "Iteration 87550: loss = 2.5917\n",
      "Iteration 87560: loss = 2.4110\n",
      "Iteration 87570: loss = 2.3290\n",
      "Iteration 87580: loss = 2.6854\n",
      "Iteration 87590: loss = 2.4254\n",
      "Iteration 87600: loss = 2.3731\n",
      "Iteration 87610: loss = 2.4592\n",
      "Iteration 87620: loss = 2.4758\n",
      "Iteration 87630: loss = 2.2715\n",
      "Iteration 87640: loss = 2.6769\n",
      "Iteration 87650: loss = 2.0921\n",
      "Iteration 87660: loss = 2.6333\n",
      "Iteration 87670: loss = 2.4384\n",
      "Iteration 87680: loss = 2.4911\n",
      "Iteration 87690: loss = 2.5537\n",
      "Iteration 87700: loss = 2.1396\n",
      "Iteration 87710: loss = 2.3724\n",
      "Iteration 87720: loss = 2.4818\n",
      "Iteration 87730: loss = 2.4833\n",
      "Iteration 87740: loss = 2.4319\n",
      "Iteration 87750: loss = 2.2360\n",
      "Iteration 87760: loss = 2.3201\n",
      "Iteration 87770: loss = 2.6237\n",
      "Iteration 87780: loss = 1.9957\n",
      "Iteration 87790: loss = 2.2903\n",
      "Iteration 87800: loss = 2.1751\n",
      "Iteration 87810: loss = 2.3164\n",
      "Iteration 87820: loss = 2.0862\n",
      "Iteration 87830: loss = 2.2295\n",
      "Iteration 87840: loss = 2.2033\n",
      "Iteration 87850: loss = 2.6878\n",
      "Iteration 87860: loss = 2.6681\n",
      "Iteration 87870: loss = 2.2697\n",
      "Iteration 87880: loss = 2.9585\n",
      "Iteration 87890: loss = 2.6558\n",
      "Iteration 87900: loss = 2.6573\n",
      "Iteration 87910: loss = 2.5190\n",
      "Iteration 87920: loss = 2.5036\n",
      "Iteration 87930: loss = 2.3114\n",
      "Iteration 87940: loss = 2.4960\n",
      "Iteration 87950: loss = 2.4938\n",
      "Iteration 87960: loss = 2.9159\n",
      "Iteration 87970: loss = 2.1909\n",
      "Iteration 87980: loss = 2.3092\n",
      "Iteration 87990: loss = 2.1908\n",
      "Iteration 88000: loss = 2.6251\n",
      "Iteration 88010: loss = 2.3222\n",
      "Iteration 88020: loss = 2.6215\n",
      "Iteration 88030: loss = 2.4418\n",
      "Iteration 88040: loss = 2.6309\n",
      "Iteration 88050: loss = 2.8064\n",
      "Iteration 88060: loss = 2.4622\n",
      "Iteration 88070: loss = 2.2545\n",
      "Iteration 88080: loss = 2.5457\n",
      "Iteration 88090: loss = 2.1909\n",
      "Iteration 88100: loss = 2.2058\n",
      "Iteration 88110: loss = 2.7628\n",
      "Iteration 88120: loss = 2.4232\n",
      "Iteration 88130: loss = 2.4099\n",
      "Iteration 88140: loss = 2.4139\n",
      "Iteration 88150: loss = 2.6682\n",
      "Iteration 88160: loss = 2.6569\n",
      "Iteration 88170: loss = 2.3698\n",
      "Iteration 88180: loss = 2.1331\n",
      "Iteration 88190: loss = 2.4279\n",
      "Iteration 88200: loss = 2.5618\n",
      "Iteration 88210: loss = 2.7127\n",
      "Iteration 88220: loss = 3.0168\n",
      "Iteration 88230: loss = 2.3915\n",
      "Iteration 88240: loss = 2.5468\n",
      "Iteration 88250: loss = 2.6159\n",
      "Iteration 88260: loss = 2.3993\n",
      "Iteration 88270: loss = 2.5179\n",
      "Iteration 88280: loss = 2.3933\n",
      "Iteration 88290: loss = 2.6629\n",
      "Iteration 88300: loss = 2.4978\n",
      "Iteration 88310: loss = 2.5765\n",
      "Iteration 88320: loss = 2.3833\n",
      "Iteration 88330: loss = 2.4344\n",
      "Iteration 88340: loss = 2.5072\n",
      "Iteration 88350: loss = 2.3078\n",
      "Iteration 88360: loss = 2.5253\n",
      "Iteration 88370: loss = 2.4629\n",
      "Iteration 88380: loss = 2.2202\n",
      "Iteration 88390: loss = 2.2546\n",
      "Iteration 88400: loss = 2.7210\n",
      "Iteration 88410: loss = 2.3848\n",
      "Iteration 88420: loss = 2.6795\n",
      "Iteration 88430: loss = 2.7194\n",
      "Iteration 88440: loss = 2.4046\n",
      "Iteration 88450: loss = 2.6798\n",
      "Iteration 88460: loss = 2.3954\n",
      "Iteration 88470: loss = 2.5590\n",
      "Iteration 88480: loss = 2.5527\n",
      "Iteration 88490: loss = 2.4325\n",
      "Iteration 88500: loss = 2.2238\n",
      "Iteration 88510: loss = 2.3388\n",
      "Iteration 88520: loss = 2.6157\n",
      "Iteration 88530: loss = 2.2884\n",
      "Iteration 88540: loss = 2.3636\n",
      "Iteration 88550: loss = 2.3302\n",
      "Iteration 88560: loss = 2.6492\n",
      "Iteration 88570: loss = 2.4321\n",
      "Iteration 88580: loss = 2.5143\n",
      "Iteration 88590: loss = 2.8082\n",
      "Iteration 88600: loss = 2.4007\n",
      "Iteration 88610: loss = 2.2533\n",
      "Iteration 88620: loss = 2.2530\n",
      "Iteration 88630: loss = 2.5943\n",
      "Iteration 88640: loss = 2.3418\n",
      "Iteration 88650: loss = 2.2866\n",
      "Iteration 88660: loss = 2.2527\n",
      "Iteration 88670: loss = 2.3055\n",
      "Iteration 88680: loss = 2.4238\n",
      "Iteration 88690: loss = 2.5264\n",
      "Iteration 88700: loss = 2.1841\n",
      "Iteration 88710: loss = 2.7894\n",
      "Iteration 88720: loss = 2.6544\n",
      "Iteration 88730: loss = 2.5409\n",
      "Iteration 88740: loss = 2.1067\n",
      "Iteration 88750: loss = 2.4627\n",
      "Iteration 88760: loss = 2.2046\n",
      "Iteration 88770: loss = 2.2357\n",
      "Iteration 88780: loss = 2.3918\n",
      "Iteration 88790: loss = 2.3194\n",
      "Iteration 88800: loss = 2.5325\n",
      "Iteration 88810: loss = 2.3755\n",
      "Iteration 88820: loss = 2.1934\n",
      "Iteration 88830: loss = 2.4886\n",
      "Iteration 88840: loss = 2.3980\n",
      "Iteration 88850: loss = 2.4518\n",
      "Iteration 88860: loss = 2.2315\n",
      "Iteration 88870: loss = 2.4388\n",
      "Iteration 88880: loss = 2.5244\n",
      "Iteration 88890: loss = 2.7332\n",
      "Iteration 88900: loss = 2.2576\n",
      "Iteration 88910: loss = 2.4755\n",
      "Iteration 88920: loss = 2.1516\n",
      "Iteration 88930: loss = 2.4207\n",
      "Iteration 88940: loss = 2.4835\n",
      "Iteration 88950: loss = 2.0624\n",
      "Iteration 88960: loss = 2.3985\n",
      "Iteration 88970: loss = 2.7515\n",
      "Iteration 88980: loss = 2.7250\n",
      "Iteration 88990: loss = 2.6837\n",
      "Iteration 89000: loss = 2.8344\n",
      "Iteration 89010: loss = 2.5108\n",
      "Iteration 89020: loss = 2.4581\n",
      "Iteration 89030: loss = 2.0753\n",
      "Iteration 89040: loss = 2.2222\n",
      "Iteration 89050: loss = 2.2485\n",
      "Iteration 89060: loss = 2.3555\n",
      "Iteration 89070: loss = 2.4292\n",
      "Iteration 89080: loss = 2.3762\n",
      "Iteration 89090: loss = 2.5399\n",
      "Iteration 89100: loss = 2.6078\n",
      "Iteration 89110: loss = 1.9770\n",
      "Iteration 89120: loss = 2.4197\n",
      "Iteration 89130: loss = 2.0242\n",
      "Iteration 89140: loss = 2.5580\n",
      "Iteration 89150: loss = 2.5714\n",
      "Iteration 89160: loss = 2.6780\n",
      "Iteration 89170: loss = 2.2366\n",
      "Iteration 89180: loss = 3.0470\n",
      "Iteration 89190: loss = 2.3680\n",
      "Iteration 89200: loss = 2.4823\n",
      "Iteration 89210: loss = 2.8240\n",
      "Iteration 89220: loss = 2.6665\n",
      "Iteration 89230: loss = 2.3857\n",
      "Iteration 89240: loss = 2.5905\n",
      "Iteration 89250: loss = 2.4893\n",
      "Iteration 89260: loss = 2.2713\n",
      "Iteration 89270: loss = 2.0895\n",
      "Iteration 89280: loss = 2.6200\n",
      "Iteration 89290: loss = 2.7016\n",
      "Iteration 89300: loss = 2.1655\n",
      "Iteration 89310: loss = 2.9338\n",
      "Iteration 89320: loss = 2.7763\n",
      "Iteration 89330: loss = 2.3878\n",
      "Iteration 89340: loss = 3.1092\n",
      "Iteration 89350: loss = 2.0430\n",
      "Iteration 89360: loss = 2.2410\n",
      "Iteration 89370: loss = 2.3090\n",
      "Iteration 89380: loss = 2.6308\n",
      "Iteration 89390: loss = 2.2899\n",
      "Iteration 89400: loss = 2.3606\n",
      "Iteration 89410: loss = 2.5983\n",
      "Iteration 89420: loss = 2.4331\n",
      "Iteration 89430: loss = 2.4576\n",
      "Iteration 89440: loss = 2.1437\n",
      "Iteration 89450: loss = 2.5232\n",
      "Iteration 89460: loss = 2.7527\n",
      "Iteration 89470: loss = 2.4895\n",
      "Iteration 89480: loss = 2.4959\n",
      "Iteration 89490: loss = 2.4493\n",
      "Iteration 89500: loss = 2.2843\n",
      "Iteration 89510: loss = 2.1410\n",
      "Iteration 89520: loss = 2.3867\n",
      "Iteration 89530: loss = 2.5081\n",
      "Iteration 89540: loss = 2.8244\n",
      "Iteration 89550: loss = 2.6614\n",
      "Iteration 89560: loss = 2.7756\n",
      "Iteration 89570: loss = 2.5574\n",
      "Iteration 89580: loss = 2.4555\n",
      "Iteration 89590: loss = 2.3513\n",
      "Iteration 89600: loss = 2.5579\n",
      "Iteration 89610: loss = 2.4634\n",
      "Iteration 89620: loss = 2.4444\n",
      "Iteration 89630: loss = 2.5385\n",
      "Iteration 89640: loss = 2.1498\n",
      "Iteration 89650: loss = 2.6271\n",
      "Iteration 89660: loss = 2.7648\n",
      "Iteration 89670: loss = 2.6188\n",
      "Iteration 89680: loss = 2.3296\n",
      "Iteration 89690: loss = 2.8095\n",
      "Iteration 89700: loss = 2.7349\n",
      "Iteration 89710: loss = 2.6155\n",
      "Iteration 89720: loss = 2.2022\n",
      "Iteration 89730: loss = 2.4516\n",
      "Iteration 89740: loss = 2.5001\n",
      "Iteration 89750: loss = 2.5924\n",
      "Iteration 89760: loss = 2.4665\n",
      "Iteration 89770: loss = 2.4713\n",
      "Iteration 89780: loss = 2.2529\n",
      "Iteration 89790: loss = 2.2538\n",
      "Iteration 89800: loss = 2.7646\n",
      "Iteration 89810: loss = 2.1876\n",
      "Iteration 89820: loss = 2.7732\n",
      "Iteration 89830: loss = 2.3808\n",
      "Iteration 89840: loss = 2.5091\n",
      "Iteration 89850: loss = 2.4953\n",
      "Iteration 89860: loss = 2.8398\n",
      "Iteration 89870: loss = 2.4169\n",
      "Iteration 89880: loss = 2.0658\n",
      "Iteration 89890: loss = 2.0897\n",
      "Iteration 89900: loss = 2.4642\n",
      "Iteration 89910: loss = 2.7935\n",
      "Iteration 89920: loss = 2.3097\n",
      "Iteration 89930: loss = 2.3091\n",
      "Iteration 89940: loss = 2.5112\n",
      "Iteration 89950: loss = 2.7069\n",
      "Iteration 89960: loss = 2.2003\n",
      "Iteration 89970: loss = 2.4523\n",
      "Iteration 89980: loss = 2.4211\n",
      "Iteration 89990: loss = 2.4467\n",
      "Iteration 90000: loss = 2.5470\n",
      "Iteration 90010: loss = 2.4175\n",
      "Iteration 90020: loss = 2.6716\n",
      "Iteration 90030: loss = 2.2789\n",
      "Iteration 90040: loss = 2.3172\n",
      "Iteration 90050: loss = 2.4004\n",
      "Iteration 90060: loss = 2.2690\n",
      "Iteration 90070: loss = 2.2076\n",
      "Iteration 90080: loss = 2.8247\n",
      "Iteration 90090: loss = 2.4152\n",
      "Iteration 90100: loss = 2.2023\n",
      "Iteration 90110: loss = 2.3026\n",
      "Iteration 90120: loss = 2.1190\n",
      "Iteration 90130: loss = 2.4122\n",
      "Iteration 90140: loss = 2.0088\n",
      "Iteration 90150: loss = 2.1369\n",
      "Iteration 90160: loss = 2.5628\n",
      "Iteration 90170: loss = 2.0830\n",
      "Iteration 90180: loss = 2.5479\n",
      "Iteration 90190: loss = 2.7453\n",
      "Iteration 90200: loss = 2.4287\n",
      "Iteration 90210: loss = 2.5106\n",
      "Iteration 90220: loss = 2.7631\n",
      "Iteration 90230: loss = 2.3391\n",
      "Iteration 90240: loss = 2.3561\n",
      "Iteration 90250: loss = 2.3644\n",
      "Iteration 90260: loss = 2.6772\n",
      "Iteration 90270: loss = 2.3136\n",
      "Iteration 90280: loss = 2.3588\n",
      "Iteration 90290: loss = 2.5741\n",
      "Iteration 90300: loss = 2.8148\n",
      "Iteration 90310: loss = 2.7008\n",
      "Iteration 90320: loss = 2.5427\n",
      "Iteration 90330: loss = 2.8120\n",
      "Iteration 90340: loss = 2.5666\n",
      "Iteration 90350: loss = 2.3479\n",
      "Iteration 90360: loss = 2.2167\n",
      "Iteration 90370: loss = 2.5150\n",
      "Iteration 90380: loss = 2.3865\n",
      "Iteration 90390: loss = 2.6156\n",
      "Iteration 90400: loss = 2.5986\n",
      "Iteration 90410: loss = 2.6117\n",
      "Iteration 90420: loss = 2.8785\n",
      "Iteration 90430: loss = 2.6327\n",
      "Iteration 90440: loss = 2.7571\n",
      "Iteration 90450: loss = 2.3920\n",
      "Iteration 90460: loss = 2.4850\n",
      "Iteration 90470: loss = 1.9792\n",
      "Iteration 90480: loss = 2.3201\n",
      "Iteration 90490: loss = 2.4174\n",
      "Iteration 90500: loss = 2.3430\n",
      "Iteration 90510: loss = 2.0541\n",
      "Iteration 90520: loss = 2.6810\n",
      "Iteration 90530: loss = 2.2954\n",
      "Iteration 90540: loss = 2.6093\n",
      "Iteration 90550: loss = 2.0978\n",
      "Iteration 90560: loss = 2.0753\n",
      "Iteration 90570: loss = 2.4263\n",
      "Iteration 90580: loss = 2.7259\n",
      "Iteration 90590: loss = 2.3142\n",
      "Iteration 90600: loss = 2.3538\n",
      "Iteration 90610: loss = 2.2934\n",
      "Iteration 90620: loss = 2.9815\n",
      "Iteration 90630: loss = 2.3763\n",
      "Iteration 90640: loss = 2.7131\n",
      "Iteration 90650: loss = 2.6293\n",
      "Iteration 90660: loss = 2.1943\n",
      "Iteration 90670: loss = 2.8676\n",
      "Iteration 90680: loss = 2.3567\n",
      "Iteration 90690: loss = 2.4183\n",
      "Iteration 90700: loss = 2.3285\n",
      "Iteration 90710: loss = 2.0184\n",
      "Iteration 90720: loss = 2.5234\n",
      "Iteration 90730: loss = 2.1916\n",
      "Iteration 90740: loss = 2.4333\n",
      "Iteration 90750: loss = 2.0196\n",
      "Iteration 90760: loss = 2.7052\n",
      "Iteration 90770: loss = 2.3914\n",
      "Iteration 90780: loss = 2.2833\n",
      "Iteration 90790: loss = 2.4179\n",
      "Iteration 90800: loss = 2.2097\n",
      "Iteration 90810: loss = 2.1763\n",
      "Iteration 90820: loss = 2.4930\n",
      "Iteration 90830: loss = 2.5345\n",
      "Iteration 90840: loss = 2.1965\n",
      "Iteration 90850: loss = 2.1786\n",
      "Iteration 90860: loss = 2.2573\n",
      "Iteration 90870: loss = 2.4929\n",
      "Iteration 90880: loss = 2.4690\n",
      "Iteration 90890: loss = 2.4056\n",
      "Iteration 90900: loss = 2.2554\n",
      "Iteration 90910: loss = 2.3206\n",
      "Iteration 90920: loss = 3.0441\n",
      "Iteration 90930: loss = 2.3692\n",
      "Iteration 90940: loss = 2.4781\n",
      "Iteration 90950: loss = 2.2924\n",
      "Iteration 90960: loss = 2.2779\n",
      "Iteration 90970: loss = 2.3802\n",
      "Iteration 90980: loss = 2.2566\n",
      "Iteration 90990: loss = 2.4013\n",
      "Iteration 91000: loss = 2.6599\n",
      "Iteration 91010: loss = 2.5230\n",
      "Iteration 91020: loss = 2.6705\n",
      "Iteration 91030: loss = 2.5935\n",
      "Iteration 91040: loss = 2.4209\n",
      "Iteration 91050: loss = 2.3079\n",
      "Iteration 91060: loss = 2.2165\n",
      "Iteration 91070: loss = 2.3261\n",
      "Iteration 91080: loss = 2.2414\n",
      "Iteration 91090: loss = 2.1513\n",
      "Iteration 91100: loss = 2.1831\n",
      "Iteration 91110: loss = 2.1458\n",
      "Iteration 91120: loss = 2.5714\n",
      "Iteration 91130: loss = 1.9468\n",
      "Iteration 91140: loss = 2.7347\n",
      "Iteration 91150: loss = 2.5764\n",
      "Iteration 91160: loss = 2.3369\n",
      "Iteration 91170: loss = 2.1544\n",
      "Iteration 91180: loss = 2.2441\n",
      "Iteration 91190: loss = 2.1712\n",
      "Iteration 91200: loss = 2.4306\n",
      "Iteration 91210: loss = 2.4373\n",
      "Iteration 91220: loss = 2.2098\n",
      "Iteration 91230: loss = 2.6567\n",
      "Iteration 91240: loss = 2.5902\n",
      "Iteration 91250: loss = 2.4839\n",
      "Iteration 91260: loss = 2.5087\n",
      "Iteration 91270: loss = 2.4614\n",
      "Iteration 91280: loss = 1.9838\n",
      "Iteration 91290: loss = 2.3298\n",
      "Iteration 91300: loss = 2.2186\n",
      "Iteration 91310: loss = 2.5496\n",
      "Iteration 91320: loss = 2.6919\n",
      "Iteration 91330: loss = 2.6957\n",
      "Iteration 91340: loss = 2.2843\n",
      "Iteration 91350: loss = 2.6166\n",
      "Iteration 91360: loss = 2.4195\n",
      "Iteration 91370: loss = 2.6736\n",
      "Iteration 91380: loss = 2.4598\n",
      "Iteration 91390: loss = 2.1451\n",
      "Iteration 91400: loss = 2.3558\n",
      "Iteration 91410: loss = 2.2618\n",
      "Iteration 91420: loss = 2.3122\n",
      "Iteration 91430: loss = 2.2385\n",
      "Iteration 91440: loss = 2.4637\n",
      "Iteration 91450: loss = 2.4845\n",
      "Iteration 91460: loss = 2.7404\n",
      "Iteration 91470: loss = 2.6591\n",
      "Iteration 91480: loss = 2.7285\n",
      "Iteration 91490: loss = 2.1172\n",
      "Iteration 91500: loss = 2.5470\n",
      "Iteration 91510: loss = 2.3333\n",
      "Iteration 91520: loss = 2.0606\n",
      "Iteration 91530: loss = 2.1730\n",
      "Iteration 91540: loss = 2.4551\n",
      "Iteration 91550: loss = 2.5441\n",
      "Iteration 91560: loss = 2.3253\n",
      "Iteration 91570: loss = 2.8246\n",
      "Iteration 91580: loss = 2.5779\n",
      "Iteration 91590: loss = 2.2996\n",
      "Iteration 91600: loss = 2.5374\n",
      "Iteration 91610: loss = 2.5608\n",
      "Iteration 91620: loss = 2.6149\n",
      "Iteration 91630: loss = 2.6634\n",
      "Iteration 91640: loss = 2.3416\n",
      "Iteration 91650: loss = 2.4734\n",
      "Iteration 91660: loss = 2.8235\n",
      "Iteration 91670: loss = 2.3826\n",
      "Iteration 91680: loss = 2.3751\n",
      "Iteration 91690: loss = 2.5054\n",
      "Iteration 91700: loss = 2.8376\n",
      "Iteration 91710: loss = 2.4612\n",
      "Iteration 91720: loss = 2.1689\n",
      "Iteration 91730: loss = 2.7940\n",
      "Iteration 91740: loss = 2.1845\n",
      "Iteration 91750: loss = 2.3858\n",
      "Iteration 91760: loss = 2.3890\n",
      "Iteration 91770: loss = 2.2478\n",
      "Iteration 91780: loss = 2.7609\n",
      "Iteration 91790: loss = 2.1145\n",
      "Iteration 91800: loss = 2.2024\n",
      "Iteration 91810: loss = 2.8919\n",
      "Iteration 91820: loss = 2.0858\n",
      "Iteration 91830: loss = 2.5534\n",
      "Iteration 91840: loss = 2.9684\n",
      "Iteration 91850: loss = 2.6359\n",
      "Iteration 91860: loss = 2.5309\n",
      "Iteration 91870: loss = 2.1672\n",
      "Iteration 91880: loss = 2.6816\n",
      "Iteration 91890: loss = 2.2885\n",
      "Iteration 91900: loss = 2.3781\n",
      "Iteration 91910: loss = 2.4553\n",
      "Iteration 91920: loss = 2.2240\n",
      "Iteration 91930: loss = 2.1731\n",
      "Iteration 91940: loss = 2.5412\n",
      "Iteration 91950: loss = 2.6067\n",
      "Iteration 91960: loss = 2.7111\n",
      "Iteration 91970: loss = 2.5526\n",
      "Iteration 91980: loss = 2.6035\n",
      "Iteration 91990: loss = 2.4790\n",
      "Iteration 92000: loss = 2.6653\n",
      "Iteration 92010: loss = 2.5405\n",
      "Iteration 92020: loss = 2.5688\n",
      "Iteration 92030: loss = 2.9346\n",
      "Iteration 92040: loss = 2.6826\n",
      "Iteration 92050: loss = 2.3052\n",
      "Iteration 92060: loss = 2.5333\n",
      "Iteration 92070: loss = 2.8037\n",
      "Iteration 92080: loss = 2.6967\n",
      "Iteration 92090: loss = 2.4202\n",
      "Iteration 92100: loss = 2.2369\n",
      "Iteration 92110: loss = 2.3178\n",
      "Iteration 92120: loss = 2.1016\n",
      "Iteration 92130: loss = 2.3508\n",
      "Iteration 92140: loss = 2.1788\n",
      "Iteration 92150: loss = 2.5048\n",
      "Iteration 92160: loss = 2.8619\n",
      "Iteration 92170: loss = 2.5140\n",
      "Iteration 92180: loss = 2.4684\n",
      "Iteration 92190: loss = 3.0266\n",
      "Iteration 92200: loss = 2.2799\n",
      "Iteration 92210: loss = 2.4698\n",
      "Iteration 92220: loss = 2.6456\n",
      "Iteration 92230: loss = 2.7405\n",
      "Iteration 92240: loss = 2.7977\n",
      "Iteration 92250: loss = 2.4493\n",
      "Iteration 92260: loss = 2.6095\n",
      "Iteration 92270: loss = 2.5389\n",
      "Iteration 92280: loss = 2.1649\n",
      "Iteration 92290: loss = 2.2642\n",
      "Iteration 92300: loss = 2.6492\n",
      "Iteration 92310: loss = 2.5927\n",
      "Iteration 92320: loss = 2.4829\n",
      "Iteration 92330: loss = 2.1983\n",
      "Iteration 92340: loss = 2.2579\n",
      "Iteration 92350: loss = 2.2100\n",
      "Iteration 92360: loss = 2.5617\n",
      "Iteration 92370: loss = 2.2477\n",
      "Iteration 92380: loss = 2.6704\n",
      "Iteration 92390: loss = 1.8757\n",
      "Iteration 92400: loss = 2.4763\n",
      "Iteration 92410: loss = 2.5413\n",
      "Iteration 92420: loss = 2.3270\n",
      "Iteration 92430: loss = 2.7551\n",
      "Iteration 92440: loss = 2.1326\n",
      "Iteration 92450: loss = 2.3618\n",
      "Iteration 92460: loss = 2.6847\n",
      "Iteration 92470: loss = 2.3668\n",
      "Iteration 92480: loss = 2.7535\n",
      "Iteration 92490: loss = 2.3222\n",
      "Iteration 92500: loss = 2.4867\n",
      "Iteration 92510: loss = 2.5412\n",
      "Iteration 92520: loss = 2.2496\n",
      "Iteration 92530: loss = 2.4043\n",
      "Iteration 92540: loss = 2.4906\n",
      "Iteration 92550: loss = 2.1121\n",
      "Iteration 92560: loss = 2.3205\n",
      "Iteration 92570: loss = 2.4382\n",
      "Iteration 92580: loss = 2.1839\n",
      "Iteration 92590: loss = 2.2639\n",
      "Iteration 92600: loss = 2.5462\n",
      "Iteration 92610: loss = 2.7402\n",
      "Iteration 92620: loss = 2.7021\n",
      "Iteration 92630: loss = 2.6466\n",
      "Iteration 92640: loss = 2.0570\n",
      "Iteration 92650: loss = 2.3670\n",
      "Iteration 92660: loss = 2.2068\n",
      "Iteration 92670: loss = 2.4846\n",
      "Iteration 92680: loss = 2.5895\n",
      "Iteration 92690: loss = 2.2372\n",
      "Iteration 92700: loss = 2.3653\n",
      "Iteration 92710: loss = 2.8000\n",
      "Iteration 92720: loss = 2.8565\n",
      "Iteration 92730: loss = 2.5171\n",
      "Iteration 92740: loss = 2.6210\n",
      "Iteration 92750: loss = 2.5644\n",
      "Iteration 92760: loss = 2.3514\n",
      "Iteration 92770: loss = 2.7001\n",
      "Iteration 92780: loss = 3.0542\n",
      "Iteration 92790: loss = 2.3801\n",
      "Iteration 92800: loss = 2.4560\n",
      "Iteration 92810: loss = 2.5346\n",
      "Iteration 92820: loss = 2.4803\n",
      "Iteration 92830: loss = 2.2520\n",
      "Iteration 92840: loss = 2.0988\n",
      "Iteration 92850: loss = 2.3281\n",
      "Iteration 92860: loss = 2.6957\n",
      "Iteration 92870: loss = 2.0848\n",
      "Iteration 92880: loss = 2.6297\n",
      "Iteration 92890: loss = 2.1080\n",
      "Iteration 92900: loss = 2.3341\n",
      "Iteration 92910: loss = 2.4550\n",
      "Iteration 92920: loss = 2.5742\n",
      "Iteration 92930: loss = 2.1497\n",
      "Iteration 92940: loss = 2.5634\n",
      "Iteration 92950: loss = 2.4639\n",
      "Iteration 92960: loss = 1.9218\n",
      "Iteration 92970: loss = 2.7195\n",
      "Iteration 92980: loss = 2.5482\n",
      "Iteration 92990: loss = 2.2772\n",
      "Iteration 93000: loss = 2.5022\n",
      "Iteration 93010: loss = 2.5400\n",
      "Iteration 93020: loss = 2.5695\n",
      "Iteration 93030: loss = 2.2926\n",
      "Iteration 93040: loss = 2.1884\n",
      "Iteration 93050: loss = 2.2596\n",
      "Iteration 93060: loss = 2.2991\n",
      "Iteration 93070: loss = 2.4063\n",
      "Iteration 93080: loss = 2.2971\n",
      "Iteration 93090: loss = 2.1198\n",
      "Iteration 93100: loss = 2.4465\n",
      "Iteration 93110: loss = 2.6046\n",
      "Iteration 93120: loss = 2.5827\n",
      "Iteration 93130: loss = 2.5484\n",
      "Iteration 93140: loss = 2.4101\n",
      "Iteration 93150: loss = 2.5660\n",
      "Iteration 93160: loss = 2.1354\n",
      "Iteration 93170: loss = 2.6050\n",
      "Iteration 93180: loss = 2.3353\n",
      "Iteration 93190: loss = 2.5670\n",
      "Iteration 93200: loss = 2.2417\n",
      "Iteration 93210: loss = 2.4340\n",
      "Iteration 93220: loss = 2.4769\n",
      "Iteration 93230: loss = 2.8515\n",
      "Iteration 93240: loss = 2.8612\n",
      "Iteration 93250: loss = 2.4713\n",
      "Iteration 93260: loss = 2.0027\n",
      "Iteration 93270: loss = 2.4984\n",
      "Iteration 93280: loss = 2.4756\n",
      "Iteration 93290: loss = 2.7341\n",
      "Iteration 93300: loss = 2.1943\n",
      "Iteration 93310: loss = 2.2761\n",
      "Iteration 93320: loss = 2.6760\n",
      "Iteration 93330: loss = 2.0603\n",
      "Iteration 93340: loss = 2.1617\n",
      "Iteration 93350: loss = 2.7237\n",
      "Iteration 93360: loss = 2.6392\n",
      "Iteration 93370: loss = 2.4407\n",
      "Iteration 93380: loss = 2.2999\n",
      "Iteration 93390: loss = 2.6213\n",
      "Iteration 93400: loss = 2.2049\n",
      "Iteration 93410: loss = 2.2785\n",
      "Iteration 93420: loss = 2.8047\n",
      "Iteration 93430: loss = 2.2611\n",
      "Iteration 93440: loss = 2.5865\n",
      "Iteration 93450: loss = 2.3964\n",
      "Iteration 93460: loss = 2.1806\n",
      "Iteration 93470: loss = 2.1974\n",
      "Iteration 93480: loss = 2.1422\n",
      "Iteration 93490: loss = 2.1565\n",
      "Iteration 93500: loss = 2.7368\n",
      "Iteration 93510: loss = 2.5400\n",
      "Iteration 93520: loss = 1.9801\n",
      "Iteration 93530: loss = 2.4687\n",
      "Iteration 93540: loss = 2.5882\n",
      "Iteration 93550: loss = 2.3809\n",
      "Iteration 93560: loss = 2.4175\n",
      "Iteration 93570: loss = 3.0867\n",
      "Iteration 93580: loss = 2.3164\n",
      "Iteration 93590: loss = 1.9964\n",
      "Iteration 93600: loss = 2.3534\n",
      "Iteration 93610: loss = 2.5672\n",
      "Iteration 93620: loss = 2.9422\n",
      "Iteration 93630: loss = 2.6381\n",
      "Iteration 93640: loss = 2.3999\n",
      "Iteration 93650: loss = 2.5920\n",
      "Iteration 93660: loss = 2.7361\n",
      "Iteration 93670: loss = 2.3766\n",
      "Iteration 93680: loss = 2.7497\n",
      "Iteration 93690: loss = 2.6011\n",
      "Iteration 93700: loss = 2.3549\n",
      "Iteration 93710: loss = 2.4842\n",
      "Iteration 93720: loss = 2.8365\n",
      "Iteration 93730: loss = 2.5984\n",
      "Iteration 93740: loss = 2.4811\n",
      "Iteration 93750: loss = 2.7092\n",
      "Iteration 93760: loss = 2.1914\n",
      "Iteration 93770: loss = 1.9215\n",
      "Iteration 93780: loss = 2.4845\n",
      "Iteration 93790: loss = 2.4060\n",
      "Iteration 93800: loss = 2.9304\n",
      "Iteration 93810: loss = 2.3911\n",
      "Iteration 93820: loss = 2.7901\n",
      "Iteration 93830: loss = 2.8120\n",
      "Iteration 93840: loss = 2.7014\n",
      "Iteration 93850: loss = 2.6825\n",
      "Iteration 93860: loss = 2.7568\n",
      "Iteration 93870: loss = 2.5902\n",
      "Iteration 93880: loss = 2.5636\n",
      "Iteration 93890: loss = 2.6344\n",
      "Iteration 93900: loss = 2.5313\n",
      "Iteration 93910: loss = 2.6527\n",
      "Iteration 93920: loss = 2.4036\n",
      "Iteration 93930: loss = 2.7549\n",
      "Iteration 93940: loss = 2.2446\n",
      "Iteration 93950: loss = 2.3729\n",
      "Iteration 93960: loss = 2.4768\n",
      "Iteration 93970: loss = 2.2444\n",
      "Iteration 93980: loss = 2.5282\n",
      "Iteration 93990: loss = 2.5146\n",
      "Iteration 94000: loss = 2.5643\n",
      "Iteration 94010: loss = 2.3498\n",
      "Iteration 94020: loss = 2.1424\n",
      "Iteration 94030: loss = 2.6006\n",
      "Iteration 94040: loss = 2.6619\n",
      "Iteration 94050: loss = 2.2526\n",
      "Iteration 94060: loss = 2.5831\n",
      "Iteration 94070: loss = 2.6891\n",
      "Iteration 94080: loss = 2.4444\n",
      "Iteration 94090: loss = 2.4046\n",
      "Iteration 94100: loss = 2.4599\n",
      "Iteration 94110: loss = 2.4707\n",
      "Iteration 94120: loss = 2.2596\n",
      "Iteration 94130: loss = 2.2061\n",
      "Iteration 94140: loss = 2.1013\n",
      "Iteration 94150: loss = 2.3664\n",
      "Iteration 94160: loss = 2.3457\n",
      "Iteration 94170: loss = 2.6374\n",
      "Iteration 94180: loss = 2.3335\n",
      "Iteration 94190: loss = 2.4311\n",
      "Iteration 94200: loss = 2.3535\n",
      "Iteration 94210: loss = 2.5525\n",
      "Iteration 94220: loss = 2.4161\n",
      "Iteration 94230: loss = 2.7263\n",
      "Iteration 94240: loss = 2.5513\n",
      "Iteration 94250: loss = 2.5792\n",
      "Iteration 94260: loss = 2.3892\n",
      "Iteration 94270: loss = 2.4515\n",
      "Iteration 94280: loss = 2.1775\n",
      "Iteration 94290: loss = 2.4082\n",
      "Iteration 94300: loss = 2.3532\n",
      "Iteration 94310: loss = 2.5577\n",
      "Iteration 94320: loss = 2.2265\n",
      "Iteration 94330: loss = 2.0324\n",
      "Iteration 94340: loss = 2.2708\n",
      "Iteration 94350: loss = 2.1515\n",
      "Iteration 94360: loss = 2.3042\n",
      "Iteration 94370: loss = 2.3969\n",
      "Iteration 94380: loss = 2.2925\n",
      "Iteration 94390: loss = 2.6482\n",
      "Iteration 94400: loss = 2.4265\n",
      "Iteration 94410: loss = 2.4662\n",
      "Iteration 94420: loss = 2.6061\n",
      "Iteration 94430: loss = 2.3820\n",
      "Iteration 94440: loss = 2.4402\n",
      "Iteration 94450: loss = 2.1797\n",
      "Iteration 94460: loss = 2.3102\n",
      "Iteration 94470: loss = 2.2700\n",
      "Iteration 94480: loss = 2.2191\n",
      "Iteration 94490: loss = 2.3659\n",
      "Iteration 94500: loss = 2.3348\n",
      "Iteration 94510: loss = 2.6880\n",
      "Iteration 94520: loss = 2.4038\n",
      "Iteration 94530: loss = 2.4942\n",
      "Iteration 94540: loss = 2.5304\n",
      "Iteration 94550: loss = 2.6249\n",
      "Iteration 94560: loss = 2.6406\n",
      "Iteration 94570: loss = 2.5221\n",
      "Iteration 94580: loss = 2.3749\n",
      "Iteration 94590: loss = 2.7277\n",
      "Iteration 94600: loss = 2.1524\n",
      "Iteration 94610: loss = 2.4074\n",
      "Iteration 94620: loss = 3.1447\n",
      "Iteration 94630: loss = 2.5133\n",
      "Iteration 94640: loss = 2.9349\n",
      "Iteration 94650: loss = 2.1974\n",
      "Iteration 94660: loss = 2.5030\n",
      "Iteration 94670: loss = 2.3960\n",
      "Iteration 94680: loss = 2.2417\n",
      "Iteration 94690: loss = 2.3802\n",
      "Iteration 94700: loss = 2.5841\n",
      "Iteration 94710: loss = 2.3222\n",
      "Iteration 94720: loss = 2.1339\n",
      "Iteration 94730: loss = 2.7948\n",
      "Iteration 94740: loss = 2.3602\n",
      "Iteration 94750: loss = 2.3052\n",
      "Iteration 94760: loss = 2.0150\n",
      "Iteration 94770: loss = 2.3172\n",
      "Iteration 94780: loss = 2.3345\n",
      "Iteration 94790: loss = 2.9342\n",
      "Iteration 94800: loss = 2.4762\n",
      "Iteration 94810: loss = 2.4762\n",
      "Iteration 94820: loss = 2.4323\n",
      "Iteration 94830: loss = 2.5506\n",
      "Iteration 94840: loss = 2.6203\n",
      "Iteration 94850: loss = 2.3378\n",
      "Iteration 94860: loss = 2.3669\n",
      "Iteration 94870: loss = 2.3765\n",
      "Iteration 94880: loss = 2.6290\n",
      "Iteration 94890: loss = 2.5754\n",
      "Iteration 94900: loss = 2.6767\n",
      "Iteration 94910: loss = 2.3717\n",
      "Iteration 94920: loss = 2.4112\n",
      "Iteration 94930: loss = 2.0692\n",
      "Iteration 94940: loss = 2.2364\n",
      "Iteration 94950: loss = 2.1416\n",
      "Iteration 94960: loss = 2.6690\n",
      "Iteration 94970: loss = 2.0553\n",
      "Iteration 94980: loss = 2.3231\n",
      "Iteration 94990: loss = 2.2663\n",
      "Iteration 95000: loss = 2.2659\n",
      "Iteration 95010: loss = 2.5121\n",
      "Iteration 95020: loss = 2.7278\n",
      "Iteration 95030: loss = 2.4295\n",
      "Iteration 95040: loss = 1.9388\n",
      "Iteration 95050: loss = 2.3133\n",
      "Iteration 95060: loss = 2.5900\n",
      "Iteration 95070: loss = 2.5747\n",
      "Iteration 95080: loss = 2.6480\n",
      "Iteration 95090: loss = 2.4502\n",
      "Iteration 95100: loss = 2.5304\n",
      "Iteration 95110: loss = 2.5234\n",
      "Iteration 95120: loss = 2.2804\n",
      "Iteration 95130: loss = 2.4892\n",
      "Iteration 95140: loss = 2.4546\n",
      "Iteration 95150: loss = 2.4640\n",
      "Iteration 95160: loss = 2.7759\n",
      "Iteration 95170: loss = 2.1838\n",
      "Iteration 95180: loss = 2.9550\n",
      "Iteration 95190: loss = 2.3349\n",
      "Iteration 95200: loss = 2.5129\n",
      "Iteration 95210: loss = 2.3379\n",
      "Iteration 95220: loss = 2.5429\n",
      "Iteration 95230: loss = 2.5089\n",
      "Iteration 95240: loss = 2.5777\n",
      "Iteration 95250: loss = 2.7332\n",
      "Iteration 95260: loss = 2.6769\n",
      "Iteration 95270: loss = 2.5390\n",
      "Iteration 95280: loss = 2.4690\n",
      "Iteration 95290: loss = 2.4516\n",
      "Iteration 95300: loss = 2.6482\n",
      "Iteration 95310: loss = 1.8962\n",
      "Iteration 95320: loss = 2.5343\n",
      "Iteration 95330: loss = 2.5438\n",
      "Iteration 95340: loss = 2.2913\n",
      "Iteration 95350: loss = 2.6080\n",
      "Iteration 95360: loss = 2.3362\n",
      "Iteration 95370: loss = 2.6117\n",
      "Iteration 95380: loss = 2.7619\n",
      "Iteration 95390: loss = 2.5252\n",
      "Iteration 95400: loss = 2.7138\n",
      "Iteration 95410: loss = 2.0117\n",
      "Iteration 95420: loss = 2.9258\n",
      "Iteration 95430: loss = 2.6345\n",
      "Iteration 95440: loss = 2.3081\n",
      "Iteration 95450: loss = 2.1828\n",
      "Iteration 95460: loss = 2.8892\n",
      "Iteration 95470: loss = 2.5304\n",
      "Iteration 95480: loss = 2.5710\n",
      "Iteration 95490: loss = 2.8282\n",
      "Iteration 95500: loss = 2.5102\n",
      "Iteration 95510: loss = 2.3846\n",
      "Iteration 95520: loss = 1.9988\n",
      "Iteration 95530: loss = 2.5832\n",
      "Iteration 95540: loss = 2.4602\n",
      "Iteration 95550: loss = 2.6288\n",
      "Iteration 95560: loss = 2.2182\n",
      "Iteration 95570: loss = 2.3280\n",
      "Iteration 95580: loss = 2.2501\n",
      "Iteration 95590: loss = 2.6018\n",
      "Iteration 95600: loss = 2.3958\n",
      "Iteration 95610: loss = 2.6866\n",
      "Iteration 95620: loss = 2.4183\n",
      "Iteration 95630: loss = 2.1610\n",
      "Iteration 95640: loss = 2.5935\n",
      "Iteration 95650: loss = 2.5765\n",
      "Iteration 95660: loss = 2.3839\n",
      "Iteration 95670: loss = 2.6911\n",
      "Iteration 95680: loss = 2.3046\n",
      "Iteration 95690: loss = 2.1966\n",
      "Iteration 95700: loss = 2.4536\n",
      "Iteration 95710: loss = 2.0523\n",
      "Iteration 95720: loss = 2.0271\n",
      "Iteration 95730: loss = 2.3923\n",
      "Iteration 95740: loss = 2.3252\n",
      "Iteration 95750: loss = 2.8018\n",
      "Iteration 95760: loss = 2.1403\n",
      "Iteration 95770: loss = 2.2942\n",
      "Iteration 95780: loss = 2.3792\n",
      "Iteration 95790: loss = 2.5947\n",
      "Iteration 95800: loss = 2.2699\n",
      "Iteration 95810: loss = 2.3987\n",
      "Iteration 95820: loss = 2.5941\n",
      "Iteration 95830: loss = 2.4313\n",
      "Iteration 95840: loss = 2.3114\n",
      "Iteration 95850: loss = 2.4877\n",
      "Iteration 95860: loss = 2.5008\n",
      "Iteration 95870: loss = 2.6214\n",
      "Iteration 95880: loss = 2.3874\n",
      "Iteration 95890: loss = 2.5090\n",
      "Iteration 95900: loss = 2.1686\n",
      "Iteration 95910: loss = 2.1779\n",
      "Iteration 95920: loss = 2.4294\n",
      "Iteration 95930: loss = 2.3992\n",
      "Iteration 95940: loss = 2.3471\n",
      "Iteration 95950: loss = 2.6254\n",
      "Iteration 95960: loss = 2.6969\n",
      "Iteration 95970: loss = 2.5867\n",
      "Iteration 95980: loss = 2.4101\n",
      "Iteration 95990: loss = 2.2936\n",
      "Iteration 96000: loss = 2.4857\n",
      "Iteration 96010: loss = 2.5707\n",
      "Iteration 96020: loss = 2.5383\n",
      "Iteration 96030: loss = 2.3904\n",
      "Iteration 96040: loss = 2.2079\n",
      "Iteration 96050: loss = 2.3235\n",
      "Iteration 96060: loss = 2.1756\n",
      "Iteration 96070: loss = 2.8466\n",
      "Iteration 96080: loss = 2.2663\n",
      "Iteration 96090: loss = 2.4287\n",
      "Iteration 96100: loss = 2.3352\n",
      "Iteration 96110: loss = 2.6184\n",
      "Iteration 96120: loss = 2.5145\n",
      "Iteration 96130: loss = 2.8020\n",
      "Iteration 96140: loss = 2.6930\n",
      "Iteration 96150: loss = 2.6094\n",
      "Iteration 96160: loss = 2.3764\n",
      "Iteration 96170: loss = 2.4317\n",
      "Iteration 96180: loss = 2.4757\n",
      "Iteration 96190: loss = 2.3720\n",
      "Iteration 96200: loss = 2.6424\n",
      "Iteration 96210: loss = 2.9433\n",
      "Iteration 96220: loss = 2.5897\n",
      "Iteration 96230: loss = 2.4298\n",
      "Iteration 96240: loss = 1.9881\n",
      "Iteration 96250: loss = 2.6219\n",
      "Iteration 96260: loss = 2.4624\n",
      "Iteration 96270: loss = 2.6443\n",
      "Iteration 96280: loss = 2.1925\n",
      "Iteration 96290: loss = 2.0611\n",
      "Iteration 96300: loss = 2.2077\n",
      "Iteration 96310: loss = 2.6042\n",
      "Iteration 96320: loss = 2.4960\n",
      "Iteration 96330: loss = 2.2934\n",
      "Iteration 96340: loss = 2.2065\n",
      "Iteration 96350: loss = 2.2695\n",
      "Iteration 96360: loss = 2.2102\n",
      "Iteration 96370: loss = 2.4772\n",
      "Iteration 96380: loss = 2.2113\n",
      "Iteration 96390: loss = 2.2313\n",
      "Iteration 96400: loss = 2.5570\n",
      "Iteration 96410: loss = 2.5232\n",
      "Iteration 96420: loss = 1.8862\n",
      "Iteration 96430: loss = 2.6854\n",
      "Iteration 96440: loss = 2.2975\n",
      "Iteration 96450: loss = 2.1982\n",
      "Iteration 96460: loss = 2.2416\n",
      "Iteration 96470: loss = 2.6552\n",
      "Iteration 96480: loss = 2.3171\n",
      "Iteration 96490: loss = 2.3996\n",
      "Iteration 96500: loss = 2.8877\n",
      "Iteration 96510: loss = 2.4099\n",
      "Iteration 96520: loss = 2.8674\n",
      "Iteration 96530: loss = 2.4402\n",
      "Iteration 96540: loss = 2.3800\n",
      "Iteration 96550: loss = 2.3952\n",
      "Iteration 96560: loss = 2.7215\n",
      "Iteration 96570: loss = 2.4323\n",
      "Iteration 96580: loss = 2.4153\n",
      "Iteration 96590: loss = 2.2150\n",
      "Iteration 96600: loss = 2.1748\n",
      "Iteration 96610: loss = 2.7477\n",
      "Iteration 96620: loss = 2.6940\n",
      "Iteration 96630: loss = 2.2204\n",
      "Iteration 96640: loss = 1.9932\n",
      "Iteration 96650: loss = 2.3982\n",
      "Iteration 96660: loss = 2.0891\n",
      "Iteration 96670: loss = 2.2983\n",
      "Iteration 96680: loss = 2.2418\n",
      "Iteration 96690: loss = 2.4088\n",
      "Iteration 96700: loss = 2.4131\n",
      "Iteration 96710: loss = 2.3163\n",
      "Iteration 96720: loss = 2.5193\n",
      "Iteration 96730: loss = 2.4901\n",
      "Iteration 96740: loss = 2.4480\n",
      "Iteration 96750: loss = 2.5460\n",
      "Iteration 96760: loss = 2.4646\n",
      "Iteration 96770: loss = 2.3796\n",
      "Iteration 96780: loss = 2.3725\n",
      "Iteration 96790: loss = 2.0588\n",
      "Iteration 96800: loss = 2.7217\n",
      "Iteration 96810: loss = 2.4323\n",
      "Iteration 96820: loss = 2.8768\n",
      "Iteration 96830: loss = 2.1028\n",
      "Iteration 96840: loss = 2.2059\n",
      "Iteration 96850: loss = 2.4502\n",
      "Iteration 96860: loss = 2.8357\n",
      "Iteration 96870: loss = 2.6185\n",
      "Iteration 96880: loss = 2.4577\n",
      "Iteration 96890: loss = 2.3962\n",
      "Iteration 96900: loss = 2.3964\n",
      "Iteration 96910: loss = 2.5317\n",
      "Iteration 96920: loss = 2.5107\n",
      "Iteration 96930: loss = 2.4703\n",
      "Iteration 96940: loss = 2.1475\n",
      "Iteration 96950: loss = 2.8101\n",
      "Iteration 96960: loss = 2.3438\n",
      "Iteration 96970: loss = 2.3496\n",
      "Iteration 96980: loss = 2.3049\n",
      "Iteration 96990: loss = 2.3630\n",
      "Iteration 97000: loss = 2.3275\n",
      "Iteration 97010: loss = 2.2993\n",
      "Iteration 97020: loss = 2.6873\n",
      "Iteration 97030: loss = 2.4039\n",
      "Iteration 97040: loss = 2.4458\n",
      "Iteration 97050: loss = 2.1712\n",
      "Iteration 97060: loss = 2.6069\n",
      "Iteration 97070: loss = 2.5299\n",
      "Iteration 97080: loss = 2.8842\n",
      "Iteration 97090: loss = 2.3569\n",
      "Iteration 97100: loss = 2.6191\n",
      "Iteration 97110: loss = 2.2878\n",
      "Iteration 97120: loss = 2.6491\n",
      "Iteration 97130: loss = 2.1798\n",
      "Iteration 97140: loss = 2.5286\n",
      "Iteration 97150: loss = 2.2786\n",
      "Iteration 97160: loss = 2.3453\n",
      "Iteration 97170: loss = 2.9453\n",
      "Iteration 97180: loss = 2.0782\n",
      "Iteration 97190: loss = 2.3255\n",
      "Iteration 97200: loss = 2.5499\n",
      "Iteration 97210: loss = 2.4781\n",
      "Iteration 97220: loss = 2.2778\n",
      "Iteration 97230: loss = 2.1629\n",
      "Iteration 97240: loss = 2.3793\n",
      "Iteration 97250: loss = 2.3152\n",
      "Iteration 97260: loss = 2.4727\n",
      "Iteration 97270: loss = 2.4938\n",
      "Iteration 97280: loss = 2.4469\n",
      "Iteration 97290: loss = 2.5054\n",
      "Iteration 97300: loss = 2.5000\n",
      "Iteration 97310: loss = 2.2165\n",
      "Iteration 97320: loss = 2.3063\n",
      "Iteration 97330: loss = 2.6203\n",
      "Iteration 97340: loss = 2.4709\n",
      "Iteration 97350: loss = 2.3876\n",
      "Iteration 97360: loss = 2.5669\n",
      "Iteration 97370: loss = 2.4758\n",
      "Iteration 97380: loss = 2.5615\n",
      "Iteration 97390: loss = 2.6470\n",
      "Iteration 97400: loss = 2.1957\n",
      "Iteration 97410: loss = 2.4849\n",
      "Iteration 97420: loss = 2.6383\n",
      "Iteration 97430: loss = 2.1409\n",
      "Iteration 97440: loss = 2.2796\n",
      "Iteration 97450: loss = 2.4815\n",
      "Iteration 97460: loss = 2.3740\n",
      "Iteration 97470: loss = 2.2960\n",
      "Iteration 97480: loss = 2.4689\n",
      "Iteration 97490: loss = 2.4722\n",
      "Iteration 97500: loss = 2.5474\n",
      "Iteration 97510: loss = 2.3931\n",
      "Iteration 97520: loss = 2.0214\n",
      "Iteration 97530: loss = 2.6179\n",
      "Iteration 97540: loss = 2.3407\n",
      "Iteration 97550: loss = 2.4456\n",
      "Iteration 97560: loss = 2.1742\n",
      "Iteration 97570: loss = 2.2606\n",
      "Iteration 97580: loss = 2.7022\n",
      "Iteration 97590: loss = 2.3448\n",
      "Iteration 97600: loss = 2.3889\n",
      "Iteration 97610: loss = 2.9573\n",
      "Iteration 97620: loss = 2.7469\n",
      "Iteration 97630: loss = 2.1717\n",
      "Iteration 97640: loss = 2.2817\n",
      "Iteration 97650: loss = 2.4089\n",
      "Iteration 97660: loss = 2.0830\n",
      "Iteration 97670: loss = 1.9526\n",
      "Iteration 97680: loss = 2.4315\n",
      "Iteration 97690: loss = 2.3464\n",
      "Iteration 97700: loss = 3.0183\n",
      "Iteration 97710: loss = 2.4672\n",
      "Iteration 97720: loss = 2.6545\n",
      "Iteration 97730: loss = 2.4719\n",
      "Iteration 97740: loss = 2.3033\n",
      "Iteration 97750: loss = 2.1579\n",
      "Iteration 97760: loss = 2.4726\n",
      "Iteration 97770: loss = 2.4813\n",
      "Iteration 97780: loss = 2.4791\n",
      "Iteration 97790: loss = 2.6942\n",
      "Iteration 97800: loss = 2.0809\n",
      "Iteration 97810: loss = 2.0991\n",
      "Iteration 97820: loss = 2.6801\n",
      "Iteration 97830: loss = 2.6085\n",
      "Iteration 97840: loss = 2.2352\n",
      "Iteration 97850: loss = 2.5095\n",
      "Iteration 97860: loss = 2.7300\n",
      "Iteration 97870: loss = 2.3697\n",
      "Iteration 97880: loss = 2.7270\n",
      "Iteration 97890: loss = 2.4987\n",
      "Iteration 97900: loss = 2.2127\n",
      "Iteration 97910: loss = 2.3639\n",
      "Iteration 97920: loss = 2.5082\n",
      "Iteration 97930: loss = 2.1757\n",
      "Iteration 97940: loss = 2.4161\n",
      "Iteration 97950: loss = 2.5164\n",
      "Iteration 97960: loss = 2.6754\n",
      "Iteration 97970: loss = 2.5341\n",
      "Iteration 97980: loss = 2.5536\n",
      "Iteration 97990: loss = 2.4242\n",
      "Iteration 98000: loss = 2.4367\n",
      "Iteration 98010: loss = 2.3776\n",
      "Iteration 98020: loss = 2.1469\n",
      "Iteration 98030: loss = 1.9903\n",
      "Iteration 98040: loss = 2.4336\n",
      "Iteration 98050: loss = 2.4728\n",
      "Iteration 98060: loss = 2.4293\n",
      "Iteration 98070: loss = 2.3769\n",
      "Iteration 98080: loss = 2.3644\n",
      "Iteration 98090: loss = 2.4746\n",
      "Iteration 98100: loss = 2.3811\n",
      "Iteration 98110: loss = 2.6145\n",
      "Iteration 98120: loss = 2.3378\n",
      "Iteration 98130: loss = 2.4268\n",
      "Iteration 98140: loss = 2.4833\n",
      "Iteration 98150: loss = 2.4448\n",
      "Iteration 98160: loss = 2.2933\n",
      "Iteration 98170: loss = 2.4893\n",
      "Iteration 98180: loss = 1.9680\n",
      "Iteration 98190: loss = 2.5277\n",
      "Iteration 98200: loss = 2.8960\n",
      "Iteration 98210: loss = 2.1357\n",
      "Iteration 98220: loss = 2.3291\n",
      "Iteration 98230: loss = 2.4309\n",
      "Iteration 98240: loss = 2.3448\n",
      "Iteration 98250: loss = 2.4352\n",
      "Iteration 98260: loss = 2.7870\n",
      "Iteration 98270: loss = 2.4710\n",
      "Iteration 98280: loss = 2.6551\n",
      "Iteration 98290: loss = 2.2733\n",
      "Iteration 98300: loss = 2.3528\n",
      "Iteration 98310: loss = 2.4040\n",
      "Iteration 98320: loss = 2.8068\n",
      "Iteration 98330: loss = 2.1593\n",
      "Iteration 98340: loss = 2.4765\n",
      "Iteration 98350: loss = 2.4149\n",
      "Iteration 98360: loss = 2.3714\n",
      "Iteration 98370: loss = 2.5206\n",
      "Iteration 98380: loss = 2.5482\n",
      "Iteration 98390: loss = 2.5169\n",
      "Iteration 98400: loss = 2.2665\n",
      "Iteration 98410: loss = 2.4493\n",
      "Iteration 98420: loss = 2.6406\n",
      "Iteration 98430: loss = 3.0373\n",
      "Iteration 98440: loss = 2.4929\n",
      "Iteration 98450: loss = 2.4443\n",
      "Iteration 98460: loss = 2.4132\n",
      "Iteration 98470: loss = 2.2025\n",
      "Iteration 98480: loss = 2.5876\n",
      "Iteration 98490: loss = 2.4311\n",
      "Iteration 98500: loss = 2.3935\n",
      "Iteration 98510: loss = 2.5770\n",
      "Iteration 98520: loss = 2.2734\n",
      "Iteration 98530: loss = 2.4263\n",
      "Iteration 98540: loss = 2.3087\n",
      "Iteration 98550: loss = 2.4702\n",
      "Iteration 98560: loss = 2.7117\n",
      "Iteration 98570: loss = 2.6864\n",
      "Iteration 98580: loss = 2.3813\n",
      "Iteration 98590: loss = 2.7076\n",
      "Iteration 98600: loss = 2.5266\n",
      "Iteration 98610: loss = 2.5646\n",
      "Iteration 98620: loss = 2.6242\n",
      "Iteration 98630: loss = 2.1358\n",
      "Iteration 98640: loss = 2.4118\n",
      "Iteration 98650: loss = 2.3617\n",
      "Iteration 98660: loss = 2.5364\n",
      "Iteration 98670: loss = 2.5945\n",
      "Iteration 98680: loss = 3.0063\n",
      "Iteration 98690: loss = 2.0509\n",
      "Iteration 98700: loss = 2.3303\n",
      "Iteration 98710: loss = 2.3434\n",
      "Iteration 98720: loss = 2.3079\n",
      "Iteration 98730: loss = 2.5991\n",
      "Iteration 98740: loss = 2.3293\n",
      "Iteration 98750: loss = 2.1818\n",
      "Iteration 98760: loss = 2.3341\n",
      "Iteration 98770: loss = 2.0370\n",
      "Iteration 98780: loss = 2.1787\n",
      "Iteration 98790: loss = 2.3109\n",
      "Iteration 98800: loss = 2.3546\n",
      "Iteration 98810: loss = 2.4568\n",
      "Iteration 98820: loss = 2.5031\n",
      "Iteration 98830: loss = 2.7929\n",
      "Iteration 98840: loss = 2.6682\n",
      "Iteration 98850: loss = 2.6781\n",
      "Iteration 98860: loss = 2.4824\n",
      "Iteration 98870: loss = 2.4042\n",
      "Iteration 98880: loss = 2.6299\n",
      "Iteration 98890: loss = 2.6472\n",
      "Iteration 98900: loss = 2.2112\n",
      "Iteration 98910: loss = 2.5473\n",
      "Iteration 98920: loss = 2.2851\n",
      "Iteration 98930: loss = 2.4872\n",
      "Iteration 98940: loss = 2.3641\n",
      "Iteration 98950: loss = 2.5194\n",
      "Iteration 98960: loss = 2.1878\n",
      "Iteration 98970: loss = 2.1922\n",
      "Iteration 98980: loss = 2.7319\n",
      "Iteration 98990: loss = 2.2137\n",
      "Iteration 99000: loss = 2.7194\n",
      "Iteration 99010: loss = 2.6220\n",
      "Iteration 99020: loss = 2.4984\n",
      "Iteration 99030: loss = 2.5909\n",
      "Iteration 99040: loss = 2.8078\n",
      "Iteration 99050: loss = 2.3668\n",
      "Iteration 99060: loss = 2.5009\n",
      "Iteration 99070: loss = 2.6207\n",
      "Iteration 99080: loss = 2.9322\n",
      "Iteration 99090: loss = 2.8424\n",
      "Iteration 99100: loss = 2.3145\n",
      "Iteration 99110: loss = 2.3957\n",
      "Iteration 99120: loss = 2.3952\n",
      "Iteration 99130: loss = 2.2252\n",
      "Iteration 99140: loss = 2.5012\n",
      "Iteration 99150: loss = 2.4863\n",
      "Iteration 99160: loss = 1.9824\n",
      "Iteration 99170: loss = 2.5717\n",
      "Iteration 99180: loss = 2.6037\n",
      "Iteration 99190: loss = 2.2781\n",
      "Iteration 99200: loss = 2.4598\n",
      "Iteration 99210: loss = 2.6033\n",
      "Iteration 99220: loss = 2.2540\n",
      "Iteration 99230: loss = 2.6875\n",
      "Iteration 99240: loss = 2.4888\n",
      "Iteration 99250: loss = 2.4335\n",
      "Iteration 99260: loss = 2.6778\n",
      "Iteration 99270: loss = 2.2413\n",
      "Iteration 99280: loss = 2.5097\n",
      "Iteration 99290: loss = 2.8454\n",
      "Iteration 99300: loss = 2.4962\n",
      "Iteration 99310: loss = 2.2616\n",
      "Iteration 99320: loss = 2.3364\n",
      "Iteration 99330: loss = 2.8579\n",
      "Iteration 99340: loss = 2.1720\n",
      "Iteration 99350: loss = 2.5405\n",
      "Iteration 99360: loss = 2.4488\n",
      "Iteration 99370: loss = 2.2858\n",
      "Iteration 99380: loss = 2.3211\n",
      "Iteration 99390: loss = 2.4529\n",
      "Iteration 99400: loss = 2.0365\n",
      "Iteration 99410: loss = 2.1453\n",
      "Iteration 99420: loss = 2.2094\n",
      "Iteration 99430: loss = 2.2500\n",
      "Iteration 99440: loss = 2.5317\n",
      "Iteration 99450: loss = 2.7083\n",
      "Iteration 99460: loss = 2.7082\n",
      "Iteration 99470: loss = 2.5553\n",
      "Iteration 99480: loss = 2.1017\n",
      "Iteration 99490: loss = 2.4571\n",
      "Iteration 99500: loss = 2.0739\n",
      "Iteration 99510: loss = 2.7864\n",
      "Iteration 99520: loss = 2.6388\n",
      "Iteration 99530: loss = 2.2185\n",
      "Iteration 99540: loss = 2.7351\n",
      "Iteration 99550: loss = 2.5147\n",
      "Iteration 99560: loss = 2.1795\n",
      "Iteration 99570: loss = 2.5108\n",
      "Iteration 99580: loss = 2.1557\n",
      "Iteration 99590: loss = 2.5414\n",
      "Iteration 99600: loss = 2.2379\n",
      "Iteration 99610: loss = 2.0408\n",
      "Iteration 99620: loss = 2.6124\n",
      "Iteration 99630: loss = 2.1630\n",
      "Iteration 99640: loss = 2.2134\n",
      "Iteration 99650: loss = 2.4030\n",
      "Iteration 99660: loss = 2.5281\n",
      "Iteration 99670: loss = 2.6076\n",
      "Iteration 99680: loss = 2.2461\n",
      "Iteration 99690: loss = 2.6448\n",
      "Iteration 99700: loss = 2.7685\n",
      "Iteration 99710: loss = 2.6131\n",
      "Iteration 99720: loss = 2.6698\n",
      "Iteration 99730: loss = 2.3084\n",
      "Iteration 99740: loss = 2.3193\n",
      "Iteration 99750: loss = 2.5291\n",
      "Iteration 99760: loss = 2.4909\n",
      "Iteration 99770: loss = 2.9478\n",
      "Iteration 99780: loss = 2.3158\n",
      "Iteration 99790: loss = 2.2359\n",
      "Iteration 99800: loss = 2.6842\n",
      "Iteration 99810: loss = 2.1962\n",
      "Iteration 99820: loss = 3.0723\n",
      "Iteration 99830: loss = 2.5803\n",
      "Iteration 99840: loss = 2.5182\n",
      "Iteration 99850: loss = 2.6896\n",
      "Iteration 99860: loss = 2.5091\n",
      "Iteration 99870: loss = 2.3667\n",
      "Iteration 99880: loss = 2.9314\n",
      "Iteration 99890: loss = 2.5089\n",
      "Iteration 99900: loss = 2.1428\n",
      "Iteration 99910: loss = 2.4295\n",
      "Iteration 99920: loss = 2.3999\n",
      "Iteration 99930: loss = 2.4378\n",
      "Iteration 99940: loss = 2.3101\n",
      "Iteration 99950: loss = 2.4368\n",
      "Iteration 99960: loss = 2.9105\n",
      "Iteration 99970: loss = 2.3029\n",
      "Iteration 99980: loss = 2.4484\n",
      "Iteration 99990: loss = 2.1391\n",
      "Iteration 100000: loss = 2.4199\n",
      "Iteration 100010: loss = 2.4055\n",
      "Iteration 100020: loss = 2.4191\n",
      "Iteration 100030: loss = 2.6374\n",
      "Iteration 100040: loss = 2.4611\n",
      "Iteration 100050: loss = 2.5606\n",
      "Iteration 100060: loss = 2.2982\n",
      "Iteration 100070: loss = 2.2469\n",
      "Iteration 100080: loss = 2.6502\n",
      "Iteration 100090: loss = 2.4196\n",
      "Iteration 100100: loss = 2.7840\n",
      "Iteration 100110: loss = 2.2768\n",
      "Iteration 100120: loss = 2.6855\n",
      "Iteration 100130: loss = 2.4286\n",
      "Iteration 100140: loss = 2.3392\n",
      "Iteration 100150: loss = 3.0521\n",
      "Iteration 100160: loss = 2.8846\n",
      "Iteration 100170: loss = 2.5022\n",
      "Iteration 100180: loss = 1.9745\n",
      "Iteration 100190: loss = 2.5656\n",
      "Iteration 100200: loss = 2.4131\n",
      "Iteration 100210: loss = 2.4581\n",
      "Iteration 100220: loss = 2.2337\n",
      "Iteration 100230: loss = 2.3123\n",
      "Iteration 100240: loss = 2.6719\n",
      "Iteration 100250: loss = 2.3824\n",
      "Iteration 100260: loss = 2.7251\n",
      "Iteration 100270: loss = 2.0552\n",
      "Iteration 100280: loss = 2.2947\n",
      "Iteration 100290: loss = 2.2835\n",
      "Iteration 100300: loss = 2.4596\n",
      "Iteration 100310: loss = 2.6826\n",
      "Iteration 100320: loss = 2.3403\n",
      "Iteration 100330: loss = 2.1932\n",
      "Iteration 100340: loss = 2.5155\n",
      "Iteration 100350: loss = 2.2249\n",
      "Iteration 100360: loss = 2.5833\n",
      "Iteration 100370: loss = 2.1005\n",
      "Iteration 100380: loss = 2.4151\n",
      "Iteration 100390: loss = 2.6876\n",
      "Iteration 100400: loss = 2.6273\n",
      "Iteration 100410: loss = 2.3535\n",
      "Iteration 100420: loss = 2.9296\n",
      "Iteration 100430: loss = 2.2547\n",
      "Iteration 100440: loss = 2.3084\n",
      "Iteration 100450: loss = 2.3113\n",
      "Iteration 100460: loss = 2.4093\n",
      "Iteration 100470: loss = 2.7895\n",
      "Iteration 100480: loss = 2.6844\n",
      "Iteration 100490: loss = 2.5429\n",
      "Iteration 100500: loss = 2.2807\n",
      "Iteration 100510: loss = 2.3331\n",
      "Iteration 100520: loss = 2.4367\n",
      "Iteration 100530: loss = 2.5597\n",
      "Iteration 100540: loss = 2.4718\n",
      "Iteration 100550: loss = 2.2497\n",
      "Iteration 100560: loss = 2.6152\n",
      "Iteration 100570: loss = 2.3685\n",
      "Iteration 100580: loss = 3.0042\n",
      "Iteration 100590: loss = 2.6099\n",
      "Iteration 100600: loss = 2.0991\n",
      "Iteration 100610: loss = 2.5115\n",
      "Iteration 100620: loss = 2.3510\n",
      "Iteration 100630: loss = 2.3607\n",
      "Iteration 100640: loss = 2.1051\n",
      "Iteration 100650: loss = 2.3470\n",
      "Iteration 100660: loss = 2.4432\n",
      "Iteration 100670: loss = 2.2395\n",
      "Iteration 100680: loss = 2.4108\n",
      "Iteration 100690: loss = 2.5708\n",
      "Iteration 100700: loss = 2.4280\n",
      "Iteration 100710: loss = 1.9961\n",
      "Iteration 100720: loss = 2.5445\n",
      "Iteration 100730: loss = 2.1981\n",
      "Iteration 100740: loss = 2.1472\n",
      "Iteration 100750: loss = 2.1744\n",
      "Iteration 100760: loss = 2.4032\n",
      "Iteration 100770: loss = 2.4698\n",
      "Iteration 100780: loss = 2.2823\n",
      "Iteration 100790: loss = 2.9065\n",
      "Iteration 100800: loss = 2.6350\n",
      "Iteration 100810: loss = 2.7081\n",
      "Iteration 100820: loss = 2.7581\n",
      "Iteration 100830: loss = 2.5859\n",
      "Iteration 100840: loss = 2.5109\n",
      "Iteration 100850: loss = 2.5678\n",
      "Iteration 100860: loss = 2.6617\n",
      "Iteration 100870: loss = 2.5485\n",
      "Iteration 100880: loss = 2.3537\n",
      "Iteration 100890: loss = 2.6015\n",
      "Iteration 100900: loss = 2.4038\n",
      "Iteration 100910: loss = 2.5325\n",
      "Iteration 100920: loss = 2.2000\n",
      "Iteration 100930: loss = 2.4745\n",
      "Iteration 100940: loss = 2.5036\n",
      "Iteration 100950: loss = 2.6480\n",
      "Iteration 100960: loss = 2.5538\n",
      "Iteration 100970: loss = 2.6089\n",
      "Iteration 100980: loss = 2.4881\n",
      "Iteration 100990: loss = 2.1951\n",
      "Iteration 101000: loss = 2.5094\n",
      "Iteration 101010: loss = 2.2115\n",
      "Iteration 101020: loss = 2.2686\n",
      "Iteration 101030: loss = 2.6463\n",
      "Iteration 101040: loss = 2.4464\n",
      "Iteration 101050: loss = 2.5246\n",
      "Iteration 101060: loss = 2.5420\n",
      "Iteration 101070: loss = 2.0963\n",
      "Iteration 101080: loss = 2.5317\n",
      "Iteration 101090: loss = 2.1943\n",
      "Iteration 101100: loss = 2.1910\n",
      "Iteration 101110: loss = 1.9077\n",
      "Iteration 101120: loss = 2.4789\n",
      "Iteration 101130: loss = 2.5212\n",
      "Iteration 101140: loss = 2.4442\n",
      "Iteration 101150: loss = 2.1999\n",
      "Iteration 101160: loss = 2.3283\n",
      "Iteration 101170: loss = 2.5715\n",
      "Iteration 101180: loss = 2.3392\n",
      "Iteration 101190: loss = 2.8112\n",
      "Iteration 101200: loss = 2.0409\n",
      "Iteration 101210: loss = 2.6179\n",
      "Iteration 101220: loss = 2.5413\n",
      "Iteration 101230: loss = 2.4700\n",
      "Iteration 101240: loss = 2.4520\n",
      "Iteration 101250: loss = 2.3237\n",
      "Iteration 101260: loss = 2.3367\n",
      "Iteration 101270: loss = 2.5873\n",
      "Iteration 101280: loss = 2.5154\n",
      "Iteration 101290: loss = 2.2313\n",
      "Iteration 101300: loss = 2.7659\n",
      "Iteration 101310: loss = 2.2350\n",
      "Iteration 101320: loss = 2.5329\n",
      "Iteration 101330: loss = 2.7638\n",
      "Iteration 101340: loss = 2.1719\n",
      "Iteration 101350: loss = 2.7115\n",
      "Iteration 101360: loss = 2.4723\n",
      "Iteration 101370: loss = 2.6458\n",
      "Iteration 101380: loss = 2.8121\n",
      "Iteration 101390: loss = 2.4519\n",
      "Iteration 101400: loss = 2.1949\n",
      "Iteration 101410: loss = 2.5591\n",
      "Iteration 101420: loss = 2.3013\n",
      "Iteration 101430: loss = 2.3022\n",
      "Iteration 101440: loss = 2.4700\n",
      "Iteration 101450: loss = 2.1212\n",
      "Iteration 101460: loss = 2.6483\n",
      "Iteration 101470: loss = 2.5932\n",
      "Iteration 101480: loss = 2.2095\n",
      "Iteration 101490: loss = 2.6168\n",
      "Iteration 101500: loss = 2.2877\n",
      "Iteration 101510: loss = 2.3124\n",
      "Iteration 101520: loss = 2.3449\n",
      "Iteration 101530: loss = 2.5938\n",
      "Iteration 101540: loss = 2.4370\n",
      "Iteration 101550: loss = 2.6219\n",
      "Iteration 101560: loss = 2.2476\n",
      "Iteration 101570: loss = 2.4506\n",
      "Iteration 101580: loss = 2.2492\n",
      "Iteration 101590: loss = 2.3409\n",
      "Iteration 101600: loss = 2.1837\n",
      "Iteration 101610: loss = 2.7636\n",
      "Iteration 101620: loss = 2.6239\n",
      "Iteration 101630: loss = 2.8325\n",
      "Iteration 101640: loss = 2.2161\n",
      "Iteration 101650: loss = 2.3854\n",
      "Iteration 101660: loss = 2.3147\n",
      "Iteration 101670: loss = 2.3296\n",
      "Iteration 101680: loss = 2.4134\n",
      "Iteration 101690: loss = 2.5335\n",
      "Iteration 101700: loss = 2.5730\n",
      "Iteration 101710: loss = 2.3496\n",
      "Iteration 101720: loss = 2.3694\n",
      "Iteration 101730: loss = 2.3539\n",
      "Iteration 101740: loss = 2.2099\n",
      "Iteration 101750: loss = 2.3959\n",
      "Iteration 101760: loss = 2.4131\n",
      "Iteration 101770: loss = 2.4583\n",
      "Iteration 101780: loss = 2.9628\n",
      "Iteration 101790: loss = 2.5714\n",
      "Iteration 101800: loss = 2.3172\n",
      "Iteration 101810: loss = 2.3997\n",
      "Iteration 101820: loss = 2.4529\n",
      "Iteration 101830: loss = 2.4591\n",
      "Iteration 101840: loss = 2.2163\n",
      "Iteration 101850: loss = 2.1777\n",
      "Iteration 101860: loss = 2.3327\n",
      "Iteration 101870: loss = 2.7163\n",
      "Iteration 101880: loss = 2.3663\n",
      "Iteration 101890: loss = 2.2719\n",
      "Iteration 101900: loss = 2.9005\n",
      "Iteration 101910: loss = 2.3028\n",
      "Iteration 101920: loss = 2.3651\n",
      "Iteration 101930: loss = 2.2100\n",
      "Iteration 101940: loss = 2.4199\n",
      "Iteration 101950: loss = 2.5820\n",
      "Iteration 101960: loss = 2.1457\n",
      "Iteration 101970: loss = 2.2151\n",
      "Iteration 101980: loss = 2.7614\n",
      "Iteration 101990: loss = 2.3123\n",
      "Iteration 102000: loss = 2.1923\n",
      "Iteration 102010: loss = 2.1054\n",
      "Iteration 102020: loss = 2.5227\n",
      "Iteration 102030: loss = 2.4010\n",
      "Iteration 102040: loss = 2.2653\n",
      "Iteration 102050: loss = 2.7666\n",
      "Iteration 102060: loss = 2.5531\n",
      "Iteration 102070: loss = 2.3282\n",
      "Iteration 102080: loss = 2.1325\n",
      "Iteration 102090: loss = 2.3080\n",
      "Iteration 102100: loss = 2.1759\n",
      "Iteration 102110: loss = 2.5661\n",
      "Iteration 102120: loss = 2.5849\n",
      "Iteration 102130: loss = 2.4552\n",
      "Iteration 102140: loss = 2.7447\n",
      "Iteration 102150: loss = 2.4479\n",
      "Iteration 102160: loss = 2.4283\n",
      "Iteration 102170: loss = 2.5223\n",
      "Iteration 102180: loss = 2.6997\n",
      "Iteration 102190: loss = 2.8365\n",
      "Iteration 102200: loss = 2.2933\n",
      "Iteration 102210: loss = 2.1518\n",
      "Iteration 102220: loss = 2.5706\n",
      "Iteration 102230: loss = 2.6116\n",
      "Iteration 102240: loss = 2.4653\n",
      "Iteration 102250: loss = 2.2778\n",
      "Iteration 102260: loss = 2.5167\n",
      "Iteration 102270: loss = 2.4082\n",
      "Iteration 102280: loss = 2.5690\n",
      "Iteration 102290: loss = 2.2180\n",
      "Iteration 102300: loss = 2.4612\n",
      "Iteration 102310: loss = 2.3049\n",
      "Iteration 102320: loss = 2.5446\n",
      "Iteration 102330: loss = 2.5565\n",
      "Iteration 102340: loss = 2.5845\n",
      "Iteration 102350: loss = 2.4497\n",
      "Iteration 102360: loss = 2.2265\n",
      "Iteration 102370: loss = 2.5819\n",
      "Iteration 102380: loss = 2.4600\n",
      "Iteration 102390: loss = 2.0215\n",
      "Iteration 102400: loss = 2.3889\n",
      "Iteration 102410: loss = 2.4313\n",
      "Iteration 102420: loss = 2.0941\n",
      "Iteration 102430: loss = 2.5355\n",
      "Iteration 102440: loss = 2.3188\n",
      "Iteration 102450: loss = 2.5894\n",
      "Iteration 102460: loss = 2.1416\n",
      "Iteration 102470: loss = 2.0799\n",
      "Iteration 102480: loss = 2.6446\n",
      "Iteration 102490: loss = 2.9880\n",
      "Iteration 102500: loss = 2.1253\n",
      "Iteration 102510: loss = 2.3369\n",
      "Iteration 102520: loss = 2.2174\n",
      "Iteration 102530: loss = 2.4543\n",
      "Iteration 102540: loss = 2.7575\n",
      "Iteration 102550: loss = 2.7989\n",
      "Iteration 102560: loss = 2.2707\n",
      "Iteration 102570: loss = 2.3483\n",
      "Iteration 102580: loss = 2.4774\n",
      "Iteration 102590: loss = 2.2867\n",
      "Iteration 102600: loss = 2.2217\n",
      "Iteration 102610: loss = 2.4902\n",
      "Iteration 102620: loss = 2.3820\n",
      "Iteration 102630: loss = 2.5781\n",
      "Iteration 102640: loss = 2.5562\n",
      "Iteration 102650: loss = 2.4882\n",
      "Iteration 102660: loss = 2.5011\n",
      "Iteration 102670: loss = 2.0193\n",
      "Iteration 102680: loss = 2.9054\n",
      "Iteration 102690: loss = 2.2718\n",
      "Iteration 102700: loss = 2.6184\n",
      "Iteration 102710: loss = 2.7508\n",
      "Iteration 102720: loss = 2.0998\n",
      "Iteration 102730: loss = 2.4285\n",
      "Iteration 102740: loss = 2.7457\n",
      "Iteration 102750: loss = 2.4991\n",
      "Iteration 102760: loss = 2.9721\n",
      "Iteration 102770: loss = 2.8043\n",
      "Iteration 102780: loss = 2.9660\n",
      "Iteration 102790: loss = 2.3535\n",
      "Iteration 102800: loss = 2.2097\n",
      "Iteration 102810: loss = 2.7362\n",
      "Iteration 102820: loss = 2.4108\n",
      "Iteration 102830: loss = 2.4403\n",
      "Iteration 102840: loss = 2.4804\n",
      "Iteration 102850: loss = 2.5642\n",
      "Iteration 102860: loss = 2.4109\n",
      "Iteration 102870: loss = 2.4575\n",
      "Iteration 102880: loss = 2.4085\n",
      "Iteration 102890: loss = 2.3841\n",
      "Iteration 102900: loss = 2.3479\n",
      "Iteration 102910: loss = 2.3183\n",
      "Iteration 102920: loss = 2.3874\n",
      "Iteration 102930: loss = 2.3684\n",
      "Iteration 102940: loss = 2.4704\n",
      "Iteration 102950: loss = 2.5322\n",
      "Iteration 102960: loss = 2.4979\n",
      "Iteration 102970: loss = 2.3760\n",
      "Iteration 102980: loss = 2.5194\n",
      "Iteration 102990: loss = 2.4801\n",
      "Iteration 103000: loss = 2.4418\n",
      "Iteration 103010: loss = 2.7812\n",
      "Iteration 103020: loss = 2.4247\n",
      "Iteration 103030: loss = 2.4594\n",
      "Iteration 103040: loss = 2.1727\n",
      "Iteration 103050: loss = 2.3812\n",
      "Iteration 103060: loss = 2.4458\n",
      "Iteration 103070: loss = 3.0988\n",
      "Iteration 103080: loss = 2.1440\n",
      "Iteration 103090: loss = 1.8847\n",
      "Iteration 103100: loss = 2.2495\n",
      "Iteration 103110: loss = 2.4599\n",
      "Iteration 103120: loss = 2.3489\n",
      "Iteration 103130: loss = 2.6362\n",
      "Iteration 103140: loss = 2.6091\n",
      "Iteration 103150: loss = 2.5773\n",
      "Iteration 103160: loss = 2.9436\n",
      "Iteration 103170: loss = 2.2015\n",
      "Iteration 103180: loss = 2.3830\n",
      "Iteration 103190: loss = 2.4096\n",
      "Iteration 103200: loss = 2.2500\n",
      "Iteration 103210: loss = 2.6089\n",
      "Iteration 103220: loss = 2.6262\n",
      "Iteration 103230: loss = 2.6085\n",
      "Iteration 103240: loss = 2.3247\n",
      "Iteration 103250: loss = 2.4901\n",
      "Iteration 103260: loss = 2.6492\n",
      "Iteration 103270: loss = 2.5690\n",
      "Iteration 103280: loss = 2.1433\n",
      "Iteration 103290: loss = 2.3389\n",
      "Iteration 103300: loss = 2.3943\n",
      "Iteration 103310: loss = 2.3816\n",
      "Iteration 103320: loss = 2.7020\n",
      "Iteration 103330: loss = 2.8695\n",
      "Iteration 103340: loss = 2.2030\n",
      "Iteration 103350: loss = 2.3833\n",
      "Iteration 103360: loss = 2.6192\n",
      "Iteration 103370: loss = 2.4304\n",
      "Iteration 103380: loss = 2.4383\n",
      "Iteration 103390: loss = 2.3317\n",
      "Iteration 103400: loss = 2.2183\n",
      "Iteration 103410: loss = 2.4371\n",
      "Iteration 103420: loss = 2.6711\n",
      "Iteration 103430: loss = 2.4519\n",
      "Iteration 103440: loss = 2.5256\n",
      "Iteration 103450: loss = 2.7608\n",
      "Iteration 103460: loss = 2.3938\n",
      "Iteration 103470: loss = 2.7466\n",
      "Iteration 103480: loss = 2.1223\n",
      "Iteration 103490: loss = 2.2661\n",
      "Iteration 103500: loss = 2.3250\n",
      "Iteration 103510: loss = 2.3397\n",
      "Iteration 103520: loss = 1.8734\n",
      "Iteration 103530: loss = 2.2231\n",
      "Iteration 103540: loss = 2.7876\n",
      "Iteration 103550: loss = 2.4351\n",
      "Iteration 103560: loss = 2.7842\n",
      "Iteration 103570: loss = 2.5577\n",
      "Iteration 103580: loss = 2.5613\n",
      "Iteration 103590: loss = 2.9584\n",
      "Iteration 103600: loss = 2.2888\n",
      "Iteration 103610: loss = 2.3623\n",
      "Iteration 103620: loss = 2.4757\n",
      "Iteration 103630: loss = 2.4587\n",
      "Iteration 103640: loss = 2.2866\n",
      "Iteration 103650: loss = 2.4463\n",
      "Iteration 103660: loss = 2.2896\n",
      "Iteration 103670: loss = 2.0742\n",
      "Iteration 103680: loss = 3.1060\n",
      "Iteration 103690: loss = 2.6527\n",
      "Iteration 103700: loss = 2.5660\n",
      "Iteration 103710: loss = 2.3906\n",
      "Iteration 103720: loss = 2.2413\n",
      "Iteration 103730: loss = 2.5710\n",
      "Iteration 103740: loss = 2.7963\n",
      "Iteration 103750: loss = 2.4804\n",
      "Iteration 103760: loss = 2.2940\n",
      "Iteration 103770: loss = 2.4850\n",
      "Iteration 103780: loss = 2.5295\n",
      "Iteration 103790: loss = 2.3337\n",
      "Iteration 103800: loss = 2.7220\n",
      "Iteration 103810: loss = 2.2930\n",
      "Iteration 103820: loss = 2.5217\n",
      "Iteration 103830: loss = 2.4669\n",
      "Iteration 103840: loss = 2.4332\n",
      "Iteration 103850: loss = 2.3355\n",
      "Iteration 103860: loss = 2.3304\n",
      "Iteration 103870: loss = 2.0863\n",
      "Iteration 103880: loss = 2.4866\n",
      "Iteration 103890: loss = 2.5593\n",
      "Iteration 103900: loss = 2.6732\n",
      "Iteration 103910: loss = 2.3491\n",
      "Iteration 103920: loss = 2.3252\n",
      "Iteration 103930: loss = 2.5959\n",
      "Iteration 103940: loss = 2.8595\n",
      "Iteration 103950: loss = 2.4236\n",
      "Iteration 103960: loss = 2.1482\n",
      "Iteration 103970: loss = 2.4963\n",
      "Iteration 103980: loss = 2.6924\n",
      "Iteration 103990: loss = 2.5253\n",
      "Iteration 104000: loss = 2.4030\n",
      "Iteration 104010: loss = 2.5114\n",
      "Iteration 104020: loss = 2.4047\n",
      "Iteration 104030: loss = 2.3408\n",
      "Iteration 104040: loss = 2.4352\n",
      "Iteration 104050: loss = 2.6166\n",
      "Iteration 104060: loss = 2.3667\n",
      "Iteration 104070: loss = 2.2269\n",
      "Iteration 104080: loss = 2.7716\n",
      "Iteration 104090: loss = 2.4278\n",
      "Iteration 104100: loss = 2.4638\n",
      "Iteration 104110: loss = 2.3352\n",
      "Iteration 104120: loss = 2.3549\n",
      "Iteration 104130: loss = 2.5725\n",
      "Iteration 104140: loss = 2.3158\n",
      "Iteration 104150: loss = 2.5742\n",
      "Iteration 104160: loss = 2.4592\n",
      "Iteration 104170: loss = 2.7631\n",
      "Iteration 104180: loss = 2.5419\n",
      "Iteration 104190: loss = 2.2322\n",
      "Iteration 104200: loss = 2.3824\n",
      "Iteration 104210: loss = 2.2880\n",
      "Iteration 104220: loss = 2.3392\n",
      "Iteration 104230: loss = 2.5777\n",
      "Iteration 104240: loss = 2.6314\n",
      "Iteration 104250: loss = 2.4852\n",
      "Iteration 104260: loss = 2.0313\n",
      "Iteration 104270: loss = 2.4059\n",
      "Iteration 104280: loss = 2.4401\n",
      "Iteration 104290: loss = 2.5193\n",
      "Iteration 104300: loss = 2.5548\n",
      "Iteration 104310: loss = 2.3133\n",
      "Iteration 104320: loss = 2.4405\n",
      "Iteration 104330: loss = 2.2005\n",
      "Iteration 104340: loss = 2.4805\n",
      "Iteration 104350: loss = 2.4757\n",
      "Iteration 104360: loss = 2.7554\n",
      "Iteration 104370: loss = 2.5235\n",
      "Iteration 104380: loss = 2.4940\n",
      "Iteration 104390: loss = 2.4528\n",
      "Iteration 104400: loss = 2.0843\n",
      "Iteration 104410: loss = 2.9499\n",
      "Iteration 104420: loss = 2.2261\n",
      "Iteration 104430: loss = 2.6515\n",
      "Iteration 104440: loss = 2.5824\n",
      "Iteration 104450: loss = 2.1994\n",
      "Iteration 104460: loss = 2.7421\n",
      "Iteration 104470: loss = 2.1687\n",
      "Iteration 104480: loss = 2.4705\n",
      "Iteration 104490: loss = 2.7499\n",
      "Iteration 104500: loss = 2.4532\n",
      "Iteration 104510: loss = 2.5134\n",
      "Iteration 104520: loss = 2.7802\n",
      "Iteration 104530: loss = 2.6209\n",
      "Iteration 104540: loss = 2.7622\n",
      "Iteration 104550: loss = 2.2752\n",
      "Iteration 104560: loss = 2.2758\n",
      "Iteration 104570: loss = 2.0468\n",
      "Iteration 104580: loss = 2.5589\n",
      "Iteration 104590: loss = 2.1182\n",
      "Iteration 104600: loss = 2.4242\n",
      "Iteration 104610: loss = 2.5041\n",
      "Iteration 104620: loss = 2.6251\n",
      "Iteration 104630: loss = 2.6282\n",
      "Iteration 104640: loss = 2.3793\n",
      "Iteration 104650: loss = 2.5398\n",
      "Iteration 104660: loss = 2.7197\n",
      "Iteration 104670: loss = 2.3042\n",
      "Iteration 104680: loss = 2.5938\n",
      "Iteration 104690: loss = 2.6028\n",
      "Iteration 104700: loss = 2.4705\n",
      "Iteration 104710: loss = 2.2732\n",
      "Iteration 104720: loss = 2.6541\n",
      "Iteration 104730: loss = 1.8685\n",
      "Iteration 104740: loss = 2.8735\n",
      "Iteration 104750: loss = 2.3476\n",
      "Iteration 104760: loss = 2.4406\n",
      "Iteration 104770: loss = 2.6021\n",
      "Iteration 104780: loss = 2.5537\n",
      "Iteration 104790: loss = 2.6439\n",
      "Iteration 104800: loss = 2.5844\n",
      "Iteration 104810: loss = 2.5949\n",
      "Iteration 104820: loss = 2.5237\n",
      "Iteration 104830: loss = 2.4545\n",
      "Iteration 104840: loss = 2.2227\n",
      "Iteration 104850: loss = 2.9303\n",
      "Iteration 104860: loss = 2.3422\n",
      "Iteration 104870: loss = 2.4269\n",
      "Iteration 104880: loss = 2.2100\n",
      "Iteration 104890: loss = 2.5496\n",
      "Iteration 104900: loss = 2.5415\n",
      "Iteration 104910: loss = 2.4529\n",
      "Iteration 104920: loss = 2.9062\n",
      "Iteration 104930: loss = 2.3328\n",
      "Iteration 104940: loss = 2.4587\n",
      "Iteration 104950: loss = 2.6341\n",
      "Iteration 104960: loss = 2.3071\n",
      "Iteration 104970: loss = 2.5499\n",
      "Iteration 104980: loss = 2.5158\n",
      "Iteration 104990: loss = 2.4381\n",
      "Iteration 105000: loss = 2.3444\n",
      "Iteration 105010: loss = 2.4452\n",
      "Iteration 105020: loss = 2.4649\n",
      "Iteration 105030: loss = 2.0912\n",
      "Iteration 105040: loss = 2.2445\n",
      "Iteration 105050: loss = 2.4464\n",
      "Iteration 105060: loss = 2.3108\n",
      "Iteration 105070: loss = 2.4928\n",
      "Iteration 105080: loss = 2.1973\n",
      "Iteration 105090: loss = 2.5883\n",
      "Iteration 105100: loss = 2.1430\n",
      "Iteration 105110: loss = 2.7837\n",
      "Iteration 105120: loss = 2.2057\n",
      "Iteration 105130: loss = 2.6852\n",
      "Iteration 105140: loss = 2.1767\n",
      "Iteration 105150: loss = 2.3686\n",
      "Iteration 105160: loss = 2.0716\n",
      "Iteration 105170: loss = 2.3802\n",
      "Iteration 105180: loss = 2.7289\n",
      "Iteration 105190: loss = 2.4309\n",
      "Iteration 105200: loss = 2.1109\n",
      "Iteration 105210: loss = 2.8927\n",
      "Iteration 105220: loss = 2.6321\n",
      "Iteration 105230: loss = 2.4834\n",
      "Iteration 105240: loss = 2.3827\n",
      "Iteration 105250: loss = 2.5508\n",
      "Iteration 105260: loss = 2.6599\n",
      "Iteration 105270: loss = 2.8255\n",
      "Iteration 105280: loss = 2.5785\n",
      "Iteration 105290: loss = 2.3981\n",
      "Iteration 105300: loss = 2.7712\n",
      "Iteration 105310: loss = 2.4341\n",
      "Iteration 105320: loss = 2.3850\n",
      "Iteration 105330: loss = 2.3036\n",
      "Iteration 105340: loss = 2.1217\n",
      "Iteration 105350: loss = 2.2138\n",
      "Iteration 105360: loss = 2.2211\n",
      "Iteration 105370: loss = 2.1063\n",
      "Iteration 105380: loss = 2.4590\n",
      "Iteration 105390: loss = 2.3717\n",
      "Iteration 105400: loss = 2.4558\n",
      "Iteration 105410: loss = 2.7349\n",
      "Iteration 105420: loss = 2.1560\n",
      "Iteration 105430: loss = 2.3736\n",
      "Iteration 105440: loss = 2.7739\n",
      "Iteration 105450: loss = 2.4099\n",
      "Iteration 105460: loss = 2.0536\n",
      "Iteration 105470: loss = 2.3411\n",
      "Iteration 105480: loss = 2.5790\n",
      "Iteration 105490: loss = 2.6352\n",
      "Iteration 105500: loss = 2.0744\n",
      "Iteration 105510: loss = 2.7790\n",
      "Iteration 105520: loss = 2.7111\n",
      "Iteration 105530: loss = 2.6146\n",
      "Iteration 105540: loss = 2.4860\n",
      "Iteration 105550: loss = 2.4209\n",
      "Iteration 105560: loss = 2.6508\n",
      "Iteration 105570: loss = 2.1832\n",
      "Iteration 105580: loss = 2.8039\n",
      "Iteration 105590: loss = 2.1456\n",
      "Iteration 105600: loss = 2.7960\n",
      "Iteration 105610: loss = 2.9537\n",
      "Iteration 105620: loss = 2.4314\n",
      "Iteration 105630: loss = 2.1935\n",
      "Iteration 105640: loss = 2.9038\n",
      "Iteration 105650: loss = 2.3640\n",
      "Iteration 105660: loss = 2.2298\n",
      "Iteration 105670: loss = 2.3289\n",
      "Iteration 105680: loss = 2.3913\n",
      "Iteration 105690: loss = 2.8379\n",
      "Iteration 105700: loss = 2.5590\n",
      "Iteration 105710: loss = 2.2496\n",
      "Iteration 105720: loss = 2.4476\n",
      "Iteration 105730: loss = 2.6766\n",
      "Iteration 105740: loss = 2.3183\n",
      "Iteration 105750: loss = 2.4061\n",
      "Iteration 105760: loss = 2.5467\n",
      "Iteration 105770: loss = 2.3626\n",
      "Iteration 105780: loss = 2.2985\n",
      "Iteration 105790: loss = 2.2716\n",
      "Iteration 105800: loss = 2.4733\n",
      "Iteration 105810: loss = 2.2042\n",
      "Iteration 105820: loss = 2.3366\n",
      "Iteration 105830: loss = 2.5056\n",
      "Iteration 105840: loss = 2.6189\n",
      "Iteration 105850: loss = 2.2296\n",
      "Iteration 105860: loss = 2.4876\n",
      "Iteration 105870: loss = 2.4147\n",
      "Iteration 105880: loss = 2.3109\n",
      "Iteration 105890: loss = 2.0834\n",
      "Iteration 105900: loss = 2.7047\n",
      "Iteration 105910: loss = 2.5068\n",
      "Iteration 105920: loss = 2.4766\n",
      "Iteration 105930: loss = 2.3869\n",
      "Iteration 105940: loss = 2.0363\n",
      "Iteration 105950: loss = 2.3312\n",
      "Iteration 105960: loss = 2.2153\n",
      "Iteration 105970: loss = 2.4076\n",
      "Iteration 105980: loss = 2.4028\n",
      "Iteration 105990: loss = 2.4447\n",
      "Iteration 106000: loss = 2.3919\n",
      "Iteration 106010: loss = 3.0387\n",
      "Iteration 106020: loss = 2.6352\n",
      "Iteration 106030: loss = 2.3040\n",
      "Iteration 106040: loss = 2.4097\n",
      "Iteration 106050: loss = 2.3454\n",
      "Iteration 106060: loss = 2.3642\n",
      "Iteration 106070: loss = 2.3782\n",
      "Iteration 106080: loss = 2.5655\n",
      "Iteration 106090: loss = 2.0684\n",
      "Iteration 106100: loss = 2.9828\n",
      "Iteration 106110: loss = 2.5756\n",
      "Iteration 106120: loss = 2.3141\n",
      "Iteration 106130: loss = 2.8296\n",
      "Iteration 106140: loss = 2.2946\n",
      "Iteration 106150: loss = 2.0184\n",
      "Iteration 106160: loss = 2.6839\n",
      "Iteration 106170: loss = 2.4675\n",
      "Iteration 106180: loss = 2.6122\n",
      "Iteration 106190: loss = 2.1813\n",
      "Iteration 106200: loss = 2.5585\n",
      "Iteration 106210: loss = 2.3449\n",
      "Iteration 106220: loss = 2.3045\n",
      "Iteration 106230: loss = 2.5410\n",
      "Iteration 106240: loss = 2.5531\n",
      "Iteration 106250: loss = 2.4215\n",
      "Iteration 106260: loss = 2.5129\n",
      "Iteration 106270: loss = 2.4579\n",
      "Iteration 106280: loss = 2.4558\n",
      "Iteration 106290: loss = 2.1214\n",
      "Iteration 106300: loss = 2.2907\n",
      "Iteration 106310: loss = 2.2886\n",
      "Iteration 106320: loss = 2.2762\n",
      "Iteration 106330: loss = 2.5348\n",
      "Iteration 106340: loss = 2.5314\n",
      "Iteration 106350: loss = 2.3323\n",
      "Iteration 106360: loss = 2.6501\n",
      "Iteration 106370: loss = 2.6341\n",
      "Iteration 106380: loss = 3.0744\n",
      "Iteration 106390: loss = 2.7691\n",
      "Iteration 106400: loss = 2.6618\n",
      "Iteration 106410: loss = 2.4796\n",
      "Iteration 106420: loss = 2.7418\n",
      "Iteration 106430: loss = 2.2850\n",
      "Iteration 106440: loss = 2.5229\n",
      "Iteration 106450: loss = 2.2018\n",
      "Iteration 106460: loss = 2.7058\n",
      "Iteration 106470: loss = 2.3680\n",
      "Iteration 106480: loss = 2.5714\n",
      "Iteration 106490: loss = 2.2473\n",
      "Iteration 106500: loss = 2.4163\n",
      "Iteration 106510: loss = 2.5049\n",
      "Iteration 106520: loss = 2.1978\n",
      "Iteration 106530: loss = 2.5951\n",
      "Iteration 106540: loss = 2.2894\n",
      "Iteration 106550: loss = 2.5934\n",
      "Iteration 106560: loss = 2.6726\n",
      "Iteration 106570: loss = 2.6709\n",
      "Iteration 106580: loss = 2.2127\n",
      "Iteration 106590: loss = 2.5103\n",
      "Iteration 106600: loss = 2.6112\n",
      "Iteration 106610: loss = 2.4934\n",
      "Iteration 106620: loss = 2.4639\n",
      "Iteration 106630: loss = 2.7096\n",
      "Iteration 106640: loss = 2.4400\n",
      "Iteration 106650: loss = 2.3588\n",
      "Iteration 106660: loss = 2.8658\n",
      "Iteration 106670: loss = 2.3628\n",
      "Iteration 106680: loss = 2.9136\n",
      "Iteration 106690: loss = 2.4730\n",
      "Iteration 106700: loss = 2.6177\n",
      "Iteration 106710: loss = 2.2294\n",
      "Iteration 106720: loss = 2.5652\n",
      "Iteration 106730: loss = 2.4127\n",
      "Iteration 106740: loss = 2.2626\n",
      "Iteration 106750: loss = 2.6871\n",
      "Iteration 106760: loss = 2.7161\n",
      "Iteration 106770: loss = 2.3260\n",
      "Iteration 106780: loss = 2.6963\n",
      "Iteration 106790: loss = 2.3159\n",
      "Iteration 106800: loss = 2.3435\n",
      "Iteration 106810: loss = 2.4612\n",
      "Iteration 106820: loss = 2.5902\n",
      "Iteration 106830: loss = 2.3243\n",
      "Iteration 106840: loss = 2.6965\n",
      "Iteration 106850: loss = 2.8027\n",
      "Iteration 106860: loss = 1.9444\n",
      "Iteration 106870: loss = 2.3484\n",
      "Iteration 106880: loss = 2.4728\n",
      "Iteration 106890: loss = 2.7572\n",
      "Iteration 106900: loss = 2.2178\n",
      "Iteration 106910: loss = 2.1133\n",
      "Iteration 106920: loss = 2.3957\n",
      "Iteration 106930: loss = 2.2474\n",
      "Iteration 106940: loss = 2.7610\n",
      "Iteration 106950: loss = 2.3099\n",
      "Iteration 106960: loss = 2.3653\n",
      "Iteration 106970: loss = 2.5345\n",
      "Iteration 106980: loss = 2.5849\n",
      "Iteration 106990: loss = 2.1110\n",
      "Iteration 107000: loss = 2.8372\n",
      "Iteration 107010: loss = 2.5855\n",
      "Iteration 107020: loss = 2.4240\n",
      "Iteration 107030: loss = 2.5325\n",
      "Iteration 107040: loss = 2.0154\n",
      "Iteration 107050: loss = 2.5690\n",
      "Iteration 107060: loss = 2.5033\n",
      "Iteration 107070: loss = 2.5288\n",
      "Iteration 107080: loss = 2.1009\n",
      "Iteration 107090: loss = 2.3454\n",
      "Iteration 107100: loss = 2.6702\n",
      "Iteration 107110: loss = 2.4668\n",
      "Iteration 107120: loss = 2.5382\n",
      "Iteration 107130: loss = 2.3409\n",
      "Iteration 107140: loss = 2.5367\n",
      "Iteration 107150: loss = 2.6717\n",
      "Iteration 107160: loss = 2.2616\n",
      "Iteration 107170: loss = 2.6675\n",
      "Iteration 107180: loss = 2.7370\n",
      "Iteration 107190: loss = 2.3991\n",
      "Iteration 107200: loss = 2.4141\n",
      "Iteration 107210: loss = 2.2162\n",
      "Iteration 107220: loss = 2.2667\n",
      "Iteration 107230: loss = 2.0240\n",
      "Iteration 107240: loss = 2.1566\n",
      "Iteration 107250: loss = 2.5847\n",
      "Iteration 107260: loss = 2.2942\n",
      "Iteration 107270: loss = 2.3146\n",
      "Iteration 107280: loss = 2.3159\n",
      "Iteration 107290: loss = 2.6989\n",
      "Iteration 107300: loss = 2.3175\n",
      "Iteration 107310: loss = 2.6297\n",
      "Iteration 107320: loss = 2.5410\n",
      "Iteration 107330: loss = 2.1390\n",
      "Iteration 107340: loss = 2.7199\n",
      "Iteration 107350: loss = 2.5094\n",
      "Iteration 107360: loss = 2.1542\n",
      "Iteration 107370: loss = 2.5278\n",
      "Iteration 107380: loss = 2.9500\n",
      "Iteration 107390: loss = 2.4479\n",
      "Iteration 107400: loss = 2.0569\n",
      "Iteration 107410: loss = 2.5362\n",
      "Iteration 107420: loss = 2.9412\n",
      "Iteration 107430: loss = 2.2508\n",
      "Iteration 107440: loss = 2.0809\n",
      "Iteration 107450: loss = 2.7122\n",
      "Iteration 107460: loss = 2.6995\n",
      "Iteration 107470: loss = 2.3426\n",
      "Iteration 107480: loss = 2.1708\n",
      "Iteration 107490: loss = 2.7213\n",
      "Iteration 107500: loss = 2.1813\n",
      "Iteration 107510: loss = 2.5043\n",
      "Iteration 107520: loss = 2.5112\n",
      "Iteration 107530: loss = 2.6994\n",
      "Iteration 107540: loss = 2.6053\n",
      "Iteration 107550: loss = 2.3801\n",
      "Iteration 107560: loss = 2.7611\n",
      "Iteration 107570: loss = 2.2293\n",
      "Iteration 107580: loss = 2.3328\n",
      "Iteration 107590: loss = 2.3035\n",
      "Iteration 107600: loss = 2.9122\n",
      "Iteration 107610: loss = 1.9127\n",
      "Iteration 107620: loss = 2.5866\n",
      "Iteration 107630: loss = 2.7437\n",
      "Iteration 107640: loss = 2.1139\n",
      "Iteration 107650: loss = 2.2834\n",
      "Iteration 107660: loss = 2.6691\n",
      "Iteration 107670: loss = 2.1954\n",
      "Iteration 107680: loss = 2.4974\n",
      "Iteration 107690: loss = 2.5690\n",
      "Iteration 107700: loss = 2.5653\n",
      "Iteration 107710: loss = 2.3313\n",
      "Iteration 107720: loss = 2.5003\n",
      "Iteration 107730: loss = 2.1748\n",
      "Iteration 107740: loss = 2.4404\n",
      "Iteration 107750: loss = 2.8711\n",
      "Iteration 107760: loss = 2.6334\n",
      "Iteration 107770: loss = 2.7061\n",
      "Iteration 107780: loss = 2.2831\n",
      "Iteration 107790: loss = 2.5364\n",
      "Iteration 107800: loss = 2.4280\n",
      "Iteration 107810: loss = 2.3849\n",
      "Iteration 107820: loss = 2.4794\n",
      "Iteration 107830: loss = 2.7464\n",
      "Iteration 107840: loss = 2.2030\n",
      "Iteration 107850: loss = 2.3295\n",
      "Iteration 107860: loss = 2.3538\n",
      "Iteration 107870: loss = 2.4659\n",
      "Iteration 107880: loss = 2.4020\n",
      "Iteration 107890: loss = 2.6040\n",
      "Iteration 107900: loss = 2.7455\n",
      "Iteration 107910: loss = 2.4058\n",
      "Iteration 107920: loss = 2.4483\n",
      "Iteration 107930: loss = 2.6613\n",
      "Iteration 107940: loss = 2.5129\n",
      "Iteration 107950: loss = 2.6621\n",
      "Iteration 107960: loss = 1.9952\n",
      "Iteration 107970: loss = 2.2397\n",
      "Iteration 107980: loss = 2.6622\n",
      "Iteration 107990: loss = 2.5983\n",
      "Iteration 108000: loss = 2.5542\n",
      "Iteration 108010: loss = 2.3056\n",
      "Iteration 108020: loss = 2.1168\n",
      "Iteration 108030: loss = 2.5140\n",
      "Iteration 108040: loss = 2.6478\n",
      "Iteration 108050: loss = 2.5639\n",
      "Iteration 108060: loss = 2.3585\n",
      "Iteration 108070: loss = 2.2706\n",
      "Iteration 108080: loss = 2.3296\n",
      "Iteration 108090: loss = 2.2506\n",
      "Iteration 108100: loss = 2.5398\n",
      "Iteration 108110: loss = 2.8682\n",
      "Iteration 108120: loss = 2.6143\n",
      "Iteration 108130: loss = 2.2148\n",
      "Iteration 108140: loss = 2.4520\n",
      "Iteration 108150: loss = 2.6333\n",
      "Iteration 108160: loss = 2.2748\n",
      "Iteration 108170: loss = 2.5151\n",
      "Iteration 108180: loss = 2.2269\n",
      "Iteration 108190: loss = 2.2535\n",
      "Iteration 108200: loss = 2.2568\n",
      "Iteration 108210: loss = 2.7070\n",
      "Iteration 108220: loss = 2.4095\n",
      "Iteration 108230: loss = 2.3515\n",
      "Iteration 108240: loss = 2.5963\n",
      "Iteration 108250: loss = 3.0232\n",
      "Iteration 108260: loss = 2.2810\n",
      "Iteration 108270: loss = 2.3846\n",
      "Iteration 108280: loss = 2.2628\n",
      "Iteration 108290: loss = 2.8198\n",
      "Iteration 108300: loss = 2.1082\n",
      "Iteration 108310: loss = 2.1248\n",
      "Iteration 108320: loss = 2.4395\n",
      "Iteration 108330: loss = 2.4540\n",
      "Iteration 108340: loss = 2.2144\n",
      "Iteration 108350: loss = 2.2990\n",
      "Iteration 108360: loss = 2.8871\n",
      "Iteration 108370: loss = 2.5297\n",
      "Iteration 108380: loss = 2.4152\n",
      "Iteration 108390: loss = 2.1667\n",
      "Iteration 108400: loss = 2.4028\n",
      "Iteration 108410: loss = 2.3618\n",
      "Iteration 108420: loss = 2.5007\n",
      "Iteration 108430: loss = 2.2656\n",
      "Iteration 108440: loss = 2.6548\n",
      "Iteration 108450: loss = 2.5310\n",
      "Iteration 108460: loss = 2.2341\n",
      "Iteration 108470: loss = 2.7234\n",
      "Iteration 108480: loss = 2.0476\n",
      "Iteration 108490: loss = 1.9720\n",
      "Iteration 108500: loss = 2.4524\n",
      "Iteration 108510: loss = 2.4208\n",
      "Iteration 108520: loss = 3.1884\n",
      "Iteration 108530: loss = 2.3786\n",
      "Iteration 108540: loss = 2.4879\n",
      "Iteration 108550: loss = 2.5581\n",
      "Iteration 108560: loss = 2.3992\n",
      "Iteration 108570: loss = 2.3225\n",
      "Iteration 108580: loss = 2.4753\n",
      "Iteration 108590: loss = 2.4766\n",
      "Iteration 108600: loss = 2.5811\n",
      "Iteration 108610: loss = 2.2873\n",
      "Iteration 108620: loss = 2.4860\n",
      "Iteration 108630: loss = 2.3924\n",
      "Iteration 108640: loss = 2.2002\n",
      "Iteration 108650: loss = 2.6197\n",
      "Iteration 108660: loss = 2.3941\n",
      "Iteration 108670: loss = 2.2951\n",
      "Iteration 108680: loss = 2.7444\n",
      "Iteration 108690: loss = 2.2634\n",
      "Iteration 108700: loss = 2.4368\n",
      "Iteration 108710: loss = 2.3555\n",
      "Iteration 108720: loss = 2.7817\n",
      "Iteration 108730: loss = 2.8346\n",
      "Iteration 108740: loss = 2.1599\n",
      "Iteration 108750: loss = 2.4804\n",
      "Iteration 108760: loss = 2.1733\n",
      "Iteration 108770: loss = 2.2772\n",
      "Iteration 108780: loss = 2.3990\n",
      "Iteration 108790: loss = 2.3935\n",
      "Iteration 108800: loss = 3.0230\n",
      "Iteration 108810: loss = 2.3751\n",
      "Iteration 108820: loss = 2.6009\n",
      "Iteration 108830: loss = 2.8133\n",
      "Iteration 108840: loss = 2.7679\n",
      "Iteration 108850: loss = 2.5841\n",
      "Iteration 108860: loss = 2.4502\n",
      "Iteration 108870: loss = 2.0966\n",
      "Iteration 108880: loss = 2.3174\n",
      "Iteration 108890: loss = 2.5250\n",
      "Iteration 108900: loss = 2.2903\n",
      "Iteration 108910: loss = 2.2954\n",
      "Iteration 108920: loss = 2.6143\n",
      "Iteration 108930: loss = 2.1812\n",
      "Iteration 108940: loss = 2.8947\n",
      "Iteration 108950: loss = 2.3224\n",
      "Iteration 108960: loss = 2.1925\n",
      "Iteration 108970: loss = 2.4667\n",
      "Iteration 108980: loss = 2.1412\n",
      "Iteration 108990: loss = 2.9149\n",
      "Iteration 109000: loss = 2.6555\n",
      "Iteration 109010: loss = 2.0690\n",
      "Iteration 109020: loss = 2.1568\n",
      "Iteration 109030: loss = 2.6048\n",
      "Iteration 109040: loss = 2.7558\n",
      "Iteration 109050: loss = 2.0685\n",
      "Iteration 109060: loss = 2.5718\n",
      "Iteration 109070: loss = 2.2750\n",
      "Iteration 109080: loss = 2.6134\n",
      "Iteration 109090: loss = 2.5506\n",
      "Iteration 109100: loss = 2.6578\n",
      "Iteration 109110: loss = 2.1055\n",
      "Iteration 109120: loss = 2.5136\n",
      "Iteration 109130: loss = 2.1283\n",
      "Iteration 109140: loss = 2.5594\n",
      "Iteration 109150: loss = 2.3300\n",
      "Iteration 109160: loss = 2.4184\n",
      "Iteration 109170: loss = 2.3296\n",
      "Iteration 109180: loss = 2.6664\n",
      "Iteration 109190: loss = 2.4839\n",
      "Iteration 109200: loss = 2.4252\n",
      "Iteration 109210: loss = 2.3567\n",
      "Iteration 109220: loss = 1.9513\n",
      "Iteration 109230: loss = 2.6121\n",
      "Iteration 109240: loss = 2.2682\n",
      "Iteration 109250: loss = 2.3137\n",
      "Iteration 109260: loss = 2.0756\n",
      "Iteration 109270: loss = 2.3085\n",
      "Iteration 109280: loss = 2.5876\n",
      "Iteration 109290: loss = 2.2687\n",
      "Iteration 109300: loss = 2.1892\n",
      "Iteration 109310: loss = 2.7555\n",
      "Iteration 109320: loss = 2.1827\n",
      "Iteration 109330: loss = 2.1839\n",
      "Iteration 109340: loss = 2.2967\n",
      "Iteration 109350: loss = 2.2987\n",
      "Iteration 109360: loss = 2.4745\n",
      "Iteration 109370: loss = 2.2828\n",
      "Iteration 109380: loss = 2.6288\n",
      "Iteration 109390: loss = 2.0565\n",
      "Iteration 109400: loss = 2.3049\n",
      "Iteration 109410: loss = 2.1811\n",
      "Iteration 109420: loss = 2.5624\n",
      "Iteration 109430: loss = 2.3899\n",
      "Iteration 109440: loss = 2.4511\n",
      "Iteration 109450: loss = 2.4097\n",
      "Iteration 109460: loss = 2.0574\n",
      "Iteration 109470: loss = 2.8676\n",
      "Iteration 109480: loss = 2.8667\n",
      "Iteration 109490: loss = 2.1289\n",
      "Iteration 109500: loss = 2.6563\n",
      "Iteration 109510: loss = 2.4839\n",
      "Iteration 109520: loss = 2.3440\n",
      "Iteration 109530: loss = 2.3457\n",
      "Iteration 109540: loss = 2.1304\n",
      "Iteration 109550: loss = 2.7188\n",
      "Iteration 109560: loss = 2.0759\n",
      "Iteration 109570: loss = 2.5343\n",
      "Iteration 109580: loss = 2.2685\n",
      "Iteration 109590: loss = 2.2523\n",
      "Iteration 109600: loss = 2.1567\n",
      "Iteration 109610: loss = 2.4456\n",
      "Iteration 109620: loss = 2.4773\n",
      "Iteration 109630: loss = 1.8904\n",
      "Iteration 109640: loss = 2.6171\n",
      "Iteration 109650: loss = 2.4029\n",
      "Iteration 109660: loss = 2.3000\n",
      "Iteration 109670: loss = 2.1725\n",
      "Iteration 109680: loss = 2.5273\n",
      "Iteration 109690: loss = 2.1790\n",
      "Iteration 109700: loss = 2.6572\n",
      "Iteration 109710: loss = 2.6502\n",
      "Iteration 109720: loss = 2.1063\n",
      "Iteration 109730: loss = 2.4847\n",
      "Iteration 109740: loss = 2.1997\n",
      "Iteration 109750: loss = 1.9417\n",
      "Iteration 109760: loss = 2.2462\n",
      "Iteration 109770: loss = 2.7090\n",
      "Iteration 109780: loss = 2.2892\n",
      "Iteration 109790: loss = 2.3770\n",
      "Iteration 109800: loss = 2.3751\n",
      "Iteration 109810: loss = 2.3743\n",
      "Iteration 109820: loss = 2.4298\n",
      "Iteration 109830: loss = 2.2596\n",
      "Iteration 109840: loss = 2.4188\n",
      "Iteration 109850: loss = 2.4082\n",
      "Iteration 109860: loss = 2.4788\n",
      "Iteration 109870: loss = 2.3186\n",
      "Iteration 109880: loss = 2.6455\n",
      "Iteration 109890: loss = 2.4479\n",
      "Iteration 109900: loss = 2.6851\n",
      "Iteration 109910: loss = 2.1602\n",
      "Iteration 109920: loss = 2.6276\n",
      "Iteration 109930: loss = 1.8161\n",
      "Iteration 109940: loss = 2.4434\n",
      "Iteration 109950: loss = 1.7415\n",
      "Iteration 109960: loss = 2.2350\n",
      "Iteration 109970: loss = 2.3603\n",
      "Iteration 109980: loss = 2.7158\n",
      "Iteration 109990: loss = 2.1869\n",
      "Iteration 110000: loss = 2.4615\n",
      "Iteration 110010: loss = 2.6750\n",
      "Iteration 110020: loss = 2.6039\n",
      "Iteration 110030: loss = 3.0181\n",
      "Iteration 110040: loss = 2.0052\n",
      "Iteration 110050: loss = 2.6824\n",
      "Iteration 110060: loss = 2.1724\n",
      "Iteration 110070: loss = 2.4184\n",
      "Iteration 110080: loss = 2.5721\n",
      "Iteration 110090: loss = 2.6848\n",
      "Iteration 110100: loss = 1.8576\n",
      "Iteration 110110: loss = 2.2537\n",
      "Iteration 110120: loss = 2.4400\n",
      "Iteration 110130: loss = 2.2922\n",
      "Iteration 110140: loss = 1.9775\n",
      "Iteration 110150: loss = 2.3338\n",
      "Iteration 110160: loss = 2.3147\n",
      "Iteration 110170: loss = 2.8020\n",
      "Iteration 110180: loss = 2.2635\n",
      "Iteration 110190: loss = 2.5785\n",
      "Iteration 110200: loss = 2.9405\n",
      "Iteration 110210: loss = 2.4121\n",
      "Iteration 110220: loss = 2.7635\n",
      "Iteration 110230: loss = 2.4333\n",
      "Iteration 110240: loss = 2.7016\n",
      "Iteration 110250: loss = 2.2177\n",
      "Iteration 110260: loss = 2.8788\n",
      "Iteration 110270: loss = 2.5355\n",
      "Iteration 110280: loss = 2.5797\n",
      "Iteration 110290: loss = 2.4879\n",
      "Iteration 110300: loss = 2.5854\n",
      "Iteration 110310: loss = 2.3770\n",
      "Iteration 110320: loss = 2.2397\n",
      "Iteration 110330: loss = 2.3283\n",
      "Iteration 110340: loss = 2.4011\n",
      "Iteration 110350: loss = 2.5497\n",
      "Iteration 110360: loss = 2.2232\n",
      "Iteration 110370: loss = 2.8172\n",
      "Iteration 110380: loss = 2.2308\n",
      "Iteration 110390: loss = 2.5977\n",
      "Iteration 110400: loss = 2.8259\n",
      "Iteration 110410: loss = 1.6870\n",
      "Iteration 110420: loss = 2.6477\n",
      "Iteration 110430: loss = 2.4507\n",
      "Iteration 110440: loss = 2.3093\n",
      "Iteration 110450: loss = 2.3098\n",
      "Iteration 110460: loss = 2.1912\n",
      "Iteration 110470: loss = 2.0489\n",
      "Iteration 110480: loss = 2.4033\n",
      "Iteration 110490: loss = 2.6734\n",
      "Iteration 110500: loss = 2.4640\n",
      "Iteration 110510: loss = 2.4489\n",
      "Iteration 110520: loss = 2.8401\n",
      "Iteration 110530: loss = 2.4769\n",
      "Iteration 110540: loss = 2.5298\n",
      "Iteration 110550: loss = 2.8001\n",
      "Iteration 110560: loss = 2.4006\n",
      "Iteration 110570: loss = 2.1072\n",
      "Iteration 110580: loss = 2.3962\n",
      "Iteration 110590: loss = 2.5288\n",
      "Iteration 110600: loss = 2.4509\n",
      "Iteration 110610: loss = 2.3647\n",
      "Iteration 110620: loss = 2.2161\n",
      "Iteration 110630: loss = 2.4561\n",
      "Iteration 110640: loss = 2.2315\n",
      "Iteration 110650: loss = 2.4364\n",
      "Iteration 110660: loss = 2.5488\n",
      "Iteration 110670: loss = 2.1492\n",
      "Iteration 110680: loss = 2.2802\n",
      "Iteration 110690: loss = 2.5218\n",
      "Iteration 110700: loss = 2.6860\n",
      "Iteration 110710: loss = 2.4497\n",
      "Iteration 110720: loss = 2.4497\n",
      "Iteration 110730: loss = 2.2135\n",
      "Iteration 110740: loss = 2.2752\n",
      "Iteration 110750: loss = 2.4587\n",
      "Iteration 110760: loss = 2.9097\n",
      "Iteration 110770: loss = 2.1930\n",
      "Iteration 110780: loss = 2.5741\n",
      "Iteration 110790: loss = 2.2424\n",
      "Iteration 110800: loss = 2.5242\n",
      "Iteration 110810: loss = 2.2323\n",
      "Iteration 110820: loss = 2.5107\n",
      "Iteration 110830: loss = 2.0790\n",
      "Iteration 110840: loss = 2.1263\n",
      "Iteration 110850: loss = 2.7874\n",
      "Iteration 110860: loss = 2.6763\n",
      "Iteration 110870: loss = 2.6929\n",
      "Iteration 110880: loss = 2.3609\n",
      "Iteration 110890: loss = 2.3842\n",
      "Iteration 110900: loss = 2.3083\n",
      "Iteration 110910: loss = 2.2569\n",
      "Iteration 110920: loss = 2.6241\n",
      "Iteration 110930: loss = 2.5187\n",
      "Iteration 110940: loss = 2.4750\n",
      "Iteration 110950: loss = 2.7255\n",
      "Iteration 110960: loss = 3.3113\n",
      "Iteration 110970: loss = 2.6016\n",
      "Iteration 110980: loss = 2.5916\n",
      "Iteration 110990: loss = 2.3454\n",
      "Iteration 111000: loss = 2.2466\n",
      "Iteration 111010: loss = 2.6415\n",
      "Iteration 111020: loss = 2.6247\n",
      "Iteration 111030: loss = 2.2828\n",
      "Iteration 111040: loss = 2.8863\n",
      "Iteration 111050: loss = 2.6441\n",
      "Iteration 111060: loss = 2.5410\n",
      "Iteration 111070: loss = 2.4924\n",
      "Iteration 111080: loss = 2.4430\n",
      "Iteration 111090: loss = 2.2106\n",
      "Iteration 111100: loss = 2.2115\n",
      "Iteration 111110: loss = 2.1005\n",
      "Iteration 111120: loss = 2.4092\n",
      "Iteration 111130: loss = 2.8133\n",
      "Iteration 111140: loss = 2.7615\n",
      "Iteration 111150: loss = 2.4713\n",
      "Iteration 111160: loss = 2.5212\n",
      "Iteration 111170: loss = 2.3617\n",
      "Iteration 111180: loss = 2.9454\n",
      "Iteration 111190: loss = 2.2129\n",
      "Iteration 111200: loss = 2.5144\n",
      "Iteration 111210: loss = 2.5414\n",
      "Iteration 111220: loss = 2.5702\n",
      "Iteration 111230: loss = 2.5580\n",
      "Iteration 111240: loss = 2.5401\n",
      "Iteration 111250: loss = 2.3785\n",
      "Iteration 111260: loss = 2.2339\n",
      "Iteration 111270: loss = 2.1070\n",
      "Iteration 111280: loss = 2.6395\n",
      "Iteration 111290: loss = 2.2315\n",
      "Iteration 111300: loss = 2.0979\n",
      "Iteration 111310: loss = 2.2848\n",
      "Iteration 111320: loss = 2.5070\n",
      "Iteration 111330: loss = 2.3134\n",
      "Iteration 111340: loss = 2.5903\n",
      "Iteration 111350: loss = 2.1826\n",
      "Iteration 111360: loss = 2.1164\n",
      "Iteration 111370: loss = 2.6504\n",
      "Iteration 111380: loss = 2.1283\n",
      "Iteration 111390: loss = 2.3994\n",
      "Iteration 111400: loss = 2.2087\n",
      "Iteration 111410: loss = 2.6951\n",
      "Iteration 111420: loss = 2.2889\n",
      "Iteration 111430: loss = 2.3573\n",
      "Iteration 111440: loss = 2.5267\n",
      "Iteration 111450: loss = 2.7824\n",
      "Iteration 111460: loss = 2.4105\n",
      "Iteration 111470: loss = 2.2456\n",
      "Iteration 111480: loss = 2.1973\n",
      "Iteration 111490: loss = 2.3675\n",
      "Iteration 111500: loss = 2.3488\n",
      "Iteration 111510: loss = 2.4329\n",
      "Iteration 111520: loss = 2.1318\n",
      "Iteration 111530: loss = 2.3612\n",
      "Iteration 111540: loss = 2.0495\n",
      "Iteration 111550: loss = 2.1799\n",
      "Iteration 111560: loss = 2.4362\n",
      "Iteration 111570: loss = 2.3507\n",
      "Iteration 111580: loss = 2.7916\n",
      "Iteration 111590: loss = 2.1822\n",
      "Iteration 111600: loss = 2.2290\n",
      "Iteration 111610: loss = 2.2728\n",
      "Iteration 111620: loss = 2.2737\n",
      "Iteration 111630: loss = 2.6096\n",
      "Iteration 111640: loss = 2.4593\n",
      "Iteration 111650: loss = 2.4436\n",
      "Iteration 111660: loss = 2.1249\n",
      "Iteration 111670: loss = 2.2362\n",
      "Iteration 111680: loss = 2.2971\n",
      "Iteration 111690: loss = 2.4488\n",
      "Iteration 111700: loss = 2.3277\n",
      "Iteration 111710: loss = 2.3402\n",
      "Iteration 111720: loss = 2.6631\n",
      "Iteration 111730: loss = 2.1105\n",
      "Iteration 111740: loss = 2.7858\n",
      "Iteration 111750: loss = 2.4377\n",
      "Iteration 111760: loss = 2.3429\n",
      "Iteration 111770: loss = 2.4492\n",
      "Iteration 111780: loss = 2.3923\n",
      "Iteration 111790: loss = 2.6132\n",
      "Iteration 111800: loss = 2.6265\n",
      "Iteration 111810: loss = 2.7033\n",
      "Iteration 111820: loss = 2.9352\n",
      "Iteration 111830: loss = 2.4528\n",
      "Iteration 111840: loss = 2.4510\n",
      "Iteration 111850: loss = 2.6823\n",
      "Iteration 111860: loss = 2.3613\n",
      "Iteration 111870: loss = 2.6588\n",
      "Iteration 111880: loss = 2.3530\n",
      "Iteration 111890: loss = 2.5463\n",
      "Iteration 111900: loss = 2.5650\n",
      "Iteration 111910: loss = 2.4339\n",
      "Iteration 111920: loss = 2.5875\n",
      "Iteration 111930: loss = 2.4048\n",
      "Iteration 111940: loss = 2.6995\n",
      "Iteration 111950: loss = 2.2989\n",
      "Iteration 111960: loss = 2.4464\n",
      "Iteration 111970: loss = 2.5759\n",
      "Iteration 111980: loss = 2.2832\n",
      "Iteration 111990: loss = 2.5324\n",
      "Iteration 112000: loss = 3.0842\n",
      "Iteration 112010: loss = 2.4489\n",
      "Iteration 112020: loss = 2.6918\n",
      "Iteration 112030: loss = 2.6000\n",
      "Iteration 112040: loss = 2.4929\n",
      "Iteration 112050: loss = 2.1330\n",
      "Iteration 112060: loss = 2.2156\n",
      "Iteration 112070: loss = 2.5562\n",
      "Iteration 112080: loss = 2.5612\n",
      "Iteration 112090: loss = 2.4174\n",
      "Iteration 112100: loss = 2.4318\n",
      "Iteration 112110: loss = 2.9736\n",
      "Iteration 112120: loss = 2.4649\n",
      "Iteration 112130: loss = 2.5610\n",
      "Iteration 112140: loss = 2.5751\n",
      "Iteration 112150: loss = 2.6939\n",
      "Iteration 112160: loss = 2.2393\n",
      "Iteration 112170: loss = 2.2779\n",
      "Iteration 112180: loss = 2.5283\n",
      "Iteration 112190: loss = 2.3097\n",
      "Iteration 112200: loss = 2.4692\n",
      "Iteration 112210: loss = 2.4227\n",
      "Iteration 112220: loss = 2.4582\n",
      "Iteration 112230: loss = 2.2672\n",
      "Iteration 112240: loss = 2.2482\n",
      "Iteration 112250: loss = 2.1148\n",
      "Iteration 112260: loss = 2.3702\n",
      "Iteration 112270: loss = 2.6631\n",
      "Iteration 112280: loss = 2.6826\n",
      "Iteration 112290: loss = 2.4553\n",
      "Iteration 112300: loss = 2.1199\n",
      "Iteration 112310: loss = 2.7966\n",
      "Iteration 112320: loss = 2.6666\n",
      "Iteration 112330: loss = 2.3430\n",
      "Iteration 112340: loss = 2.8705\n",
      "Iteration 112350: loss = 2.5912\n",
      "Iteration 112360: loss = 2.8119\n",
      "Iteration 112370: loss = 2.4283\n",
      "Iteration 112380: loss = 2.5473\n",
      "Iteration 112390: loss = 2.4140\n",
      "Iteration 112400: loss = 2.5420\n",
      "Iteration 112410: loss = 2.5763\n",
      "Iteration 112420: loss = 2.2839\n",
      "Iteration 112430: loss = 2.2811\n",
      "Iteration 112440: loss = 2.4967\n",
      "Iteration 112450: loss = 2.3781\n",
      "Iteration 112460: loss = 2.4778\n",
      "Iteration 112470: loss = 2.3103\n",
      "Iteration 112480: loss = 2.2787\n",
      "Iteration 112490: loss = 2.8402\n",
      "Iteration 112500: loss = 2.4056\n",
      "Iteration 112510: loss = 2.7941\n",
      "Iteration 112520: loss = 2.5223\n",
      "Iteration 112530: loss = 2.3133\n",
      "Iteration 112540: loss = 2.4918\n",
      "Iteration 112550: loss = 2.3484\n",
      "Iteration 112560: loss = 2.3190\n",
      "Iteration 112570: loss = 2.0133\n",
      "Iteration 112580: loss = 2.1497\n",
      "Iteration 112590: loss = 2.6616\n",
      "Iteration 112600: loss = 2.4492\n",
      "Iteration 112610: loss = 2.7128\n",
      "Iteration 112620: loss = 2.2249\n",
      "Iteration 112630: loss = 2.3671\n",
      "Iteration 112640: loss = 2.3440\n",
      "Iteration 112650: loss = 2.4775\n",
      "Iteration 112660: loss = 2.2379\n",
      "Iteration 112670: loss = 2.4176\n",
      "Iteration 112680: loss = 2.6249\n",
      "Iteration 112690: loss = 2.5378\n",
      "Iteration 112700: loss = 2.7222\n",
      "Iteration 112710: loss = 2.4476\n",
      "Iteration 112720: loss = 1.9961\n",
      "Iteration 112730: loss = 2.2209\n",
      "Iteration 112740: loss = 2.4151\n",
      "Iteration 112750: loss = 2.1905\n",
      "Iteration 112760: loss = 2.2421\n",
      "Iteration 112770: loss = 2.5796\n",
      "Iteration 112780: loss = 2.0631\n",
      "Iteration 112790: loss = 2.5601\n",
      "Iteration 112800: loss = 2.3965\n",
      "Iteration 112810: loss = 2.5549\n",
      "Iteration 112820: loss = 2.3981\n",
      "Iteration 112830: loss = 2.1151\n",
      "Iteration 112840: loss = 2.7911\n",
      "Iteration 112850: loss = 2.7119\n",
      "Iteration 112860: loss = 2.7497\n",
      "Iteration 112870: loss = 2.5327\n",
      "Iteration 112880: loss = 2.0096\n",
      "Iteration 112890: loss = 2.1562\n",
      "Iteration 112900: loss = 2.6408\n",
      "Iteration 112910: loss = 2.6619\n",
      "Iteration 112920: loss = 2.2308\n",
      "Iteration 112930: loss = 2.2131\n",
      "Iteration 112940: loss = 2.6119\n",
      "Iteration 112950: loss = 2.5164\n",
      "Iteration 112960: loss = 2.5817\n",
      "Iteration 112970: loss = 2.5337\n",
      "Iteration 112980: loss = 2.3746\n",
      "Iteration 112990: loss = 2.3661\n",
      "Iteration 113000: loss = 2.4746\n",
      "Iteration 113010: loss = 2.1953\n",
      "Iteration 113020: loss = 2.4289\n",
      "Iteration 113030: loss = 2.3498\n",
      "Iteration 113040: loss = 2.5134\n",
      "Iteration 113050: loss = 2.3160\n",
      "Iteration 113060: loss = 1.9523\n",
      "Iteration 113070: loss = 2.2415\n",
      "Iteration 113080: loss = 2.0916\n",
      "Iteration 113090: loss = 2.6447\n",
      "Iteration 113100: loss = 2.3619\n",
      "Iteration 113110: loss = 2.4039\n",
      "Iteration 113120: loss = 2.3643\n",
      "Iteration 113130: loss = 2.2050\n",
      "Iteration 113140: loss = 2.3781\n",
      "Iteration 113150: loss = 2.6270\n",
      "Iteration 113160: loss = 2.4498\n",
      "Iteration 113170: loss = 2.1838\n",
      "Iteration 113180: loss = 1.7323\n",
      "Iteration 113190: loss = 2.4869\n",
      "Iteration 113200: loss = 2.6315\n",
      "Iteration 113210: loss = 1.9898\n",
      "Iteration 113220: loss = 2.6645\n",
      "Iteration 113230: loss = 2.6883\n",
      "Iteration 113240: loss = 2.4252\n",
      "Iteration 113250: loss = 2.3009\n",
      "Iteration 113260: loss = 2.4631\n",
      "Iteration 113270: loss = 2.2858\n",
      "Iteration 113280: loss = 2.4469\n",
      "Iteration 113290: loss = 2.4396\n",
      "Iteration 113300: loss = 2.1903\n",
      "Iteration 113310: loss = 2.7264\n",
      "Iteration 113320: loss = 2.6110\n",
      "Iteration 113330: loss = 2.1316\n",
      "Iteration 113340: loss = 2.5191\n",
      "Iteration 113350: loss = 2.6464\n",
      "Iteration 113360: loss = 2.2735\n",
      "Iteration 113370: loss = 2.3579\n",
      "Iteration 113380: loss = 2.7156\n",
      "Iteration 113390: loss = 2.3836\n",
      "Iteration 113400: loss = 2.0377\n",
      "Iteration 113410: loss = 2.4452\n",
      "Iteration 113420: loss = 2.3374\n",
      "Iteration 113430: loss = 2.9094\n",
      "Iteration 113440: loss = 2.4137\n",
      "Iteration 113450: loss = 2.3045\n",
      "Iteration 113460: loss = 2.7556\n",
      "Iteration 113470: loss = 2.5529\n",
      "Iteration 113480: loss = 2.2872\n",
      "Iteration 113490: loss = 2.5457\n",
      "Iteration 113500: loss = 2.1797\n",
      "Iteration 113510: loss = 2.7232\n",
      "Iteration 113520: loss = 2.4009\n",
      "Iteration 113530: loss = 2.4774\n",
      "Iteration 113540: loss = 2.1578\n",
      "Iteration 113550: loss = 2.3787\n",
      "Iteration 113560: loss = 2.1519\n",
      "Iteration 113570: loss = 2.5614\n",
      "Iteration 113580: loss = 2.0285\n",
      "Iteration 113590: loss = 2.3264\n",
      "Iteration 113600: loss = 2.2488\n",
      "Iteration 113610: loss = 2.2118\n",
      "Iteration 113620: loss = 2.0337\n",
      "Iteration 113630: loss = 2.3724\n",
      "Iteration 113640: loss = 2.4081\n",
      "Iteration 113650: loss = 2.7761\n",
      "Iteration 113660: loss = 2.7074\n",
      "Iteration 113670: loss = 2.7471\n",
      "Iteration 113680: loss = 2.4261\n",
      "Iteration 113690: loss = 2.3996\n",
      "Iteration 113700: loss = 2.4899\n",
      "Iteration 113710: loss = 2.5858\n",
      "Iteration 113720: loss = 2.4058\n",
      "Iteration 113730: loss = 2.5259\n",
      "Iteration 113740: loss = 2.5999\n",
      "Iteration 113750: loss = 2.9041\n",
      "Iteration 113760: loss = 2.4060\n",
      "Iteration 113770: loss = 2.2288\n",
      "Iteration 113780: loss = 2.7224\n",
      "Iteration 113790: loss = 2.3362\n",
      "Iteration 113800: loss = 2.3895\n",
      "Iteration 113810: loss = 2.8010\n",
      "Iteration 113820: loss = 2.1431\n",
      "Iteration 113830: loss = 2.1896\n",
      "Iteration 113840: loss = 2.5865\n",
      "Iteration 113850: loss = 2.7075\n",
      "Iteration 113860: loss = 2.2755\n",
      "Iteration 113870: loss = 2.7869\n",
      "Iteration 113880: loss = 2.2678\n",
      "Iteration 113890: loss = 2.6710\n",
      "Iteration 113900: loss = 2.6887\n",
      "Iteration 113910: loss = 2.5638\n",
      "Iteration 113920: loss = 2.7580\n",
      "Iteration 113930: loss = 2.1840\n",
      "Iteration 113940: loss = 2.0389\n",
      "Iteration 113950: loss = 2.4183\n",
      "Iteration 113960: loss = 2.5109\n",
      "Iteration 113970: loss = 2.2842\n",
      "Iteration 113980: loss = 2.6362\n",
      "Iteration 113990: loss = 2.5487\n",
      "Iteration 114000: loss = 2.4560\n",
      "Iteration 114010: loss = 2.3948\n",
      "Iteration 114020: loss = 2.1603\n",
      "Iteration 114030: loss = 2.2674\n",
      "Iteration 114040: loss = 2.3662\n",
      "Iteration 114050: loss = 2.4375\n",
      "Iteration 114060: loss = 1.9829\n",
      "Iteration 114070: loss = 2.3600\n",
      "Iteration 114080: loss = 2.6025\n",
      "Iteration 114090: loss = 2.4851\n",
      "Iteration 114100: loss = 2.2360\n",
      "Iteration 114110: loss = 2.2723\n",
      "Iteration 114120: loss = 3.1392\n",
      "Iteration 114130: loss = 2.6329\n",
      "Iteration 114140: loss = 2.8586\n",
      "Iteration 114150: loss = 2.4532\n",
      "Iteration 114160: loss = 2.2936\n",
      "Iteration 114170: loss = 2.0553\n",
      "Iteration 114180: loss = 2.2480\n",
      "Iteration 114190: loss = 2.3682\n",
      "Iteration 114200: loss = 2.2165\n",
      "Iteration 114210: loss = 2.7409\n",
      "Iteration 114220: loss = 2.4678\n",
      "Iteration 114230: loss = 2.5937\n",
      "Iteration 114240: loss = 2.5008\n",
      "Iteration 114250: loss = 2.9612\n",
      "Iteration 114260: loss = 2.7615\n",
      "Iteration 114270: loss = 2.5212\n",
      "Iteration 114280: loss = 2.2454\n",
      "Iteration 114290: loss = 2.1703\n",
      "Iteration 114300: loss = 2.8274\n",
      "Iteration 114310: loss = 2.3430\n",
      "Iteration 114320: loss = 2.1699\n",
      "Iteration 114330: loss = 2.7998\n",
      "Iteration 114340: loss = 2.2916\n",
      "Iteration 114350: loss = 2.4318\n",
      "Iteration 114360: loss = 2.6982\n",
      "Iteration 114370: loss = 2.4222\n",
      "Iteration 114380: loss = 2.4882\n",
      "Iteration 114390: loss = 1.9689\n",
      "Iteration 114400: loss = 2.3937\n",
      "Iteration 114410: loss = 2.6791\n",
      "Iteration 114420: loss = 2.4798\n",
      "Iteration 114430: loss = 2.2551\n",
      "Iteration 114440: loss = 2.4550\n",
      "Iteration 114450: loss = 2.5455\n",
      "Iteration 114460: loss = 2.5015\n",
      "Iteration 114470: loss = 2.0675\n",
      "Iteration 114480: loss = 2.4690\n",
      "Iteration 114490: loss = 2.7879\n",
      "Iteration 114500: loss = 2.5231\n",
      "Iteration 114510: loss = 2.6299\n",
      "Iteration 114520: loss = 2.3522\n",
      "Iteration 114530: loss = 2.2223\n",
      "Iteration 114540: loss = 2.9301\n",
      "Iteration 114550: loss = 2.3360\n",
      "Iteration 114560: loss = 2.2477\n",
      "Iteration 114570: loss = 2.6100\n",
      "Iteration 114580: loss = 2.5636\n",
      "Iteration 114590: loss = 2.4862\n",
      "Iteration 114600: loss = 2.4827\n",
      "Iteration 114610: loss = 2.4395\n",
      "Iteration 114620: loss = 2.7322\n",
      "Iteration 114630: loss = 2.2486\n",
      "Iteration 114640: loss = 2.4693\n",
      "Iteration 114650: loss = 2.0663\n",
      "Iteration 114660: loss = 2.5545\n",
      "Iteration 114670: loss = 2.6523\n",
      "Iteration 114680: loss = 2.7157\n",
      "Iteration 114690: loss = 2.4578\n",
      "Iteration 114700: loss = 2.4015\n",
      "Iteration 114710: loss = 2.3201\n",
      "Iteration 114720: loss = 2.2685\n",
      "Iteration 114730: loss = 2.6527\n",
      "Iteration 114740: loss = 2.1715\n",
      "Iteration 114750: loss = 2.6039\n",
      "Iteration 114760: loss = 2.6769\n",
      "Iteration 114770: loss = 2.6582\n",
      "Iteration 114780: loss = 2.3105\n",
      "Iteration 114790: loss = 2.4163\n",
      "Iteration 114800: loss = 2.6385\n",
      "Iteration 114810: loss = 2.4278\n",
      "Iteration 114820: loss = 2.4913\n",
      "Iteration 114830: loss = 2.3450\n",
      "Iteration 114840: loss = 2.4686\n",
      "Iteration 114850: loss = 2.2076\n",
      "Iteration 114860: loss = 2.0712\n",
      "Iteration 114870: loss = 2.6176\n",
      "Iteration 114880: loss = 2.3395\n",
      "Iteration 114890: loss = 2.4099\n",
      "Iteration 114900: loss = 2.4407\n",
      "Iteration 114910: loss = 2.3086\n",
      "Iteration 114920: loss = 2.7481\n",
      "Iteration 114930: loss = 2.4190\n",
      "Iteration 114940: loss = 2.5506\n",
      "Iteration 114950: loss = 2.4362\n",
      "Iteration 114960: loss = 2.4839\n",
      "Iteration 114970: loss = 2.4030\n",
      "Iteration 114980: loss = 2.1887\n",
      "Iteration 114990: loss = 2.2298\n",
      "Iteration 115000: loss = 2.4817\n",
      "Iteration 115010: loss = 2.6424\n",
      "Iteration 115020: loss = 2.3873\n",
      "Iteration 115030: loss = 2.5630\n",
      "Iteration 115040: loss = 2.5901\n",
      "Iteration 115050: loss = 2.6023\n",
      "Iteration 115060: loss = 2.7514\n",
      "Iteration 115070: loss = 2.6067\n",
      "Iteration 115080: loss = 2.5662\n",
      "Iteration 115090: loss = 1.9933\n",
      "Iteration 115100: loss = 2.1980\n",
      "Iteration 115110: loss = 2.4727\n",
      "Iteration 115120: loss = 2.2798\n",
      "Iteration 115130: loss = 2.3502\n",
      "Iteration 115140: loss = 2.8051\n",
      "Iteration 115150: loss = 2.2249\n",
      "Iteration 115160: loss = 2.2481\n",
      "Iteration 115170: loss = 2.4635\n",
      "Iteration 115180: loss = 2.1732\n",
      "Iteration 115190: loss = 2.2862\n",
      "Iteration 115200: loss = 2.2329\n",
      "Iteration 115210: loss = 2.8580\n",
      "Iteration 115220: loss = 2.1093\n",
      "Iteration 115230: loss = 2.2998\n",
      "Iteration 115240: loss = 2.7252\n",
      "Iteration 115250: loss = 2.4831\n",
      "Iteration 115260: loss = 2.2087\n",
      "Iteration 115270: loss = 2.0855\n",
      "Iteration 115280: loss = 2.6360\n",
      "Iteration 115290: loss = 2.2425\n",
      "Iteration 115300: loss = 2.4185\n",
      "Iteration 115310: loss = 2.2205\n",
      "Iteration 115320: loss = 2.4114\n",
      "Iteration 115330: loss = 2.3439\n",
      "Iteration 115340: loss = 2.3248\n",
      "Iteration 115350: loss = 2.3932\n",
      "Iteration 115360: loss = 2.5470\n",
      "Iteration 115370: loss = 2.4120\n",
      "Iteration 115380: loss = 2.4246\n",
      "Iteration 115390: loss = 2.6169\n",
      "Iteration 115400: loss = 2.4178\n",
      "Iteration 115410: loss = 2.7940\n",
      "Iteration 115420: loss = 2.2965\n",
      "Iteration 115430: loss = 2.4816\n",
      "Iteration 115440: loss = 2.5448\n",
      "Iteration 115450: loss = 2.2234\n",
      "Iteration 115460: loss = 2.4596\n",
      "Iteration 115470: loss = 2.5112\n",
      "Iteration 115480: loss = 2.4078\n",
      "Iteration 115490: loss = 2.5256\n",
      "Iteration 115500: loss = 2.1977\n",
      "Iteration 115510: loss = 2.6743\n",
      "Iteration 115520: loss = 2.1941\n",
      "Iteration 115530: loss = 2.4391\n",
      "Iteration 115540: loss = 2.3162\n",
      "Iteration 115550: loss = 2.8591\n",
      "Iteration 115560: loss = 2.3381\n",
      "Iteration 115570: loss = 2.7485\n",
      "Iteration 115580: loss = 2.4877\n",
      "Iteration 115590: loss = 2.7223\n",
      "Iteration 115600: loss = 2.7308\n",
      "Iteration 115610: loss = 3.2286\n",
      "Iteration 115620: loss = 2.2911\n",
      "Iteration 115630: loss = 2.5657\n",
      "Iteration 115640: loss = 2.4907\n",
      "Iteration 115650: loss = 2.1620\n",
      "Iteration 115660: loss = 2.8364\n",
      "Iteration 115670: loss = 2.2096\n",
      "Iteration 115680: loss = 2.2740\n",
      "Iteration 115690: loss = 2.2012\n",
      "Iteration 115700: loss = 2.4632\n",
      "Iteration 115710: loss = 2.1808\n",
      "Iteration 115720: loss = 2.6380\n",
      "Iteration 115730: loss = 2.4362\n",
      "Iteration 115740: loss = 2.3222\n",
      "Iteration 115750: loss = 2.3037\n",
      "Iteration 115760: loss = 2.5039\n",
      "Iteration 115770: loss = 2.2376\n",
      "Iteration 115780: loss = 2.6705\n",
      "Iteration 115790: loss = 2.1559\n",
      "Iteration 115800: loss = 2.7223\n",
      "Iteration 115810: loss = 2.8066\n",
      "Iteration 115820: loss = 2.3620\n",
      "Iteration 115830: loss = 2.7211\n",
      "Iteration 115840: loss = 2.3636\n",
      "Iteration 115850: loss = 2.4065\n",
      "Iteration 115860: loss = 2.0847\n",
      "Iteration 115870: loss = 2.4202\n",
      "Iteration 115880: loss = 2.5296\n",
      "Iteration 115890: loss = 2.2598\n",
      "Iteration 115900: loss = 2.3997\n",
      "Iteration 115910: loss = 2.6364\n",
      "Iteration 115920: loss = 2.5183\n",
      "Iteration 115930: loss = 2.2532\n",
      "Iteration 115940: loss = 2.4235\n",
      "Iteration 115950: loss = 2.4303\n",
      "Iteration 115960: loss = 2.3301\n",
      "Iteration 115970: loss = 2.5657\n",
      "Iteration 115980: loss = 2.2497\n",
      "Iteration 115990: loss = 2.6562\n",
      "Iteration 116000: loss = 2.4249\n",
      "Iteration 116010: loss = 2.3722\n",
      "Iteration 116020: loss = 2.5685\n",
      "Iteration 116030: loss = 2.4668\n",
      "Iteration 116040: loss = 2.3196\n",
      "Iteration 116050: loss = 2.4145\n",
      "Iteration 116060: loss = 2.2733\n",
      "Iteration 116070: loss = 2.3655\n",
      "Iteration 116080: loss = 2.3704\n",
      "Iteration 116090: loss = 2.6405\n",
      "Iteration 116100: loss = 2.2107\n",
      "Iteration 116110: loss = 2.2556\n",
      "Iteration 116120: loss = 1.9023\n",
      "Iteration 116130: loss = 2.3968\n",
      "Iteration 116140: loss = 2.6684\n",
      "Iteration 116150: loss = 2.4495\n",
      "Iteration 116160: loss = 2.2553\n",
      "Iteration 116170: loss = 2.2534\n",
      "Iteration 116180: loss = 2.8079\n",
      "Iteration 116190: loss = 2.5017\n",
      "Iteration 116200: loss = 2.3517\n",
      "Iteration 116210: loss = 2.6078\n",
      "Iteration 116220: loss = 2.5147\n",
      "Iteration 116230: loss = 2.5857\n",
      "Iteration 116240: loss = 2.5318\n",
      "Iteration 116250: loss = 2.4411\n",
      "Iteration 116260: loss = 2.4605\n",
      "Iteration 116270: loss = 2.0893\n",
      "Iteration 116280: loss = 2.0359\n",
      "Iteration 116290: loss = 2.5543\n",
      "Iteration 116300: loss = 2.3500\n",
      "Iteration 116310: loss = 2.4389\n",
      "Iteration 116320: loss = 2.7738\n",
      "Iteration 116330: loss = 2.3270\n",
      "Iteration 116340: loss = 2.4412\n",
      "Iteration 116350: loss = 2.3648\n",
      "Iteration 116360: loss = 2.4845\n",
      "Iteration 116370: loss = 2.5977\n",
      "Iteration 116380: loss = 2.0482\n",
      "Iteration 116390: loss = 2.4747\n",
      "Iteration 116400: loss = 2.1654\n",
      "Iteration 116410: loss = 2.2642\n",
      "Iteration 116420: loss = 2.1025\n",
      "Iteration 116430: loss = 2.3465\n",
      "Iteration 116440: loss = 2.0832\n",
      "Iteration 116450: loss = 2.5779\n",
      "Iteration 116460: loss = 2.5079\n",
      "Iteration 116470: loss = 2.5358\n",
      "Iteration 116480: loss = 2.3724\n",
      "Iteration 116490: loss = 2.0781\n",
      "Iteration 116500: loss = 2.2880\n",
      "Iteration 116510: loss = 2.1896\n",
      "Iteration 116520: loss = 2.2480\n",
      "Iteration 116530: loss = 2.3724\n",
      "Iteration 116540: loss = 2.2407\n",
      "Iteration 116550: loss = 2.5050\n",
      "Iteration 116560: loss = 2.1653\n",
      "Iteration 116570: loss = 2.4780\n",
      "Iteration 116580: loss = 2.4055\n",
      "Iteration 116590: loss = 2.6456\n",
      "Iteration 116600: loss = 2.8919\n",
      "Iteration 116610: loss = 2.2756\n",
      "Iteration 116620: loss = 2.4527\n",
      "Iteration 116630: loss = 2.1782\n",
      "Iteration 116640: loss = 2.7675\n",
      "Iteration 116650: loss = 2.5853\n",
      "Iteration 116660: loss = 2.5332\n",
      "Iteration 116670: loss = 2.1260\n",
      "Iteration 116680: loss = 2.0321\n",
      "Iteration 116690: loss = 2.7029\n",
      "Iteration 116700: loss = 2.5209\n",
      "Iteration 116710: loss = 2.1196\n",
      "Iteration 116720: loss = 2.5428\n",
      "Iteration 116730: loss = 2.2551\n",
      "Iteration 116740: loss = 2.6672\n",
      "Iteration 116750: loss = 2.4855\n",
      "Iteration 116760: loss = 2.4337\n",
      "Iteration 116770: loss = 2.5060\n",
      "Iteration 116780: loss = 2.5776\n",
      "Iteration 116790: loss = 2.0827\n",
      "Iteration 116800: loss = 2.5795\n",
      "Iteration 116810: loss = 2.1608\n",
      "Iteration 116820: loss = 2.6188\n",
      "Iteration 116830: loss = 2.4862\n",
      "Iteration 116840: loss = 2.8290\n",
      "Iteration 116850: loss = 2.4538\n",
      "Iteration 116860: loss = 2.1265\n",
      "Iteration 116870: loss = 2.6349\n",
      "Iteration 116880: loss = 2.2038\n",
      "Iteration 116890: loss = 2.2137\n",
      "Iteration 116900: loss = 2.3118\n",
      "Iteration 116910: loss = 2.1696\n",
      "Iteration 116920: loss = 2.4188\n",
      "Iteration 116930: loss = 2.4682\n",
      "Iteration 116940: loss = 2.3095\n",
      "Iteration 116950: loss = 2.4354\n",
      "Iteration 116960: loss = 2.0339\n",
      "Iteration 116970: loss = 2.7293\n",
      "Iteration 116980: loss = 2.2427\n",
      "Iteration 116990: loss = 2.5951\n",
      "Iteration 117000: loss = 2.5863\n",
      "Iteration 117010: loss = 2.2467\n",
      "Iteration 117020: loss = 2.3898\n",
      "Iteration 117030: loss = 2.1227\n",
      "Iteration 117040: loss = 2.4827\n",
      "Iteration 117050: loss = 2.1763\n",
      "Iteration 117060: loss = 3.0250\n",
      "Iteration 117070: loss = 2.8205\n",
      "Iteration 117080: loss = 1.9968\n",
      "Iteration 117090: loss = 2.2177\n",
      "Iteration 117100: loss = 2.4250\n",
      "Iteration 117110: loss = 2.2085\n",
      "Iteration 117120: loss = 2.2483\n",
      "Iteration 117130: loss = 2.1604\n",
      "Iteration 117140: loss = 2.3625\n",
      "Iteration 117150: loss = 2.5644\n",
      "Iteration 117160: loss = 2.5035\n",
      "Iteration 117170: loss = 2.3471\n",
      "Iteration 117180: loss = 2.7601\n",
      "Iteration 117190: loss = 2.7886\n",
      "Iteration 117200: loss = 2.3406\n",
      "Iteration 117210: loss = 2.4029\n",
      "Iteration 117220: loss = 2.5825\n",
      "Iteration 117230: loss = 2.5896\n",
      "Iteration 117240: loss = 2.2521\n",
      "Iteration 117250: loss = 2.3220\n",
      "Iteration 117260: loss = 2.2189\n",
      "Iteration 117270: loss = 1.9536\n",
      "Iteration 117280: loss = 2.5609\n",
      "Iteration 117290: loss = 2.5155\n",
      "Iteration 117300: loss = 2.6521\n",
      "Iteration 117310: loss = 2.1083\n",
      "Iteration 117320: loss = 2.9332\n",
      "Iteration 117330: loss = 2.1308\n",
      "Iteration 117340: loss = 2.7984\n",
      "Iteration 117350: loss = 2.2953\n",
      "Iteration 117360: loss = 2.6802\n",
      "Iteration 117370: loss = 2.2695\n",
      "Iteration 117380: loss = 2.3573\n",
      "Iteration 117390: loss = 2.5010\n",
      "Iteration 117400: loss = 2.4276\n",
      "Iteration 117410: loss = 2.4425\n",
      "Iteration 117420: loss = 2.0680\n",
      "Iteration 117430: loss = 2.1846\n",
      "Iteration 117440: loss = 2.5857\n",
      "Iteration 117450: loss = 2.1789\n",
      "Iteration 117460: loss = 2.5572\n",
      "Iteration 117470: loss = 2.3598\n",
      "Iteration 117480: loss = 2.4170\n",
      "Iteration 117490: loss = 2.2878\n",
      "Iteration 117500: loss = 2.4874\n",
      "Iteration 117510: loss = 2.6209\n",
      "Iteration 117520: loss = 2.2156\n",
      "Iteration 117530: loss = 2.3024\n",
      "Iteration 117540: loss = 2.2860\n",
      "Iteration 117550: loss = 2.5631\n",
      "Iteration 117560: loss = 2.5517\n",
      "Iteration 117570: loss = 2.4904\n",
      "Iteration 117580: loss = 2.5321\n",
      "Iteration 117590: loss = 2.3081\n",
      "Iteration 117600: loss = 2.7948\n",
      "Iteration 117610: loss = 2.6894\n",
      "Iteration 117620: loss = 2.5950\n",
      "Iteration 117630: loss = 2.3085\n",
      "Iteration 117640: loss = 2.2916\n",
      "Iteration 117650: loss = 2.2953\n",
      "Iteration 117660: loss = 2.3753\n",
      "Iteration 117670: loss = 2.3025\n",
      "Iteration 117680: loss = 2.3679\n",
      "Iteration 117690: loss = 2.3863\n",
      "Iteration 117700: loss = 2.6890\n",
      "Iteration 117710: loss = 2.4390\n",
      "Iteration 117720: loss = 2.2150\n",
      "Iteration 117730: loss = 2.9006\n",
      "Iteration 117740: loss = 2.7152\n",
      "Iteration 117750: loss = 2.6206\n",
      "Iteration 117760: loss = 2.1833\n",
      "Iteration 117770: loss = 1.9042\n",
      "Iteration 117780: loss = 2.3100\n",
      "Iteration 117790: loss = 2.3428\n",
      "Iteration 117800: loss = 2.6962\n",
      "Iteration 117810: loss = 2.4651\n",
      "Iteration 117820: loss = 2.3362\n",
      "Iteration 117830: loss = 2.4301\n",
      "Iteration 117840: loss = 2.8222\n",
      "Iteration 117850: loss = 2.5497\n",
      "Iteration 117860: loss = 2.5381\n",
      "Iteration 117870: loss = 2.7680\n",
      "Iteration 117880: loss = 2.4627\n",
      "Iteration 117890: loss = 2.6430\n",
      "Iteration 117900: loss = 2.3467\n",
      "Iteration 117910: loss = 2.2270\n",
      "Iteration 117920: loss = 2.4679\n",
      "Iteration 117930: loss = 2.6778\n",
      "Iteration 117940: loss = 2.3211\n",
      "Iteration 117950: loss = 2.4826\n",
      "Iteration 117960: loss = 2.1617\n",
      "Iteration 117970: loss = 2.3895\n",
      "Iteration 117980: loss = 2.4033\n",
      "Iteration 117990: loss = 1.9485\n",
      "Iteration 118000: loss = 2.2895\n",
      "Iteration 118010: loss = 2.2121\n",
      "Iteration 118020: loss = 2.3558\n",
      "Iteration 118030: loss = 2.2482\n",
      "Iteration 118040: loss = 2.6037\n",
      "Iteration 118050: loss = 2.6160\n",
      "Iteration 118060: loss = 2.3096\n",
      "Iteration 118070: loss = 2.2163\n",
      "Iteration 118080: loss = 2.3619\n",
      "Iteration 118090: loss = 2.4483\n",
      "Iteration 118100: loss = 2.1809\n",
      "Iteration 118110: loss = 2.5408\n",
      "Iteration 118120: loss = 2.6396\n",
      "Iteration 118130: loss = 2.5666\n",
      "Iteration 118140: loss = 2.4808\n",
      "Iteration 118150: loss = 2.4069\n",
      "Iteration 118160: loss = 2.2546\n",
      "Iteration 118170: loss = 2.4372\n",
      "Iteration 118180: loss = 2.3919\n",
      "Iteration 118190: loss = 2.9250\n",
      "Iteration 118200: loss = 2.3861\n",
      "Iteration 118210: loss = 2.5755\n",
      "Iteration 118220: loss = 2.1960\n",
      "Iteration 118230: loss = 2.4244\n",
      "Iteration 118240: loss = 2.4347\n",
      "Iteration 118250: loss = 2.1567\n",
      "Iteration 118260: loss = 2.1832\n",
      "Iteration 118270: loss = 2.5910\n",
      "Iteration 118280: loss = 2.1167\n",
      "Iteration 118290: loss = 2.2342\n",
      "Iteration 118300: loss = 2.1548\n",
      "Iteration 118310: loss = 2.2678\n",
      "Iteration 118320: loss = 2.2271\n",
      "Iteration 118330: loss = 2.2444\n",
      "Iteration 118340: loss = 2.5303\n",
      "Iteration 118350: loss = 2.2746\n",
      "Iteration 118360: loss = 2.3280\n",
      "Iteration 118370: loss = 2.1401\n",
      "Iteration 118380: loss = 2.1834\n",
      "Iteration 118390: loss = 2.4169\n",
      "Iteration 118400: loss = 2.3783\n",
      "Iteration 118410: loss = 2.7351\n",
      "Iteration 118420: loss = 2.4786\n",
      "Iteration 118430: loss = 2.2283\n",
      "Iteration 118440: loss = 2.6382\n",
      "Iteration 118450: loss = 2.4820\n",
      "Iteration 118460: loss = 2.5790\n",
      "Iteration 118470: loss = 2.4331\n",
      "Iteration 118480: loss = 2.6144\n",
      "Iteration 118490: loss = 2.4738\n",
      "Iteration 118500: loss = 2.9042\n",
      "Iteration 118510: loss = 2.5542\n",
      "Iteration 118520: loss = 2.3161\n",
      "Iteration 118530: loss = 2.4054\n",
      "Iteration 118540: loss = 2.2679\n",
      "Iteration 118550: loss = 2.7405\n",
      "Iteration 118560: loss = 2.4174\n",
      "Iteration 118570: loss = 2.2990\n",
      "Iteration 118580: loss = 2.5838\n",
      "Iteration 118590: loss = 2.7112\n",
      "Iteration 118600: loss = 2.5591\n",
      "Iteration 118610: loss = 2.3601\n",
      "Iteration 118620: loss = 2.3833\n",
      "Iteration 118630: loss = 2.5570\n",
      "Iteration 118640: loss = 2.4646\n",
      "Iteration 118650: loss = 2.5502\n",
      "Iteration 118660: loss = 2.2780\n",
      "Iteration 118670: loss = 2.4041\n",
      "Iteration 118680: loss = 2.2313\n",
      "Iteration 118690: loss = 2.2504\n",
      "Iteration 118700: loss = 2.2732\n",
      "Iteration 118710: loss = 2.6419\n",
      "Iteration 118720: loss = 2.0317\n",
      "Iteration 118730: loss = 2.2024\n",
      "Iteration 118740: loss = 2.3360\n",
      "Iteration 118750: loss = 2.5288\n",
      "Iteration 118760: loss = 2.2967\n",
      "Iteration 118770: loss = 2.5029\n",
      "Iteration 118780: loss = 2.2590\n",
      "Iteration 118790: loss = 2.4584\n",
      "Iteration 118800: loss = 2.5647\n",
      "Iteration 118810: loss = 2.3295\n",
      "Iteration 118820: loss = 2.5595\n",
      "Iteration 118830: loss = 2.3487\n",
      "Iteration 118840: loss = 2.2916\n",
      "Iteration 118850: loss = 2.5340\n",
      "Iteration 118860: loss = 2.1569\n",
      "Iteration 118870: loss = 2.5233\n",
      "Iteration 118880: loss = 2.3891\n",
      "Iteration 118890: loss = 1.9678\n",
      "Iteration 118900: loss = 2.1618\n",
      "Iteration 118910: loss = 2.4079\n",
      "Iteration 118920: loss = 2.5265\n",
      "Iteration 118930: loss = 2.4683\n",
      "Iteration 118940: loss = 2.4557\n",
      "Iteration 118950: loss = 2.4596\n",
      "Iteration 118960: loss = 2.5268\n",
      "Iteration 118970: loss = 2.4532\n",
      "Iteration 118980: loss = 2.3171\n",
      "Iteration 118990: loss = 2.7170\n",
      "Iteration 119000: loss = 2.2381\n",
      "Iteration 119010: loss = 2.7191\n",
      "Iteration 119020: loss = 2.2304\n",
      "Iteration 119030: loss = 2.4513\n",
      "Iteration 119040: loss = 2.6077\n",
      "Iteration 119050: loss = 2.7182\n",
      "Iteration 119060: loss = 2.8052\n",
      "Iteration 119070: loss = 2.9765\n",
      "Iteration 119080: loss = 2.7274\n",
      "Iteration 119090: loss = 2.3349\n",
      "Iteration 119100: loss = 2.5130\n",
      "Iteration 119110: loss = 2.3480\n",
      "Iteration 119120: loss = 2.3619\n",
      "Iteration 119130: loss = 2.5669\n",
      "Iteration 119140: loss = 2.5589\n",
      "Iteration 119150: loss = 2.8495\n",
      "Iteration 119160: loss = 2.4764\n",
      "Iteration 119170: loss = 2.3136\n",
      "Iteration 119180: loss = 2.5338\n",
      "Iteration 119190: loss = 2.4364\n",
      "Iteration 119200: loss = 2.1542\n",
      "Iteration 119210: loss = 2.3068\n",
      "Iteration 119220: loss = 2.7302\n",
      "Iteration 119230: loss = 2.2153\n",
      "Iteration 119240: loss = 2.4336\n",
      "Iteration 119250: loss = 2.7520\n",
      "Iteration 119260: loss = 2.6079\n",
      "Iteration 119270: loss = 2.3334\n",
      "Iteration 119280: loss = 2.2580\n",
      "Iteration 119290: loss = 2.5146\n",
      "Iteration 119300: loss = 2.1708\n",
      "Iteration 119310: loss = 2.4252\n",
      "Iteration 119320: loss = 2.5023\n",
      "Iteration 119330: loss = 2.6589\n",
      "Iteration 119340: loss = 2.8316\n",
      "Iteration 119350: loss = 2.1146\n",
      "Iteration 119360: loss = 2.1866\n",
      "Iteration 119370: loss = 2.4046\n",
      "Iteration 119380: loss = 2.1924\n",
      "Iteration 119390: loss = 2.3915\n",
      "Iteration 119400: loss = 2.4269\n",
      "Iteration 119410: loss = 2.2293\n",
      "Iteration 119420: loss = 2.4644\n",
      "Iteration 119430: loss = 2.0871\n",
      "Iteration 119440: loss = 2.4121\n",
      "Iteration 119450: loss = 2.4487\n",
      "Iteration 119460: loss = 2.6899\n",
      "Iteration 119470: loss = 2.4688\n",
      "Iteration 119480: loss = 2.7135\n",
      "Iteration 119490: loss = 2.3264\n",
      "Iteration 119500: loss = 2.6560\n",
      "Iteration 119510: loss = 2.3650\n",
      "Iteration 119520: loss = 2.6905\n",
      "Iteration 119530: loss = 2.3010\n",
      "Iteration 119540: loss = 2.7950\n",
      "Iteration 119550: loss = 2.4019\n",
      "Iteration 119560: loss = 2.1981\n",
      "Iteration 119570: loss = 2.2981\n",
      "Iteration 119580: loss = 2.3587\n",
      "Iteration 119590: loss = 2.4839\n",
      "Iteration 119600: loss = 2.8710\n",
      "Iteration 119610: loss = 2.5925\n",
      "Iteration 119620: loss = 2.0504\n",
      "Iteration 119630: loss = 2.4929\n",
      "Iteration 119640: loss = 2.6268\n",
      "Iteration 119650: loss = 2.4568\n",
      "Iteration 119660: loss = 2.5101\n",
      "Iteration 119670: loss = 2.4045\n",
      "Iteration 119680: loss = 2.4375\n",
      "Iteration 119690: loss = 2.3851\n",
      "Iteration 119700: loss = 2.2353\n",
      "Iteration 119710: loss = 2.2509\n",
      "Iteration 119720: loss = 2.4643\n",
      "Iteration 119730: loss = 2.4195\n",
      "Iteration 119740: loss = 2.2203\n",
      "Iteration 119750: loss = 1.9506\n",
      "Iteration 119760: loss = 2.1463\n",
      "Iteration 119770: loss = 2.1264\n",
      "Iteration 119780: loss = 2.1986\n",
      "Iteration 119790: loss = 2.4913\n",
      "Iteration 119800: loss = 2.6613\n",
      "Iteration 119810: loss = 2.4206\n",
      "Iteration 119820: loss = 2.3813\n",
      "Iteration 119830: loss = 2.5207\n",
      "Iteration 119840: loss = 2.4950\n",
      "Iteration 119850: loss = 2.1229\n",
      "Iteration 119860: loss = 2.3331\n",
      "Iteration 119870: loss = 2.2402\n",
      "Iteration 119880: loss = 2.6935\n",
      "Iteration 119890: loss = 2.4350\n",
      "Iteration 119900: loss = 2.2232\n",
      "Iteration 119910: loss = 2.4503\n",
      "Iteration 119920: loss = 2.6245\n",
      "Iteration 119930: loss = 2.5193\n",
      "Iteration 119940: loss = 2.4708\n",
      "Iteration 119950: loss = 1.9676\n",
      "Iteration 119960: loss = 2.6674\n",
      "Iteration 119970: loss = 2.2065\n",
      "Iteration 119980: loss = 3.0340\n",
      "Iteration 119990: loss = 2.5354\n",
      "Iteration 120000: loss = 2.7985\n",
      "Iteration 120010: loss = 2.3806\n",
      "Iteration 120020: loss = 2.2655\n",
      "Iteration 120030: loss = 3.1723\n",
      "Iteration 120040: loss = 1.9473\n",
      "Iteration 120050: loss = 2.6088\n",
      "Iteration 120060: loss = 2.6194\n",
      "Iteration 120070: loss = 2.3228\n",
      "Iteration 120080: loss = 2.6180\n",
      "Iteration 120090: loss = 2.2171\n",
      "Iteration 120100: loss = 2.2577\n",
      "Iteration 120110: loss = 2.4546\n",
      "Iteration 120120: loss = 2.1340\n",
      "Iteration 120130: loss = 2.4301\n",
      "Iteration 120140: loss = 2.0079\n",
      "Iteration 120150: loss = 2.0579\n",
      "Iteration 120160: loss = 2.5127\n",
      "Iteration 120170: loss = 2.4539\n",
      "Iteration 120180: loss = 2.3900\n",
      "Iteration 120190: loss = 2.5555\n",
      "Iteration 120200: loss = 2.3789\n",
      "Iteration 120210: loss = 2.4626\n",
      "Iteration 120220: loss = 2.5663\n",
      "Iteration 120230: loss = 2.6507\n",
      "Iteration 120240: loss = 2.2684\n",
      "Iteration 120250: loss = 2.1735\n",
      "Iteration 120260: loss = 2.3985\n",
      "Iteration 120270: loss = 2.7839\n",
      "Iteration 120280: loss = 2.1503\n",
      "Iteration 120290: loss = 2.3948\n",
      "Iteration 120300: loss = 2.6822\n",
      "Iteration 120310: loss = 2.4922\n",
      "Iteration 120320: loss = 2.8723\n",
      "Iteration 120330: loss = 2.3923\n",
      "Iteration 120340: loss = 2.8119\n",
      "Iteration 120350: loss = 2.2493\n",
      "Iteration 120360: loss = 2.3884\n",
      "Iteration 120370: loss = 2.3435\n",
      "Iteration 120380: loss = 2.4942\n",
      "Iteration 120390: loss = 2.4268\n",
      "Iteration 120400: loss = 2.3225\n",
      "Iteration 120410: loss = 2.8970\n",
      "Iteration 120420: loss = 2.3801\n",
      "Iteration 120430: loss = 2.6333\n",
      "Iteration 120440: loss = 2.0718\n",
      "Iteration 120450: loss = 2.6728\n",
      "Iteration 120460: loss = 2.5077\n",
      "Iteration 120470: loss = 2.4984\n",
      "Iteration 120480: loss = 2.3496\n",
      "Iteration 120490: loss = 2.5940\n",
      "Iteration 120500: loss = 2.7281\n",
      "Iteration 120510: loss = 2.3636\n",
      "Iteration 120520: loss = 2.2808\n",
      "Iteration 120530: loss = 2.6264\n",
      "Iteration 120540: loss = 2.5452\n",
      "Iteration 120550: loss = 2.3193\n",
      "Iteration 120560: loss = 2.9824\n",
      "Iteration 120570: loss = 2.4221\n",
      "Iteration 120580: loss = 2.2187\n",
      "Iteration 120590: loss = 2.1644\n",
      "Iteration 120600: loss = 2.6420\n",
      "Iteration 120610: loss = 2.4121\n",
      "Iteration 120620: loss = 2.6094\n",
      "Iteration 120630: loss = 2.2538\n",
      "Iteration 120640: loss = 2.3844\n",
      "Iteration 120650: loss = 2.4383\n",
      "Iteration 120660: loss = 2.5643\n",
      "Iteration 120670: loss = 2.5962\n",
      "Iteration 120680: loss = 2.5339\n",
      "Iteration 120690: loss = 2.6762\n",
      "Iteration 120700: loss = 2.0631\n",
      "Iteration 120710: loss = 2.4123\n",
      "Iteration 120720: loss = 2.1155\n",
      "Iteration 120730: loss = 2.5662\n",
      "Iteration 120740: loss = 2.7827\n",
      "Iteration 120750: loss = 2.4745\n",
      "Iteration 120760: loss = 2.4468\n",
      "Iteration 120770: loss = 2.3099\n",
      "Iteration 120780: loss = 2.5510\n",
      "Iteration 120790: loss = 2.6070\n",
      "Iteration 120800: loss = 2.5702\n",
      "Iteration 120810: loss = 2.3590\n",
      "Iteration 120820: loss = 2.3713\n",
      "Iteration 120830: loss = 2.6725\n",
      "Iteration 120840: loss = 2.8883\n",
      "Iteration 120850: loss = 2.2705\n",
      "Iteration 120860: loss = 2.4938\n",
      "Iteration 120870: loss = 1.9766\n",
      "Iteration 120880: loss = 2.2779\n",
      "Iteration 120890: loss = 2.4301\n",
      "Iteration 120900: loss = 2.2247\n",
      "Iteration 120910: loss = 2.4032\n",
      "Iteration 120920: loss = 2.3410\n",
      "Iteration 120930: loss = 2.4431\n",
      "Iteration 120940: loss = 2.7835\n",
      "Iteration 120950: loss = 2.4435\n",
      "Iteration 120960: loss = 2.2328\n",
      "Iteration 120970: loss = 2.3263\n",
      "Iteration 120980: loss = 2.1386\n",
      "Iteration 120990: loss = 2.3270\n",
      "Iteration 121000: loss = 2.0993\n",
      "Iteration 121010: loss = 2.3353\n",
      "Iteration 121020: loss = 2.1682\n",
      "Iteration 121030: loss = 2.5911\n",
      "Iteration 121040: loss = 2.0432\n",
      "Iteration 121050: loss = 2.2379\n",
      "Iteration 121060: loss = 2.5534\n",
      "Iteration 121070: loss = 2.5767\n",
      "Iteration 121080: loss = 2.3754\n",
      "Iteration 121090: loss = 2.7474\n",
      "Iteration 121100: loss = 2.2143\n",
      "Iteration 121110: loss = 2.4078\n",
      "Iteration 121120: loss = 2.4101\n",
      "Iteration 121130: loss = 2.3869\n",
      "Iteration 121140: loss = 2.8441\n",
      "Iteration 121150: loss = 2.4613\n",
      "Iteration 121160: loss = 2.3682\n",
      "Iteration 121170: loss = 2.1828\n",
      "Iteration 121180: loss = 2.5713\n",
      "Iteration 121190: loss = 2.4729\n",
      "Iteration 121200: loss = 2.6293\n",
      "Iteration 121210: loss = 2.3365\n",
      "Iteration 121220: loss = 2.6115\n",
      "Iteration 121230: loss = 2.3107\n",
      "Iteration 121240: loss = 2.4923\n",
      "Iteration 121250: loss = 2.8716\n",
      "Iteration 121260: loss = 2.4688\n",
      "Iteration 121270: loss = 3.3645\n",
      "Iteration 121280: loss = 2.3551\n",
      "Iteration 121290: loss = 2.6502\n",
      "Iteration 121300: loss = 2.6121\n",
      "Iteration 121310: loss = 2.4506\n",
      "Iteration 121320: loss = 2.5455\n",
      "Iteration 121330: loss = 2.5975\n",
      "Iteration 121340: loss = 2.5747\n",
      "Iteration 121350: loss = 2.1015\n",
      "Iteration 121360: loss = 2.5372\n",
      "Iteration 121370: loss = 2.7834\n",
      "Iteration 121380: loss = 1.8832\n",
      "Iteration 121390: loss = 2.3100\n",
      "Iteration 121400: loss = 2.3839\n",
      "Iteration 121410: loss = 2.2628\n",
      "Iteration 121420: loss = 2.3475\n",
      "Iteration 121430: loss = 2.9174\n",
      "Iteration 121440: loss = 2.4923\n",
      "Iteration 121450: loss = 2.4680\n",
      "Iteration 121460: loss = 2.7935\n",
      "Iteration 121470: loss = 2.4766\n",
      "Iteration 121480: loss = 2.4758\n",
      "Iteration 121490: loss = 2.2688\n",
      "Iteration 121500: loss = 2.4367\n",
      "Iteration 121510: loss = 2.6501\n",
      "Iteration 121520: loss = 2.6927\n",
      "Iteration 121530: loss = 2.5511\n",
      "Iteration 121540: loss = 2.3224\n",
      "Iteration 121550: loss = 2.5843\n",
      "Iteration 121560: loss = 2.2206\n",
      "Iteration 121570: loss = 2.2701\n",
      "Iteration 121580: loss = 2.4730\n",
      "Iteration 121590: loss = 2.2546\n",
      "Iteration 121600: loss = 2.4285\n",
      "Iteration 121610: loss = 2.4574\n",
      "Iteration 121620: loss = 2.9042\n",
      "Iteration 121630: loss = 2.4215\n",
      "Iteration 121640: loss = 2.4091\n",
      "Iteration 121650: loss = 2.7497\n",
      "Iteration 121660: loss = 2.5690\n",
      "Iteration 121670: loss = 2.4161\n",
      "Iteration 121680: loss = 2.6382\n",
      "Iteration 121690: loss = 2.6354\n",
      "Iteration 121700: loss = 2.6351\n",
      "Iteration 121710: loss = 2.4292\n",
      "Iteration 121720: loss = 2.4630\n",
      "Iteration 121730: loss = 2.5360\n",
      "Iteration 121740: loss = 2.3161\n",
      "Iteration 121750: loss = 2.5175\n",
      "Iteration 121760: loss = 2.5046\n",
      "Iteration 121770: loss = 2.2121\n",
      "Iteration 121780: loss = 2.3311\n",
      "Iteration 121790: loss = 2.6998\n",
      "Iteration 121800: loss = 2.3438\n",
      "Iteration 121810: loss = 3.0282\n",
      "Iteration 121820: loss = 2.8068\n",
      "Iteration 121830: loss = 2.3961\n",
      "Iteration 121840: loss = 2.4446\n",
      "Iteration 121850: loss = 2.4789\n",
      "Iteration 121860: loss = 2.2866\n",
      "Iteration 121870: loss = 2.6273\n",
      "Iteration 121880: loss = 2.4760\n",
      "Iteration 121890: loss = 2.4713\n",
      "Iteration 121900: loss = 2.4499\n",
      "Iteration 121910: loss = 2.7789\n",
      "Iteration 121920: loss = 2.4767\n",
      "Iteration 121930: loss = 2.5289\n",
      "Iteration 121940: loss = 2.2874\n",
      "Iteration 121950: loss = 2.4690\n",
      "Iteration 121960: loss = 2.5675\n",
      "Iteration 121970: loss = 2.4373\n",
      "Iteration 121980: loss = 2.3467\n",
      "Iteration 121990: loss = 2.5768\n",
      "Iteration 122000: loss = 2.3136\n",
      "Iteration 122010: loss = 2.2190\n",
      "Iteration 122020: loss = 2.2150\n",
      "Iteration 122030: loss = 2.2684\n",
      "Iteration 122040: loss = 2.4249\n",
      "Iteration 122050: loss = 2.2768\n",
      "Iteration 122060: loss = 2.4285\n",
      "Iteration 122070: loss = 2.3456\n",
      "Iteration 122080: loss = 2.1951\n",
      "Iteration 122090: loss = 2.8094\n",
      "Iteration 122100: loss = 2.1173\n",
      "Iteration 122110: loss = 2.6132\n",
      "Iteration 122120: loss = 2.2727\n",
      "Iteration 122130: loss = 2.6122\n",
      "Iteration 122140: loss = 2.4059\n",
      "Iteration 122150: loss = 2.7620\n",
      "Iteration 122160: loss = 2.6958\n",
      "Iteration 122170: loss = 2.4071\n",
      "Iteration 122180: loss = 1.8898\n",
      "Iteration 122190: loss = 2.8023\n",
      "Iteration 122200: loss = 1.7665\n",
      "Iteration 122210: loss = 2.6215\n",
      "Iteration 122220: loss = 2.4481\n",
      "Iteration 122230: loss = 2.7900\n",
      "Iteration 122240: loss = 2.4718\n",
      "Iteration 122250: loss = 2.7548\n",
      "Iteration 122260: loss = 2.3110\n",
      "Iteration 122270: loss = 2.0470\n",
      "Iteration 122280: loss = 2.2259\n",
      "Iteration 122290: loss = 2.4148\n",
      "Iteration 122300: loss = 2.2640\n",
      "Iteration 122310: loss = 2.3462\n",
      "Iteration 122320: loss = 2.4471\n",
      "Iteration 122330: loss = 2.5601\n",
      "Iteration 122340: loss = 2.3068\n",
      "Iteration 122350: loss = 2.0798\n",
      "Iteration 122360: loss = 2.4090\n",
      "Iteration 122370: loss = 2.2329\n",
      "Iteration 122380: loss = 2.5171\n",
      "Iteration 122390: loss = 2.4067\n",
      "Iteration 122400: loss = 2.8020\n",
      "Iteration 122410: loss = 2.4719\n",
      "Iteration 122420: loss = 2.4983\n",
      "Iteration 122430: loss = 2.1844\n",
      "Iteration 122440: loss = 2.3218\n",
      "Iteration 122450: loss = 2.2910\n",
      "Iteration 122460: loss = 2.8507\n",
      "Iteration 122470: loss = 2.5130\n",
      "Iteration 122480: loss = 2.7070\n",
      "Iteration 122490: loss = 2.4727\n",
      "Iteration 122500: loss = 2.8581\n",
      "Iteration 122510: loss = 2.8024\n",
      "Iteration 122520: loss = 2.5723\n",
      "Iteration 122530: loss = 2.4060\n",
      "Iteration 122540: loss = 2.1586\n",
      "Iteration 122550: loss = 2.3682\n",
      "Iteration 122560: loss = 2.4224\n",
      "Iteration 122570: loss = 2.5620\n",
      "Iteration 122580: loss = 1.9066\n",
      "Iteration 122590: loss = 2.4250\n",
      "Iteration 122600: loss = 2.3774\n",
      "Iteration 122610: loss = 2.4409\n",
      "Iteration 122620: loss = 2.5118\n",
      "Iteration 122630: loss = 2.3015\n",
      "Iteration 122640: loss = 2.3740\n",
      "Iteration 122650: loss = 2.5421\n",
      "Iteration 122660: loss = 2.6644\n",
      "Iteration 122670: loss = 1.9857\n",
      "Iteration 122680: loss = 2.1374\n",
      "Iteration 122690: loss = 2.4743\n",
      "Iteration 122700: loss = 2.3822\n",
      "Iteration 122710: loss = 2.1489\n",
      "Iteration 122720: loss = 2.5563\n",
      "Iteration 122730: loss = 2.6372\n",
      "Iteration 122740: loss = 2.4789\n",
      "Iteration 122750: loss = 2.3558\n",
      "Iteration 122760: loss = 2.1772\n",
      "Iteration 122770: loss = 2.7300\n",
      "Iteration 122780: loss = 2.9774\n",
      "Iteration 122790: loss = 2.3494\n",
      "Iteration 122800: loss = 2.4852\n",
      "Iteration 122810: loss = 2.1664\n",
      "Iteration 122820: loss = 2.8107\n",
      "Iteration 122830: loss = 2.5386\n",
      "Iteration 122840: loss = 2.5056\n",
      "Iteration 122850: loss = 2.3621\n",
      "Iteration 122860: loss = 2.1417\n",
      "Iteration 122870: loss = 2.2389\n",
      "Iteration 122880: loss = 2.5176\n",
      "Iteration 122890: loss = 2.0036\n",
      "Iteration 122900: loss = 2.5999\n",
      "Iteration 122910: loss = 2.4005\n",
      "Iteration 122920: loss = 2.3791\n",
      "Iteration 122930: loss = 2.2188\n",
      "Iteration 122940: loss = 2.5086\n",
      "Iteration 122950: loss = 2.4961\n",
      "Iteration 122960: loss = 2.3918\n",
      "Iteration 122970: loss = 2.2535\n",
      "Iteration 122980: loss = 2.5052\n",
      "Iteration 122990: loss = 2.0589\n",
      "Iteration 123000: loss = 2.5707\n",
      "Iteration 123010: loss = 2.2200\n",
      "Iteration 123020: loss = 2.5295\n",
      "Iteration 123030: loss = 2.6083\n",
      "Iteration 123040: loss = 2.5518\n",
      "Iteration 123050: loss = 2.4396\n",
      "Iteration 123060: loss = 2.6381\n",
      "Iteration 123070: loss = 2.2378\n",
      "Iteration 123080: loss = 2.3321\n",
      "Iteration 123090: loss = 2.5551\n",
      "Iteration 123100: loss = 2.4519\n",
      "Iteration 123110: loss = 2.7835\n",
      "Iteration 123120: loss = 2.5808\n",
      "Iteration 123130: loss = 2.3164\n",
      "Iteration 123140: loss = 2.3601\n",
      "Iteration 123150: loss = 2.3678\n",
      "Iteration 123160: loss = 2.2351\n",
      "Iteration 123170: loss = 2.0745\n",
      "Iteration 123180: loss = 2.4846\n",
      "Iteration 123190: loss = 2.2871\n",
      "Iteration 123200: loss = 2.5645\n",
      "Iteration 123210: loss = 2.2676\n",
      "Iteration 123220: loss = 2.5764\n",
      "Iteration 123230: loss = 2.2283\n",
      "Iteration 123240: loss = 2.4459\n",
      "Iteration 123250: loss = 2.3958\n",
      "Iteration 123260: loss = 1.8147\n",
      "Iteration 123270: loss = 2.4122\n",
      "Iteration 123280: loss = 2.3034\n",
      "Iteration 123290: loss = 2.5184\n",
      "Iteration 123300: loss = 2.5209\n",
      "Iteration 123310: loss = 2.6581\n",
      "Iteration 123320: loss = 2.6142\n",
      "Iteration 123330: loss = 2.2881\n",
      "Iteration 123340: loss = 2.2457\n",
      "Iteration 123350: loss = 2.4423\n",
      "Iteration 123360: loss = 2.2971\n",
      "Iteration 123370: loss = 2.5887\n",
      "Iteration 123380: loss = 2.4982\n",
      "Iteration 123390: loss = 2.3479\n",
      "Iteration 123400: loss = 3.0069\n",
      "Iteration 123410: loss = 2.5715\n",
      "Iteration 123420: loss = 1.9370\n",
      "Iteration 123430: loss = 2.4926\n",
      "Iteration 123440: loss = 2.4457\n",
      "Iteration 123450: loss = 2.6627\n",
      "Iteration 123460: loss = 2.5596\n",
      "Iteration 123470: loss = 2.0550\n",
      "Iteration 123480: loss = 2.5776\n",
      "Iteration 123490: loss = 2.2800\n",
      "Iteration 123500: loss = 2.2166\n",
      "Iteration 123510: loss = 2.4165\n",
      "Iteration 123520: loss = 2.6937\n",
      "Iteration 123530: loss = 2.4061\n",
      "Iteration 123540: loss = 2.2839\n",
      "Iteration 123550: loss = 2.1893\n",
      "Iteration 123560: loss = 2.4111\n",
      "Iteration 123570: loss = 2.5719\n",
      "Iteration 123580: loss = 2.0596\n",
      "Iteration 123590: loss = 2.4440\n",
      "Iteration 123600: loss = 2.4865\n",
      "Iteration 123610: loss = 2.6787\n",
      "Iteration 123620: loss = 2.3988\n",
      "Iteration 123630: loss = 2.1402\n",
      "Iteration 123640: loss = 2.5536\n",
      "Iteration 123650: loss = 2.5661\n",
      "Iteration 123660: loss = 2.3606\n",
      "Iteration 123670: loss = 2.5783\n",
      "Iteration 123680: loss = 2.3186\n",
      "Iteration 123690: loss = 2.5693\n",
      "Iteration 123700: loss = 2.3657\n",
      "Iteration 123710: loss = 2.8095\n",
      "Iteration 123720: loss = 2.6331\n",
      "Iteration 123730: loss = 2.2435\n",
      "Iteration 123740: loss = 2.5815\n",
      "Iteration 123750: loss = 2.3317\n",
      "Iteration 123760: loss = 2.3701\n",
      "Iteration 123770: loss = 2.2263\n",
      "Iteration 123780: loss = 2.6949\n",
      "Iteration 123790: loss = 2.6612\n",
      "Iteration 123800: loss = 2.2770\n",
      "Iteration 123810: loss = 2.1727\n",
      "Iteration 123820: loss = 2.4203\n",
      "Iteration 123830: loss = 2.4929\n",
      "Iteration 123840: loss = 2.3042\n",
      "Iteration 123850: loss = 2.5616\n",
      "Iteration 123860: loss = 2.2931\n",
      "Iteration 123870: loss = 2.5967\n",
      "Iteration 123880: loss = 2.1456\n",
      "Iteration 123890: loss = 1.9040\n",
      "Iteration 123900: loss = 2.6086\n",
      "Iteration 123910: loss = 1.8895\n",
      "Iteration 123920: loss = 2.5332\n",
      "Iteration 123930: loss = 2.5344\n",
      "Iteration 123940: loss = 2.4044\n",
      "Iteration 123950: loss = 2.3515\n",
      "Iteration 123960: loss = 2.1843\n",
      "Iteration 123970: loss = 2.6512\n",
      "Iteration 123980: loss = 2.6428\n",
      "Iteration 123990: loss = 2.4749\n",
      "Iteration 124000: loss = 2.4837\n",
      "Iteration 124010: loss = 2.3601\n",
      "Iteration 124020: loss = 2.3667\n",
      "Iteration 124030: loss = 2.7727\n",
      "Iteration 124040: loss = 2.4633\n",
      "Iteration 124050: loss = 2.4127\n",
      "Iteration 124060: loss = 2.3682\n",
      "Iteration 124070: loss = 2.6883\n",
      "Iteration 124080: loss = 2.4327\n",
      "Iteration 124090: loss = 2.4351\n",
      "Iteration 124100: loss = 2.3615\n",
      "Iteration 124110: loss = 2.5655\n",
      "Iteration 124120: loss = 2.4925\n",
      "Iteration 124130: loss = 2.1558\n",
      "Iteration 124140: loss = 2.2469\n",
      "Iteration 124150: loss = 2.3439\n",
      "Iteration 124160: loss = 2.2684\n",
      "Iteration 124170: loss = 2.6731\n",
      "Iteration 124180: loss = 2.4728\n",
      "Iteration 124190: loss = 2.5330\n",
      "Iteration 124200: loss = 2.4173\n",
      "Iteration 124210: loss = 2.5308\n",
      "Iteration 124220: loss = 2.3802\n",
      "Iteration 124230: loss = 2.4488\n",
      "Iteration 124240: loss = 2.3732\n",
      "Iteration 124250: loss = 2.1557\n",
      "Iteration 124260: loss = 2.2544\n",
      "Iteration 124270: loss = 2.6309\n",
      "Iteration 124280: loss = 2.4246\n",
      "Iteration 124290: loss = 2.6836\n",
      "Iteration 124300: loss = 2.6204\n",
      "Iteration 124310: loss = 2.5503\n",
      "Iteration 124320: loss = 2.3674\n",
      "Iteration 124330: loss = 2.0048\n",
      "Iteration 124340: loss = 2.4542\n",
      "Iteration 124350: loss = 2.4870\n",
      "Iteration 124360: loss = 2.7058\n",
      "Iteration 124370: loss = 2.2236\n",
      "Iteration 124380: loss = 2.3701\n",
      "Iteration 124390: loss = 2.6481\n",
      "Iteration 124400: loss = 2.3323\n",
      "Iteration 124410: loss = 2.4577\n",
      "Iteration 124420: loss = 2.3589\n",
      "Iteration 124430: loss = 2.6259\n",
      "Iteration 124440: loss = 2.2413\n",
      "Iteration 124450: loss = 2.6530\n",
      "Iteration 124460: loss = 2.3324\n",
      "Iteration 124470: loss = 2.3136\n",
      "Iteration 124480: loss = 2.4336\n",
      "Iteration 124490: loss = 2.2241\n",
      "Iteration 124500: loss = 2.3366\n",
      "Iteration 124510: loss = 2.4576\n",
      "Iteration 124520: loss = 2.4901\n",
      "Iteration 124530: loss = 2.1836\n",
      "Iteration 124540: loss = 2.7922\n",
      "Iteration 124550: loss = 2.6927\n",
      "Iteration 124560: loss = 2.7011\n",
      "Iteration 124570: loss = 2.2999\n",
      "Iteration 124580: loss = 2.5459\n",
      "Iteration 124590: loss = 2.1322\n",
      "Iteration 124600: loss = 2.3344\n",
      "Iteration 124610: loss = 2.5345\n",
      "Iteration 124620: loss = 2.2170\n",
      "Iteration 124630: loss = 2.5050\n",
      "Iteration 124640: loss = 2.4142\n",
      "Iteration 124650: loss = 2.6145\n",
      "Iteration 124660: loss = 2.0578\n",
      "Iteration 124670: loss = 2.3887\n",
      "Iteration 124680: loss = 1.9449\n",
      "Iteration 124690: loss = 2.3614\n",
      "Iteration 124700: loss = 2.8138\n",
      "Iteration 124710: loss = 2.2816\n",
      "Iteration 124720: loss = 2.3398\n",
      "Iteration 124730: loss = 2.4225\n",
      "Iteration 124740: loss = 2.6303\n",
      "Iteration 124750: loss = 3.0496\n",
      "Iteration 124760: loss = 2.2798\n",
      "Iteration 124770: loss = 2.4119\n",
      "Iteration 124780: loss = 2.1856\n",
      "Iteration 124790: loss = 2.1521\n",
      "Iteration 124800: loss = 2.2247\n",
      "Iteration 124810: loss = 2.4827\n",
      "Iteration 124820: loss = 2.0552\n",
      "Iteration 124830: loss = 2.3562\n",
      "Iteration 124840: loss = 2.3677\n",
      "Iteration 124850: loss = 2.6349\n",
      "Iteration 124860: loss = 2.5029\n",
      "Iteration 124870: loss = 2.4033\n",
      "Iteration 124880: loss = 2.3671\n",
      "Iteration 124890: loss = 2.3516\n",
      "Iteration 124900: loss = 2.6752\n",
      "Iteration 124910: loss = 2.4037\n",
      "Iteration 124920: loss = 2.3093\n",
      "Iteration 124930: loss = 2.5690\n",
      "Iteration 124940: loss = 2.6301\n",
      "Iteration 124950: loss = 2.4795\n",
      "Iteration 124960: loss = 1.9918\n",
      "Iteration 124970: loss = 2.0856\n",
      "Iteration 124980: loss = 2.5324\n",
      "Iteration 124990: loss = 2.3363\n",
      "Iteration 125000: loss = 2.2928\n",
      "Iteration 125010: loss = 2.4696\n",
      "Iteration 125020: loss = 3.0725\n",
      "Iteration 125030: loss = 2.4536\n",
      "Iteration 125040: loss = 2.6825\n",
      "Iteration 125050: loss = 2.6010\n",
      "Iteration 125060: loss = 2.3589\n",
      "Iteration 125070: loss = 2.2499\n",
      "Iteration 125080: loss = 2.6677\n",
      "Iteration 125090: loss = 2.3517\n",
      "Iteration 125100: loss = 2.6727\n",
      "Iteration 125110: loss = 2.6268\n",
      "Iteration 125120: loss = 2.5141\n",
      "Iteration 125130: loss = 2.8229\n",
      "Iteration 125140: loss = 2.4096\n",
      "Iteration 125150: loss = 2.2117\n",
      "Iteration 125160: loss = 2.3363\n",
      "Iteration 125170: loss = 2.1331\n",
      "Iteration 125180: loss = 2.3600\n",
      "Iteration 125190: loss = 2.4982\n",
      "Iteration 125200: loss = 2.4372\n",
      "Iteration 125210: loss = 2.4249\n",
      "Iteration 125220: loss = 2.1294\n",
      "Iteration 125230: loss = 2.0441\n",
      "Iteration 125240: loss = 2.5666\n",
      "Iteration 125250: loss = 2.2841\n",
      "Iteration 125260: loss = 2.1538\n",
      "Iteration 125270: loss = 2.6127\n",
      "Iteration 125280: loss = 2.5397\n",
      "Iteration 125290: loss = 2.5715\n",
      "Iteration 125300: loss = 2.0159\n",
      "Iteration 125310: loss = 2.3599\n",
      "Iteration 125320: loss = 2.2572\n",
      "Iteration 125330: loss = 2.8157\n",
      "Iteration 125340: loss = 2.3987\n",
      "Iteration 125350: loss = 2.5858\n",
      "Iteration 125360: loss = 2.0995\n",
      "Iteration 125370: loss = 2.0463\n",
      "Iteration 125380: loss = 2.2918\n",
      "Iteration 125390: loss = 2.4437\n",
      "Iteration 125400: loss = 2.2486\n",
      "Iteration 125410: loss = 2.1347\n",
      "Iteration 125420: loss = 2.6172\n",
      "Iteration 125430: loss = 2.1635\n",
      "Iteration 125440: loss = 2.4060\n",
      "Iteration 125450: loss = 2.5283\n",
      "Iteration 125460: loss = 2.7217\n",
      "Iteration 125470: loss = 2.3900\n",
      "Iteration 125480: loss = 3.0745\n",
      "Iteration 125490: loss = 2.5141\n",
      "Iteration 125500: loss = 2.3745\n",
      "Iteration 125510: loss = 2.5396\n",
      "Iteration 125520: loss = 2.5664\n",
      "Iteration 125530: loss = 2.7416\n",
      "Iteration 125540: loss = 2.3810\n",
      "Iteration 125550: loss = 2.3983\n",
      "Iteration 125560: loss = 2.5219\n",
      "Iteration 125570: loss = 2.0682\n",
      "Iteration 125580: loss = 2.2779\n",
      "Iteration 125590: loss = 2.4918\n",
      "Iteration 125600: loss = 2.6144\n",
      "Iteration 125610: loss = 2.3418\n",
      "Iteration 125620: loss = 2.4187\n",
      "Iteration 125630: loss = 2.2662\n",
      "Iteration 125640: loss = 2.5373\n",
      "Iteration 125650: loss = 2.1342\n",
      "Iteration 125660: loss = 1.9694\n",
      "Iteration 125670: loss = 2.1794\n",
      "Iteration 125680: loss = 2.4827\n",
      "Iteration 125690: loss = 2.5883\n",
      "Iteration 125700: loss = 2.3035\n",
      "Iteration 125710: loss = 2.3223\n",
      "Iteration 125720: loss = 2.7123\n",
      "Iteration 125730: loss = 2.5306\n",
      "Iteration 125740: loss = 2.4289\n",
      "Iteration 125750: loss = 2.1081\n",
      "Iteration 125760: loss = 2.3935\n",
      "Iteration 125770: loss = 3.2943\n",
      "Iteration 125780: loss = 2.4331\n",
      "Iteration 125790: loss = 2.4019\n",
      "Iteration 125800: loss = 2.2163\n",
      "Iteration 125810: loss = 2.6936\n",
      "Iteration 125820: loss = 2.4325\n",
      "Iteration 125830: loss = 2.1516\n",
      "Iteration 125840: loss = 2.3981\n",
      "Iteration 125850: loss = 2.0426\n",
      "Iteration 125860: loss = 2.0240\n",
      "Iteration 125870: loss = 2.3455\n",
      "Iteration 125880: loss = 2.6086\n",
      "Iteration 125890: loss = 2.4597\n",
      "Iteration 125900: loss = 2.1611\n",
      "Iteration 125910: loss = 2.3483\n",
      "Iteration 125920: loss = 2.5045\n",
      "Iteration 125930: loss = 2.3804\n",
      "Iteration 125940: loss = 2.2108\n",
      "Iteration 125950: loss = 2.6013\n",
      "Iteration 125960: loss = 2.5793\n",
      "Iteration 125970: loss = 2.1421\n",
      "Iteration 125980: loss = 2.5006\n",
      "Iteration 125990: loss = 2.0905\n",
      "Iteration 126000: loss = 2.4952\n",
      "Iteration 126010: loss = 2.2463\n",
      "Iteration 126020: loss = 2.2517\n",
      "Iteration 126030: loss = 2.6078\n",
      "Iteration 126040: loss = 2.2679\n",
      "Iteration 126050: loss = 2.3458\n",
      "Iteration 126060: loss = 2.3008\n",
      "Iteration 126070: loss = 2.2719\n",
      "Iteration 126080: loss = 2.9091\n",
      "Iteration 126090: loss = 2.5705\n",
      "Iteration 126100: loss = 2.4494\n",
      "Iteration 126110: loss = 2.2635\n",
      "Iteration 126120: loss = 2.3330\n",
      "Iteration 126130: loss = 2.4469\n",
      "Iteration 126140: loss = 2.6998\n",
      "Iteration 126150: loss = 2.0832\n",
      "Iteration 126160: loss = 2.5936\n",
      "Iteration 126170: loss = 2.5432\n",
      "Iteration 126180: loss = 2.4400\n",
      "Iteration 126190: loss = 2.5044\n",
      "Iteration 126200: loss = 2.2137\n",
      "Iteration 126210: loss = 2.5476\n",
      "Iteration 126220: loss = 1.8495\n",
      "Iteration 126230: loss = 2.5884\n",
      "Iteration 126240: loss = 2.0608\n",
      "Iteration 126250: loss = 2.5499\n",
      "Iteration 126260: loss = 2.2643\n",
      "Iteration 126270: loss = 2.7140\n",
      "Iteration 126280: loss = 2.1083\n",
      "Iteration 126290: loss = 2.9637\n",
      "Iteration 126300: loss = 2.1094\n",
      "Iteration 126310: loss = 2.5906\n",
      "Iteration 126320: loss = 2.1218\n",
      "Iteration 126330: loss = 2.6078\n",
      "Iteration 126340: loss = 2.0683\n",
      "Iteration 126350: loss = 2.1073\n",
      "Iteration 126360: loss = 2.2210\n",
      "Iteration 126370: loss = 2.5106\n",
      "Iteration 126380: loss = 2.6701\n",
      "Iteration 126390: loss = 2.3929\n",
      "Iteration 126400: loss = 2.5714\n",
      "Iteration 126410: loss = 2.6783\n",
      "Iteration 126420: loss = 2.6507\n",
      "Iteration 126430: loss = 2.5603\n",
      "Iteration 126440: loss = 2.1189\n",
      "Iteration 126450: loss = 2.1989\n",
      "Iteration 126460: loss = 2.2686\n",
      "Iteration 126470: loss = 2.4079\n",
      "Iteration 126480: loss = 2.1942\n",
      "Iteration 126490: loss = 2.0953\n",
      "Iteration 126500: loss = 1.9340\n",
      "Iteration 126510: loss = 2.3041\n",
      "Iteration 126520: loss = 2.3750\n",
      "Iteration 126530: loss = 2.1432\n",
      "Iteration 126540: loss = 2.3081\n",
      "Iteration 126550: loss = 2.3655\n",
      "Iteration 126560: loss = 2.2466\n",
      "Iteration 126570: loss = 2.3233\n",
      "Iteration 126580: loss = 2.3995\n",
      "Iteration 126590: loss = 2.2833\n",
      "Iteration 126600: loss = 1.8966\n",
      "Iteration 126610: loss = 2.4699\n",
      "Iteration 126620: loss = 2.5822\n",
      "Iteration 126630: loss = 2.3345\n",
      "Iteration 126640: loss = 2.1314\n",
      "Iteration 126650: loss = 2.6730\n",
      "Iteration 126660: loss = 2.5346\n",
      "Iteration 126670: loss = 2.5670\n",
      "Iteration 126680: loss = 2.8934\n",
      "Iteration 126690: loss = 2.2923\n",
      "Iteration 126700: loss = 2.3332\n",
      "Iteration 126710: loss = 2.5898\n",
      "Iteration 126720: loss = 2.4145\n",
      "Iteration 126730: loss = 2.6370\n",
      "Iteration 126740: loss = 2.2592\n",
      "Iteration 126750: loss = 2.3216\n",
      "Iteration 126760: loss = 2.2032\n",
      "Iteration 126770: loss = 2.4692\n",
      "Iteration 126780: loss = 2.5918\n",
      "Iteration 126790: loss = 2.5048\n",
      "Iteration 126800: loss = 2.3893\n",
      "Iteration 126810: loss = 2.7534\n",
      "Iteration 126820: loss = 2.6037\n",
      "Iteration 126830: loss = 2.0573\n",
      "Iteration 126840: loss = 2.4689\n",
      "Iteration 126850: loss = 2.7376\n",
      "Iteration 126860: loss = 2.6040\n",
      "Iteration 126870: loss = 2.5029\n",
      "Iteration 126880: loss = 2.4056\n",
      "Iteration 126890: loss = 2.3971\n",
      "Iteration 126900: loss = 2.0592\n",
      "Iteration 126910: loss = 2.2791\n",
      "Iteration 126920: loss = 2.6278\n",
      "Iteration 126930: loss = 2.5300\n",
      "Iteration 126940: loss = 2.2657\n",
      "Iteration 126950: loss = 2.2975\n",
      "Iteration 126960: loss = 2.1712\n",
      "Iteration 126970: loss = 2.6478\n",
      "Iteration 126980: loss = 2.2736\n",
      "Iteration 126990: loss = 2.1720\n",
      "Iteration 127000: loss = 2.5332\n",
      "Iteration 127010: loss = 2.0653\n",
      "Iteration 127020: loss = 2.3657\n",
      "Iteration 127030: loss = 2.5262\n",
      "Iteration 127040: loss = 2.1332\n",
      "Iteration 127050: loss = 2.3355\n",
      "Iteration 127060: loss = 2.7541\n",
      "Iteration 127070: loss = 2.3586\n",
      "Iteration 127080: loss = 2.1756\n",
      "Iteration 127090: loss = 2.4458\n",
      "Iteration 127100: loss = 2.5227\n",
      "Iteration 127110: loss = 2.4488\n",
      "Iteration 127120: loss = 2.1952\n",
      "Iteration 127130: loss = 2.6522\n",
      "Iteration 127140: loss = 2.2803\n",
      "Iteration 127150: loss = 2.7652\n",
      "Iteration 127160: loss = 2.6625\n",
      "Iteration 127170: loss = 2.8020\n",
      "Iteration 127180: loss = 2.9166\n",
      "Iteration 127190: loss = 2.6207\n",
      "Iteration 127200: loss = 2.4549\n",
      "Iteration 127210: loss = 2.1737\n",
      "Iteration 127220: loss = 2.4212\n",
      "Iteration 127230: loss = 2.4496\n",
      "Iteration 127240: loss = 2.3545\n",
      "Iteration 127250: loss = 2.1025\n",
      "Iteration 127260: loss = 2.4131\n",
      "Iteration 127270: loss = 2.5511\n",
      "Iteration 127280: loss = 2.5185\n",
      "Iteration 127290: loss = 2.1996\n",
      "Iteration 127300: loss = 2.4683\n",
      "Iteration 127310: loss = 2.4915\n",
      "Iteration 127320: loss = 2.2806\n",
      "Iteration 127330: loss = 2.4795\n",
      "Iteration 127340: loss = 2.6817\n",
      "Iteration 127350: loss = 2.6938\n",
      "Iteration 127360: loss = 2.3791\n",
      "Iteration 127370: loss = 2.5953\n",
      "Iteration 127380: loss = 2.2142\n",
      "Iteration 127390: loss = 2.2957\n",
      "Iteration 127400: loss = 2.3829\n",
      "Iteration 127410: loss = 2.5701\n",
      "Iteration 127420: loss = 2.3345\n",
      "Iteration 127430: loss = 2.7032\n",
      "Iteration 127440: loss = 2.4767\n",
      "Iteration 127450: loss = 2.7465\n",
      "Iteration 127460: loss = 2.4149\n",
      "Iteration 127470: loss = 2.4503\n",
      "Iteration 127480: loss = 2.4748\n",
      "Iteration 127490: loss = 2.6784\n",
      "Iteration 127500: loss = 2.6511\n",
      "Iteration 127510: loss = 2.2671\n",
      "Iteration 127520: loss = 2.3934\n",
      "Iteration 127530: loss = 2.6365\n",
      "Iteration 127540: loss = 2.5080\n",
      "Iteration 127550: loss = 2.3306\n",
      "Iteration 127560: loss = 2.3760\n",
      "Iteration 127570: loss = 2.6702\n",
      "Iteration 127580: loss = 2.4953\n",
      "Iteration 127590: loss = 2.1946\n",
      "Iteration 127600: loss = 2.3161\n",
      "Iteration 127610: loss = 2.4784\n",
      "Iteration 127620: loss = 2.2912\n",
      "Iteration 127630: loss = 2.4546\n",
      "Iteration 127640: loss = 2.5116\n",
      "Iteration 127650: loss = 2.3862\n",
      "Iteration 127660: loss = 2.2467\n",
      "Iteration 127670: loss = 2.4290\n",
      "Iteration 127680: loss = 2.4701\n",
      "Iteration 127690: loss = 2.8135\n",
      "Iteration 127700: loss = 2.1197\n",
      "Iteration 127710: loss = 2.7665\n",
      "Iteration 127720: loss = 2.2674\n",
      "Iteration 127730: loss = 2.3484\n",
      "Iteration 127740: loss = 2.9640\n",
      "Iteration 127750: loss = 2.5874\n",
      "Iteration 127760: loss = 2.1743\n",
      "Iteration 127770: loss = 2.6296\n",
      "Iteration 127780: loss = 2.3153\n",
      "Iteration 127790: loss = 2.7953\n",
      "Iteration 127800: loss = 2.3626\n",
      "Iteration 127810: loss = 2.5248\n",
      "Iteration 127820: loss = 2.6186\n",
      "Iteration 127830: loss = 2.3798\n",
      "Iteration 127840: loss = 2.5188\n",
      "Iteration 127850: loss = 2.4421\n",
      "Iteration 127860: loss = 2.2240\n",
      "Iteration 127870: loss = 2.3537\n",
      "Iteration 127880: loss = 2.0771\n",
      "Iteration 127890: loss = 2.5991\n",
      "Iteration 127900: loss = 2.7884\n",
      "Iteration 127910: loss = 2.6282\n",
      "Iteration 127920: loss = 2.3100\n",
      "Iteration 127930: loss = 2.2674\n",
      "Iteration 127940: loss = 2.3470\n",
      "Iteration 127950: loss = 2.4195\n",
      "Iteration 127960: loss = 2.3159\n",
      "Iteration 127970: loss = 2.2938\n",
      "Iteration 127980: loss = 2.3442\n",
      "Iteration 127990: loss = 2.5951\n",
      "Iteration 128000: loss = 2.1731\n",
      "Iteration 128010: loss = 2.5753\n",
      "Iteration 128020: loss = 2.2335\n",
      "Iteration 128030: loss = 2.7540\n",
      "Iteration 128040: loss = 2.3359\n",
      "Iteration 128050: loss = 2.3327\n",
      "Iteration 128060: loss = 2.5748\n",
      "Iteration 128070: loss = 2.6098\n",
      "Iteration 128080: loss = 2.6375\n",
      "Iteration 128090: loss = 2.5143\n",
      "Iteration 128100: loss = 2.7173\n",
      "Iteration 128110: loss = 2.4867\n",
      "Iteration 128120: loss = 2.5280\n",
      "Iteration 128130: loss = 2.3163\n",
      "Iteration 128140: loss = 2.4818\n",
      "Iteration 128150: loss = 2.7557\n",
      "Iteration 128160: loss = 2.3073\n",
      "Iteration 128170: loss = 2.2082\n",
      "Iteration 128180: loss = 2.5137\n",
      "Iteration 128190: loss = 2.3756\n",
      "Iteration 128200: loss = 2.5506\n",
      "Iteration 128210: loss = 2.4397\n",
      "Iteration 128220: loss = 2.5642\n",
      "Iteration 128230: loss = 2.2881\n",
      "Iteration 128240: loss = 2.1793\n",
      "Iteration 128250: loss = 2.6779\n",
      "Iteration 128260: loss = 2.2163\n",
      "Iteration 128270: loss = 2.4798\n",
      "Iteration 128280: loss = 2.1927\n",
      "Iteration 128290: loss = 2.6294\n",
      "Iteration 128300: loss = 2.6505\n",
      "Iteration 128310: loss = 2.5781\n",
      "Iteration 128320: loss = 2.5217\n",
      "Iteration 128330: loss = 2.4427\n",
      "Iteration 128340: loss = 2.4305\n",
      "Iteration 128350: loss = 2.3063\n",
      "Iteration 128360: loss = 2.5331\n",
      "Iteration 128370: loss = 2.2176\n",
      "Iteration 128380: loss = 2.3702\n",
      "Iteration 128390: loss = 2.5836\n",
      "Iteration 128400: loss = 2.7914\n",
      "Iteration 128410: loss = 2.7899\n",
      "Iteration 128420: loss = 2.2917\n",
      "Iteration 128430: loss = 2.2160\n",
      "Iteration 128440: loss = 2.0354\n",
      "Iteration 128450: loss = 2.7548\n",
      "Iteration 128460: loss = 2.1529\n",
      "Iteration 128470: loss = 1.8576\n",
      "Iteration 128480: loss = 2.5487\n",
      "Iteration 128490: loss = 2.5186\n",
      "Iteration 128500: loss = 2.6824\n",
      "Iteration 128510: loss = 2.4470\n",
      "Iteration 128520: loss = 2.2943\n",
      "Iteration 128530: loss = 2.4449\n",
      "Iteration 128540: loss = 2.3619\n",
      "Iteration 128550: loss = 2.7066\n",
      "Iteration 128560: loss = 2.7507\n",
      "Iteration 128570: loss = 2.3270\n",
      "Iteration 128580: loss = 2.7562\n",
      "Iteration 128590: loss = 2.3283\n",
      "Iteration 128600: loss = 2.4478\n",
      "Iteration 128610: loss = 2.3005\n",
      "Iteration 128620: loss = 2.3183\n",
      "Iteration 128630: loss = 2.4098\n",
      "Iteration 128640: loss = 2.6597\n",
      "Iteration 128650: loss = 2.6164\n",
      "Iteration 128660: loss = 2.7379\n",
      "Iteration 128670: loss = 2.8901\n",
      "Iteration 128680: loss = 2.3774\n",
      "Iteration 128690: loss = 2.5352\n",
      "Iteration 128700: loss = 2.7101\n",
      "Iteration 128710: loss = 2.2588\n",
      "Iteration 128720: loss = 2.6027\n",
      "Iteration 128730: loss = 2.4201\n",
      "Iteration 128740: loss = 2.3891\n",
      "Iteration 128750: loss = 2.1500\n",
      "Iteration 128760: loss = 2.7242\n",
      "Iteration 128770: loss = 2.5136\n",
      "Iteration 128780: loss = 2.2509\n",
      "Iteration 128790: loss = 2.2786\n",
      "Iteration 128800: loss = 2.5284\n",
      "Iteration 128810: loss = 2.4440\n",
      "Iteration 128820: loss = 2.0367\n",
      "Iteration 128830: loss = 2.4876\n",
      "Iteration 128840: loss = 1.8575\n",
      "Iteration 128850: loss = 2.2890\n",
      "Iteration 128860: loss = 2.2923\n",
      "Iteration 128870: loss = 2.1935\n",
      "Iteration 128880: loss = 2.4773\n",
      "Iteration 128890: loss = 2.2010\n",
      "Iteration 128900: loss = 2.3344\n",
      "Iteration 128910: loss = 2.8545\n",
      "Iteration 128920: loss = 2.5658\n",
      "Iteration 128930: loss = 2.4065\n",
      "Iteration 128940: loss = 2.3473\n",
      "Iteration 128950: loss = 2.2351\n",
      "Iteration 128960: loss = 2.4601\n",
      "Iteration 128970: loss = 2.0936\n",
      "Iteration 128980: loss = 2.4511\n",
      "Iteration 128990: loss = 2.5227\n",
      "Iteration 129000: loss = 2.5199\n",
      "Iteration 129010: loss = 2.5010\n",
      "Iteration 129020: loss = 2.6381\n",
      "Iteration 129030: loss = 2.4850\n",
      "Iteration 129040: loss = 2.4678\n",
      "Iteration 129050: loss = 2.6593\n",
      "Iteration 129060: loss = 2.2489\n",
      "Iteration 129070: loss = 2.2327\n",
      "Iteration 129080: loss = 2.5329\n",
      "Iteration 129090: loss = 2.1334\n",
      "Iteration 129100: loss = 2.0587\n",
      "Iteration 129110: loss = 2.4913\n",
      "Iteration 129120: loss = 2.0536\n",
      "Iteration 129130: loss = 2.3742\n",
      "Iteration 129140: loss = 2.4187\n",
      "Iteration 129150: loss = 2.1809\n",
      "Iteration 129160: loss = 2.6169\n",
      "Iteration 129170: loss = 2.2182\n",
      "Iteration 129180: loss = 2.2944\n",
      "Iteration 129190: loss = 2.5570\n",
      "Iteration 129200: loss = 2.3573\n",
      "Iteration 129210: loss = 2.4819\n",
      "Iteration 129220: loss = 2.5712\n",
      "Iteration 129230: loss = 2.3164\n",
      "Iteration 129240: loss = 2.1396\n",
      "Iteration 129250: loss = 2.3721\n",
      "Iteration 129260: loss = 2.6609\n",
      "Iteration 129270: loss = 2.6764\n",
      "Iteration 129280: loss = 2.5706\n",
      "Iteration 129290: loss = 2.4458\n",
      "Iteration 129300: loss = 2.6607\n",
      "Iteration 129310: loss = 2.4685\n",
      "Iteration 129320: loss = 2.4865\n",
      "Iteration 129330: loss = 2.3584\n",
      "Iteration 129340: loss = 2.3457\n",
      "Iteration 129350: loss = 2.6821\n",
      "Iteration 129360: loss = 2.3767\n",
      "Iteration 129370: loss = 2.1828\n",
      "Iteration 129380: loss = 2.3117\n",
      "Iteration 129390: loss = 2.4283\n",
      "Iteration 129400: loss = 2.4403\n",
      "Iteration 129410: loss = 2.3480\n",
      "Iteration 129420: loss = 2.5565\n",
      "Iteration 129430: loss = 2.4586\n",
      "Iteration 129440: loss = 2.2990\n",
      "Iteration 129450: loss = 2.5338\n",
      "Iteration 129460: loss = 2.3770\n",
      "Iteration 129470: loss = 2.8766\n",
      "Iteration 129480: loss = 2.5784\n",
      "Iteration 129490: loss = 2.4432\n",
      "Iteration 129500: loss = 2.5558\n",
      "Iteration 129510: loss = 2.2652\n",
      "Iteration 129520: loss = 2.3219\n",
      "Iteration 129530: loss = 2.1276\n",
      "Iteration 129540: loss = 2.0968\n",
      "Iteration 129550: loss = 3.0104\n",
      "Iteration 129560: loss = 2.2169\n",
      "Iteration 129570: loss = 2.5219\n",
      "Iteration 129580: loss = 2.3978\n",
      "Iteration 129590: loss = 2.7761\n",
      "Iteration 129600: loss = 2.3301\n",
      "Iteration 129610: loss = 2.0672\n",
      "Iteration 129620: loss = 2.3755\n",
      "Iteration 129630: loss = 2.1982\n",
      "Iteration 129640: loss = 2.1718\n",
      "Iteration 129650: loss = 2.3930\n",
      "Iteration 129660: loss = 2.8083\n",
      "Iteration 129670: loss = 2.4549\n",
      "Iteration 129680: loss = 2.5335\n",
      "Iteration 129690: loss = 2.5152\n",
      "Iteration 129700: loss = 2.5557\n",
      "Iteration 129710: loss = 2.4512\n",
      "Iteration 129720: loss = 2.2820\n",
      "Iteration 129730: loss = 2.3037\n",
      "Iteration 129740: loss = 2.7083\n",
      "Iteration 129750: loss = 2.7128\n",
      "Iteration 129760: loss = 2.5886\n",
      "Iteration 129770: loss = 2.5635\n",
      "Iteration 129780: loss = 2.5661\n",
      "Iteration 129790: loss = 2.5754\n",
      "Iteration 129800: loss = 2.2514\n",
      "Iteration 129810: loss = 2.0995\n",
      "Iteration 129820: loss = 2.5988\n",
      "Iteration 129830: loss = 2.3769\n",
      "Iteration 129840: loss = 2.3815\n",
      "Iteration 129850: loss = 2.4461\n",
      "Iteration 129860: loss = 2.4766\n",
      "Iteration 129870: loss = 2.6850\n",
      "Iteration 129880: loss = 2.0999\n",
      "Iteration 129890: loss = 2.3225\n",
      "Iteration 129900: loss = 2.5054\n",
      "Iteration 129910: loss = 2.7125\n",
      "Iteration 129920: loss = 2.6359\n",
      "Iteration 129930: loss = 2.3118\n",
      "Iteration 129940: loss = 2.3844\n",
      "Iteration 129950: loss = 2.4166\n",
      "Iteration 129960: loss = 2.3238\n",
      "Iteration 129970: loss = 2.4750\n",
      "Iteration 129980: loss = 2.6300\n",
      "Iteration 129990: loss = 2.4835\n",
      "Iteration 130000: loss = 2.2622\n",
      "Iteration 130010: loss = 2.0681\n",
      "Iteration 130020: loss = 2.3735\n",
      "Iteration 130030: loss = 2.4635\n",
      "Iteration 130040: loss = 2.9590\n",
      "Iteration 130050: loss = 2.3169\n",
      "Iteration 130060: loss = 2.4433\n",
      "Iteration 130070: loss = 2.5190\n",
      "Iteration 130080: loss = 2.1928\n",
      "Iteration 130090: loss = 2.3613\n",
      "Iteration 130100: loss = 2.3728\n",
      "Iteration 130110: loss = 2.3872\n",
      "Iteration 130120: loss = 2.5533\n",
      "Iteration 130130: loss = 2.4074\n",
      "Iteration 130140: loss = 2.5418\n",
      "Iteration 130150: loss = 2.2718\n",
      "Iteration 130160: loss = 2.5769\n",
      "Iteration 130170: loss = 2.4980\n",
      "Iteration 130180: loss = 2.3395\n",
      "Iteration 130190: loss = 2.4414\n",
      "Iteration 130200: loss = 2.4015\n",
      "Iteration 130210: loss = 2.6834\n",
      "Iteration 130220: loss = 2.9781\n",
      "Iteration 130230: loss = 2.3569\n",
      "Iteration 130240: loss = 2.1644\n",
      "Iteration 130250: loss = 2.6495\n",
      "Iteration 130260: loss = 2.5562\n",
      "Iteration 130270: loss = 2.5679\n",
      "Iteration 130280: loss = 2.3376\n",
      "Iteration 130290: loss = 2.8022\n",
      "Iteration 130300: loss = 2.4930\n",
      "Iteration 130310: loss = 2.3844\n",
      "Iteration 130320: loss = 2.2458\n",
      "Iteration 130330: loss = 2.4480\n",
      "Iteration 130340: loss = 2.5704\n",
      "Iteration 130350: loss = 2.6696\n",
      "Iteration 130360: loss = 2.4070\n",
      "Iteration 130370: loss = 2.4483\n",
      "Iteration 130380: loss = 2.4214\n",
      "Iteration 130390: loss = 2.2782\n",
      "Iteration 130400: loss = 2.1570\n",
      "Iteration 130410: loss = 2.6211\n",
      "Iteration 130420: loss = 2.3970\n",
      "Iteration 130430: loss = 2.6147\n",
      "Iteration 130440: loss = 2.5167\n",
      "Iteration 130450: loss = 2.1373\n",
      "Iteration 130460: loss = 2.2330\n",
      "Iteration 130470: loss = 2.1493\n",
      "Iteration 130480: loss = 2.7569\n",
      "Iteration 130490: loss = 2.6679\n",
      "Iteration 130500: loss = 2.6352\n",
      "Iteration 130510: loss = 2.4658\n",
      "Iteration 130520: loss = 2.9134\n",
      "Iteration 130530: loss = 2.0990\n",
      "Iteration 130540: loss = 2.3134\n",
      "Iteration 130550: loss = 2.5615\n",
      "Iteration 130560: loss = 2.1684\n",
      "Iteration 130570: loss = 2.2323\n",
      "Iteration 130580: loss = 2.3258\n",
      "Iteration 130590: loss = 2.2896\n",
      "Iteration 130600: loss = 2.3348\n",
      "Iteration 130610: loss = 2.3117\n",
      "Iteration 130620: loss = 2.2106\n",
      "Iteration 130630: loss = 2.8304\n",
      "Iteration 130640: loss = 2.5330\n",
      "Iteration 130650: loss = 2.2189\n",
      "Iteration 130660: loss = 2.3593\n",
      "Iteration 130670: loss = 2.6219\n",
      "Iteration 130680: loss = 2.4677\n",
      "Iteration 130690: loss = 2.2429\n",
      "Iteration 130700: loss = 2.4654\n",
      "Iteration 130710: loss = 2.2648\n",
      "Iteration 130720: loss = 2.6672\n",
      "Iteration 130730: loss = 2.3407\n",
      "Iteration 130740: loss = 2.3763\n",
      "Iteration 130750: loss = 2.2035\n",
      "Iteration 130760: loss = 2.7275\n",
      "Iteration 130770: loss = 2.4497\n",
      "Iteration 130780: loss = 2.4096\n",
      "Iteration 130790: loss = 2.4997\n",
      "Iteration 130800: loss = 2.6884\n",
      "Iteration 130810: loss = 2.2644\n",
      "Iteration 130820: loss = 2.2005\n",
      "Iteration 130830: loss = 2.0962\n",
      "Iteration 130840: loss = 3.2870\n",
      "Iteration 130850: loss = 2.3423\n",
      "Iteration 130860: loss = 2.2111\n",
      "Iteration 130870: loss = 2.5627\n",
      "Iteration 130880: loss = 2.9034\n",
      "Iteration 130890: loss = 2.6058\n",
      "Iteration 130900: loss = 2.6443\n",
      "Iteration 130910: loss = 2.6573\n",
      "Iteration 130920: loss = 2.0843\n",
      "Iteration 130930: loss = 2.6275\n",
      "Iteration 130940: loss = 2.4743\n",
      "Iteration 130950: loss = 2.6677\n",
      "Iteration 130960: loss = 2.4250\n",
      "Iteration 130970: loss = 2.6351\n",
      "Iteration 130980: loss = 2.5412\n",
      "Iteration 130990: loss = 2.6529\n",
      "Iteration 131000: loss = 2.2521\n",
      "Iteration 131010: loss = 3.0584\n",
      "Iteration 131020: loss = 2.8167\n",
      "Iteration 131030: loss = 2.3903\n",
      "Iteration 131040: loss = 2.5569\n",
      "Iteration 131050: loss = 2.7013\n",
      "Iteration 131060: loss = 2.5555\n",
      "Iteration 131070: loss = 2.3041\n",
      "Iteration 131080: loss = 2.3367\n",
      "Iteration 131090: loss = 2.4314\n",
      "Iteration 131100: loss = 2.2813\n",
      "Iteration 131110: loss = 2.6363\n",
      "Iteration 131120: loss = 2.3499\n",
      "Iteration 131130: loss = 2.2974\n",
      "Iteration 131140: loss = 2.6445\n",
      "Iteration 131150: loss = 2.7647\n",
      "Iteration 131160: loss = 2.3179\n",
      "Iteration 131170: loss = 2.4265\n",
      "Iteration 131180: loss = 2.3571\n",
      "Iteration 131190: loss = 2.6136\n",
      "Iteration 131200: loss = 2.4304\n",
      "Iteration 131210: loss = 2.4131\n",
      "Iteration 131220: loss = 2.6008\n",
      "Iteration 131230: loss = 2.5792\n",
      "Iteration 131240: loss = 2.3837\n",
      "Iteration 131250: loss = 2.4072\n",
      "Iteration 131260: loss = 2.4362\n",
      "Iteration 131270: loss = 2.6524\n",
      "Iteration 131280: loss = 2.5115\n",
      "Iteration 131290: loss = 2.7257\n",
      "Iteration 131300: loss = 2.7329\n",
      "Iteration 131310: loss = 2.4930\n",
      "Iteration 131320: loss = 2.2527\n",
      "Iteration 131330: loss = 2.2527\n",
      "Iteration 131340: loss = 2.3360\n",
      "Iteration 131350: loss = 2.5159\n",
      "Iteration 131360: loss = 2.2062\n",
      "Iteration 131370: loss = 2.4928\n",
      "Iteration 131380: loss = 2.4389\n",
      "Iteration 131390: loss = 2.3499\n",
      "Iteration 131400: loss = 2.4725\n",
      "Iteration 131410: loss = 2.2347\n",
      "Iteration 131420: loss = 2.4135\n",
      "Iteration 131430: loss = 2.6221\n",
      "Iteration 131440: loss = 2.5304\n",
      "Iteration 131450: loss = 2.4876\n",
      "Iteration 131460: loss = 2.4044\n",
      "Iteration 131470: loss = 2.4648\n",
      "Iteration 131480: loss = 2.0248\n",
      "Iteration 131490: loss = 2.4332\n",
      "Iteration 131500: loss = 2.5416\n",
      "Iteration 131510: loss = 1.9147\n",
      "Iteration 131520: loss = 2.7560\n",
      "Iteration 131530: loss = 2.8517\n",
      "Iteration 131540: loss = 2.7626\n",
      "Iteration 131550: loss = 2.6862\n",
      "Iteration 131560: loss = 2.7480\n",
      "Iteration 131570: loss = 2.6783\n",
      "Iteration 131580: loss = 2.1573\n",
      "Iteration 131590: loss = 2.6179\n",
      "Iteration 131600: loss = 2.4365\n",
      "Iteration 131610: loss = 2.2931\n",
      "Iteration 131620: loss = 2.4346\n",
      "Iteration 131630: loss = 2.2200\n",
      "Iteration 131640: loss = 2.2098\n",
      "Iteration 131650: loss = 2.3536\n",
      "Iteration 131660: loss = 2.5399\n",
      "Iteration 131670: loss = 2.1588\n",
      "Iteration 131680: loss = 2.3161\n",
      "Iteration 131690: loss = 2.5304\n",
      "Iteration 131700: loss = 2.5042\n",
      "Iteration 131710: loss = 2.3677\n",
      "Iteration 131720: loss = 2.0692\n",
      "Iteration 131730: loss = 2.2114\n",
      "Iteration 131740: loss = 2.4496\n",
      "Iteration 131750: loss = 2.5843\n",
      "Iteration 131760: loss = 2.3314\n",
      "Iteration 131770: loss = 2.5447\n",
      "Iteration 131780: loss = 2.4439\n",
      "Iteration 131790: loss = 2.4622\n",
      "Iteration 131800: loss = 2.7082\n",
      "Iteration 131810: loss = 2.1727\n",
      "Iteration 131820: loss = 2.1939\n",
      "Iteration 131830: loss = 2.6490\n",
      "Iteration 131840: loss = 2.4864\n",
      "Iteration 131850: loss = 2.6704\n",
      "Iteration 131860: loss = 2.5395\n",
      "Iteration 131870: loss = 2.4643\n",
      "Iteration 131880: loss = 2.3437\n",
      "Iteration 131890: loss = 2.5497\n",
      "Iteration 131900: loss = 2.5715\n",
      "Iteration 131910: loss = 2.6064\n",
      "Iteration 131920: loss = 2.0892\n",
      "Iteration 131930: loss = 2.6598\n",
      "Iteration 131940: loss = 2.3621\n",
      "Iteration 131950: loss = 2.4934\n",
      "Iteration 131960: loss = 2.3968\n",
      "Iteration 131970: loss = 2.6073\n",
      "Iteration 131980: loss = 2.5851\n",
      "Iteration 131990: loss = 2.9337\n",
      "Iteration 132000: loss = 2.4057\n",
      "Iteration 132010: loss = 2.3562\n",
      "Iteration 132020: loss = 2.0727\n",
      "Iteration 132030: loss = 2.2189\n",
      "Iteration 132040: loss = 2.4265\n",
      "Iteration 132050: loss = 2.5839\n",
      "Iteration 132060: loss = 2.8022\n",
      "Iteration 132070: loss = 2.8911\n",
      "Iteration 132080: loss = 2.5532\n",
      "Iteration 132090: loss = 2.3093\n",
      "Iteration 132100: loss = 2.2482\n",
      "Iteration 132110: loss = 2.2781\n",
      "Iteration 132120: loss = 2.9634\n",
      "Iteration 132130: loss = 2.5103\n",
      "Iteration 132140: loss = 2.5698\n",
      "Iteration 132150: loss = 2.3870\n",
      "Iteration 132160: loss = 2.4240\n",
      "Iteration 132170: loss = 2.6291\n",
      "Iteration 132180: loss = 2.3491\n",
      "Iteration 132190: loss = 2.3920\n",
      "Iteration 132200: loss = 2.2329\n",
      "Iteration 132210: loss = 2.2967\n",
      "Iteration 132220: loss = 2.6391\n",
      "Iteration 132230: loss = 2.2989\n",
      "Iteration 132240: loss = 2.5333\n",
      "Iteration 132250: loss = 2.7025\n",
      "Iteration 132260: loss = 2.2021\n",
      "Iteration 132270: loss = 2.0555\n",
      "Iteration 132280: loss = 2.5993\n",
      "Iteration 132290: loss = 2.7881\n",
      "Iteration 132300: loss = 2.0532\n",
      "Iteration 132310: loss = 2.3697\n",
      "Iteration 132320: loss = 2.3658\n",
      "Iteration 132330: loss = 2.6520\n",
      "Iteration 132340: loss = 2.3112\n",
      "Iteration 132350: loss = 2.3775\n",
      "Iteration 132360: loss = 2.6685\n",
      "Iteration 132370: loss = 2.2014\n",
      "Iteration 132380: loss = 2.2719\n",
      "Iteration 132390: loss = 2.2803\n",
      "Iteration 132400: loss = 2.2585\n",
      "Iteration 132410: loss = 2.5549\n",
      "Iteration 132420: loss = 2.7345\n",
      "Iteration 132430: loss = 2.2553\n",
      "Iteration 132440: loss = 2.6157\n",
      "Iteration 132450: loss = 2.6635\n",
      "Iteration 132460: loss = 1.9825\n",
      "Iteration 132470: loss = 1.9998\n",
      "Iteration 132480: loss = 2.3591\n",
      "Iteration 132490: loss = 2.5526\n",
      "Iteration 132500: loss = 2.4110\n",
      "Iteration 132510: loss = 2.7199\n",
      "Iteration 132520: loss = 2.2728\n",
      "Iteration 132530: loss = 2.6459\n",
      "Iteration 132540: loss = 2.4611\n",
      "Iteration 132550: loss = 2.4027\n",
      "Iteration 132560: loss = 2.5263\n",
      "Iteration 132570: loss = 2.5889\n",
      "Iteration 132580: loss = 2.5824\n",
      "Iteration 132590: loss = 2.5900\n",
      "Iteration 132600: loss = 2.8285\n",
      "Iteration 132610: loss = 1.9391\n",
      "Iteration 132620: loss = 2.5668\n",
      "Iteration 132630: loss = 2.5614\n",
      "Iteration 132640: loss = 2.3175\n",
      "Iteration 132650: loss = 2.4122\n",
      "Iteration 132660: loss = 2.4577\n",
      "Iteration 132670: loss = 2.4567\n",
      "Iteration 132680: loss = 2.3841\n",
      "Iteration 132690: loss = 2.3760\n",
      "Iteration 132700: loss = 2.9098\n",
      "Iteration 132710: loss = 2.3729\n",
      "Iteration 132720: loss = 2.3712\n",
      "Iteration 132730: loss = 2.4717\n",
      "Iteration 132740: loss = 1.9754\n",
      "Iteration 132750: loss = 2.6837\n",
      "Iteration 132760: loss = 2.2894\n",
      "Iteration 132770: loss = 2.5805\n",
      "Iteration 132780: loss = 2.7639\n",
      "Iteration 132790: loss = 2.2926\n",
      "Iteration 132800: loss = 2.5792\n",
      "Iteration 132810: loss = 2.8052\n",
      "Iteration 132820: loss = 2.3900\n",
      "Iteration 132830: loss = 2.2740\n",
      "Iteration 132840: loss = 2.4844\n",
      "Iteration 132850: loss = 2.2325\n",
      "Iteration 132860: loss = 2.7062\n",
      "Iteration 132870: loss = 2.4916\n",
      "Iteration 132880: loss = 2.7163\n",
      "Iteration 132890: loss = 2.1492\n",
      "Iteration 132900: loss = 2.5202\n",
      "Iteration 132910: loss = 2.4076\n",
      "Iteration 132920: loss = 2.1873\n",
      "Iteration 132930: loss = 2.1559\n",
      "Iteration 132940: loss = 2.4429\n",
      "Iteration 132950: loss = 2.3341\n",
      "Iteration 132960: loss = 2.4062\n",
      "Iteration 132970: loss = 2.3370\n",
      "Iteration 132980: loss = 2.6800\n",
      "Iteration 132990: loss = 2.3504\n",
      "Iteration 133000: loss = 2.5662\n",
      "Iteration 133010: loss = 2.2883\n",
      "Iteration 133020: loss = 2.4454\n",
      "Iteration 133030: loss = 2.5396\n",
      "Iteration 133040: loss = 2.7077\n",
      "Iteration 133050: loss = 2.3185\n",
      "Iteration 133060: loss = 2.1636\n",
      "Iteration 133070: loss = 1.9031\n",
      "Iteration 133080: loss = 2.3472\n",
      "Iteration 133090: loss = 2.8051\n",
      "Iteration 133100: loss = 2.1601\n",
      "Iteration 133110: loss = 2.1715\n",
      "Iteration 133120: loss = 2.3267\n",
      "Iteration 133130: loss = 2.4986\n",
      "Iteration 133140: loss = 2.3832\n",
      "Iteration 133150: loss = 2.1949\n",
      "Iteration 133160: loss = 2.1521\n",
      "Iteration 133170: loss = 2.6679\n",
      "Iteration 133180: loss = 2.5579\n",
      "Iteration 133190: loss = 2.5764\n",
      "Iteration 133200: loss = 2.3411\n",
      "Iteration 133210: loss = 2.3822\n",
      "Iteration 133220: loss = 2.2690\n",
      "Iteration 133230: loss = 2.4586\n",
      "Iteration 133240: loss = 2.6936\n",
      "Iteration 133250: loss = 2.4708\n",
      "Iteration 133260: loss = 2.3591\n",
      "Iteration 133270: loss = 2.2929\n",
      "Iteration 133280: loss = 2.6697\n",
      "Iteration 133290: loss = 2.7188\n",
      "Iteration 133300: loss = 2.7321\n",
      "Iteration 133310: loss = 2.7480\n",
      "Iteration 133320: loss = 2.3204\n",
      "Iteration 133330: loss = 2.9137\n",
      "Iteration 133340: loss = 2.6855\n",
      "Iteration 133350: loss = 2.4278\n",
      "Iteration 133360: loss = 2.1250\n",
      "Iteration 133370: loss = 2.4061\n",
      "Iteration 133380: loss = 2.1227\n",
      "Iteration 133390: loss = 2.2485\n",
      "Iteration 133400: loss = 2.4563\n",
      "Iteration 133410: loss = 3.0597\n",
      "Iteration 133420: loss = 2.4412\n",
      "Iteration 133430: loss = 2.3300\n",
      "Iteration 133440: loss = 2.4201\n",
      "Iteration 133450: loss = 2.5079\n",
      "Iteration 133460: loss = 2.6006\n",
      "Iteration 133470: loss = 2.6252\n",
      "Iteration 133480: loss = 2.8130\n",
      "Iteration 133490: loss = 2.4083\n",
      "Iteration 133500: loss = 2.3630\n",
      "Iteration 133510: loss = 2.5742\n",
      "Iteration 133520: loss = 2.4021\n",
      "Iteration 133530: loss = 2.5701\n",
      "Iteration 133540: loss = 2.7942\n",
      "Iteration 133550: loss = 2.2829\n",
      "Iteration 133560: loss = 2.1943\n",
      "Iteration 133570: loss = 2.0832\n",
      "Iteration 133580: loss = 2.2045\n",
      "Iteration 133590: loss = 2.3591\n",
      "Iteration 133600: loss = 2.5671\n",
      "Iteration 133610: loss = 2.0986\n",
      "Iteration 133620: loss = 2.3433\n",
      "Iteration 133630: loss = 2.2144\n",
      "Iteration 133640: loss = 2.5238\n",
      "Iteration 133650: loss = 2.3827\n",
      "Iteration 133660: loss = 2.3915\n",
      "Iteration 133670: loss = 2.1292\n",
      "Iteration 133680: loss = 2.4932\n",
      "Iteration 133690: loss = 2.4475\n",
      "Iteration 133700: loss = 2.2846\n",
      "Iteration 133710: loss = 2.2065\n",
      "Iteration 133720: loss = 2.0524\n",
      "Iteration 133730: loss = 2.1498\n",
      "Iteration 133740: loss = 3.0472\n",
      "Iteration 133750: loss = 2.3734\n",
      "Iteration 133760: loss = 2.4810\n",
      "Iteration 133770: loss = 2.3296\n",
      "Iteration 133780: loss = 2.3618\n",
      "Iteration 133790: loss = 2.4536\n",
      "Iteration 133800: loss = 2.3036\n",
      "Iteration 133810: loss = 2.4813\n",
      "Iteration 133820: loss = 2.2278\n",
      "Iteration 133830: loss = 2.4791\n",
      "Iteration 133840: loss = 2.3554\n",
      "Iteration 133850: loss = 2.4278\n",
      "Iteration 133860: loss = 2.0679\n",
      "Iteration 133870: loss = 2.3605\n",
      "Iteration 133880: loss = 2.6193\n",
      "Iteration 133890: loss = 2.6800\n",
      "Iteration 133900: loss = 2.4721\n",
      "Iteration 133910: loss = 2.2976\n",
      "Iteration 133920: loss = 2.6323\n",
      "Iteration 133930: loss = 2.4618\n",
      "Iteration 133940: loss = 2.7082\n",
      "Iteration 133950: loss = 2.2819\n",
      "Iteration 133960: loss = 2.4034\n",
      "Iteration 133970: loss = 2.5918\n",
      "Iteration 133980: loss = 2.8472\n",
      "Iteration 133990: loss = 2.6248\n",
      "Iteration 134000: loss = 2.3592\n",
      "Iteration 134010: loss = 2.6476\n",
      "Iteration 134020: loss = 2.4657\n",
      "Iteration 134030: loss = 2.6098\n",
      "Iteration 134040: loss = 2.3447\n",
      "Iteration 134050: loss = 2.2929\n",
      "Iteration 134060: loss = 2.6288\n",
      "Iteration 134070: loss = 2.6727\n",
      "Iteration 134080: loss = 2.7108\n",
      "Iteration 134090: loss = 2.3542\n",
      "Iteration 134100: loss = 2.3007\n",
      "Iteration 134110: loss = 2.0568\n",
      "Iteration 134120: loss = 2.6675\n",
      "Iteration 134130: loss = 2.1658\n",
      "Iteration 134140: loss = 2.5761\n",
      "Iteration 134150: loss = 2.5101\n",
      "Iteration 134160: loss = 2.0461\n",
      "Iteration 134170: loss = 2.4639\n",
      "Iteration 134180: loss = 2.2265\n",
      "Iteration 134190: loss = 2.3907\n",
      "Iteration 134200: loss = 2.4712\n",
      "Iteration 134210: loss = 2.4445\n",
      "Iteration 134220: loss = 2.8676\n",
      "Iteration 134230: loss = 2.3884\n",
      "Iteration 134240: loss = 2.4890\n",
      "Iteration 134250: loss = 2.6113\n",
      "Iteration 134260: loss = 2.4289\n",
      "Iteration 134270: loss = 2.1963\n",
      "Iteration 134280: loss = 2.2004\n",
      "Iteration 134290: loss = 2.4011\n",
      "Iteration 134300: loss = 2.6949\n",
      "Iteration 134310: loss = 2.3715\n",
      "Iteration 134320: loss = 2.4687\n",
      "Iteration 134330: loss = 2.5531\n",
      "Iteration 134340: loss = 2.1548\n",
      "Iteration 134350: loss = 2.5026\n",
      "Iteration 134360: loss = 2.3933\n",
      "Iteration 134370: loss = 2.4132\n",
      "Iteration 134380: loss = 2.3554\n",
      "Iteration 134390: loss = 2.7650\n",
      "Iteration 134400: loss = 2.6043\n",
      "Iteration 134410: loss = 2.9250\n",
      "Iteration 134420: loss = 2.2705\n",
      "Iteration 134430: loss = 2.5587\n",
      "Iteration 134440: loss = 2.5007\n",
      "Iteration 134450: loss = 1.9760\n",
      "Iteration 134460: loss = 2.6261\n",
      "Iteration 134470: loss = 2.5444\n",
      "Iteration 134480: loss = 2.3875\n",
      "Iteration 134490: loss = 2.5797\n",
      "Iteration 134500: loss = 2.2628\n",
      "Iteration 134510: loss = 2.2009\n",
      "Iteration 134520: loss = 2.4082\n",
      "Iteration 134530: loss = 2.7172\n",
      "Iteration 134540: loss = 2.4626\n",
      "Iteration 134550: loss = 2.6643\n",
      "Iteration 134560: loss = 2.4152\n",
      "Iteration 134570: loss = 2.6168\n",
      "Iteration 134580: loss = 2.1986\n",
      "Iteration 134590: loss = 2.4338\n",
      "Iteration 134600: loss = 2.5444\n",
      "Iteration 134610: loss = 2.5596\n",
      "Iteration 134620: loss = 2.5961\n",
      "Iteration 134630: loss = 2.9595\n",
      "Iteration 134640: loss = 2.2824\n",
      "Iteration 134650: loss = 2.0790\n",
      "Iteration 134660: loss = 2.3668\n",
      "Iteration 134670: loss = 2.1403\n",
      "Iteration 134680: loss = 2.2847\n",
      "Iteration 134690: loss = 2.6936\n",
      "Iteration 134700: loss = 2.6496\n",
      "Iteration 134710: loss = 2.4959\n",
      "Iteration 134720: loss = 2.3617\n",
      "Iteration 134730: loss = 2.5106\n",
      "Iteration 134740: loss = 2.1349\n",
      "Iteration 134750: loss = 2.1927\n",
      "Iteration 134760: loss = 2.3152\n",
      "Iteration 134770: loss = 2.0203\n",
      "Iteration 134780: loss = 2.6479\n",
      "Iteration 134790: loss = 2.2601\n",
      "Iteration 134800: loss = 2.5633\n",
      "Iteration 134810: loss = 2.3704\n",
      "Iteration 134820: loss = 2.5442\n",
      "Iteration 134830: loss = 2.8898\n",
      "Iteration 134840: loss = 2.1921\n",
      "Iteration 134850: loss = 2.4807\n",
      "Iteration 134860: loss = 2.3341\n",
      "Iteration 134870: loss = 2.5233\n",
      "Iteration 134880: loss = 2.3955\n",
      "Iteration 134890: loss = 2.6310\n",
      "Iteration 134900: loss = 2.2485\n",
      "Iteration 134910: loss = 2.0578\n",
      "Iteration 134920: loss = 2.6146\n",
      "Iteration 134930: loss = 2.0996\n",
      "Iteration 134940: loss = 2.0850\n",
      "Iteration 134950: loss = 2.2999\n",
      "Iteration 134960: loss = 2.9688\n",
      "Iteration 134970: loss = 2.4188\n",
      "Iteration 134980: loss = 2.3428\n",
      "Iteration 134990: loss = 2.7777\n",
      "Iteration 135000: loss = 2.5192\n",
      "Iteration 135010: loss = 2.4716\n",
      "Iteration 135020: loss = 2.4650\n",
      "Iteration 135030: loss = 2.8495\n",
      "Iteration 135040: loss = 2.5339\n",
      "Iteration 135050: loss = 2.5560\n",
      "Iteration 135060: loss = 2.5024\n",
      "Iteration 135070: loss = 2.0966\n",
      "Iteration 135080: loss = 2.7213\n",
      "Iteration 135090: loss = 2.1410\n",
      "Iteration 135100: loss = 2.4604\n",
      "Iteration 135110: loss = 2.4723\n",
      "Iteration 135120: loss = 2.6993\n",
      "Iteration 135130: loss = 2.3224\n",
      "Iteration 135140: loss = 2.2823\n",
      "Iteration 135150: loss = 2.3328\n",
      "Iteration 135160: loss = 2.3965\n",
      "Iteration 135170: loss = 2.5414\n",
      "Iteration 135180: loss = 2.8954\n",
      "Iteration 135190: loss = 2.4123\n",
      "Iteration 135200: loss = 2.5712\n",
      "Iteration 135210: loss = 1.9935\n",
      "Iteration 135220: loss = 2.6546\n",
      "Iteration 135230: loss = 2.2882\n",
      "Iteration 135240: loss = 2.4725\n",
      "Iteration 135250: loss = 2.5264\n",
      "Iteration 135260: loss = 2.2584\n",
      "Iteration 135270: loss = 2.5450\n",
      "Iteration 135280: loss = 3.0732\n",
      "Iteration 135290: loss = 2.3638\n",
      "Iteration 135300: loss = 2.1746\n",
      "Iteration 135310: loss = 2.1899\n",
      "Iteration 135320: loss = 2.3901\n",
      "Iteration 135330: loss = 2.3424\n",
      "Iteration 135340: loss = 2.3103\n",
      "Iteration 135350: loss = 2.4262\n",
      "Iteration 135360: loss = 2.2694\n",
      "Iteration 135370: loss = 2.5044\n",
      "Iteration 135380: loss = 2.4175\n",
      "Iteration 135390: loss = 2.2203\n",
      "Iteration 135400: loss = 2.2905\n",
      "Iteration 135410: loss = 1.7559\n",
      "Iteration 135420: loss = 2.6040\n",
      "Iteration 135430: loss = 2.4373\n",
      "Iteration 135440: loss = 2.3498\n",
      "Iteration 135450: loss = 2.6357\n",
      "Iteration 135460: loss = 2.0343\n",
      "Iteration 135470: loss = 2.6463\n",
      "Iteration 135480: loss = 2.3468\n",
      "Iteration 135490: loss = 2.3759\n",
      "Iteration 135500: loss = 2.6154\n",
      "Iteration 135510: loss = 2.3614\n",
      "Iteration 135520: loss = 2.1797\n",
      "Iteration 135530: loss = 2.2123\n",
      "Iteration 135540: loss = 2.2835\n",
      "Iteration 135550: loss = 2.5296\n",
      "Iteration 135560: loss = 2.7012\n",
      "Iteration 135570: loss = 2.5050\n",
      "Iteration 135580: loss = 2.4535\n",
      "Iteration 135590: loss = 2.1560\n",
      "Iteration 135600: loss = 2.1154\n",
      "Iteration 135610: loss = 2.0186\n",
      "Iteration 135620: loss = 2.7183\n",
      "Iteration 135630: loss = 2.6325\n",
      "Iteration 135640: loss = 2.5470\n",
      "Iteration 135650: loss = 2.6160\n",
      "Iteration 135660: loss = 2.5104\n",
      "Iteration 135670: loss = 2.5189\n",
      "Iteration 135680: loss = 2.2592\n",
      "Iteration 135690: loss = 2.5469\n",
      "Iteration 135700: loss = 3.0473\n",
      "Iteration 135710: loss = 2.3789\n",
      "Iteration 135720: loss = 2.3367\n",
      "Iteration 135730: loss = 2.8989\n",
      "Iteration 135740: loss = 2.4713\n",
      "Iteration 135750: loss = 2.3794\n",
      "Iteration 135760: loss = 2.4788\n",
      "Iteration 135770: loss = 2.3629\n",
      "Iteration 135780: loss = 2.3097\n",
      "Iteration 135790: loss = 2.2142\n",
      "Iteration 135800: loss = 2.2387\n",
      "Iteration 135810: loss = 2.5725\n",
      "Iteration 135820: loss = 2.2134\n",
      "Iteration 135830: loss = 2.1248\n",
      "Iteration 135840: loss = 2.5200\n",
      "Iteration 135850: loss = 2.5158\n",
      "Iteration 135860: loss = 2.3456\n",
      "Iteration 135870: loss = 2.3399\n",
      "Iteration 135880: loss = 2.6648\n",
      "Iteration 135890: loss = 2.1619\n",
      "Iteration 135900: loss = 2.5166\n",
      "Iteration 135910: loss = 2.7070\n",
      "Iteration 135920: loss = 2.3541\n",
      "Iteration 135930: loss = 2.3575\n",
      "Iteration 135940: loss = 2.7464\n",
      "Iteration 135950: loss = 2.5439\n",
      "Iteration 135960: loss = 2.1957\n",
      "Iteration 135970: loss = 2.0729\n",
      "Iteration 135980: loss = 2.3005\n",
      "Iteration 135990: loss = 2.3105\n",
      "Iteration 136000: loss = 2.2358\n",
      "Iteration 136010: loss = 2.1778\n",
      "Iteration 136020: loss = 2.8395\n",
      "Iteration 136030: loss = 2.2495\n",
      "Iteration 136040: loss = 2.2369\n",
      "Iteration 136050: loss = 2.3892\n",
      "Iteration 136060: loss = 2.4634\n",
      "Iteration 136070: loss = 2.1943\n",
      "Iteration 136080: loss = 2.6439\n",
      "Iteration 136090: loss = 2.1455\n",
      "Iteration 136100: loss = 2.6006\n",
      "Iteration 136110: loss = 2.3063\n",
      "Iteration 136120: loss = 2.9193\n",
      "Iteration 136130: loss = 2.5551\n",
      "Iteration 136140: loss = 2.4539\n",
      "Iteration 136150: loss = 2.3978\n",
      "Iteration 136160: loss = 2.9433\n",
      "Iteration 136170: loss = 2.5142\n",
      "Iteration 136180: loss = 3.0460\n",
      "Iteration 136190: loss = 2.3489\n",
      "Iteration 136200: loss = 2.4183\n",
      "Iteration 136210: loss = 2.6146\n",
      "Iteration 136220: loss = 2.4713\n",
      "Iteration 136230: loss = 2.5571\n",
      "Iteration 136240: loss = 2.6484\n",
      "Iteration 136250: loss = 2.0258\n",
      "Iteration 136260: loss = 2.3389\n",
      "Iteration 136270: loss = 2.1775\n",
      "Iteration 136280: loss = 2.8335\n",
      "Iteration 136290: loss = 2.2257\n",
      "Iteration 136300: loss = 2.5980\n",
      "Iteration 136310: loss = 2.2516\n",
      "Iteration 136320: loss = 2.4311\n",
      "Iteration 136330: loss = 2.5848\n",
      "Iteration 136340: loss = 2.4585\n",
      "Iteration 136350: loss = 2.3735\n",
      "Iteration 136360: loss = 2.4096\n",
      "Iteration 136370: loss = 2.1687\n",
      "Iteration 136380: loss = 2.3807\n",
      "Iteration 136390: loss = 2.2149\n",
      "Iteration 136400: loss = 2.7036\n",
      "Iteration 136410: loss = 2.6325\n",
      "Iteration 136420: loss = 2.5631\n",
      "Iteration 136430: loss = 2.7033\n",
      "Iteration 136440: loss = 2.5945\n",
      "Iteration 136450: loss = 2.7078\n",
      "Iteration 136460: loss = 2.2505\n",
      "Iteration 136470: loss = 2.2279\n",
      "Iteration 136480: loss = 2.2515\n",
      "Iteration 136490: loss = 2.4887\n",
      "Iteration 136500: loss = 2.8023\n",
      "Iteration 136510: loss = 2.6255\n",
      "Iteration 136520: loss = 2.3477\n",
      "Iteration 136530: loss = 2.2665\n",
      "Iteration 136540: loss = 2.0149\n",
      "Iteration 136550: loss = 2.2648\n",
      "Iteration 136560: loss = 2.4913\n",
      "Iteration 136570: loss = 2.4698\n",
      "Iteration 136580: loss = 2.5328\n",
      "Iteration 136590: loss = 2.3266\n",
      "Iteration 136600: loss = 2.5977\n",
      "Iteration 136610: loss = 2.8994\n",
      "Iteration 136620: loss = 2.2278\n",
      "Iteration 136630: loss = 2.2328\n",
      "Iteration 136640: loss = 2.3639\n",
      "Iteration 136650: loss = 2.1621\n",
      "Iteration 136660: loss = 2.3240\n",
      "Iteration 136670: loss = 2.6242\n",
      "Iteration 136680: loss = 2.4330\n",
      "Iteration 136690: loss = 2.5626\n",
      "Iteration 136700: loss = 2.8414\n",
      "Iteration 136710: loss = 2.2553\n",
      "Iteration 136720: loss = 2.5469\n",
      "Iteration 136730: loss = 2.2859\n",
      "Iteration 136740: loss = 2.6585\n",
      "Iteration 136750: loss = 2.3746\n",
      "Iteration 136760: loss = 2.3585\n",
      "Iteration 136770: loss = 2.7427\n",
      "Iteration 136780: loss = 2.1093\n",
      "Iteration 136790: loss = 2.6555\n",
      "Iteration 136800: loss = 2.7557\n",
      "Iteration 136810: loss = 2.4886\n",
      "Iteration 136820: loss = 2.4719\n",
      "Iteration 136830: loss = 2.1953\n",
      "Iteration 136840: loss = 2.5335\n",
      "Iteration 136850: loss = 2.8251\n",
      "Iteration 136860: loss = 2.4931\n",
      "Iteration 136870: loss = 2.1016\n",
      "Iteration 136880: loss = 2.4537\n",
      "Iteration 136890: loss = 2.5827\n",
      "Iteration 136900: loss = 2.4604\n",
      "Iteration 136910: loss = 2.4338\n",
      "Iteration 136920: loss = 2.1885\n",
      "Iteration 136930: loss = 2.7772\n",
      "Iteration 136940: loss = 2.2167\n",
      "Iteration 136950: loss = 2.0042\n",
      "Iteration 136960: loss = 2.1784\n",
      "Iteration 136970: loss = 2.3424\n",
      "Iteration 136980: loss = 2.3827\n",
      "Iteration 136990: loss = 2.4488\n",
      "Iteration 137000: loss = 2.3272\n",
      "Iteration 137010: loss = 2.4503\n",
      "Iteration 137020: loss = 2.1912\n",
      "Iteration 137030: loss = 2.4964\n",
      "Iteration 137040: loss = 3.0015\n",
      "Iteration 137050: loss = 2.7989\n",
      "Iteration 137060: loss = 1.9740\n",
      "Iteration 137070: loss = 2.3814\n",
      "Iteration 137080: loss = 2.3772\n",
      "Iteration 137090: loss = 2.8109\n",
      "Iteration 137100: loss = 2.2566\n",
      "Iteration 137110: loss = 2.6678\n",
      "Iteration 137120: loss = 2.0260\n",
      "Iteration 137130: loss = 2.4568\n",
      "Iteration 137140: loss = 2.2194\n",
      "Iteration 137150: loss = 2.6283\n",
      "Iteration 137160: loss = 2.6984\n",
      "Iteration 137170: loss = 2.5582\n",
      "Iteration 137180: loss = 2.1691\n",
      "Iteration 137190: loss = 2.4543\n",
      "Iteration 137200: loss = 2.2798\n",
      "Iteration 137210: loss = 2.3973\n",
      "Iteration 137220: loss = 2.7871\n",
      "Iteration 137230: loss = 2.5666\n",
      "Iteration 137240: loss = 2.4206\n",
      "Iteration 137250: loss = 2.5675\n",
      "Iteration 137260: loss = 2.5356\n",
      "Iteration 137270: loss = 2.3871\n",
      "Iteration 137280: loss = 2.6126\n",
      "Iteration 137290: loss = 2.6448\n",
      "Iteration 137300: loss = 2.4687\n",
      "Iteration 137310: loss = 2.3610\n",
      "Iteration 137320: loss = 2.6155\n",
      "Iteration 137330: loss = 2.4597\n",
      "Iteration 137340: loss = 2.1984\n",
      "Iteration 137350: loss = 2.5359\n",
      "Iteration 137360: loss = 2.9204\n",
      "Iteration 137370: loss = 2.2301\n",
      "Iteration 137380: loss = 2.3267\n",
      "Iteration 137390: loss = 2.2124\n",
      "Iteration 137400: loss = 2.5739\n",
      "Iteration 137410: loss = 2.2701\n",
      "Iteration 137420: loss = 2.5367\n",
      "Iteration 137430: loss = 2.4017\n",
      "Iteration 137440: loss = 2.6162\n",
      "Iteration 137450: loss = 2.1643\n",
      "Iteration 137460: loss = 2.2573\n",
      "Iteration 137470: loss = 2.3244\n",
      "Iteration 137480: loss = 2.6986\n",
      "Iteration 137490: loss = 2.6567\n",
      "Iteration 137500: loss = 2.5515\n",
      "Iteration 137510: loss = 2.1697\n",
      "Iteration 137520: loss = 2.2496\n",
      "Iteration 137530: loss = 2.7956\n",
      "Iteration 137540: loss = 2.4436\n",
      "Iteration 137550: loss = 2.6207\n",
      "Iteration 137560: loss = 2.4517\n",
      "Iteration 137570: loss = 2.0526\n",
      "Iteration 137580: loss = 2.1148\n",
      "Iteration 137590: loss = 2.2329\n",
      "Iteration 137600: loss = 2.3483\n",
      "Iteration 137610: loss = 2.6043\n",
      "Iteration 137620: loss = 2.8823\n",
      "Iteration 137630: loss = 2.4677\n",
      "Iteration 137640: loss = 2.6562\n",
      "Iteration 137650: loss = 2.5540\n",
      "Iteration 137660: loss = 2.2060\n",
      "Iteration 137670: loss = 2.1798\n",
      "Iteration 137680: loss = 2.5113\n",
      "Iteration 137690: loss = 2.5229\n",
      "Iteration 137700: loss = 2.2591\n",
      "Iteration 137710: loss = 2.5874\n",
      "Iteration 137720: loss = 2.3044\n",
      "Iteration 137730: loss = 2.0544\n",
      "Iteration 137740: loss = 2.2758\n",
      "Iteration 137750: loss = 2.4469\n",
      "Iteration 137760: loss = 2.9486\n",
      "Iteration 137770: loss = 2.1255\n",
      "Iteration 137780: loss = 2.4703\n",
      "Iteration 137790: loss = 2.2804\n",
      "Iteration 137800: loss = 2.4471\n",
      "Iteration 137810: loss = 2.4854\n",
      "Iteration 137820: loss = 2.8776\n",
      "Iteration 137830: loss = 2.3322\n",
      "Iteration 137840: loss = 2.2517\n",
      "Iteration 137850: loss = 2.3097\n",
      "Iteration 137860: loss = 2.5770\n",
      "Iteration 137870: loss = 2.2639\n",
      "Iteration 137880: loss = 3.0407\n",
      "Iteration 137890: loss = 2.2727\n",
      "Iteration 137900: loss = 2.3855\n",
      "Iteration 137910: loss = 2.6695\n",
      "Iteration 137920: loss = 2.0795\n",
      "Iteration 137930: loss = 2.2783\n",
      "Iteration 137940: loss = 2.9189\n",
      "Iteration 137950: loss = 2.3535\n",
      "Iteration 137960: loss = 2.6662\n",
      "Iteration 137970: loss = 2.5386\n",
      "Iteration 137980: loss = 2.3176\n",
      "Iteration 137990: loss = 2.5505\n",
      "Iteration 138000: loss = 2.3760\n",
      "Iteration 138010: loss = 2.1585\n",
      "Iteration 138020: loss = 2.1164\n",
      "Iteration 138030: loss = 2.2729\n",
      "Iteration 138040: loss = 2.4857\n",
      "Iteration 138050: loss = 2.8762\n",
      "Iteration 138060: loss = 2.3992\n",
      "Iteration 138070: loss = 2.2963\n",
      "Iteration 138080: loss = 2.4024\n",
      "Iteration 138090: loss = 2.6565\n",
      "Iteration 138100: loss = 2.1404\n",
      "Iteration 138110: loss = 2.3056\n",
      "Iteration 138120: loss = 2.5376\n",
      "Iteration 138130: loss = 2.3041\n",
      "Iteration 138140: loss = 2.7511\n",
      "Iteration 138150: loss = 2.5338\n",
      "Iteration 138160: loss = 2.7414\n",
      "Iteration 138170: loss = 2.7236\n",
      "Iteration 138180: loss = 2.6177\n",
      "Iteration 138190: loss = 2.3184\n",
      "Iteration 138200: loss = 2.4880\n",
      "Iteration 138210: loss = 2.0983\n",
      "Iteration 138220: loss = 2.5703\n",
      "Iteration 138230: loss = 2.3789\n",
      "Iteration 138240: loss = 2.6594\n",
      "Iteration 138250: loss = 2.2169\n",
      "Iteration 138260: loss = 2.1107\n",
      "Iteration 138270: loss = 2.5446\n",
      "Iteration 138280: loss = 2.5004\n",
      "Iteration 138290: loss = 2.5271\n",
      "Iteration 138300: loss = 2.2973\n",
      "Iteration 138310: loss = 2.4914\n",
      "Iteration 138320: loss = 2.3838\n",
      "Iteration 138330: loss = 2.6206\n",
      "Iteration 138340: loss = 2.1886\n",
      "Iteration 138350: loss = 2.8140\n",
      "Iteration 138360: loss = 2.6745\n",
      "Iteration 138370: loss = 2.1947\n",
      "Iteration 138380: loss = 2.2574\n",
      "Iteration 138390: loss = 2.2583\n",
      "Iteration 138400: loss = 2.4521\n",
      "Iteration 138410: loss = 2.2187\n",
      "Iteration 138420: loss = 2.3344\n",
      "Iteration 138430: loss = 2.8709\n",
      "Iteration 138440: loss = 2.5991\n",
      "Iteration 138450: loss = 2.3246\n",
      "Iteration 138460: loss = 2.2752\n",
      "Iteration 138470: loss = 2.7036\n",
      "Iteration 138480: loss = 2.3879\n",
      "Iteration 138490: loss = 2.7580\n",
      "Iteration 138500: loss = 2.3914\n",
      "Iteration 138510: loss = 2.6331\n",
      "Iteration 138520: loss = 2.9164\n",
      "Iteration 138530: loss = 2.6673\n",
      "Iteration 138540: loss = 2.7331\n",
      "Iteration 138550: loss = 2.3115\n",
      "Iteration 138560: loss = 2.3077\n",
      "Iteration 138570: loss = 2.6706\n",
      "Iteration 138580: loss = 2.1432\n",
      "Iteration 138590: loss = 2.9017\n",
      "Iteration 138600: loss = 2.5789\n",
      "Iteration 138610: loss = 2.1137\n",
      "Iteration 138620: loss = 2.1855\n",
      "Iteration 138630: loss = 2.8032\n",
      "Iteration 138640: loss = 2.3226\n",
      "Iteration 138650: loss = 2.3769\n",
      "Iteration 138660: loss = 2.4306\n",
      "Iteration 138670: loss = 2.7355\n",
      "Iteration 138680: loss = 2.3903\n",
      "Iteration 138690: loss = 2.2947\n",
      "Iteration 138700: loss = 2.2927\n",
      "Iteration 138710: loss = 2.5462\n",
      "Iteration 138720: loss = 2.4060\n",
      "Iteration 138730: loss = 2.1808\n",
      "Iteration 138740: loss = 2.5873\n",
      "Iteration 138750: loss = 2.4035\n",
      "Iteration 138760: loss = 2.6180\n",
      "Iteration 138770: loss = 2.5558\n",
      "Iteration 138780: loss = 2.0200\n",
      "Iteration 138790: loss = 2.6362\n",
      "Iteration 138800: loss = 1.8088\n",
      "Iteration 138810: loss = 2.2828\n",
      "Iteration 138820: loss = 2.6570\n",
      "Iteration 138830: loss = 2.4603\n",
      "Iteration 138840: loss = 2.1640\n",
      "Iteration 138850: loss = 2.4762\n",
      "Iteration 138860: loss = 2.7898\n",
      "Iteration 138870: loss = 2.4981\n",
      "Iteration 138880: loss = 2.6703\n",
      "Iteration 138890: loss = 2.4784\n",
      "Iteration 138900: loss = 2.6591\n",
      "Iteration 138910: loss = 2.3963\n",
      "Iteration 138920: loss = 2.5632\n",
      "Iteration 138930: loss = 1.8781\n",
      "Iteration 138940: loss = 2.6403\n",
      "Iteration 138950: loss = 2.0898\n",
      "Iteration 138960: loss = 2.2409\n",
      "Iteration 138970: loss = 2.5871\n",
      "Iteration 138980: loss = 2.3075\n",
      "Iteration 138990: loss = 2.4294\n",
      "Iteration 139000: loss = 2.5072\n",
      "Iteration 139010: loss = 2.4909\n",
      "Iteration 139020: loss = 2.2291\n",
      "Iteration 139030: loss = 2.4980\n",
      "Iteration 139040: loss = 2.3854\n",
      "Iteration 139050: loss = 2.3902\n",
      "Iteration 139060: loss = 2.6030\n",
      "Iteration 139070: loss = 2.5858\n",
      "Iteration 139080: loss = 2.1175\n",
      "Iteration 139090: loss = 2.2941\n",
      "Iteration 139100: loss = 2.3168\n",
      "Iteration 139110: loss = 2.6688\n",
      "Iteration 139120: loss = 2.7504\n",
      "Iteration 139130: loss = 2.5651\n",
      "Iteration 139140: loss = 2.4437\n",
      "Iteration 139150: loss = 2.6257\n",
      "Iteration 139160: loss = 2.3167\n",
      "Iteration 139170: loss = 2.4131\n",
      "Iteration 139180: loss = 2.1989\n",
      "Iteration 139190: loss = 2.5475\n",
      "Iteration 139200: loss = 2.5194\n",
      "Iteration 139210: loss = 2.4745\n",
      "Iteration 139220: loss = 2.6368\n",
      "Iteration 139230: loss = 2.5055\n",
      "Iteration 139240: loss = 2.3286\n",
      "Iteration 139250: loss = 2.7524\n",
      "Iteration 139260: loss = 2.3689\n",
      "Iteration 139270: loss = 2.3121\n",
      "Iteration 139280: loss = 2.3310\n",
      "Iteration 139290: loss = 2.3665\n",
      "Iteration 139300: loss = 2.5532\n",
      "Iteration 139310: loss = 2.4748\n",
      "Iteration 139320: loss = 2.6400\n",
      "Iteration 139330: loss = 2.3939\n",
      "Iteration 139340: loss = 2.1934\n",
      "Iteration 139350: loss = 2.6507\n",
      "Iteration 139360: loss = 2.4055\n",
      "Iteration 139370: loss = 2.4198\n",
      "Iteration 139380: loss = 2.1540\n",
      "Iteration 139390: loss = 2.6327\n",
      "Iteration 139400: loss = 2.3245\n",
      "Iteration 139410: loss = 2.4802\n",
      "Iteration 139420: loss = 2.6908\n",
      "Iteration 139430: loss = 2.4482\n",
      "Iteration 139440: loss = 2.3626\n",
      "Iteration 139450: loss = 2.6855\n",
      "Iteration 139460: loss = 3.1140\n",
      "Iteration 139470: loss = 2.3127\n",
      "Iteration 139480: loss = 2.2562\n",
      "Iteration 139490: loss = 2.5991\n",
      "Iteration 139500: loss = 2.4905\n",
      "Iteration 139510: loss = 2.2679\n",
      "Iteration 139520: loss = 2.3279\n",
      "Iteration 139530: loss = 2.2743\n",
      "Iteration 139540: loss = 2.5304\n",
      "Iteration 139550: loss = 2.4576\n",
      "Iteration 139560: loss = 2.2875\n",
      "Iteration 139570: loss = 2.3908\n",
      "Iteration 139580: loss = 2.5305\n",
      "Iteration 139590: loss = 2.7493\n",
      "Iteration 139600: loss = 2.4477\n",
      "Iteration 139610: loss = 2.2227\n",
      "Iteration 139620: loss = 2.6071\n",
      "Iteration 139630: loss = 2.5075\n",
      "Iteration 139640: loss = 2.0910\n",
      "Iteration 139650: loss = 2.4889\n",
      "Iteration 139660: loss = 2.4447\n",
      "Iteration 139670: loss = 1.7295\n",
      "Iteration 139680: loss = 1.9158\n",
      "Iteration 139690: loss = 2.1092\n",
      "Iteration 139700: loss = 2.3192\n",
      "Iteration 139710: loss = 2.6468\n",
      "Iteration 139720: loss = 2.2477\n",
      "Iteration 139730: loss = 2.4270\n",
      "Iteration 139740: loss = 2.0964\n",
      "Iteration 139750: loss = 2.4983\n",
      "Iteration 139760: loss = 2.1720\n",
      "Iteration 139770: loss = 2.4268\n",
      "Iteration 139780: loss = 2.2660\n",
      "Iteration 139790: loss = 2.2050\n",
      "Iteration 139800: loss = 2.6410\n",
      "Iteration 139810: loss = 2.1922\n",
      "Iteration 139820: loss = 2.3838\n",
      "Iteration 139830: loss = 2.2524\n",
      "Iteration 139840: loss = 2.5756\n",
      "Iteration 139850: loss = 2.4029\n",
      "Iteration 139860: loss = 2.2798\n",
      "Iteration 139870: loss = 2.7503\n",
      "Iteration 139880: loss = 2.5584\n",
      "Iteration 139890: loss = 2.3316\n",
      "Iteration 139900: loss = 2.2411\n",
      "Iteration 139910: loss = 2.7461\n",
      "Iteration 139920: loss = 2.7165\n",
      "Iteration 139930: loss = 2.4622\n",
      "Iteration 139940: loss = 2.4485\n",
      "Iteration 139950: loss = 2.4817\n",
      "Iteration 139960: loss = 2.6137\n",
      "Iteration 139970: loss = 2.5609\n",
      "Iteration 139980: loss = 2.3292\n",
      "Iteration 139990: loss = 2.4712\n",
      "Iteration 140000: loss = 2.2194\n",
      "Iteration 140010: loss = 2.2340\n",
      "Iteration 140020: loss = 2.4007\n",
      "Iteration 140030: loss = 2.3571\n",
      "Iteration 140040: loss = 2.6140\n",
      "Iteration 140050: loss = 1.9975\n",
      "Iteration 140060: loss = 2.0541\n",
      "Iteration 140070: loss = 2.6110\n",
      "Iteration 140080: loss = 2.6100\n",
      "Iteration 140090: loss = 2.5378\n",
      "Iteration 140100: loss = 2.7790\n",
      "Iteration 140110: loss = 2.3485\n",
      "Iteration 140120: loss = 2.0145\n",
      "Iteration 140130: loss = 2.3110\n",
      "Iteration 140140: loss = 2.6383\n",
      "Iteration 140150: loss = 2.3092\n",
      "Iteration 140160: loss = 2.0367\n",
      "Iteration 140170: loss = 2.9243\n",
      "Iteration 140180: loss = 2.7850\n",
      "Iteration 140190: loss = 2.5575\n",
      "Iteration 140200: loss = 2.4999\n",
      "Iteration 140210: loss = 2.6672\n",
      "Iteration 140220: loss = 2.2470\n",
      "Iteration 140230: loss = 2.5155\n",
      "Iteration 140240: loss = 2.4761\n",
      "Iteration 140250: loss = 2.3834\n",
      "Iteration 140260: loss = 2.7268\n",
      "Iteration 140270: loss = 2.3269\n",
      "Iteration 140280: loss = 1.9768\n",
      "Iteration 140290: loss = 2.3712\n",
      "Iteration 140300: loss = 2.2555\n",
      "Iteration 140310: loss = 1.9483\n",
      "Iteration 140320: loss = 2.3142\n",
      "Iteration 140330: loss = 2.5720\n",
      "Iteration 140340: loss = 2.3072\n",
      "Iteration 140350: loss = 2.4477\n",
      "Iteration 140360: loss = 2.4533\n",
      "Iteration 140370: loss = 2.4535\n",
      "Iteration 140380: loss = 2.0632\n",
      "Iteration 140390: loss = 2.7397\n",
      "Iteration 140400: loss = 2.6907\n",
      "Iteration 140410: loss = 2.5480\n",
      "Iteration 140420: loss = 2.6069\n",
      "Iteration 140430: loss = 2.2750\n",
      "Iteration 140440: loss = 2.3889\n",
      "Iteration 140450: loss = 2.3097\n",
      "Iteration 140460: loss = 2.1420\n",
      "Iteration 140470: loss = 2.3804\n",
      "Iteration 140480: loss = 2.6144\n",
      "Iteration 140490: loss = 2.2420\n",
      "Iteration 140500: loss = 2.5071\n",
      "Iteration 140510: loss = 2.2422\n",
      "Iteration 140520: loss = 2.3625\n",
      "Iteration 140530: loss = 2.0114\n",
      "Iteration 140540: loss = 2.6487\n",
      "Iteration 140550: loss = 2.4575\n",
      "Iteration 140560: loss = 2.4939\n",
      "Iteration 140570: loss = 2.2065\n",
      "Iteration 140580: loss = 2.2802\n",
      "Iteration 140590: loss = 2.4094\n",
      "Iteration 140600: loss = 2.7109\n",
      "Iteration 140610: loss = 2.3329\n",
      "Iteration 140620: loss = 2.2984\n",
      "Iteration 140630: loss = 2.4149\n",
      "Iteration 140640: loss = 2.2340\n",
      "Iteration 140650: loss = 2.0952\n",
      "Iteration 140660: loss = 2.4966\n",
      "Iteration 140670: loss = 2.6690\n",
      "Iteration 140680: loss = 2.2503\n",
      "Iteration 140690: loss = 2.4048\n",
      "Iteration 140700: loss = 2.8928\n",
      "Iteration 140710: loss = 2.4458\n",
      "Iteration 140720: loss = 2.6359\n",
      "Iteration 140730: loss = 2.5446\n",
      "Iteration 140740: loss = 2.1804\n",
      "Iteration 140750: loss = 2.1447\n",
      "Iteration 140760: loss = 2.0581\n",
      "Iteration 140770: loss = 2.7340\n",
      "Iteration 140780: loss = 2.4837\n",
      "Iteration 140790: loss = 1.9155\n",
      "Iteration 140800: loss = 2.2766\n",
      "Iteration 140810: loss = 2.3694\n",
      "Iteration 140820: loss = 2.1711\n",
      "Iteration 140830: loss = 2.2248\n",
      "Iteration 140840: loss = 2.5472\n",
      "Iteration 140850: loss = 2.2678\n",
      "Iteration 140860: loss = 2.3957\n",
      "Iteration 140870: loss = 2.3110\n",
      "Iteration 140880: loss = 2.6364\n",
      "Iteration 140890: loss = 2.5713\n",
      "Iteration 140900: loss = 2.5103\n",
      "Iteration 140910: loss = 2.2196\n",
      "Iteration 140920: loss = 2.3813\n",
      "Iteration 140930: loss = 2.3161\n",
      "Iteration 140940: loss = 2.2554\n",
      "Iteration 140950: loss = 2.7533\n",
      "Iteration 140960: loss = 2.8395\n",
      "Iteration 140970: loss = 2.5395\n",
      "Iteration 140980: loss = 2.2332\n",
      "Iteration 140990: loss = 2.1189\n",
      "Iteration 141000: loss = 2.2948\n",
      "Iteration 141010: loss = 2.5959\n",
      "Iteration 141020: loss = 2.2462\n",
      "Iteration 141030: loss = 2.1496\n",
      "Iteration 141040: loss = 2.1553\n",
      "Iteration 141050: loss = 2.7784\n",
      "Iteration 141060: loss = 2.5232\n",
      "Iteration 141070: loss = 2.6647\n",
      "Iteration 141080: loss = 2.5726\n",
      "Iteration 141090: loss = 2.4083\n",
      "Iteration 141100: loss = 2.4903\n",
      "Iteration 141110: loss = 2.0641\n",
      "Iteration 141120: loss = 2.4640\n",
      "Iteration 141130: loss = 2.3540\n",
      "Iteration 141140: loss = 2.5239\n",
      "Iteration 141150: loss = 2.5357\n",
      "Iteration 141160: loss = 2.6021\n",
      "Iteration 141170: loss = 2.4984\n",
      "Iteration 141180: loss = 2.3636\n",
      "Iteration 141190: loss = 2.3007\n",
      "Iteration 141200: loss = 2.4173\n",
      "Iteration 141210: loss = 2.3657\n",
      "Iteration 141220: loss = 2.2100\n",
      "Iteration 141230: loss = 2.7139\n",
      "Iteration 141240: loss = 2.4433\n",
      "Iteration 141250: loss = 2.2669\n",
      "Iteration 141260: loss = 2.2790\n",
      "Iteration 141270: loss = 2.5272\n",
      "Iteration 141280: loss = 2.3431\n",
      "Iteration 141290: loss = 2.5189\n",
      "Iteration 141300: loss = 2.2528\n",
      "Iteration 141310: loss = 2.4441\n",
      "Iteration 141320: loss = 2.3115\n",
      "Iteration 141330: loss = 1.9835\n",
      "Iteration 141340: loss = 2.4077\n",
      "Iteration 141350: loss = 2.4036\n",
      "Iteration 141360: loss = 2.4005\n",
      "Iteration 141370: loss = 2.3590\n",
      "Iteration 141380: loss = 2.4873\n",
      "Iteration 141390: loss = 2.2884\n",
      "Iteration 141400: loss = 2.5612\n",
      "Iteration 141410: loss = 2.3295\n",
      "Iteration 141420: loss = 2.3145\n",
      "Iteration 141430: loss = 2.5561\n",
      "Iteration 141440: loss = 2.8492\n",
      "Iteration 141450: loss = 2.4237\n",
      "Iteration 141460: loss = 2.3255\n",
      "Iteration 141470: loss = 1.9187\n",
      "Iteration 141480: loss = 2.4946\n",
      "Iteration 141490: loss = 2.3103\n",
      "Iteration 141500: loss = 2.8320\n",
      "Iteration 141510: loss = 2.4894\n",
      "Iteration 141520: loss = 2.3677\n",
      "Iteration 141530: loss = 2.3710\n",
      "Iteration 141540: loss = 2.5242\n",
      "Iteration 141550: loss = 2.4560\n",
      "Iteration 141560: loss = 2.6712\n",
      "Iteration 141570: loss = 2.5029\n",
      "Iteration 141580: loss = 2.4222\n",
      "Iteration 141590: loss = 2.3664\n",
      "Iteration 141600: loss = 2.7316\n",
      "Iteration 141610: loss = 2.3712\n",
      "Iteration 141620: loss = 2.6914\n",
      "Iteration 141630: loss = 2.2898\n",
      "Iteration 141640: loss = 2.6822\n",
      "Iteration 141650: loss = 2.4579\n",
      "Iteration 141660: loss = 2.3109\n",
      "Iteration 141670: loss = 2.3735\n",
      "Iteration 141680: loss = 1.8272\n",
      "Iteration 141690: loss = 2.3322\n",
      "Iteration 141700: loss = 2.0862\n",
      "Iteration 141710: loss = 2.4493\n",
      "Iteration 141720: loss = 2.7609\n",
      "Iteration 141730: loss = 2.2553\n",
      "Iteration 141740: loss = 2.5454\n",
      "Iteration 141750: loss = 2.4604\n",
      "Iteration 141760: loss = 1.8834\n",
      "Iteration 141770: loss = 2.5555\n",
      "Iteration 141780: loss = 2.6417\n",
      "Iteration 141790: loss = 2.9338\n",
      "Iteration 141800: loss = 2.4992\n",
      "Iteration 141810: loss = 2.6777\n",
      "Iteration 141820: loss = 2.5554\n",
      "Iteration 141830: loss = 2.4370\n",
      "Iteration 141840: loss = 2.5883\n",
      "Iteration 141850: loss = 3.3688\n",
      "Iteration 141860: loss = 2.5493\n",
      "Iteration 141870: loss = 2.2607\n",
      "Iteration 141880: loss = 2.4084\n",
      "Iteration 141890: loss = 2.1818\n",
      "Iteration 141900: loss = 2.2423\n",
      "Iteration 141910: loss = 2.4080\n",
      "Iteration 141920: loss = 2.6145\n",
      "Iteration 141930: loss = 2.5495\n",
      "Iteration 141940: loss = 2.6552\n",
      "Iteration 141950: loss = 2.4189\n",
      "Iteration 141960: loss = 2.4347\n",
      "Iteration 141970: loss = 2.3769\n",
      "Iteration 141980: loss = 2.5678\n",
      "Iteration 141990: loss = 2.5082\n",
      "Iteration 142000: loss = 2.2404\n",
      "Iteration 142010: loss = 2.4217\n",
      "Iteration 142020: loss = 2.5718\n",
      "Iteration 142030: loss = 2.9805\n",
      "Iteration 142040: loss = 2.5963\n",
      "Iteration 142050: loss = 2.2593\n",
      "Iteration 142060: loss = 2.2649\n",
      "Iteration 142070: loss = 2.1627\n",
      "Iteration 142080: loss = 2.9245\n",
      "Iteration 142090: loss = 2.5750\n",
      "Iteration 142100: loss = 2.1640\n",
      "Iteration 142110: loss = 2.7091\n",
      "Iteration 142120: loss = 2.2238\n",
      "Iteration 142130: loss = 2.2453\n",
      "Iteration 142140: loss = 3.0361\n",
      "Iteration 142150: loss = 2.9732\n",
      "Iteration 142160: loss = 2.2178\n",
      "Iteration 142170: loss = 1.9231\n",
      "Iteration 142180: loss = 2.8188\n",
      "Iteration 142190: loss = 2.5666\n",
      "Iteration 142200: loss = 2.6636\n",
      "Iteration 142210: loss = 2.6131\n",
      "Iteration 142220: loss = 2.2807\n",
      "Iteration 142230: loss = 2.5758\n",
      "Iteration 142240: loss = 2.5427\n",
      "Iteration 142250: loss = 2.5686\n",
      "Iteration 142260: loss = 2.3571\n",
      "Iteration 142270: loss = 2.1425\n",
      "Iteration 142280: loss = 2.1838\n",
      "Iteration 142290: loss = 2.8479\n",
      "Iteration 142300: loss = 2.3482\n",
      "Iteration 142310: loss = 2.4788\n",
      "Iteration 142320: loss = 2.3699\n",
      "Iteration 142330: loss = 2.4752\n",
      "Iteration 142340: loss = 2.4305\n",
      "Iteration 142350: loss = 2.4456\n",
      "Iteration 142360: loss = 2.2402\n",
      "Iteration 142370: loss = 2.3610\n",
      "Iteration 142380: loss = 2.3432\n",
      "Iteration 142390: loss = 2.6341\n",
      "Iteration 142400: loss = 2.3720\n",
      "Iteration 142410: loss = 2.5845\n",
      "Iteration 142420: loss = 2.6445\n",
      "Iteration 142430: loss = 2.4594\n",
      "Iteration 142440: loss = 2.2242\n",
      "Iteration 142450: loss = 2.1171\n",
      "Iteration 142460: loss = 2.7602\n",
      "Iteration 142470: loss = 2.5102\n",
      "Iteration 142480: loss = 2.5094\n",
      "Iteration 142490: loss = 2.5686\n",
      "Iteration 142500: loss = 2.4794\n",
      "Iteration 142510: loss = 2.2707\n",
      "Iteration 142520: loss = 2.5365\n",
      "Iteration 142530: loss = 3.0330\n",
      "Iteration 142540: loss = 2.5486\n",
      "Iteration 142550: loss = 2.4412\n",
      "Iteration 142560: loss = 2.5972\n",
      "Iteration 142570: loss = 2.2689\n",
      "Iteration 142580: loss = 2.5421\n",
      "Iteration 142590: loss = 2.5192\n",
      "Iteration 142600: loss = 2.3238\n",
      "Iteration 142610: loss = 2.5090\n",
      "Iteration 142620: loss = 2.2878\n",
      "Iteration 142630: loss = 2.1982\n",
      "Iteration 142640: loss = 2.3193\n",
      "Iteration 142650: loss = 2.2745\n",
      "Iteration 142660: loss = 2.3459\n",
      "Iteration 142670: loss = 2.4559\n",
      "Iteration 142680: loss = 2.3372\n",
      "Iteration 142690: loss = 2.3780\n",
      "Iteration 142700: loss = 2.5179\n",
      "Iteration 142710: loss = 2.0571\n",
      "Iteration 142720: loss = 2.2996\n",
      "Iteration 142730: loss = 2.1983\n",
      "Iteration 142740: loss = 2.9116\n",
      "Iteration 142750: loss = 2.3721\n",
      "Iteration 142760: loss = 2.2697\n",
      "Iteration 142770: loss = 2.2920\n",
      "Iteration 142780: loss = 2.0458\n",
      "Iteration 142790: loss = 2.1853\n",
      "Iteration 142800: loss = 2.1711\n",
      "Iteration 142810: loss = 2.3924\n",
      "Iteration 142820: loss = 2.0178\n",
      "Iteration 142830: loss = 2.5101\n",
      "Iteration 142840: loss = 2.2962\n",
      "Iteration 142850: loss = 2.2789\n",
      "Iteration 142860: loss = 2.5154\n",
      "Iteration 142870: loss = 2.3994\n",
      "Iteration 142880: loss = 2.5407\n",
      "Iteration 142890: loss = 2.5212\n",
      "Iteration 142900: loss = 2.7453\n",
      "Iteration 142910: loss = 2.3673\n",
      "Iteration 142920: loss = 2.2640\n",
      "Iteration 142930: loss = 2.4078\n",
      "Iteration 142940: loss = 2.3878\n",
      "Iteration 142950: loss = 2.2017\n",
      "Iteration 142960: loss = 2.6935\n",
      "Iteration 142970: loss = 2.7171\n",
      "Iteration 142980: loss = 2.5629\n",
      "Iteration 142990: loss = 2.6689\n",
      "Iteration 143000: loss = 1.9940\n",
      "Iteration 143010: loss = 3.1107\n",
      "Iteration 143020: loss = 2.0594\n",
      "Iteration 143030: loss = 2.2669\n",
      "Iteration 143040: loss = 2.5960\n",
      "Iteration 143050: loss = 2.3466\n",
      "Iteration 143060: loss = 2.5625\n",
      "Iteration 143070: loss = 2.3106\n",
      "Iteration 143080: loss = 2.5844\n",
      "Iteration 143090: loss = 2.3920\n",
      "Iteration 143100: loss = 2.3583\n",
      "Iteration 143110: loss = 2.5779\n",
      "Iteration 143120: loss = 2.4944\n",
      "Iteration 143130: loss = 2.5991\n",
      "Iteration 143140: loss = 2.5898\n",
      "Iteration 143150: loss = 2.5359\n",
      "Iteration 143160: loss = 2.3468\n",
      "Iteration 143170: loss = 2.5337\n",
      "Iteration 143180: loss = 2.4156\n",
      "Iteration 143190: loss = 2.4058\n",
      "Iteration 143200: loss = 2.4696\n",
      "Iteration 143210: loss = 2.6351\n",
      "Iteration 143220: loss = 2.4733\n",
      "Iteration 143230: loss = 2.2886\n",
      "Iteration 143240: loss = 2.0663\n",
      "Iteration 143250: loss = 2.4418\n",
      "Iteration 143260: loss = 2.4423\n",
      "Iteration 143270: loss = 2.5461\n",
      "Iteration 143280: loss = 2.6579\n",
      "Iteration 143290: loss = 2.5308\n",
      "Iteration 143300: loss = 2.6259\n",
      "Iteration 143310: loss = 2.4786\n",
      "Iteration 143320: loss = 2.4629\n",
      "Iteration 143330: loss = 2.5339\n",
      "Iteration 143340: loss = 2.1734\n",
      "Iteration 143350: loss = 2.4416\n",
      "Iteration 143360: loss = 2.6994\n",
      "Iteration 143370: loss = 2.4822\n",
      "Iteration 143380: loss = 2.2427\n",
      "Iteration 143390: loss = 2.3896\n",
      "Iteration 143400: loss = 2.6453\n",
      "Iteration 143410: loss = 2.3348\n",
      "Iteration 143420: loss = 2.4888\n",
      "Iteration 143430: loss = 2.5510\n",
      "Iteration 143440: loss = 2.6932\n",
      "Iteration 143450: loss = 2.5222\n",
      "Iteration 143460: loss = 2.6169\n",
      "Iteration 143470: loss = 2.6596\n",
      "Iteration 143480: loss = 2.6189\n",
      "Iteration 143490: loss = 2.3008\n",
      "Iteration 143500: loss = 2.5713\n",
      "Iteration 143510: loss = 2.5551\n",
      "Iteration 143520: loss = 2.3510\n",
      "Iteration 143530: loss = 2.3331\n",
      "Iteration 143540: loss = 2.3834\n",
      "Iteration 143550: loss = 2.4016\n",
      "Iteration 143560: loss = 2.2044\n",
      "Iteration 143570: loss = 2.4021\n",
      "Iteration 143580: loss = 2.5730\n",
      "Iteration 143590: loss = 2.6059\n",
      "Iteration 143600: loss = 2.5329\n",
      "Iteration 143610: loss = 2.3998\n",
      "Iteration 143620: loss = 2.4850\n",
      "Iteration 143630: loss = 2.2759\n",
      "Iteration 143640: loss = 2.3260\n",
      "Iteration 143650: loss = 2.5016\n",
      "Iteration 143660: loss = 2.2541\n",
      "Iteration 143670: loss = 2.4820\n",
      "Iteration 143680: loss = 2.0757\n",
      "Iteration 143690: loss = 2.7417\n",
      "Iteration 143700: loss = 2.4460\n",
      "Iteration 143710: loss = 2.2748\n",
      "Iteration 143720: loss = 2.5820\n",
      "Iteration 143730: loss = 2.3531\n",
      "Iteration 143740: loss = 2.2784\n",
      "Iteration 143750: loss = 2.3816\n",
      "Iteration 143760: loss = 2.8666\n",
      "Iteration 143770: loss = 2.0701\n",
      "Iteration 143780: loss = 2.5552\n",
      "Iteration 143790: loss = 2.4410\n",
      "Iteration 143800: loss = 2.7386\n",
      "Iteration 143810: loss = 2.5669\n",
      "Iteration 143820: loss = 2.2929\n",
      "Iteration 143830: loss = 2.6242\n",
      "Iteration 143840: loss = 2.3159\n",
      "Iteration 143850: loss = 2.4315\n",
      "Iteration 143860: loss = 2.5386\n",
      "Iteration 143870: loss = 2.4035\n",
      "Iteration 143880: loss = 2.1272\n",
      "Iteration 143890: loss = 2.5277\n",
      "Iteration 143900: loss = 2.1465\n",
      "Iteration 143910: loss = 2.3271\n",
      "Iteration 143920: loss = 2.4835\n",
      "Iteration 143930: loss = 2.4751\n",
      "Iteration 143940: loss = 2.1893\n",
      "Iteration 143950: loss = 2.2844\n",
      "Iteration 143960: loss = 2.2513\n",
      "Iteration 143970: loss = 2.5316\n",
      "Iteration 143980: loss = 2.4242\n",
      "Iteration 143990: loss = 2.3116\n",
      "Iteration 144000: loss = 2.7142\n",
      "Iteration 144010: loss = 2.4679\n",
      "Iteration 144020: loss = 2.5143\n",
      "Iteration 144030: loss = 2.4169\n",
      "Iteration 144040: loss = 2.0835\n",
      "Iteration 144050: loss = 2.3260\n",
      "Iteration 144060: loss = 2.4756\n",
      "Iteration 144070: loss = 2.6377\n",
      "Iteration 144080: loss = 2.6069\n",
      "Iteration 144090: loss = 2.0576\n",
      "Iteration 144100: loss = 2.5859\n",
      "Iteration 144110: loss = 2.4174\n",
      "Iteration 144120: loss = 2.4924\n",
      "Iteration 144130: loss = 2.5130\n",
      "Iteration 144140: loss = 2.3329\n",
      "Iteration 144150: loss = 2.5820\n",
      "Iteration 144160: loss = 2.3630\n",
      "Iteration 144170: loss = 2.6030\n",
      "Iteration 144180: loss = 2.6396\n",
      "Iteration 144190: loss = 2.5163\n",
      "Iteration 144200: loss = 2.1569\n",
      "Iteration 144210: loss = 2.3022\n",
      "Iteration 144220: loss = 2.4602\n",
      "Iteration 144230: loss = 2.5175\n",
      "Iteration 144240: loss = 2.3013\n",
      "Iteration 144250: loss = 2.7977\n",
      "Iteration 144260: loss = 2.3011\n",
      "Iteration 144270: loss = 2.3116\n",
      "Iteration 144280: loss = 2.3915\n",
      "Iteration 144290: loss = 2.9809\n",
      "Iteration 144300: loss = 2.3559\n",
      "Iteration 144310: loss = 2.3268\n",
      "Iteration 144320: loss = 2.2184\n",
      "Iteration 144330: loss = 2.6760\n",
      "Iteration 144340: loss = 2.6169\n",
      "Iteration 144350: loss = 2.8847\n",
      "Iteration 144360: loss = 2.3158\n",
      "Iteration 144370: loss = 2.7886\n",
      "Iteration 144380: loss = 1.9777\n",
      "Iteration 144390: loss = 2.4736\n",
      "Iteration 144400: loss = 1.9990\n",
      "Iteration 144410: loss = 2.2056\n",
      "Iteration 144420: loss = 2.3272\n",
      "Iteration 144430: loss = 2.3177\n",
      "Iteration 144440: loss = 2.1006\n",
      "Iteration 144450: loss = 2.4602\n",
      "Iteration 144460: loss = 2.3789\n",
      "Iteration 144470: loss = 2.4522\n",
      "Iteration 144480: loss = 2.5337\n",
      "Iteration 144490: loss = 2.5394\n",
      "Iteration 144500: loss = 2.7936\n",
      "Iteration 144510: loss = 2.6531\n",
      "Iteration 144520: loss = 2.0803\n",
      "Iteration 144530: loss = 2.2095\n",
      "Iteration 144540: loss = 2.7447\n",
      "Iteration 144550: loss = 2.1967\n",
      "Iteration 144560: loss = 2.3220\n",
      "Iteration 144570: loss = 2.4357\n",
      "Iteration 144580: loss = 2.4476\n",
      "Iteration 144590: loss = 2.4791\n",
      "Iteration 144600: loss = 2.2243\n",
      "Iteration 144610: loss = 2.4394\n",
      "Iteration 144620: loss = 2.5042\n",
      "Iteration 144630: loss = 2.4088\n",
      "Iteration 144640: loss = 2.3840\n",
      "Iteration 144650: loss = 2.5129\n",
      "Iteration 144660: loss = 2.3876\n",
      "Iteration 144670: loss = 2.2070\n",
      "Iteration 144680: loss = 2.2267\n",
      "Iteration 144690: loss = 2.3455\n",
      "Iteration 144700: loss = 2.2216\n",
      "Iteration 144710: loss = 2.3330\n",
      "Iteration 144720: loss = 2.3039\n",
      "Iteration 144730: loss = 2.5578\n",
      "Iteration 144740: loss = 2.4549\n",
      "Iteration 144750: loss = 2.5263\n",
      "Iteration 144760: loss = 2.7579\n",
      "Iteration 144770: loss = 2.7371\n",
      "Iteration 144780: loss = 2.5081\n",
      "Iteration 144790: loss = 2.3901\n",
      "Iteration 144800: loss = 2.3383\n",
      "Iteration 144810: loss = 2.4268\n",
      "Iteration 144820: loss = 2.3987\n",
      "Iteration 144830: loss = 2.2277\n",
      "Iteration 144840: loss = 2.3733\n",
      "Iteration 144850: loss = 2.5362\n",
      "Iteration 144860: loss = 2.6481\n",
      "Iteration 144870: loss = 2.7099\n",
      "Iteration 144880: loss = 2.2633\n",
      "Iteration 144890: loss = 2.5563\n",
      "Iteration 144900: loss = 2.0131\n",
      "Iteration 144910: loss = 2.3888\n",
      "Iteration 144920: loss = 2.4517\n",
      "Iteration 144930: loss = 2.0209\n",
      "Iteration 144940: loss = 2.3100\n",
      "Iteration 144950: loss = 2.2460\n",
      "Iteration 144960: loss = 2.5333\n",
      "Iteration 144970: loss = 2.6309\n",
      "Iteration 144980: loss = 2.3032\n",
      "Iteration 144990: loss = 2.6730\n",
      "Iteration 145000: loss = 2.7467\n",
      "Iteration 145010: loss = 2.2854\n",
      "Iteration 145020: loss = 2.4446\n",
      "Iteration 145030: loss = 2.4567\n",
      "Iteration 145040: loss = 2.2371\n",
      "Iteration 145050: loss = 2.2672\n",
      "Iteration 145060: loss = 2.2427\n",
      "Iteration 145070: loss = 2.4712\n",
      "Iteration 145080: loss = 2.4997\n",
      "Iteration 145090: loss = 2.1973\n",
      "Iteration 145100: loss = 2.1510\n",
      "Iteration 145110: loss = 2.4898\n",
      "Iteration 145120: loss = 2.5158\n",
      "Iteration 145130: loss = 2.2915\n",
      "Iteration 145140: loss = 2.4621\n",
      "Iteration 145150: loss = 2.3830\n",
      "Iteration 145160: loss = 2.5045\n",
      "Iteration 145170: loss = 2.2905\n",
      "Iteration 145180: loss = 2.3894\n",
      "Iteration 145190: loss = 2.1953\n",
      "Iteration 145200: loss = 2.2087\n",
      "Iteration 145210: loss = 2.1873\n",
      "Iteration 145220: loss = 1.8965\n",
      "Iteration 145230: loss = 2.3505\n",
      "Iteration 145240: loss = 2.3768\n",
      "Iteration 145250: loss = 2.2751\n",
      "Iteration 145260: loss = 2.0964\n",
      "Iteration 145270: loss = 2.5748\n",
      "Iteration 145280: loss = 1.9597\n",
      "Iteration 145290: loss = 2.2070\n",
      "Iteration 145300: loss = 2.7751\n",
      "Iteration 145310: loss = 2.3635\n",
      "Iteration 145320: loss = 2.5307\n",
      "Iteration 145330: loss = 2.4019\n",
      "Iteration 145340: loss = 2.9038\n",
      "Iteration 145350: loss = 2.3433\n",
      "Iteration 145360: loss = 2.6411\n",
      "Iteration 145370: loss = 2.6608\n",
      "Iteration 145380: loss = 2.4623\n",
      "Iteration 145390: loss = 2.4288\n",
      "Iteration 145400: loss = 2.5024\n",
      "Iteration 145410: loss = 2.7642\n",
      "Iteration 145420: loss = 2.2282\n",
      "Iteration 145430: loss = 2.4502\n",
      "Iteration 145440: loss = 2.7675\n",
      "Iteration 145450: loss = 1.8502\n",
      "Iteration 145460: loss = 2.6333\n",
      "Iteration 145470: loss = 2.0311\n",
      "Iteration 145480: loss = 2.4574\n",
      "Iteration 145490: loss = 2.8088\n",
      "Iteration 145500: loss = 2.4137\n",
      "Iteration 145510: loss = 2.8186\n",
      "Iteration 145520: loss = 2.3759\n",
      "Iteration 145530: loss = 2.5530\n",
      "Iteration 145540: loss = 2.4761\n",
      "Iteration 145550: loss = 2.5345\n",
      "Iteration 145560: loss = 2.6323\n",
      "Iteration 145570: loss = 2.6080\n",
      "Iteration 145580: loss = 2.5307\n",
      "Iteration 145590: loss = 2.2116\n",
      "Iteration 145600: loss = 2.6621\n",
      "Iteration 145610: loss = 2.2365\n",
      "Iteration 145620: loss = 2.8256\n",
      "Iteration 145630: loss = 2.3828\n",
      "Iteration 145640: loss = 2.5228\n",
      "Iteration 145650: loss = 1.9919\n",
      "Iteration 145660: loss = 2.2625\n",
      "Iteration 145670: loss = 2.0603\n",
      "Iteration 145680: loss = 2.6293\n",
      "Iteration 145690: loss = 1.9412\n",
      "Iteration 145700: loss = 2.0146\n",
      "Iteration 145710: loss = 2.9079\n",
      "Iteration 145720: loss = 2.8229\n",
      "Iteration 145730: loss = 2.6485\n",
      "Iteration 145740: loss = 2.6311\n",
      "Iteration 145750: loss = 2.6602\n",
      "Iteration 145760: loss = 2.8257\n",
      "Iteration 145770: loss = 2.1210\n",
      "Iteration 145780: loss = 2.5735\n",
      "Iteration 145790: loss = 2.4727\n",
      "Iteration 145800: loss = 2.2907\n",
      "Iteration 145810: loss = 2.2241\n",
      "Iteration 145820: loss = 2.2944\n",
      "Iteration 145830: loss = 2.4179\n",
      "Iteration 145840: loss = 2.0504\n",
      "Iteration 145850: loss = 2.6918\n",
      "Iteration 145860: loss = 2.5632\n",
      "Iteration 145870: loss = 2.3089\n",
      "Iteration 145880: loss = 1.9022\n",
      "Iteration 145890: loss = 2.3906\n",
      "Iteration 145900: loss = 2.3361\n",
      "Iteration 145910: loss = 2.2130\n",
      "Iteration 145920: loss = 2.2306\n",
      "Iteration 145930: loss = 2.4115\n",
      "Iteration 145940: loss = 2.1451\n",
      "Iteration 145950: loss = 2.7212\n",
      "Iteration 145960: loss = 2.5257\n",
      "Iteration 145970: loss = 2.7034\n",
      "Iteration 145980: loss = 2.0782\n",
      "Iteration 145990: loss = 2.5593\n",
      "Iteration 146000: loss = 2.3020\n",
      "Iteration 146010: loss = 2.1554\n",
      "Iteration 146020: loss = 2.7049\n",
      "Iteration 146030: loss = 2.7446\n",
      "Iteration 146040: loss = 2.3667\n",
      "Iteration 146050: loss = 2.2346\n",
      "Iteration 146060: loss = 2.1055\n",
      "Iteration 146070: loss = 2.8601\n",
      "Iteration 146080: loss = 2.2346\n",
      "Iteration 146090: loss = 2.0058\n",
      "Iteration 146100: loss = 2.7796\n",
      "Iteration 146110: loss = 2.3927\n",
      "Iteration 146120: loss = 2.7788\n",
      "Iteration 146130: loss = 2.5569\n",
      "Iteration 146140: loss = 2.4206\n",
      "Iteration 146150: loss = 2.5322\n",
      "Iteration 146160: loss = 2.4898\n",
      "Iteration 146170: loss = 2.0088\n",
      "Iteration 146180: loss = 2.5975\n",
      "Iteration 146190: loss = 2.4803\n",
      "Iteration 146200: loss = 2.6600\n",
      "Iteration 146210: loss = 2.8196\n",
      "Iteration 146220: loss = 2.3349\n",
      "Iteration 146230: loss = 2.6559\n",
      "Iteration 146240: loss = 2.6465\n",
      "Iteration 146250: loss = 2.2224\n",
      "Iteration 146260: loss = 2.5305\n",
      "Iteration 146270: loss = 2.1963\n",
      "Iteration 146280: loss = 2.6489\n",
      "Iteration 146290: loss = 2.8270\n",
      "Iteration 146300: loss = 2.2173\n",
      "Iteration 146310: loss = 2.6461\n",
      "Iteration 146320: loss = 2.7142\n",
      "Iteration 146330: loss = 2.5671\n",
      "Iteration 146340: loss = 2.4537\n",
      "Iteration 146350: loss = 2.1808\n",
      "Iteration 146360: loss = 2.2709\n",
      "Iteration 146370: loss = 2.3328\n",
      "Iteration 146380: loss = 2.5753\n",
      "Iteration 146390: loss = 2.5449\n",
      "Iteration 146400: loss = 2.3217\n",
      "Iteration 146410: loss = 2.6563\n",
      "Iteration 146420: loss = 2.4596\n",
      "Iteration 146430: loss = 2.5990\n",
      "Iteration 146440: loss = 2.4435\n",
      "Iteration 146450: loss = 2.7115\n",
      "Iteration 146460: loss = 2.4999\n",
      "Iteration 146470: loss = 2.4197\n",
      "Iteration 146480: loss = 2.1618\n",
      "Iteration 146490: loss = 2.4052\n",
      "Iteration 146500: loss = 2.4636\n",
      "Iteration 146510: loss = 2.1334\n",
      "Iteration 146520: loss = 2.7041\n",
      "Iteration 146530: loss = 2.3642\n",
      "Iteration 146540: loss = 2.7126\n",
      "Iteration 146550: loss = 2.4035\n",
      "Iteration 146560: loss = 2.2023\n",
      "Iteration 146570: loss = 2.7681\n",
      "Iteration 146580: loss = 2.3825\n",
      "Iteration 146590: loss = 2.6711\n",
      "Iteration 146600: loss = 2.8131\n",
      "Iteration 146610: loss = 2.1540\n",
      "Iteration 146620: loss = 2.2801\n",
      "Iteration 146630: loss = 2.4060\n",
      "Iteration 146640: loss = 2.5493\n",
      "Iteration 146650: loss = 2.2806\n",
      "Iteration 146660: loss = 2.6862\n",
      "Iteration 146670: loss = 2.4255\n",
      "Iteration 146680: loss = 2.4066\n",
      "Iteration 146690: loss = 2.4773\n",
      "Iteration 146700: loss = 2.4715\n",
      "Iteration 146710: loss = 2.3278\n",
      "Iteration 146720: loss = 2.3580\n",
      "Iteration 146730: loss = 2.8841\n",
      "Iteration 146740: loss = 2.1382\n",
      "Iteration 146750: loss = 2.6095\n",
      "Iteration 146760: loss = 2.3370\n",
      "Iteration 146770: loss = 2.5017\n",
      "Iteration 146780: loss = 2.2979\n",
      "Iteration 146790: loss = 2.4692\n",
      "Iteration 146800: loss = 2.1646\n",
      "Iteration 146810: loss = 2.6079\n",
      "Iteration 146820: loss = 2.3916\n",
      "Iteration 146830: loss = 2.5106\n",
      "Iteration 146840: loss = 2.4123\n",
      "Iteration 146850: loss = 2.3850\n",
      "Iteration 146860: loss = 2.3676\n",
      "Iteration 146870: loss = 2.3675\n",
      "Iteration 146880: loss = 2.3540\n",
      "Iteration 146890: loss = 2.1203\n",
      "Iteration 146900: loss = 2.6065\n",
      "Iteration 146910: loss = 2.4018\n",
      "Iteration 146920: loss = 2.8434\n",
      "Iteration 146930: loss = 2.5591\n",
      "Iteration 146940: loss = 2.3395\n",
      "Iteration 146950: loss = 2.4398\n",
      "Iteration 146960: loss = 2.6209\n",
      "Iteration 146970: loss = 2.2554\n",
      "Iteration 146980: loss = 2.7284\n",
      "Iteration 146990: loss = 2.8538\n",
      "Iteration 147000: loss = 2.3791\n",
      "Iteration 147010: loss = 2.4105\n",
      "Iteration 147020: loss = 2.2918\n",
      "Iteration 147030: loss = 2.3437\n",
      "Iteration 147040: loss = 2.3264\n",
      "Iteration 147050: loss = 2.4588\n",
      "Iteration 147060: loss = 2.3064\n",
      "Iteration 147070: loss = 2.1255\n",
      "Iteration 147080: loss = 2.2048\n",
      "Iteration 147090: loss = 1.9427\n",
      "Iteration 147100: loss = 2.0204\n",
      "Iteration 147110: loss = 1.8876\n",
      "Iteration 147120: loss = 2.6987\n",
      "Iteration 147130: loss = 2.4704\n",
      "Iteration 147140: loss = 2.2881\n",
      "Iteration 147150: loss = 2.0813\n",
      "Iteration 147160: loss = 2.2104\n",
      "Iteration 147170: loss = 2.2182\n",
      "Iteration 147180: loss = 2.4263\n",
      "Iteration 147190: loss = 1.7469\n",
      "Iteration 147200: loss = 2.2878\n",
      "Iteration 147210: loss = 2.4176\n",
      "Iteration 147220: loss = 2.1033\n",
      "Iteration 147230: loss = 2.6333\n",
      "Iteration 147240: loss = 2.7977\n",
      "Iteration 147250: loss = 2.1897\n",
      "Iteration 147260: loss = 2.5778\n",
      "Iteration 147270: loss = 2.3153\n",
      "Iteration 147280: loss = 2.8544\n",
      "Iteration 147290: loss = 2.5896\n",
      "Iteration 147300: loss = 2.5427\n",
      "Iteration 147310: loss = 2.2944\n",
      "Iteration 147320: loss = 2.4072\n",
      "Iteration 147330: loss = 2.9649\n",
      "Iteration 147340: loss = 2.2829\n",
      "Iteration 147350: loss = 1.8948\n",
      "Iteration 147360: loss = 2.6081\n",
      "Iteration 147370: loss = 2.7765\n",
      "Iteration 147380: loss = 2.2169\n",
      "Iteration 147390: loss = 2.9734\n",
      "Iteration 147400: loss = 2.0742\n",
      "Iteration 147410: loss = 2.4895\n",
      "Iteration 147420: loss = 2.5702\n",
      "Iteration 147430: loss = 2.2140\n",
      "Iteration 147440: loss = 2.4980\n",
      "Iteration 147450: loss = 2.6245\n",
      "Iteration 147460: loss = 1.9954\n",
      "Iteration 147470: loss = 2.4203\n",
      "Iteration 147480: loss = 2.5416\n",
      "Iteration 147490: loss = 2.5537\n",
      "Iteration 147500: loss = 2.2493\n",
      "Iteration 147510: loss = 2.6082\n",
      "Iteration 147520: loss = 2.5548\n",
      "Iteration 147530: loss = 2.0458\n",
      "Iteration 147540: loss = 2.3177\n",
      "Iteration 147550: loss = 2.4739\n",
      "Iteration 147560: loss = 2.1754\n",
      "Iteration 147570: loss = 2.8919\n",
      "Iteration 147580: loss = 2.5506\n",
      "Iteration 147590: loss = 3.0836\n",
      "Iteration 147600: loss = 2.3740\n",
      "Iteration 147610: loss = 2.2573\n",
      "Iteration 147620: loss = 2.5057\n",
      "Iteration 147630: loss = 2.6519\n",
      "Iteration 147640: loss = 2.3574\n",
      "Iteration 147650: loss = 2.4675\n",
      "Iteration 147660: loss = 2.5012\n",
      "Iteration 147670: loss = 2.3367\n",
      "Iteration 147680: loss = 2.2885\n",
      "Iteration 147690: loss = 2.6610\n",
      "Iteration 147700: loss = 2.3471\n",
      "Iteration 147710: loss = 2.1795\n",
      "Iteration 147720: loss = 2.4212\n",
      "Iteration 147730: loss = 2.6129\n",
      "Iteration 147740: loss = 2.6092\n",
      "Iteration 147750: loss = 2.2421\n",
      "Iteration 147760: loss = 2.9096\n",
      "Iteration 147770: loss = 2.7487\n",
      "Iteration 147780: loss = 2.5071\n",
      "Iteration 147790: loss = 2.8983\n",
      "Iteration 147800: loss = 2.4013\n",
      "Iteration 147810: loss = 2.3176\n",
      "Iteration 147820: loss = 2.2790\n",
      "Iteration 147830: loss = 2.5787\n",
      "Iteration 147840: loss = 2.5919\n",
      "Iteration 147850: loss = 2.5152\n",
      "Iteration 147860: loss = 2.2390\n",
      "Iteration 147870: loss = 2.4914\n",
      "Iteration 147880: loss = 2.5508\n",
      "Iteration 147890: loss = 2.4534\n",
      "Iteration 147900: loss = 2.3950\n",
      "Iteration 147910: loss = 2.2634\n",
      "Iteration 147920: loss = 2.5920\n",
      "Iteration 147930: loss = 2.3986\n",
      "Iteration 147940: loss = 2.1011\n",
      "Iteration 147950: loss = 2.4989\n",
      "Iteration 147960: loss = 2.5893\n",
      "Iteration 147970: loss = 2.5495\n",
      "Iteration 147980: loss = 2.1853\n",
      "Iteration 147990: loss = 2.3380\n",
      "Iteration 148000: loss = 2.6342\n",
      "Iteration 148010: loss = 2.6376\n",
      "Iteration 148020: loss = 2.5015\n",
      "Iteration 148030: loss = 2.9763\n",
      "Iteration 148040: loss = 2.0518\n",
      "Iteration 148050: loss = 2.5466\n",
      "Iteration 148060: loss = 2.3353\n",
      "Iteration 148070: loss = 2.3863\n",
      "Iteration 148080: loss = 2.5129\n",
      "Iteration 148090: loss = 2.4929\n",
      "Iteration 148100: loss = 2.3078\n",
      "Iteration 148110: loss = 2.4326\n",
      "Iteration 148120: loss = 2.4020\n",
      "Iteration 148130: loss = 2.4674\n",
      "Iteration 148140: loss = 2.2044\n",
      "Iteration 148150: loss = 2.1316\n",
      "Iteration 148160: loss = 2.5330\n",
      "Iteration 148170: loss = 2.3013\n",
      "Iteration 148180: loss = 2.2228\n",
      "Iteration 148190: loss = 2.5839\n",
      "Iteration 148200: loss = 2.6271\n",
      "Iteration 148210: loss = 2.6475\n",
      "Iteration 148220: loss = 2.3525\n",
      "Iteration 148230: loss = 2.4979\n",
      "Iteration 148240: loss = 2.7299\n",
      "Iteration 148250: loss = 2.4390\n",
      "Iteration 148260: loss = 2.3852\n",
      "Iteration 148270: loss = 2.2290\n",
      "Iteration 148280: loss = 2.3097\n",
      "Iteration 148290: loss = 2.4123\n",
      "Iteration 148300: loss = 2.4236\n",
      "Iteration 148310: loss = 2.3817\n",
      "Iteration 148320: loss = 2.4522\n",
      "Iteration 148330: loss = 2.1502\n",
      "Iteration 148340: loss = 2.4805\n",
      "Iteration 148350: loss = 2.2350\n",
      "Iteration 148360: loss = 2.4363\n",
      "Iteration 148370: loss = 2.4069\n",
      "Iteration 148380: loss = 2.6007\n",
      "Iteration 148390: loss = 2.6009\n",
      "Iteration 148400: loss = 2.1235\n",
      "Iteration 148410: loss = 2.6702\n",
      "Iteration 148420: loss = 2.5615\n",
      "Iteration 148430: loss = 2.8006\n",
      "Iteration 148440: loss = 2.4537\n",
      "Iteration 148450: loss = 2.2873\n",
      "Iteration 148460: loss = 2.4919\n",
      "Iteration 148470: loss = 3.0033\n",
      "Iteration 148480: loss = 2.3539\n",
      "Iteration 148490: loss = 2.3885\n",
      "Iteration 148500: loss = 1.9112\n",
      "Iteration 148510: loss = 2.2688\n",
      "Iteration 148520: loss = 2.1201\n",
      "Iteration 148530: loss = 2.6260\n",
      "Iteration 148540: loss = 2.1427\n",
      "Iteration 148550: loss = 2.0436\n",
      "Iteration 148560: loss = 2.5530\n",
      "Iteration 148570: loss = 2.4802\n",
      "Iteration 148580: loss = 2.3093\n",
      "Iteration 148590: loss = 2.6940\n",
      "Iteration 148600: loss = 2.3560\n",
      "Iteration 148610: loss = 2.8158\n",
      "Iteration 148620: loss = 2.5698\n",
      "Iteration 148630: loss = 2.3149\n",
      "Iteration 148640: loss = 2.1495\n",
      "Iteration 148650: loss = 2.5381\n",
      "Iteration 148660: loss = 2.3348\n",
      "Iteration 148670: loss = 2.5308\n",
      "Iteration 148680: loss = 2.2200\n",
      "Iteration 148690: loss = 2.5308\n",
      "Iteration 148700: loss = 2.2885\n",
      "Iteration 148710: loss = 2.2141\n",
      "Iteration 148720: loss = 2.8034\n",
      "Iteration 148730: loss = 2.2007\n",
      "Iteration 148740: loss = 2.5377\n",
      "Iteration 148750: loss = 2.2020\n",
      "Iteration 148760: loss = 2.7609\n",
      "Iteration 148770: loss = 2.3242\n",
      "Iteration 148780: loss = 2.2854\n",
      "Iteration 148790: loss = 2.0745\n",
      "Iteration 148800: loss = 2.3591\n",
      "Iteration 148810: loss = 2.4044\n",
      "Iteration 148820: loss = 2.5507\n",
      "Iteration 148830: loss = 2.3036\n",
      "Iteration 148840: loss = 2.2545\n",
      "Iteration 148850: loss = 2.5815\n",
      "Iteration 148860: loss = 2.6187\n",
      "Iteration 148870: loss = 2.4196\n",
      "Iteration 148880: loss = 2.0699\n",
      "Iteration 148890: loss = 2.3521\n",
      "Iteration 148900: loss = 2.3822\n",
      "Iteration 148910: loss = 2.5743\n",
      "Iteration 148920: loss = 2.8668\n",
      "Iteration 148930: loss = 2.4545\n",
      "Iteration 148940: loss = 2.6203\n",
      "Iteration 148950: loss = 2.1038\n",
      "Iteration 148960: loss = 2.6643\n",
      "Iteration 148970: loss = 2.4307\n",
      "Iteration 148980: loss = 2.2122\n",
      "Iteration 148990: loss = 2.5847\n",
      "Iteration 149000: loss = 2.5259\n",
      "Iteration 149010: loss = 2.1429\n",
      "Iteration 149020: loss = 2.6524\n",
      "Iteration 149030: loss = 2.6709\n",
      "Iteration 149040: loss = 2.2642\n",
      "Iteration 149050: loss = 2.9164\n",
      "Iteration 149060: loss = 2.2978\n",
      "Iteration 149070: loss = 2.8233\n",
      "Iteration 149080: loss = 2.3796\n",
      "Iteration 149090: loss = 2.3776\n",
      "Iteration 149100: loss = 2.4455\n",
      "Iteration 149110: loss = 2.4693\n",
      "Iteration 149120: loss = 2.4930\n",
      "Iteration 149130: loss = 2.4697\n",
      "Iteration 149140: loss = 2.1524\n",
      "Iteration 149150: loss = 2.3510\n",
      "Iteration 149160: loss = 2.4144\n",
      "Iteration 149170: loss = 2.4040\n",
      "Iteration 149180: loss = 2.3786\n",
      "Iteration 149190: loss = 2.1656\n",
      "Iteration 149200: loss = 2.2952\n",
      "Iteration 149210: loss = 2.3898\n",
      "Iteration 149220: loss = 2.6609\n",
      "Iteration 149230: loss = 2.1940\n",
      "Iteration 149240: loss = 2.5495\n",
      "Iteration 149250: loss = 2.3957\n",
      "Iteration 149260: loss = 2.4669\n",
      "Iteration 149270: loss = 2.1286\n",
      "Iteration 149280: loss = 2.5487\n",
      "Iteration 149290: loss = 2.4480\n",
      "Iteration 149300: loss = 2.2375\n",
      "Iteration 149310: loss = 2.1935\n",
      "Iteration 149320: loss = 2.4531\n",
      "Iteration 149330: loss = 2.4910\n",
      "Iteration 149340: loss = 2.2805\n",
      "Iteration 149350: loss = 2.3283\n",
      "Iteration 149360: loss = 2.7449\n",
      "Iteration 149370: loss = 2.9130\n",
      "Iteration 149380: loss = 2.3716\n",
      "Iteration 149390: loss = 2.2758\n",
      "Iteration 149400: loss = 2.4329\n",
      "Iteration 149410: loss = 2.7343\n",
      "Iteration 149420: loss = 2.3779\n",
      "Iteration 149430: loss = 2.7073\n",
      "Iteration 149440: loss = 1.9200\n",
      "Iteration 149450: loss = 2.4552\n",
      "Iteration 149460: loss = 2.3522\n",
      "Iteration 149470: loss = 2.4117\n",
      "Iteration 149480: loss = 2.3390\n",
      "Iteration 149490: loss = 2.7035\n",
      "Iteration 149500: loss = 1.9922\n",
      "Iteration 149510: loss = 2.7685\n",
      "Iteration 149520: loss = 2.5979\n",
      "Iteration 149530: loss = 2.4983\n",
      "Iteration 149540: loss = 1.9609\n",
      "Iteration 149550: loss = 2.2765\n",
      "Iteration 149560: loss = 2.4621\n",
      "Iteration 149570: loss = 2.7679\n",
      "Iteration 149580: loss = 2.6116\n",
      "Iteration 149590: loss = 3.0288\n",
      "Iteration 149600: loss = 2.9081\n",
      "Iteration 149610: loss = 2.5370\n",
      "Iteration 149620: loss = 2.3286\n",
      "Iteration 149630: loss = 2.0886\n",
      "Iteration 149640: loss = 2.4447\n",
      "Iteration 149650: loss = 2.3134\n",
      "Iteration 149660: loss = 2.1979\n",
      "Iteration 149670: loss = 2.1757\n",
      "Iteration 149680: loss = 2.2153\n",
      "Iteration 149690: loss = 2.0567\n",
      "Iteration 149700: loss = 2.5595\n",
      "Iteration 149710: loss = 2.3827\n",
      "Iteration 149720: loss = 2.3823\n",
      "Iteration 149730: loss = 2.3389\n",
      "Iteration 149740: loss = 2.4070\n",
      "Iteration 149750: loss = 2.6637\n",
      "Iteration 149760: loss = 2.3857\n",
      "Iteration 149770: loss = 2.3300\n",
      "Iteration 149780: loss = 2.2469\n",
      "Iteration 149790: loss = 1.9974\n",
      "Iteration 149800: loss = 2.4159\n",
      "Iteration 149810: loss = 2.7074\n",
      "Iteration 149820: loss = 2.4897\n",
      "Iteration 149830: loss = 2.4934\n",
      "Iteration 149840: loss = 2.4617\n",
      "Iteration 149850: loss = 2.1286\n",
      "Iteration 149860: loss = 2.5944\n",
      "Iteration 149870: loss = 2.5682\n",
      "Iteration 149880: loss = 2.5534\n",
      "Iteration 149890: loss = 2.3092\n",
      "Iteration 149900: loss = 2.6916\n",
      "Iteration 149910: loss = 2.7866\n",
      "Iteration 149920: loss = 2.5223\n",
      "Iteration 149930: loss = 2.5931\n",
      "Iteration 149940: loss = 2.6391\n",
      "Iteration 149950: loss = 2.6289\n",
      "Iteration 149960: loss = 2.2749\n",
      "Iteration 149970: loss = 2.6600\n",
      "Iteration 149980: loss = 2.8290\n",
      "Iteration 149990: loss = 2.3608\n",
      "Iteration 150000: loss = 2.5391\n",
      "Iteration 150010: loss = 2.4100\n",
      "Iteration 150020: loss = 2.5281\n",
      "Iteration 150030: loss = 2.5094\n",
      "Iteration 150040: loss = 2.4885\n",
      "Iteration 150050: loss = 2.2326\n",
      "Iteration 150060: loss = 2.2744\n",
      "Iteration 150070: loss = 2.2399\n",
      "Iteration 150080: loss = 2.2963\n",
      "Iteration 150090: loss = 2.5518\n",
      "Iteration 150100: loss = 2.2877\n",
      "Iteration 150110: loss = 2.5718\n",
      "Iteration 150120: loss = 2.4970\n",
      "Iteration 150130: loss = 2.1205\n",
      "Iteration 150140: loss = 2.3810\n",
      "Iteration 150150: loss = 2.5099\n",
      "Iteration 150160: loss = 2.6150\n",
      "Iteration 150170: loss = 2.3228\n",
      "Iteration 150180: loss = 2.3413\n",
      "Iteration 150190: loss = 2.2661\n",
      "Iteration 150200: loss = 2.9648\n",
      "Iteration 150210: loss = 2.4767\n",
      "Iteration 150220: loss = 2.7853\n",
      "Iteration 150230: loss = 2.3922\n",
      "Iteration 150240: loss = 2.4280\n",
      "Iteration 150250: loss = 2.2116\n",
      "Iteration 150260: loss = 2.0899\n",
      "Iteration 150270: loss = 2.8252\n",
      "Iteration 150280: loss = 2.3683\n",
      "Iteration 150290: loss = 2.2019\n",
      "Iteration 150300: loss = 2.5992\n",
      "Iteration 150310: loss = 2.3110\n",
      "Iteration 150320: loss = 2.5080\n",
      "Iteration 150330: loss = 2.5816\n",
      "Iteration 150340: loss = 2.2673\n",
      "Iteration 150350: loss = 2.6370\n",
      "Iteration 150360: loss = 2.9480\n",
      "Iteration 150370: loss = 2.0911\n",
      "Iteration 150380: loss = 2.0990\n",
      "Iteration 150390: loss = 2.4913\n",
      "Iteration 150400: loss = 2.0668\n",
      "Iteration 150410: loss = 2.5393\n",
      "Iteration 150420: loss = 2.4008\n",
      "Iteration 150430: loss = 2.1674\n",
      "Iteration 150440: loss = 2.0918\n",
      "Iteration 150450: loss = 2.4244\n",
      "Iteration 150460: loss = 2.1737\n",
      "Iteration 150470: loss = 2.3890\n",
      "Iteration 150480: loss = 2.3827\n",
      "Iteration 150490: loss = 2.7046\n",
      "Iteration 150500: loss = 2.2941\n",
      "Iteration 150510: loss = 2.0943\n",
      "Iteration 150520: loss = 2.4852\n",
      "Iteration 150530: loss = 1.9877\n",
      "Iteration 150540: loss = 2.6310\n",
      "Iteration 150550: loss = 2.6942\n",
      "Iteration 150560: loss = 2.1413\n",
      "Iteration 150570: loss = 2.7876\n",
      "Iteration 150580: loss = 2.4119\n",
      "Iteration 150590: loss = 2.3793\n",
      "Iteration 150600: loss = 2.3615\n",
      "Iteration 150610: loss = 2.5505\n",
      "Iteration 150620: loss = 2.4702\n",
      "Iteration 150630: loss = 2.3492\n",
      "Iteration 150640: loss = 2.5520\n",
      "Iteration 150650: loss = 2.2280\n",
      "Iteration 150660: loss = 2.4717\n",
      "Iteration 150670: loss = 2.7121\n",
      "Iteration 150680: loss = 2.2925\n",
      "Iteration 150690: loss = 2.4571\n",
      "Iteration 150700: loss = 2.6164\n",
      "Iteration 150710: loss = 2.4025\n",
      "Iteration 150720: loss = 2.5398\n",
      "Iteration 150730: loss = 2.6167\n",
      "Iteration 150740: loss = 2.5691\n",
      "Iteration 150750: loss = 2.6231\n",
      "Iteration 150760: loss = 2.3403\n",
      "Iteration 150770: loss = 2.7215\n",
      "Iteration 150780: loss = 2.6944\n",
      "Iteration 150790: loss = 2.6778\n",
      "Iteration 150800: loss = 2.3064\n",
      "Iteration 150810: loss = 2.3617\n",
      "Iteration 150820: loss = 2.7394\n",
      "Iteration 150830: loss = 2.6562\n",
      "Iteration 150840: loss = 2.4366\n",
      "Iteration 150850: loss = 2.3242\n",
      "Iteration 150860: loss = 2.5075\n",
      "Iteration 150870: loss = 2.3803\n",
      "Iteration 150880: loss = 2.3009\n",
      "Iteration 150890: loss = 2.1653\n",
      "Iteration 150900: loss = 2.6111\n",
      "Iteration 150910: loss = 2.3551\n",
      "Iteration 150920: loss = 2.2582\n",
      "Iteration 150930: loss = 2.2678\n",
      "Iteration 150940: loss = 2.3450\n",
      "Iteration 150950: loss = 2.4539\n",
      "Iteration 150960: loss = 2.5332\n",
      "Iteration 150970: loss = 2.5980\n",
      "Iteration 150980: loss = 2.1159\n",
      "Iteration 150990: loss = 2.3882\n",
      "Iteration 151000: loss = 2.1369\n",
      "Iteration 151010: loss = 2.7201\n",
      "Iteration 151020: loss = 2.5495\n",
      "Iteration 151030: loss = 2.8653\n",
      "Iteration 151040: loss = 2.0214\n",
      "Iteration 151050: loss = 2.5826\n",
      "Iteration 151060: loss = 2.7812\n",
      "Iteration 151070: loss = 2.3726\n",
      "Iteration 151080: loss = 2.5478\n",
      "Iteration 151090: loss = 2.5019\n",
      "Iteration 151100: loss = 2.2999\n",
      "Iteration 151110: loss = 2.6437\n",
      "Iteration 151120: loss = 1.9922\n",
      "Iteration 151130: loss = 2.4351\n",
      "Iteration 151140: loss = 2.5093\n",
      "Iteration 151150: loss = 2.2740\n",
      "Iteration 151160: loss = 2.0402\n",
      "Iteration 151170: loss = 2.2861\n",
      "Iteration 151180: loss = 2.3212\n",
      "Iteration 151190: loss = 2.0351\n",
      "Iteration 151200: loss = 2.6581\n",
      "Iteration 151210: loss = 2.4733\n",
      "Iteration 151220: loss = 2.9391\n",
      "Iteration 151230: loss = 2.5157\n",
      "Iteration 151240: loss = 2.4312\n",
      "Iteration 151250: loss = 2.6292\n",
      "Iteration 151260: loss = 2.5014\n",
      "Iteration 151270: loss = 2.1721\n",
      "Iteration 151280: loss = 2.6188\n",
      "Iteration 151290: loss = 2.4946\n",
      "Iteration 151300: loss = 2.3453\n",
      "Iteration 151310: loss = 2.5268\n",
      "Iteration 151320: loss = 2.2721\n",
      "Iteration 151330: loss = 2.1601\n",
      "Iteration 151340: loss = 2.2904\n",
      "Iteration 151350: loss = 2.6794\n",
      "Iteration 151360: loss = 2.3979\n",
      "Iteration 151370: loss = 2.8331\n",
      "Iteration 151380: loss = 2.1469\n",
      "Iteration 151390: loss = 2.3154\n",
      "Iteration 151400: loss = 2.0948\n",
      "Iteration 151410: loss = 2.0407\n",
      "Iteration 151420: loss = 1.9664\n",
      "Iteration 151430: loss = 2.5205\n",
      "Iteration 151440: loss = 2.7366\n",
      "Iteration 151450: loss = 2.1418\n",
      "Iteration 151460: loss = 2.5215\n",
      "Iteration 151470: loss = 2.3853\n",
      "Iteration 151480: loss = 2.1277\n",
      "Iteration 151490: loss = 2.6126\n",
      "Iteration 151500: loss = 2.3413\n",
      "Iteration 151510: loss = 2.3676\n",
      "Iteration 151520: loss = 2.8098\n",
      "Iteration 151530: loss = 2.4576\n",
      "Iteration 151540: loss = 2.2741\n",
      "Iteration 151550: loss = 2.8892\n",
      "Iteration 151560: loss = 2.4624\n",
      "Iteration 151570: loss = 2.3852\n",
      "Iteration 151580: loss = 2.4801\n",
      "Iteration 151590: loss = 2.7816\n",
      "Iteration 151600: loss = 2.2645\n",
      "Iteration 151610: loss = 2.1178\n",
      "Iteration 151620: loss = 2.2573\n",
      "Iteration 151630: loss = 2.4015\n",
      "Iteration 151640: loss = 2.5050\n",
      "Iteration 151650: loss = 2.5924\n",
      "Iteration 151660: loss = 2.5097\n",
      "Iteration 151670: loss = 2.2473\n",
      "Iteration 151680: loss = 2.5067\n",
      "Iteration 151690: loss = 2.4646\n",
      "Iteration 151700: loss = 2.5081\n",
      "Iteration 151710: loss = 2.3731\n",
      "Iteration 151720: loss = 2.3424\n",
      "Iteration 151730: loss = 2.4212\n",
      "Iteration 151740: loss = 2.9525\n",
      "Iteration 151750: loss = 2.1663\n",
      "Iteration 151760: loss = 2.3680\n",
      "Iteration 151770: loss = 2.4824\n",
      "Iteration 151780: loss = 2.1334\n",
      "Iteration 151790: loss = 2.4315\n",
      "Iteration 151800: loss = 2.2925\n",
      "Iteration 151810: loss = 2.2370\n",
      "Iteration 151820: loss = 2.6041\n",
      "Iteration 151830: loss = 2.1103\n",
      "Iteration 151840: loss = 2.5303\n",
      "Iteration 151850: loss = 2.5690\n",
      "Iteration 151860: loss = 2.0927\n",
      "Iteration 151870: loss = 2.1869\n",
      "Iteration 151880: loss = 2.1821\n",
      "Iteration 151890: loss = 2.2593\n",
      "Iteration 151900: loss = 2.3708\n",
      "Iteration 151910: loss = 2.3140\n",
      "Iteration 151920: loss = 2.4634\n",
      "Iteration 151930: loss = 2.6540\n",
      "Iteration 151940: loss = 2.1471\n",
      "Iteration 151950: loss = 2.2975\n",
      "Iteration 151960: loss = 2.2552\n",
      "Iteration 151970: loss = 2.3984\n",
      "Iteration 151980: loss = 2.0845\n",
      "Iteration 151990: loss = 2.4756\n",
      "Iteration 152000: loss = 2.2681\n",
      "Iteration 152010: loss = 2.8437\n",
      "Iteration 152020: loss = 2.3077\n",
      "Iteration 152030: loss = 2.1714\n",
      "Iteration 152040: loss = 2.2538\n",
      "Iteration 152050: loss = 2.5826\n",
      "Iteration 152060: loss = 2.2303\n",
      "Iteration 152070: loss = 2.5008\n",
      "Iteration 152080: loss = 2.5470\n",
      "Iteration 152090: loss = 2.3643\n",
      "Iteration 152100: loss = 2.6804\n",
      "Iteration 152110: loss = 2.4435\n",
      "Iteration 152120: loss = 2.8394\n",
      "Iteration 152130: loss = 2.2310\n",
      "Iteration 152140: loss = 2.7824\n",
      "Iteration 152150: loss = 2.0987\n",
      "Iteration 152160: loss = 2.6484\n",
      "Iteration 152170: loss = 2.7649\n",
      "Iteration 152180: loss = 2.3271\n",
      "Iteration 152190: loss = 2.5054\n",
      "Iteration 152200: loss = 2.1075\n",
      "Iteration 152210: loss = 2.3917\n",
      "Iteration 152220: loss = 2.7096\n",
      "Iteration 152230: loss = 2.3666\n",
      "Iteration 152240: loss = 2.5432\n",
      "Iteration 152250: loss = 2.1899\n",
      "Iteration 152260: loss = 2.3750\n",
      "Iteration 152270: loss = 2.3072\n",
      "Iteration 152280: loss = 2.6241\n",
      "Iteration 152290: loss = 2.3899\n",
      "Iteration 152300: loss = 3.1352\n",
      "Iteration 152310: loss = 2.2776\n",
      "Iteration 152320: loss = 2.6710\n",
      "Iteration 152330: loss = 2.3525\n",
      "Iteration 152340: loss = 2.2026\n",
      "Iteration 152350: loss = 2.8738\n",
      "Iteration 152360: loss = 2.2055\n",
      "Iteration 152370: loss = 2.4309\n",
      "Iteration 152380: loss = 2.3448\n",
      "Iteration 152390: loss = 2.5586\n",
      "Iteration 152400: loss = 2.2499\n",
      "Iteration 152410: loss = 2.5114\n",
      "Iteration 152420: loss = 2.7451\n",
      "Iteration 152430: loss = 2.6678\n",
      "Iteration 152440: loss = 2.2954\n",
      "Iteration 152450: loss = 2.1318\n",
      "Iteration 152460: loss = 2.4070\n",
      "Iteration 152470: loss = 2.2711\n",
      "Iteration 152480: loss = 2.5149\n",
      "Iteration 152490: loss = 2.2675\n",
      "Iteration 152500: loss = 2.9666\n",
      "Iteration 152510: loss = 2.4158\n",
      "Iteration 152520: loss = 2.0431\n",
      "Iteration 152530: loss = 2.4152\n",
      "Iteration 152540: loss = 1.9702\n",
      "Iteration 152550: loss = 2.1086\n",
      "Iteration 152560: loss = 2.3988\n",
      "Iteration 152570: loss = 2.3002\n",
      "Iteration 152580: loss = 2.1639\n",
      "Iteration 152590: loss = 2.3809\n",
      "Iteration 152600: loss = 2.3434\n",
      "Iteration 152610: loss = 2.7535\n",
      "Iteration 152620: loss = 2.0276\n",
      "Iteration 152630: loss = 2.2460\n",
      "Iteration 152640: loss = 2.2116\n",
      "Iteration 152650: loss = 2.2116\n",
      "Iteration 152660: loss = 2.5720\n",
      "Iteration 152670: loss = 2.7580\n",
      "Iteration 152680: loss = 2.3428\n",
      "Iteration 152690: loss = 2.7927\n",
      "Iteration 152700: loss = 2.2825\n",
      "Iteration 152710: loss = 1.8325\n",
      "Iteration 152720: loss = 2.3087\n",
      "Iteration 152730: loss = 2.5271\n",
      "Iteration 152740: loss = 2.2589\n",
      "Iteration 152750: loss = 2.2893\n",
      "Iteration 152760: loss = 2.1926\n",
      "Iteration 152770: loss = 2.4564\n",
      "Iteration 152780: loss = 2.3237\n",
      "Iteration 152790: loss = 2.3906\n",
      "Iteration 152800: loss = 2.5909\n",
      "Iteration 152810: loss = 2.3771\n",
      "Iteration 152820: loss = 2.3100\n",
      "Iteration 152830: loss = 2.3599\n",
      "Iteration 152840: loss = 2.5176\n",
      "Iteration 152850: loss = 2.5823\n",
      "Iteration 152860: loss = 2.0188\n",
      "Iteration 152870: loss = 2.5390\n",
      "Iteration 152880: loss = 2.5230\n",
      "Iteration 152890: loss = 2.5448\n",
      "Iteration 152900: loss = 2.3660\n",
      "Iteration 152910: loss = 2.4181\n",
      "Iteration 152920: loss = 2.2314\n",
      "Iteration 152930: loss = 2.1343\n",
      "Iteration 152940: loss = 2.5740\n",
      "Iteration 152950: loss = 2.2934\n",
      "Iteration 152960: loss = 2.4549\n",
      "Iteration 152970: loss = 2.3937\n",
      "Iteration 152980: loss = 2.5088\n",
      "Iteration 152990: loss = 2.3776\n",
      "Iteration 153000: loss = 2.6137\n",
      "Iteration 153010: loss = 2.2350\n",
      "Iteration 153020: loss = 2.8223\n",
      "Iteration 153030: loss = 2.4663\n",
      "Iteration 153040: loss = 2.2797\n",
      "Iteration 153050: loss = 2.3798\n",
      "Iteration 153060: loss = 2.8633\n",
      "Iteration 153070: loss = 2.3694\n",
      "Iteration 153080: loss = 2.4840\n",
      "Iteration 153090: loss = 2.4573\n",
      "Iteration 153100: loss = 2.3349\n",
      "Iteration 153110: loss = 2.3406\n",
      "Iteration 153120: loss = 2.8615\n",
      "Iteration 153130: loss = 2.7062\n",
      "Iteration 153140: loss = 2.3557\n",
      "Iteration 153150: loss = 2.8198\n",
      "Iteration 153160: loss = 2.7351\n",
      "Iteration 153170: loss = 3.0259\n",
      "Iteration 153180: loss = 2.5851\n",
      "Iteration 153190: loss = 2.2659\n",
      "Iteration 153200: loss = 2.5762\n",
      "Iteration 153210: loss = 2.4443\n",
      "Iteration 153220: loss = 2.2239\n",
      "Iteration 153230: loss = 2.4361\n",
      "Iteration 153240: loss = 2.6125\n",
      "Iteration 153250: loss = 2.4019\n",
      "Iteration 153260: loss = 2.0534\n",
      "Iteration 153270: loss = 2.0941\n",
      "Iteration 153280: loss = 2.6706\n",
      "Iteration 153290: loss = 2.2837\n",
      "Iteration 153300: loss = 2.6215\n",
      "Iteration 153310: loss = 2.6300\n",
      "Iteration 153320: loss = 2.7974\n",
      "Iteration 153330: loss = 2.9446\n",
      "Iteration 153340: loss = 2.3149\n",
      "Iteration 153350: loss = 2.6723\n",
      "Iteration 153360: loss = 2.4664\n",
      "Iteration 153370: loss = 2.4177\n",
      "Iteration 153380: loss = 2.5176\n",
      "Iteration 153390: loss = 2.5318\n",
      "Iteration 153400: loss = 2.3849\n",
      "Iteration 153410: loss = 2.4030\n",
      "Iteration 153420: loss = 2.4827\n",
      "Iteration 153430: loss = 2.5139\n",
      "Iteration 153440: loss = 2.4849\n",
      "Iteration 153450: loss = 2.3869\n",
      "Iteration 153460: loss = 2.2899\n",
      "Iteration 153470: loss = 1.9801\n",
      "Iteration 153480: loss = 2.3147\n",
      "Iteration 153490: loss = 2.6675\n",
      "Iteration 153500: loss = 2.6216\n",
      "Iteration 153510: loss = 2.3248\n",
      "Iteration 153520: loss = 2.7622\n",
      "Iteration 153530: loss = 2.2945\n",
      "Iteration 153540: loss = 2.2015\n",
      "Iteration 153550: loss = 2.3260\n",
      "Iteration 153560: loss = 2.9459\n",
      "Iteration 153570: loss = 2.3479\n",
      "Iteration 153580: loss = 2.6663\n",
      "Iteration 153590: loss = 2.4507\n",
      "Iteration 153600: loss = 2.3476\n",
      "Iteration 153610: loss = 2.7080\n",
      "Iteration 153620: loss = 1.9217\n",
      "Iteration 153630: loss = 2.5932\n",
      "Iteration 153640: loss = 2.5820\n",
      "Iteration 153650: loss = 2.5038\n",
      "Iteration 153660: loss = 2.2723\n",
      "Iteration 153670: loss = 2.4643\n",
      "Iteration 153680: loss = 1.9659\n",
      "Iteration 153690: loss = 2.4676\n",
      "Iteration 153700: loss = 2.4457\n",
      "Iteration 153710: loss = 2.2869\n",
      "Iteration 153720: loss = 2.0270\n",
      "Iteration 153730: loss = 2.4252\n",
      "Iteration 153740: loss = 2.6160\n",
      "Iteration 153750: loss = 2.3748\n",
      "Iteration 153760: loss = 2.3672\n",
      "Iteration 153770: loss = 2.6555\n",
      "Iteration 153780: loss = 2.3003\n",
      "Iteration 153790: loss = 2.1408\n",
      "Iteration 153800: loss = 2.7187\n",
      "Iteration 153810: loss = 2.0562\n",
      "Iteration 153820: loss = 2.6195\n",
      "Iteration 153830: loss = 2.6144\n",
      "Iteration 153840: loss = 2.6501\n",
      "Iteration 153850: loss = 2.5989\n",
      "Iteration 153860: loss = 2.8364\n",
      "Iteration 153870: loss = 2.3716\n",
      "Iteration 153880: loss = 2.1883\n",
      "Iteration 153890: loss = 2.1497\n",
      "Iteration 153900: loss = 2.4589\n",
      "Iteration 153910: loss = 2.6097\n",
      "Iteration 153920: loss = 2.3767\n",
      "Iteration 153930: loss = 2.5477\n",
      "Iteration 153940: loss = 2.7450\n",
      "Iteration 153950: loss = 2.9951\n",
      "Iteration 153960: loss = 2.4874\n",
      "Iteration 153970: loss = 2.6098\n",
      "Iteration 153980: loss = 2.2636\n",
      "Iteration 153990: loss = 2.6254\n",
      "Iteration 154000: loss = 2.4018\n",
      "Iteration 154010: loss = 2.5464\n",
      "Iteration 154020: loss = 2.3904\n",
      "Iteration 154030: loss = 2.2622\n",
      "Iteration 154040: loss = 2.1360\n",
      "Iteration 154050: loss = 2.2725\n",
      "Iteration 154060: loss = 2.9038\n",
      "Iteration 154070: loss = 2.0984\n",
      "Iteration 154080: loss = 2.8175\n",
      "Iteration 154090: loss = 2.5603\n",
      "Iteration 154100: loss = 2.2580\n",
      "Iteration 154110: loss = 1.9665\n",
      "Iteration 154120: loss = 2.2899\n",
      "Iteration 154130: loss = 2.3805\n",
      "Iteration 154140: loss = 1.9633\n",
      "Iteration 154150: loss = 2.4954\n",
      "Iteration 154160: loss = 2.1417\n",
      "Iteration 154170: loss = 2.6252\n",
      "Iteration 154180: loss = 2.7077\n",
      "Iteration 154190: loss = 2.3382\n",
      "Iteration 154200: loss = 2.3646\n",
      "Iteration 154210: loss = 2.6823\n",
      "Iteration 154220: loss = 2.4549\n",
      "Iteration 154230: loss = 2.2169\n",
      "Iteration 154240: loss = 2.6426\n",
      "Iteration 154250: loss = 2.4039\n",
      "Iteration 154260: loss = 2.3157\n",
      "Iteration 154270: loss = 2.3792\n",
      "Iteration 154280: loss = 2.3974\n",
      "Iteration 154290: loss = 1.7387\n",
      "Iteration 154300: loss = 2.2750\n",
      "Iteration 154310: loss = 2.3639\n",
      "Iteration 154320: loss = 2.5393\n",
      "Iteration 154330: loss = 2.4470\n",
      "Iteration 154340: loss = 2.6039\n",
      "Iteration 154350: loss = 2.2288\n",
      "Iteration 154360: loss = 2.4176\n",
      "Iteration 154370: loss = 2.7821\n",
      "Iteration 154380: loss = 2.1896\n",
      "Iteration 154390: loss = 2.2999\n",
      "Iteration 154400: loss = 2.3178\n",
      "Iteration 154410: loss = 2.2710\n",
      "Iteration 154420: loss = 2.1956\n",
      "Iteration 154430: loss = 2.6370\n",
      "Iteration 154440: loss = 2.3962\n",
      "Iteration 154450: loss = 2.2742\n",
      "Iteration 154460: loss = 2.7738\n",
      "Iteration 154470: loss = 2.5195\n",
      "Iteration 154480: loss = 2.3726\n",
      "Iteration 154490: loss = 2.0996\n",
      "Iteration 154500: loss = 2.1787\n",
      "Iteration 154510: loss = 1.7748\n",
      "Iteration 154520: loss = 2.4933\n",
      "Iteration 154530: loss = 2.6267\n",
      "Iteration 154540: loss = 2.4265\n",
      "Iteration 154550: loss = 2.8588\n",
      "Iteration 154560: loss = 2.3600\n",
      "Iteration 154570: loss = 2.5513\n",
      "Iteration 154580: loss = 2.6063\n",
      "Iteration 154590: loss = 2.1164\n",
      "Iteration 154600: loss = 2.3205\n",
      "Iteration 154610: loss = 2.5186\n",
      "Iteration 154620: loss = 2.2218\n",
      "Iteration 154630: loss = 2.0958\n",
      "Iteration 154640: loss = 2.3569\n",
      "Iteration 154650: loss = 2.7567\n",
      "Iteration 154660: loss = 1.9217\n",
      "Iteration 154670: loss = 2.4468\n",
      "Iteration 154680: loss = 2.4121\n",
      "Iteration 154690: loss = 2.1814\n",
      "Iteration 154700: loss = 2.8755\n",
      "Iteration 154710: loss = 2.3233\n",
      "Iteration 154720: loss = 2.7677\n",
      "Iteration 154730: loss = 2.5873\n",
      "Iteration 154740: loss = 2.4499\n",
      "Iteration 154750: loss = 2.3301\n",
      "Iteration 154760: loss = 2.3560\n",
      "Iteration 154770: loss = 2.6064\n",
      "Iteration 154780: loss = 2.4617\n",
      "Iteration 154790: loss = 2.6947\n",
      "Iteration 154800: loss = 2.3075\n",
      "Iteration 154810: loss = 2.8274\n",
      "Iteration 154820: loss = 2.2181\n",
      "Iteration 154830: loss = 2.2017\n",
      "Iteration 154840: loss = 2.1175\n",
      "Iteration 154850: loss = 2.3435\n",
      "Iteration 154860: loss = 2.4328\n",
      "Iteration 154870: loss = 2.8182\n",
      "Iteration 154880: loss = 2.6557\n",
      "Iteration 154890: loss = 2.3651\n",
      "Iteration 154900: loss = 1.9540\n",
      "Iteration 154910: loss = 2.5324\n",
      "Iteration 154920: loss = 2.1915\n",
      "Iteration 154930: loss = 2.2575\n",
      "Iteration 154940: loss = 2.0256\n",
      "Iteration 154950: loss = 2.4243\n",
      "Iteration 154960: loss = 2.8634\n",
      "Iteration 154970: loss = 2.1892\n",
      "Iteration 154980: loss = 2.1925\n",
      "Iteration 154990: loss = 2.6843\n",
      "Iteration 155000: loss = 2.5259\n",
      "Iteration 155010: loss = 2.8824\n",
      "Iteration 155020: loss = 2.7236\n",
      "Iteration 155030: loss = 2.1632\n",
      "Iteration 155040: loss = 2.3727\n",
      "Iteration 155050: loss = 2.3209\n",
      "Iteration 155060: loss = 2.2201\n",
      "Iteration 155070: loss = 2.4835\n",
      "Iteration 155080: loss = 2.2249\n",
      "Iteration 155090: loss = 2.2363\n",
      "Iteration 155100: loss = 2.4213\n",
      "Iteration 155110: loss = 3.0012\n",
      "Iteration 155120: loss = 2.1616\n",
      "Iteration 155130: loss = 2.5912\n",
      "Iteration 155140: loss = 2.5700\n",
      "Iteration 155150: loss = 2.4939\n",
      "Iteration 155160: loss = 2.4981\n",
      "Iteration 155170: loss = 2.6590\n",
      "Iteration 155180: loss = 2.2900\n",
      "Iteration 155190: loss = 2.5907\n",
      "Iteration 155200: loss = 2.6349\n",
      "Iteration 155210: loss = 2.5066\n",
      "Iteration 155220: loss = 2.2007\n",
      "Iteration 155230: loss = 2.5015\n",
      "Iteration 155240: loss = 2.5833\n",
      "Iteration 155250: loss = 2.1292\n",
      "Iteration 155260: loss = 2.8616\n",
      "Iteration 155270: loss = 2.2564\n",
      "Iteration 155280: loss = 2.0680\n",
      "Iteration 155290: loss = 2.7354\n",
      "Iteration 155300: loss = 2.1500\n",
      "Iteration 155310: loss = 2.2687\n",
      "Iteration 155320: loss = 2.6200\n",
      "Iteration 155330: loss = 2.4599\n",
      "Iteration 155340: loss = 2.2027\n",
      "Iteration 155350: loss = 2.3067\n",
      "Iteration 155360: loss = 2.3674\n",
      "Iteration 155370: loss = 2.2227\n",
      "Iteration 155380: loss = 2.3203\n",
      "Iteration 155390: loss = 2.2221\n",
      "Iteration 155400: loss = 2.4470\n",
      "Iteration 155410: loss = 2.6538\n",
      "Iteration 155420: loss = 2.4830\n",
      "Iteration 155430: loss = 2.1349\n",
      "Iteration 155440: loss = 2.3143\n",
      "Iteration 155450: loss = 2.5411\n",
      "Iteration 155460: loss = 2.5204\n",
      "Iteration 155470: loss = 2.2477\n",
      "Iteration 155480: loss = 2.6231\n",
      "Iteration 155490: loss = 2.6108\n",
      "Iteration 155500: loss = 2.5182\n",
      "Iteration 155510: loss = 2.3718\n",
      "Iteration 155520: loss = 2.9308\n",
      "Iteration 155530: loss = 2.6337\n",
      "Iteration 155540: loss = 2.3227\n",
      "Iteration 155550: loss = 2.5192\n",
      "Iteration 155560: loss = 2.6007\n",
      "Iteration 155570: loss = 2.3112\n",
      "Iteration 155580: loss = 2.5637\n",
      "Iteration 155590: loss = 2.6839\n",
      "Iteration 155600: loss = 2.4930\n",
      "Iteration 155610: loss = 2.1868\n",
      "Iteration 155620: loss = 2.3708\n",
      "Iteration 155630: loss = 2.4431\n",
      "Iteration 155640: loss = 2.7053\n",
      "Iteration 155650: loss = 2.5816\n",
      "Iteration 155660: loss = 2.7510\n",
      "Iteration 155670: loss = 2.4001\n",
      "Iteration 155680: loss = 2.4044\n",
      "Iteration 155690: loss = 2.7326\n",
      "Iteration 155700: loss = 2.0731\n",
      "Iteration 155710: loss = 2.3106\n",
      "Iteration 155720: loss = 2.2649\n",
      "Iteration 155730: loss = 2.7270\n",
      "Iteration 155740: loss = 2.4913\n",
      "Iteration 155750: loss = 2.2756\n",
      "Iteration 155760: loss = 1.8624\n",
      "Iteration 155770: loss = 2.1798\n",
      "Iteration 155780: loss = 2.8185\n",
      "Iteration 155790: loss = 2.4933\n",
      "Iteration 155800: loss = 2.5010\n",
      "Iteration 155810: loss = 2.0451\n",
      "Iteration 155820: loss = 2.4105\n",
      "Iteration 155830: loss = 2.3705\n",
      "Iteration 155840: loss = 2.1013\n",
      "Iteration 155850: loss = 2.3897\n",
      "Iteration 155860: loss = 2.3905\n",
      "Iteration 155870: loss = 2.2810\n",
      "Iteration 155880: loss = 2.8002\n",
      "Iteration 155890: loss = 2.4163\n",
      "Iteration 155900: loss = 2.5469\n",
      "Iteration 155910: loss = 2.1766\n",
      "Iteration 155920: loss = 2.4339\n",
      "Iteration 155930: loss = 2.7575\n",
      "Iteration 155940: loss = 2.5107\n",
      "Iteration 155950: loss = 2.2164\n",
      "Iteration 155960: loss = 2.4646\n",
      "Iteration 155970: loss = 1.8434\n",
      "Iteration 155980: loss = 2.5449\n",
      "Iteration 155990: loss = 1.8684\n",
      "Iteration 156000: loss = 2.0437\n",
      "Iteration 156010: loss = 2.3813\n",
      "Iteration 156020: loss = 2.4631\n",
      "Iteration 156030: loss = 2.1582\n",
      "Iteration 156040: loss = 2.5656\n",
      "Iteration 156050: loss = 2.4283\n",
      "Iteration 156060: loss = 2.1419\n",
      "Iteration 156070: loss = 2.3126\n",
      "Iteration 156080: loss = 2.2753\n",
      "Iteration 156090: loss = 2.0628\n",
      "Iteration 156100: loss = 2.7157\n",
      "Iteration 156110: loss = 2.5409\n",
      "Iteration 156120: loss = 2.5128\n",
      "Iteration 156130: loss = 2.3045\n",
      "Iteration 156140: loss = 2.3796\n",
      "Iteration 156150: loss = 2.6375\n",
      "Iteration 156160: loss = 2.3470\n",
      "Iteration 156170: loss = 2.7673\n",
      "Iteration 156180: loss = 2.6621\n",
      "Iteration 156190: loss = 2.1938\n",
      "Iteration 156200: loss = 2.2840\n",
      "Iteration 156210: loss = 2.1037\n",
      "Iteration 156220: loss = 2.0303\n",
      "Iteration 156230: loss = 2.4041\n",
      "Iteration 156240: loss = 2.5938\n",
      "Iteration 156250: loss = 2.7422\n",
      "Iteration 156260: loss = 2.4585\n",
      "Iteration 156270: loss = 2.3435\n",
      "Iteration 156280: loss = 2.4595\n",
      "Iteration 156290: loss = 2.1973\n",
      "Iteration 156300: loss = 2.1169\n",
      "Iteration 156310: loss = 2.6737\n",
      "Iteration 156320: loss = 2.1733\n",
      "Iteration 156330: loss = 2.2250\n",
      "Iteration 156340: loss = 2.5641\n",
      "Iteration 156350: loss = 2.7012\n",
      "Iteration 156360: loss = 2.4754\n",
      "Iteration 156370: loss = 2.3713\n",
      "Iteration 156380: loss = 2.5089\n",
      "Iteration 156390: loss = 2.4000\n",
      "Iteration 156400: loss = 2.2380\n",
      "Iteration 156410: loss = 2.0647\n",
      "Iteration 156420: loss = 2.2408\n",
      "Iteration 156430: loss = 2.5754\n",
      "Iteration 156440: loss = 2.5549\n",
      "Iteration 156450: loss = 2.7513\n",
      "Iteration 156460: loss = 2.9033\n",
      "Iteration 156470: loss = 2.5450\n",
      "Iteration 156480: loss = 2.5142\n",
      "Iteration 156490: loss = 2.4456\n",
      "Iteration 156500: loss = 2.7128\n",
      "Iteration 156510: loss = 2.3635\n",
      "Iteration 156520: loss = 2.5969\n",
      "Iteration 156530: loss = 2.3488\n",
      "Iteration 156540: loss = 2.0319\n",
      "Iteration 156550: loss = 2.1327\n",
      "Iteration 156560: loss = 2.4939\n",
      "Iteration 156570: loss = 2.5265\n",
      "Iteration 156580: loss = 2.7223\n",
      "Iteration 156590: loss = 2.5342\n",
      "Iteration 156600: loss = 2.7902\n",
      "Iteration 156610: loss = 2.5346\n",
      "Iteration 156620: loss = 2.3799\n",
      "Iteration 156630: loss = 2.1493\n",
      "Iteration 156640: loss = 2.4149\n",
      "Iteration 156650: loss = 2.4300\n",
      "Iteration 156660: loss = 2.4185\n",
      "Iteration 156670: loss = 2.4364\n",
      "Iteration 156680: loss = 2.3651\n",
      "Iteration 156690: loss = 2.4249\n",
      "Iteration 156700: loss = 2.1950\n",
      "Iteration 156710: loss = 2.3347\n",
      "Iteration 156720: loss = 2.7820\n",
      "Iteration 156730: loss = 2.9149\n",
      "Iteration 156740: loss = 2.2336\n",
      "Iteration 156750: loss = 2.4044\n",
      "Iteration 156760: loss = 2.3224\n",
      "Iteration 156770: loss = 2.0706\n",
      "Iteration 156780: loss = 2.3377\n",
      "Iteration 156790: loss = 1.8464\n",
      "Iteration 156800: loss = 2.5469\n",
      "Iteration 156810: loss = 2.0938\n",
      "Iteration 156820: loss = 2.6112\n",
      "Iteration 156830: loss = 2.2189\n",
      "Iteration 156840: loss = 2.3516\n",
      "Iteration 156850: loss = 2.4893\n",
      "Iteration 156860: loss = 2.2590\n",
      "Iteration 156870: loss = 2.4361\n",
      "Iteration 156880: loss = 2.3318\n",
      "Iteration 156890: loss = 2.4048\n",
      "Iteration 156900: loss = 2.7329\n",
      "Iteration 156910: loss = 2.2083\n",
      "Iteration 156920: loss = 2.1620\n",
      "Iteration 156930: loss = 2.4932\n",
      "Iteration 156940: loss = 2.4695\n",
      "Iteration 156950: loss = 2.9161\n",
      "Iteration 156960: loss = 2.4690\n",
      "Iteration 156970: loss = 2.4233\n",
      "Iteration 156980: loss = 2.5874\n",
      "Iteration 156990: loss = 2.6482\n",
      "Iteration 157000: loss = 2.5338\n",
      "Iteration 157010: loss = 2.7865\n",
      "Iteration 157020: loss = 2.4151\n",
      "Iteration 157030: loss = 2.3531\n",
      "Iteration 157040: loss = 2.4358\n",
      "Iteration 157050: loss = 2.7872\n",
      "Iteration 157060: loss = 2.5107\n",
      "Iteration 157070: loss = 2.1153\n",
      "Iteration 157080: loss = 2.6448\n",
      "Iteration 157090: loss = 1.8907\n",
      "Iteration 157100: loss = 2.2134\n",
      "Iteration 157110: loss = 2.5021\n",
      "Iteration 157120: loss = 2.5696\n",
      "Iteration 157130: loss = 2.4268\n",
      "Iteration 157140: loss = 2.1189\n",
      "Iteration 157150: loss = 2.3084\n",
      "Iteration 157160: loss = 2.4888\n",
      "Iteration 157170: loss = 2.5846\n",
      "Iteration 157180: loss = 2.6026\n",
      "Iteration 157190: loss = 2.6064\n",
      "Iteration 157200: loss = 2.5914\n",
      "Iteration 157210: loss = 2.3429\n",
      "Iteration 157220: loss = 2.4844\n",
      "Iteration 157230: loss = 2.4466\n",
      "Iteration 157240: loss = 2.3768\n",
      "Iteration 157250: loss = 2.1723\n",
      "Iteration 157260: loss = 2.5356\n",
      "Iteration 157270: loss = 2.3739\n",
      "Iteration 157280: loss = 2.6357\n",
      "Iteration 157290: loss = 2.2557\n",
      "Iteration 157300: loss = 2.4843\n",
      "Iteration 157310: loss = 2.8221\n",
      "Iteration 157320: loss = 2.4705\n",
      "Iteration 157330: loss = 2.5498\n",
      "Iteration 157340: loss = 2.8848\n",
      "Iteration 157350: loss = 2.7656\n",
      "Iteration 157360: loss = 2.5407\n",
      "Iteration 157370: loss = 2.6014\n",
      "Iteration 157380: loss = 2.4581\n",
      "Iteration 157390: loss = 2.1309\n",
      "Iteration 157400: loss = 2.2896\n",
      "Iteration 157410: loss = 2.4326\n",
      "Iteration 157420: loss = 2.2883\n",
      "Iteration 157430: loss = 2.4702\n",
      "Iteration 157440: loss = 2.5808\n",
      "Iteration 157450: loss = 2.3193\n",
      "Iteration 157460: loss = 2.2749\n",
      "Iteration 157470: loss = 2.0693\n",
      "Iteration 157480: loss = 2.1533\n",
      "Iteration 157490: loss = 2.7459\n",
      "Iteration 157500: loss = 2.8985\n",
      "Iteration 157510: loss = 2.7112\n",
      "Iteration 157520: loss = 2.1581\n",
      "Iteration 157530: loss = 2.5803\n",
      "Iteration 157540: loss = 2.2374\n",
      "Iteration 157550: loss = 2.7561\n",
      "Iteration 157560: loss = 2.3065\n",
      "Iteration 157570: loss = 2.6916\n",
      "Iteration 157580: loss = 2.4586\n",
      "Iteration 157590: loss = 2.8247\n",
      "Iteration 157600: loss = 2.6278\n",
      "Iteration 157610: loss = 2.2708\n",
      "Iteration 157620: loss = 2.7763\n",
      "Iteration 157630: loss = 2.6549\n",
      "Iteration 157640: loss = 2.2321\n",
      "Iteration 157650: loss = 2.7880\n",
      "Iteration 157660: loss = 2.3054\n",
      "Iteration 157670: loss = 2.3697\n",
      "Iteration 157680: loss = 2.1734\n",
      "Iteration 157690: loss = 2.0380\n",
      "Iteration 157700: loss = 2.4541\n",
      "Iteration 157710: loss = 2.2839\n",
      "Iteration 157720: loss = 2.2735\n",
      "Iteration 157730: loss = 2.1215\n",
      "Iteration 157740: loss = 2.5444\n",
      "Iteration 157750: loss = 2.5972\n",
      "Iteration 157760: loss = 2.5205\n",
      "Iteration 157770: loss = 2.6184\n",
      "Iteration 157780: loss = 2.4442\n",
      "Iteration 157790: loss = 2.7577\n",
      "Iteration 157800: loss = 2.1597\n",
      "Iteration 157810: loss = 2.3029\n",
      "Iteration 157820: loss = 2.8824\n",
      "Iteration 157830: loss = 1.8925\n",
      "Iteration 157840: loss = 2.3367\n",
      "Iteration 157850: loss = 2.3447\n",
      "Iteration 157860: loss = 2.8030\n",
      "Iteration 157870: loss = 2.1173\n",
      "Iteration 157880: loss = 2.2281\n",
      "Iteration 157890: loss = 2.1602\n",
      "Iteration 157900: loss = 2.3925\n",
      "Iteration 157910: loss = 2.6924\n",
      "Iteration 157920: loss = 2.3232\n",
      "Iteration 157930: loss = 2.3803\n",
      "Iteration 157940: loss = 2.1864\n",
      "Iteration 157950: loss = 2.4624\n",
      "Iteration 157960: loss = 2.4833\n",
      "Iteration 157970: loss = 2.0594\n",
      "Iteration 157980: loss = 2.6534\n",
      "Iteration 157990: loss = 2.4722\n",
      "Iteration 158000: loss = 2.1813\n",
      "Iteration 158010: loss = 2.3195\n",
      "Iteration 158020: loss = 2.4475\n",
      "Iteration 158030: loss = 2.2562\n",
      "Iteration 158040: loss = 2.5474\n",
      "Iteration 158050: loss = 2.4979\n",
      "Iteration 158060: loss = 2.4659\n",
      "Iteration 158070: loss = 2.5124\n",
      "Iteration 158080: loss = 2.0642\n",
      "Iteration 158090: loss = 2.3871\n",
      "Iteration 158100: loss = 2.6024\n",
      "Iteration 158110: loss = 2.3613\n",
      "Iteration 158120: loss = 2.6661\n",
      "Iteration 158130: loss = 2.4239\n",
      "Iteration 158140: loss = 2.2564\n",
      "Iteration 158150: loss = 2.4866\n",
      "Iteration 158160: loss = 2.5546\n",
      "Iteration 158170: loss = 2.4847\n",
      "Iteration 158180: loss = 2.3825\n",
      "Iteration 158190: loss = 2.6999\n",
      "Iteration 158200: loss = 2.3622\n",
      "Iteration 158210: loss = 2.4754\n",
      "Iteration 158220: loss = 2.2147\n",
      "Iteration 158230: loss = 2.6304\n",
      "Iteration 158240: loss = 2.5109\n",
      "Iteration 158250: loss = 2.5424\n",
      "Iteration 158260: loss = 2.7267\n",
      "Iteration 158270: loss = 2.4267\n",
      "Iteration 158280: loss = 2.5720\n",
      "Iteration 158290: loss = 2.3228\n",
      "Iteration 158300: loss = 2.5665\n",
      "Iteration 158310: loss = 2.2917\n",
      "Iteration 158320: loss = 2.7173\n",
      "Iteration 158330: loss = 2.4440\n",
      "Iteration 158340: loss = 2.3997\n",
      "Iteration 158350: loss = 2.4053\n",
      "Iteration 158360: loss = 2.7073\n",
      "Iteration 158370: loss = 2.4959\n",
      "Iteration 158380: loss = 2.1050\n",
      "Iteration 158390: loss = 2.2949\n",
      "Iteration 158400: loss = 2.6022\n",
      "Iteration 158410: loss = 2.1940\n",
      "Iteration 158420: loss = 2.2488\n",
      "Iteration 158430: loss = 2.5006\n",
      "Iteration 158440: loss = 2.8189\n",
      "Iteration 158450: loss = 2.4498\n",
      "Iteration 158460: loss = 2.6927\n",
      "Iteration 158470: loss = 2.1800\n",
      "Iteration 158480: loss = 2.2858\n",
      "Iteration 158490: loss = 2.5830\n",
      "Iteration 158500: loss = 2.4137\n",
      "Iteration 158510: loss = 2.3808\n",
      "Iteration 158520: loss = 2.1593\n",
      "Iteration 158530: loss = 2.7481\n",
      "Iteration 158540: loss = 2.1076\n",
      "Iteration 158550: loss = 2.5199\n",
      "Iteration 158560: loss = 2.3655\n",
      "Iteration 158570: loss = 2.0404\n",
      "Iteration 158580: loss = 2.2581\n",
      "Iteration 158590: loss = 2.1340\n",
      "Iteration 158600: loss = 2.2739\n",
      "Iteration 158610: loss = 2.2397\n",
      "Iteration 158620: loss = 2.5906\n",
      "Iteration 158630: loss = 2.2428\n",
      "Iteration 158640: loss = 2.5191\n",
      "Iteration 158650: loss = 2.4944\n",
      "Iteration 158660: loss = 2.3799\n",
      "Iteration 158670: loss = 2.5608\n",
      "Iteration 158680: loss = 2.1509\n",
      "Iteration 158690: loss = 2.0603\n",
      "Iteration 158700: loss = 2.0614\n",
      "Iteration 158710: loss = 2.5935\n",
      "Iteration 158720: loss = 2.6588\n",
      "Iteration 158730: loss = 2.6603\n",
      "Iteration 158740: loss = 2.6858\n",
      "Iteration 158750: loss = 2.1050\n",
      "Iteration 158760: loss = 2.5772\n",
      "Iteration 158770: loss = 2.1729\n",
      "Iteration 158780: loss = 2.7076\n",
      "Iteration 158790: loss = 2.6985\n",
      "Iteration 158800: loss = 2.5164\n",
      "Iteration 158810: loss = 2.3389\n",
      "Iteration 158820: loss = 2.4472\n",
      "Iteration 158830: loss = 2.2109\n",
      "Iteration 158840: loss = 2.4673\n",
      "Iteration 158850: loss = 2.6080\n",
      "Iteration 158860: loss = 2.7243\n",
      "Iteration 158870: loss = 2.0009\n",
      "Iteration 158880: loss = 2.3161\n",
      "Iteration 158890: loss = 2.4765\n",
      "Iteration 158900: loss = 2.2951\n",
      "Iteration 158910: loss = 2.3308\n",
      "Iteration 158920: loss = 2.4838\n",
      "Iteration 158930: loss = 2.5443\n",
      "Iteration 158940: loss = 2.4694\n",
      "Iteration 158950: loss = 2.4325\n",
      "Iteration 158960: loss = 2.7113\n",
      "Iteration 158970: loss = 2.5895\n",
      "Iteration 158980: loss = 2.2851\n",
      "Iteration 158990: loss = 2.3161\n",
      "Iteration 159000: loss = 2.5260\n",
      "Iteration 159010: loss = 2.4524\n",
      "Iteration 159020: loss = 2.3054\n",
      "Iteration 159030: loss = 2.8211\n",
      "Iteration 159040: loss = 2.4452\n",
      "Iteration 159050: loss = 2.5825\n",
      "Iteration 159060: loss = 2.1050\n",
      "Iteration 159070: loss = 2.3520\n",
      "Iteration 159080: loss = 2.5077\n",
      "Iteration 159090: loss = 2.6511\n",
      "Iteration 159100: loss = 3.0503\n",
      "Iteration 159110: loss = 2.0885\n",
      "Iteration 159120: loss = 2.3189\n",
      "Iteration 159130: loss = 2.2459\n",
      "Iteration 159140: loss = 2.2060\n",
      "Iteration 159150: loss = 2.5078\n",
      "Iteration 159160: loss = 2.4132\n",
      "Iteration 159170: loss = 2.7311\n",
      "Iteration 159180: loss = 2.6373\n",
      "Iteration 159190: loss = 2.5215\n",
      "Iteration 159200: loss = 2.6049\n",
      "Iteration 159210: loss = 2.5898\n",
      "Iteration 159220: loss = 2.2000\n",
      "Iteration 159230: loss = 2.2374\n",
      "Iteration 159240: loss = 2.3298\n",
      "Iteration 159250: loss = 2.4423\n",
      "Iteration 159260: loss = 2.3543\n",
      "Iteration 159270: loss = 2.3630\n",
      "Iteration 159280: loss = 1.9860\n",
      "Iteration 159290: loss = 2.4275\n",
      "Iteration 159300: loss = 2.3150\n",
      "Iteration 159310: loss = 3.0974\n",
      "Iteration 159320: loss = 2.3601\n",
      "Iteration 159330: loss = 2.5224\n",
      "Iteration 159340: loss = 2.7566\n",
      "Iteration 159350: loss = 2.6029\n",
      "Iteration 159360: loss = 2.5017\n",
      "Iteration 159370: loss = 2.4751\n",
      "Iteration 159380: loss = 2.5863\n",
      "Iteration 159390: loss = 2.7737\n",
      "Iteration 159400: loss = 2.7856\n",
      "Iteration 159410: loss = 2.3391\n",
      "Iteration 159420: loss = 2.4935\n",
      "Iteration 159430: loss = 2.3986\n",
      "Iteration 159440: loss = 2.2698\n",
      "Iteration 159450: loss = 2.6606\n",
      "Iteration 159460: loss = 2.5452\n",
      "Iteration 159470: loss = 2.4295\n",
      "Iteration 159480: loss = 2.5765\n",
      "Iteration 159490: loss = 2.1110\n",
      "Iteration 159500: loss = 2.6688\n",
      "Iteration 159510: loss = 2.1782\n",
      "Iteration 159520: loss = 2.4473\n",
      "Iteration 159530: loss = 2.4125\n",
      "Iteration 159540: loss = 2.3676\n",
      "Iteration 159550: loss = 2.4141\n",
      "Iteration 159560: loss = 2.0123\n",
      "Iteration 159570: loss = 2.2683\n",
      "Iteration 159580: loss = 2.1775\n",
      "Iteration 159590: loss = 2.6080\n",
      "Iteration 159600: loss = 2.6828\n",
      "Iteration 159610: loss = 2.3185\n",
      "Iteration 159620: loss = 2.4472\n",
      "Iteration 159630: loss = 1.9878\n",
      "Iteration 159640: loss = 2.1604\n",
      "Iteration 159650: loss = 2.5979\n",
      "Iteration 159660: loss = 2.3109\n",
      "Iteration 159670: loss = 2.3552\n",
      "Iteration 159680: loss = 2.3564\n",
      "Iteration 159690: loss = 2.2516\n",
      "Iteration 159700: loss = 2.2898\n",
      "Iteration 159710: loss = 2.2877\n",
      "Iteration 159720: loss = 2.1730\n",
      "Iteration 159730: loss = 2.4928\n",
      "Iteration 159740: loss = 2.0949\n",
      "Iteration 159750: loss = 2.8056\n",
      "Iteration 159760: loss = 2.4222\n",
      "Iteration 159770: loss = 2.5381\n",
      "Iteration 159780: loss = 2.5424\n",
      "Iteration 159790: loss = 2.1460\n",
      "Iteration 159800: loss = 2.2425\n",
      "Iteration 159810: loss = 2.4031\n",
      "Iteration 159820: loss = 2.5359\n",
      "Iteration 159830: loss = 2.2220\n",
      "Iteration 159840: loss = 2.5519\n",
      "Iteration 159850: loss = 2.5457\n",
      "Iteration 159860: loss = 2.4459\n",
      "Iteration 159870: loss = 2.1235\n",
      "Iteration 159880: loss = 2.2866\n",
      "Iteration 159890: loss = 2.3408\n",
      "Iteration 159900: loss = 2.4976\n",
      "Iteration 159910: loss = 2.6069\n",
      "Iteration 159920: loss = 2.3761\n",
      "Iteration 159930: loss = 2.4846\n",
      "Iteration 159940: loss = 2.2600\n",
      "Iteration 159950: loss = 2.1366\n",
      "Iteration 159960: loss = 2.6391\n",
      "Iteration 159970: loss = 2.1473\n",
      "Iteration 159980: loss = 2.3283\n",
      "Iteration 159990: loss = 2.1781\n",
      "Iteration 160000: loss = 2.3324\n",
      "Iteration 160010: loss = 2.2024\n",
      "Iteration 160020: loss = 2.9063\n",
      "Iteration 160030: loss = 2.4723\n",
      "Iteration 160040: loss = 2.8922\n",
      "Iteration 160050: loss = 2.3989\n",
      "Iteration 160060: loss = 2.5837\n",
      "Iteration 160070: loss = 2.1307\n",
      "Iteration 160080: loss = 2.3988\n",
      "Iteration 160090: loss = 2.3584\n",
      "Iteration 160100: loss = 2.1022\n",
      "Iteration 160110: loss = 2.1572\n",
      "Iteration 160120: loss = 2.7934\n",
      "Iteration 160130: loss = 2.5480\n",
      "Iteration 160140: loss = 2.4309\n",
      "Iteration 160150: loss = 2.4465\n",
      "Iteration 160160: loss = 2.0215\n",
      "Iteration 160170: loss = 1.9554\n",
      "Iteration 160180: loss = 2.5424\n",
      "Iteration 160190: loss = 2.3690\n",
      "Iteration 160200: loss = 2.3482\n",
      "Iteration 160210: loss = 2.6642\n",
      "Iteration 160220: loss = 2.4535\n",
      "Iteration 160230: loss = 2.7045\n",
      "Iteration 160240: loss = 2.3837\n",
      "Iteration 160250: loss = 2.4684\n",
      "Iteration 160260: loss = 2.3085\n",
      "Iteration 160270: loss = 2.3929\n",
      "Iteration 160280: loss = 2.2330\n",
      "Iteration 160290: loss = 2.5579\n",
      "Iteration 160300: loss = 2.3147\n",
      "Iteration 160310: loss = 2.5489\n",
      "Iteration 160320: loss = 2.5101\n",
      "Iteration 160330: loss = 2.2875\n",
      "Iteration 160340: loss = 2.6028\n",
      "Iteration 160350: loss = 2.5657\n",
      "Iteration 160360: loss = 2.7166\n",
      "Iteration 160370: loss = 2.7855\n",
      "Iteration 160380: loss = 2.4079\n",
      "Iteration 160390: loss = 2.3339\n",
      "Iteration 160400: loss = 2.7141\n",
      "Iteration 160410: loss = 2.4468\n",
      "Iteration 160420: loss = 2.7910\n",
      "Iteration 160430: loss = 2.5484\n",
      "Iteration 160440: loss = 2.5984\n",
      "Iteration 160450: loss = 2.3007\n",
      "Iteration 160460: loss = 2.2291\n",
      "Iteration 160470: loss = 2.1143\n",
      "Iteration 160480: loss = 2.1303\n",
      "Iteration 160490: loss = 2.2882\n",
      "Iteration 160500: loss = 2.4780\n",
      "Iteration 160510: loss = 2.6358\n",
      "Iteration 160520: loss = 2.7904\n",
      "Iteration 160530: loss = 2.4189\n",
      "Iteration 160540: loss = 2.3731\n",
      "Iteration 160550: loss = 2.5734\n",
      "Iteration 160560: loss = 2.3608\n",
      "Iteration 160570: loss = 2.3480\n",
      "Iteration 160580: loss = 2.7253\n",
      "Iteration 160590: loss = 2.4154\n",
      "Iteration 160600: loss = 2.3565\n",
      "Iteration 160610: loss = 2.4196\n",
      "Iteration 160620: loss = 2.7824\n",
      "Iteration 160630: loss = 2.2618\n",
      "Iteration 160640: loss = 2.5665\n",
      "Iteration 160650: loss = 2.4936\n",
      "Iteration 160660: loss = 2.4206\n",
      "Iteration 160670: loss = 2.6615\n",
      "Iteration 160680: loss = 2.1808\n",
      "Iteration 160690: loss = 2.8314\n",
      "Iteration 160700: loss = 2.0666\n",
      "Iteration 160710: loss = 2.4327\n",
      "Iteration 160720: loss = 2.4897\n",
      "Iteration 160730: loss = 2.1219\n",
      "Iteration 160740: loss = 2.4428\n",
      "Iteration 160750: loss = 2.2796\n",
      "Iteration 160760: loss = 2.2412\n",
      "Iteration 160770: loss = 2.2414\n",
      "Iteration 160780: loss = 2.1297\n",
      "Iteration 160790: loss = 2.4772\n",
      "Iteration 160800: loss = 2.3752\n",
      "Iteration 160810: loss = 2.2861\n",
      "Iteration 160820: loss = 2.3520\n",
      "Iteration 160830: loss = 2.1698\n",
      "Iteration 160840: loss = 2.4508\n",
      "Iteration 160850: loss = 1.9671\n",
      "Iteration 160860: loss = 3.1526\n",
      "Iteration 160870: loss = 2.8122\n",
      "Iteration 160880: loss = 2.3354\n",
      "Iteration 160890: loss = 2.4575\n",
      "Iteration 160900: loss = 2.3573\n",
      "Iteration 160910: loss = 2.7382\n",
      "Iteration 160920: loss = 2.6787\n",
      "Iteration 160930: loss = 2.1180\n",
      "Iteration 160940: loss = 2.3067\n",
      "Iteration 160950: loss = 2.2778\n",
      "Iteration 160960: loss = 2.8749\n",
      "Iteration 160970: loss = 2.4288\n",
      "Iteration 160980: loss = 3.0379\n",
      "Iteration 160990: loss = 2.1253\n",
      "Iteration 161000: loss = 2.4974\n",
      "Iteration 161010: loss = 2.3588\n",
      "Iteration 161020: loss = 2.6697\n",
      "Iteration 161030: loss = 2.4586\n",
      "Iteration 161040: loss = 2.5110\n",
      "Iteration 161050: loss = 2.4483\n",
      "Iteration 161060: loss = 2.3763\n",
      "Iteration 161070: loss = 2.7378\n",
      "Iteration 161080: loss = 2.5686\n",
      "Iteration 161090: loss = 2.5770\n",
      "Iteration 161100: loss = 2.4648\n",
      "Iteration 161110: loss = 2.3519\n",
      "Iteration 161120: loss = 2.4199\n",
      "Iteration 161130: loss = 2.4310\n",
      "Iteration 161140: loss = 2.3395\n",
      "Iteration 161150: loss = 2.4995\n",
      "Iteration 161160: loss = 2.8712\n",
      "Iteration 161170: loss = 2.2841\n",
      "Iteration 161180: loss = 2.2118\n",
      "Iteration 161190: loss = 2.2603\n",
      "Iteration 161200: loss = 2.5976\n",
      "Iteration 161210: loss = 2.3021\n",
      "Iteration 161220: loss = 2.2269\n",
      "Iteration 161230: loss = 2.0808\n",
      "Iteration 161240: loss = 2.5413\n",
      "Iteration 161250: loss = 2.1624\n",
      "Iteration 161260: loss = 2.7322\n",
      "Iteration 161270: loss = 2.4651\n",
      "Iteration 161280: loss = 2.5639\n",
      "Iteration 161290: loss = 2.5189\n",
      "Iteration 161300: loss = 2.3069\n",
      "Iteration 161310: loss = 2.6317\n",
      "Iteration 161320: loss = 2.5515\n",
      "Iteration 161330: loss = 2.7351\n",
      "Iteration 161340: loss = 2.6166\n",
      "Iteration 161350: loss = 2.4103\n",
      "Iteration 161360: loss = 2.6052\n",
      "Iteration 161370: loss = 2.7441\n",
      "Iteration 161380: loss = 2.3943\n",
      "Iteration 161390: loss = 2.5436\n",
      "Iteration 161400: loss = 2.1578\n",
      "Iteration 161410: loss = 2.3258\n",
      "Iteration 161420: loss = 2.1971\n",
      "Iteration 161430: loss = 2.7042\n",
      "Iteration 161440: loss = 2.7703\n",
      "Iteration 161450: loss = 2.7802\n",
      "Iteration 161460: loss = 2.6648\n",
      "Iteration 161470: loss = 2.3808\n",
      "Iteration 161480: loss = 2.6423\n",
      "Iteration 161490: loss = 2.6822\n",
      "Iteration 161500: loss = 2.4011\n",
      "Iteration 161510: loss = 2.4074\n",
      "Iteration 161520: loss = 2.3100\n",
      "Iteration 161530: loss = 2.5999\n",
      "Iteration 161540: loss = 2.5346\n",
      "Iteration 161550: loss = 2.3891\n",
      "Iteration 161560: loss = 2.1901\n",
      "Iteration 161570: loss = 2.6320\n",
      "Iteration 161580: loss = 2.5877\n",
      "Iteration 161590: loss = 2.1299\n",
      "Iteration 161600: loss = 2.5769\n",
      "Iteration 161610: loss = 2.1998\n",
      "Iteration 161620: loss = 1.9910\n",
      "Iteration 161630: loss = 2.5217\n",
      "Iteration 161640: loss = 2.4027\n",
      "Iteration 161650: loss = 2.5866\n",
      "Iteration 161660: loss = 2.3341\n",
      "Iteration 161670: loss = 1.9841\n",
      "Iteration 161680: loss = 2.2945\n",
      "Iteration 161690: loss = 2.3802\n",
      "Iteration 161700: loss = 2.7483\n",
      "Iteration 161710: loss = 2.3669\n",
      "Iteration 161720: loss = 2.1800\n",
      "Iteration 161730: loss = 2.3540\n",
      "Iteration 161740: loss = 2.1981\n",
      "Iteration 161750: loss = 1.9368\n",
      "Iteration 161760: loss = 2.7470\n",
      "Iteration 161770: loss = 2.7805\n",
      "Iteration 161780: loss = 2.4233\n",
      "Iteration 161790: loss = 2.7019\n",
      "Iteration 161800: loss = 2.1724\n",
      "Iteration 161810: loss = 2.4940\n",
      "Iteration 161820: loss = 2.6073\n",
      "Iteration 161830: loss = 2.3854\n",
      "Iteration 161840: loss = 2.6407\n",
      "Iteration 161850: loss = 2.3555\n",
      "Iteration 161860: loss = 2.5567\n",
      "Iteration 161870: loss = 2.2717\n",
      "Iteration 161880: loss = 2.2965\n",
      "Iteration 161890: loss = 2.0685\n",
      "Iteration 161900: loss = 2.3748\n",
      "Iteration 161910: loss = 2.4206\n",
      "Iteration 161920: loss = 2.3670\n",
      "Iteration 161930: loss = 2.3246\n",
      "Iteration 161940: loss = 2.2582\n",
      "Iteration 161950: loss = 2.3002\n",
      "Iteration 161960: loss = 2.1184\n",
      "Iteration 161970: loss = 2.5032\n",
      "Iteration 161980: loss = 2.1010\n",
      "Iteration 161990: loss = 2.7428\n",
      "Iteration 162000: loss = 2.7843\n",
      "Iteration 162010: loss = 2.6094\n",
      "Iteration 162020: loss = 2.3661\n",
      "Iteration 162030: loss = 2.0666\n",
      "Iteration 162040: loss = 2.4001\n",
      "Iteration 162050: loss = 2.2853\n",
      "Iteration 162060: loss = 2.1575\n",
      "Iteration 162070: loss = 2.5371\n",
      "Iteration 162080: loss = 2.8499\n",
      "Iteration 162090: loss = 2.6873\n",
      "Iteration 162100: loss = 2.5528\n",
      "Iteration 162110: loss = 2.0945\n",
      "Iteration 162120: loss = 2.4081\n",
      "Iteration 162130: loss = 2.2861\n",
      "Iteration 162140: loss = 2.6286\n",
      "Iteration 162150: loss = 2.0743\n",
      "Iteration 162160: loss = 2.1860\n",
      "Iteration 162170: loss = 2.5084\n",
      "Iteration 162180: loss = 2.3542\n",
      "Iteration 162190: loss = 2.2453\n",
      "Iteration 162200: loss = 2.4690\n",
      "Iteration 162210: loss = 2.3809\n",
      "Iteration 162220: loss = 2.2207\n",
      "Iteration 162230: loss = 2.6176\n",
      "Iteration 162240: loss = 2.5729\n",
      "Iteration 162250: loss = 1.9121\n",
      "Iteration 162260: loss = 1.9063\n",
      "Iteration 162270: loss = 2.3676\n",
      "Iteration 162280: loss = 2.8473\n",
      "Iteration 162290: loss = 3.0036\n",
      "Iteration 162300: loss = 2.6503\n",
      "Iteration 162310: loss = 2.4632\n",
      "Iteration 162320: loss = 2.1773\n",
      "Iteration 162330: loss = 2.2894\n",
      "Iteration 162340: loss = 2.5606\n",
      "Iteration 162350: loss = 2.1947\n",
      "Iteration 162360: loss = 2.3244\n",
      "Iteration 162370: loss = 2.7530\n",
      "Iteration 162380: loss = 2.3799\n",
      "Iteration 162390: loss = 2.3716\n",
      "Iteration 162400: loss = 2.3362\n",
      "Iteration 162410: loss = 2.6202\n",
      "Iteration 162420: loss = 2.3692\n",
      "Iteration 162430: loss = 2.1028\n",
      "Iteration 162440: loss = 2.1247\n",
      "Iteration 162450: loss = 2.2906\n",
      "Iteration 162460: loss = 2.3318\n",
      "Iteration 162470: loss = 2.0829\n",
      "Iteration 162480: loss = 2.5766\n",
      "Iteration 162490: loss = 2.2288\n",
      "Iteration 162500: loss = 2.0326\n",
      "Iteration 162510: loss = 2.3930\n",
      "Iteration 162520: loss = 2.6342\n",
      "Iteration 162530: loss = 2.6096\n",
      "Iteration 162540: loss = 2.1296\n",
      "Iteration 162550: loss = 2.1546\n",
      "Iteration 162560: loss = 2.8369\n",
      "Iteration 162570: loss = 2.4563\n",
      "Iteration 162580: loss = 2.7099\n",
      "Iteration 162590: loss = 2.7326\n",
      "Iteration 162600: loss = 2.4411\n",
      "Iteration 162610: loss = 2.3639\n",
      "Iteration 162620: loss = 2.5002\n",
      "Iteration 162630: loss = 2.5736\n",
      "Iteration 162640: loss = 2.3388\n",
      "Iteration 162650: loss = 2.6067\n",
      "Iteration 162660: loss = 2.5502\n",
      "Iteration 162670: loss = 2.2572\n",
      "Iteration 162680: loss = 2.5329\n",
      "Iteration 162690: loss = 2.4795\n",
      "Iteration 162700: loss = 2.6379\n",
      "Iteration 162710: loss = 2.4260\n",
      "Iteration 162720: loss = 2.0940\n",
      "Iteration 162730: loss = 2.4541\n",
      "Iteration 162740: loss = 2.5943\n",
      "Iteration 162750: loss = 2.4130\n",
      "Iteration 162760: loss = 2.9878\n",
      "Iteration 162770: loss = 2.2792\n",
      "Iteration 162780: loss = 2.3244\n",
      "Iteration 162790: loss = 2.5684\n",
      "Iteration 162800: loss = 2.4720\n",
      "Iteration 162810: loss = 1.9648\n",
      "Iteration 162820: loss = 2.3120\n",
      "Iteration 162830: loss = 2.4958\n",
      "Iteration 162840: loss = 2.8353\n",
      "Iteration 162850: loss = 2.1049\n",
      "Iteration 162860: loss = 2.1153\n",
      "Iteration 162870: loss = 2.1596\n",
      "Iteration 162880: loss = 2.4799\n",
      "Iteration 162890: loss = 2.3773\n",
      "Iteration 162900: loss = 2.3551\n",
      "Iteration 162910: loss = 2.3686\n",
      "Iteration 162920: loss = 2.3921\n",
      "Iteration 162930: loss = 2.5121\n",
      "Iteration 162940: loss = 2.4586\n",
      "Iteration 162950: loss = 2.5410\n",
      "Iteration 162960: loss = 2.9824\n",
      "Iteration 162970: loss = 2.4641\n",
      "Iteration 162980: loss = 2.5724\n",
      "Iteration 162990: loss = 2.4881\n",
      "Iteration 163000: loss = 2.3063\n",
      "Iteration 163010: loss = 2.4275\n",
      "Iteration 163020: loss = 2.4980\n",
      "Iteration 163030: loss = 2.3092\n",
      "Iteration 163040: loss = 2.2288\n",
      "Iteration 163050: loss = 2.3767\n",
      "Iteration 163060: loss = 2.4024\n",
      "Iteration 163070: loss = 2.5251\n",
      "Iteration 163080: loss = 2.5225\n",
      "Iteration 163090: loss = 2.2353\n",
      "Iteration 163100: loss = 2.2857\n",
      "Iteration 163110: loss = 2.4266\n",
      "Iteration 163120: loss = 2.5424\n",
      "Iteration 163130: loss = 2.6539\n",
      "Iteration 163140: loss = 2.5677\n",
      "Iteration 163150: loss = 2.2982\n",
      "Iteration 163160: loss = 2.5950\n",
      "Iteration 163170: loss = 2.4076\n",
      "Iteration 163180: loss = 2.5145\n",
      "Iteration 163190: loss = 2.6041\n",
      "Iteration 163200: loss = 2.4358\n",
      "Iteration 163210: loss = 2.1140\n",
      "Iteration 163220: loss = 2.5533\n",
      "Iteration 163230: loss = 2.5601\n",
      "Iteration 163240: loss = 2.2982\n",
      "Iteration 163250: loss = 2.1421\n",
      "Iteration 163260: loss = 2.3843\n",
      "Iteration 163270: loss = 2.5226\n",
      "Iteration 163280: loss = 2.3892\n",
      "Iteration 163290: loss = 2.6573\n",
      "Iteration 163300: loss = 2.5034\n",
      "Iteration 163310: loss = 2.5571\n",
      "Iteration 163320: loss = 2.1711\n",
      "Iteration 163330: loss = 2.4138\n",
      "Iteration 163340: loss = 2.4313\n",
      "Iteration 163350: loss = 2.0867\n",
      "Iteration 163360: loss = 2.8107\n",
      "Iteration 163370: loss = 2.0761\n",
      "Iteration 163380: loss = 2.7993\n",
      "Iteration 163390: loss = 2.4230\n",
      "Iteration 163400: loss = 2.4077\n",
      "Iteration 163410: loss = 2.1639\n",
      "Iteration 163420: loss = 2.2221\n",
      "Iteration 163430: loss = 2.4667\n",
      "Iteration 163440: loss = 2.1811\n",
      "Iteration 163450: loss = 2.2743\n",
      "Iteration 163460: loss = 2.2229\n",
      "Iteration 163470: loss = 2.0747\n",
      "Iteration 163480: loss = 2.0611\n",
      "Iteration 163490: loss = 2.4117\n",
      "Iteration 163500: loss = 2.1757\n",
      "Iteration 163510: loss = 2.3572\n",
      "Iteration 163520: loss = 2.6133\n",
      "Iteration 163530: loss = 2.6006\n",
      "Iteration 163540: loss = 2.4391\n",
      "Iteration 163550: loss = 2.7468\n",
      "Iteration 163560: loss = 2.3390\n",
      "Iteration 163570: loss = 2.5210\n",
      "Iteration 163580: loss = 2.6058\n",
      "Iteration 163590: loss = 2.5771\n",
      "Iteration 163600: loss = 2.4460\n",
      "Iteration 163610: loss = 2.3688\n",
      "Iteration 163620: loss = 2.8343\n",
      "Iteration 163630: loss = 2.5348\n",
      "Iteration 163640: loss = 2.5332\n",
      "Iteration 163650: loss = 2.2885\n",
      "Iteration 163660: loss = 2.4483\n",
      "Iteration 163670: loss = 2.2239\n",
      "Iteration 163680: loss = 2.4382\n",
      "Iteration 163690: loss = 2.3115\n",
      "Iteration 163700: loss = 2.5066\n",
      "Iteration 163710: loss = 2.1877\n",
      "Iteration 163720: loss = 2.4062\n",
      "Iteration 163730: loss = 2.3191\n",
      "Iteration 163740: loss = 2.2925\n",
      "Iteration 163750: loss = 2.1448\n",
      "Iteration 163760: loss = 2.4460\n",
      "Iteration 163770: loss = 1.9487\n",
      "Iteration 163780: loss = 2.3469\n",
      "Iteration 163790: loss = 2.9230\n",
      "Iteration 163800: loss = 2.3750\n",
      "Iteration 163810: loss = 2.2535\n",
      "Iteration 163820: loss = 2.4591\n",
      "Iteration 163830: loss = 2.5215\n",
      "Iteration 163840: loss = 2.4819\n",
      "Iteration 163850: loss = 2.5244\n",
      "Iteration 163860: loss = 2.5245\n",
      "Iteration 163870: loss = 2.3224\n",
      "Iteration 163880: loss = 2.2947\n",
      "Iteration 163890: loss = 2.5215\n",
      "Iteration 163900: loss = 2.4180\n",
      "Iteration 163910: loss = 2.2275\n",
      "Iteration 163920: loss = 2.2677\n",
      "Iteration 163930: loss = 2.3411\n",
      "Iteration 163940: loss = 2.5941\n",
      "Iteration 163950: loss = 2.4619\n",
      "Iteration 163960: loss = 2.4931\n",
      "Iteration 163970: loss = 2.5657\n",
      "Iteration 163980: loss = 2.4843\n",
      "Iteration 163990: loss = 2.0961\n",
      "Iteration 164000: loss = 2.1306\n",
      "Iteration 164010: loss = 2.4400\n",
      "Iteration 164020: loss = 2.2639\n",
      "Iteration 164030: loss = 2.4193\n",
      "Iteration 164040: loss = 2.4737\n",
      "Iteration 164050: loss = 2.3897\n",
      "Iteration 164060: loss = 2.4404\n",
      "Iteration 164070: loss = 2.3929\n",
      "Iteration 164080: loss = 2.3615\n",
      "Iteration 164090: loss = 2.5383\n",
      "Iteration 164100: loss = 2.2952\n",
      "Iteration 164110: loss = 2.5827\n",
      "Iteration 164120: loss = 2.5212\n",
      "Iteration 164130: loss = 2.3227\n",
      "Iteration 164140: loss = 2.1567\n",
      "Iteration 164150: loss = 2.1483\n",
      "Iteration 164160: loss = 2.4791\n",
      "Iteration 164170: loss = 2.5694\n",
      "Iteration 164180: loss = 2.2254\n",
      "Iteration 164190: loss = 2.3894\n",
      "Iteration 164200: loss = 2.5843\n",
      "Iteration 164210: loss = 2.1710\n",
      "Iteration 164220: loss = 2.5226\n",
      "Iteration 164230: loss = 2.7265\n",
      "Iteration 164240: loss = 2.3782\n",
      "Iteration 164250: loss = 2.4714\n",
      "Iteration 164260: loss = 2.1655\n",
      "Iteration 164270: loss = 2.5389\n",
      "Iteration 164280: loss = 2.1608\n",
      "Iteration 164290: loss = 2.3261\n",
      "Iteration 164300: loss = 2.2473\n",
      "Iteration 164310: loss = 2.3589\n",
      "Iteration 164320: loss = 2.8010\n",
      "Iteration 164330: loss = 2.4936\n",
      "Iteration 164340: loss = 2.3615\n",
      "Iteration 164350: loss = 2.3435\n",
      "Iteration 164360: loss = 2.2172\n",
      "Iteration 164370: loss = 2.1592\n",
      "Iteration 164380: loss = 2.3869\n",
      "Iteration 164390: loss = 2.4475\n",
      "Iteration 164400: loss = 2.5149\n",
      "Iteration 164410: loss = 1.8905\n",
      "Iteration 164420: loss = 2.1999\n",
      "Iteration 164430: loss = 2.9300\n",
      "Iteration 164440: loss = 2.6336\n",
      "Iteration 164450: loss = 2.1633\n",
      "Iteration 164460: loss = 2.5698\n",
      "Iteration 164470: loss = 2.3225\n",
      "Iteration 164480: loss = 2.3121\n",
      "Iteration 164490: loss = 2.5685\n",
      "Iteration 164500: loss = 2.5514\n",
      "Iteration 164510: loss = 2.2466\n",
      "Iteration 164520: loss = 2.8210\n",
      "Iteration 164530: loss = 2.5344\n",
      "Iteration 164540: loss = 2.1620\n",
      "Iteration 164550: loss = 2.4369\n",
      "Iteration 164560: loss = 2.4273\n",
      "Iteration 164570: loss = 2.5647\n",
      "Iteration 164580: loss = 2.8121\n",
      "Iteration 164590: loss = 2.7168\n",
      "Iteration 164600: loss = 2.4009\n",
      "Iteration 164610: loss = 1.9876\n",
      "Iteration 164620: loss = 2.6488\n",
      "Iteration 164630: loss = 2.2804\n",
      "Iteration 164640: loss = 2.2486\n",
      "Iteration 164650: loss = 1.9650\n",
      "Iteration 164660: loss = 2.0424\n",
      "Iteration 164670: loss = 2.5264\n",
      "Iteration 164680: loss = 2.5838\n",
      "Iteration 164690: loss = 2.4977\n",
      "Iteration 164700: loss = 2.1076\n",
      "Iteration 164710: loss = 2.3616\n",
      "Iteration 164720: loss = 2.1278\n",
      "Iteration 164730: loss = 2.8463\n",
      "Iteration 164740: loss = 2.3584\n",
      "Iteration 164750: loss = 2.5005\n",
      "Iteration 164760: loss = 2.1819\n",
      "Iteration 164770: loss = 2.2724\n",
      "Iteration 164780: loss = 2.9073\n",
      "Iteration 164790: loss = 2.5536\n",
      "Iteration 164800: loss = 2.5558\n",
      "Iteration 164810: loss = 2.4154\n",
      "Iteration 164820: loss = 2.5978\n",
      "Iteration 164830: loss = 2.5853\n",
      "Iteration 164840: loss = 2.4601\n",
      "Iteration 164850: loss = 2.6496\n",
      "Iteration 164860: loss = 2.3701\n",
      "Iteration 164870: loss = 2.9025\n",
      "Iteration 164880: loss = 2.3391\n",
      "Iteration 164890: loss = 2.6459\n",
      "Iteration 164900: loss = 2.4678\n",
      "Iteration 164910: loss = 2.3633\n",
      "Iteration 164920: loss = 2.6423\n",
      "Iteration 164930: loss = 2.5874\n",
      "Iteration 164940: loss = 2.2416\n",
      "Iteration 164950: loss = 2.8797\n",
      "Iteration 164960: loss = 2.2974\n",
      "Iteration 164970: loss = 2.4591\n",
      "Iteration 164980: loss = 2.2386\n",
      "Iteration 164990: loss = 2.3332\n",
      "Iteration 165000: loss = 2.2498\n",
      "Iteration 165010: loss = 2.5106\n",
      "Iteration 165020: loss = 2.5805\n",
      "Iteration 165030: loss = 2.6037\n",
      "Iteration 165040: loss = 2.3482\n",
      "Iteration 165050: loss = 2.6621\n",
      "Iteration 165060: loss = 2.4918\n",
      "Iteration 165070: loss = 2.6630\n",
      "Iteration 165080: loss = 2.4030\n",
      "Iteration 165090: loss = 2.0452\n",
      "Iteration 165100: loss = 2.6757\n",
      "Iteration 165110: loss = 2.1148\n",
      "Iteration 165120: loss = 2.4383\n",
      "Iteration 165130: loss = 2.5805\n",
      "Iteration 165140: loss = 2.4266\n",
      "Iteration 165150: loss = 2.7379\n",
      "Iteration 165160: loss = 3.1040\n",
      "Iteration 165170: loss = 2.3316\n",
      "Iteration 165180: loss = 2.3678\n",
      "Iteration 165190: loss = 2.4922\n",
      "Iteration 165200: loss = 2.8068\n",
      "Iteration 165210: loss = 2.2064\n",
      "Iteration 165220: loss = 2.3822\n",
      "Iteration 165230: loss = 2.2310\n",
      "Iteration 165240: loss = 2.9355\n",
      "Iteration 165250: loss = 2.6487\n",
      "Iteration 165260: loss = 2.1065\n",
      "Iteration 165270: loss = 2.3472\n",
      "Iteration 165280: loss = 2.2975\n",
      "Iteration 165290: loss = 2.4344\n",
      "Iteration 165300: loss = 2.4856\n",
      "Iteration 165310: loss = 2.4465\n",
      "Iteration 165320: loss = 2.0957\n",
      "Iteration 165330: loss = 2.3141\n",
      "Iteration 165340: loss = 2.3809\n",
      "Iteration 165350: loss = 2.1432\n",
      "Iteration 165360: loss = 2.1265\n",
      "Iteration 165370: loss = 2.3472\n",
      "Iteration 165380: loss = 2.3514\n",
      "Iteration 165390: loss = 2.3363\n",
      "Iteration 165400: loss = 2.5811\n",
      "Iteration 165410: loss = 2.3218\n",
      "Iteration 165420: loss = 2.2019\n",
      "Iteration 165430: loss = 2.1292\n",
      "Iteration 165440: loss = 2.6704\n",
      "Iteration 165450: loss = 2.3899\n",
      "Iteration 165460: loss = 2.4817\n",
      "Iteration 165470: loss = 2.7080\n",
      "Iteration 165480: loss = 2.2998\n",
      "Iteration 165490: loss = 2.4604\n",
      "Iteration 165500: loss = 2.2657\n",
      "Iteration 165510: loss = 2.3835\n",
      "Iteration 165520: loss = 2.3705\n",
      "Iteration 165530: loss = 2.7596\n",
      "Iteration 165540: loss = 2.4056\n",
      "Iteration 165550: loss = 2.6636\n",
      "Iteration 165560: loss = 2.7543\n",
      "Iteration 165570: loss = 2.4617\n",
      "Iteration 165580: loss = 2.5392\n",
      "Iteration 165590: loss = 2.2903\n",
      "Iteration 165600: loss = 2.6211\n",
      "Iteration 165610: loss = 2.3297\n",
      "Iteration 165620: loss = 2.5248\n",
      "Iteration 165630: loss = 2.5099\n",
      "Iteration 165640: loss = 2.4149\n",
      "Iteration 165650: loss = 2.6772\n",
      "Iteration 165660: loss = 2.3131\n",
      "Iteration 165670: loss = 2.7553\n",
      "Iteration 165680: loss = 2.2757\n",
      "Iteration 165690: loss = 2.6745\n",
      "Iteration 165700: loss = 2.3154\n",
      "Iteration 165710: loss = 2.2028\n",
      "Iteration 165720: loss = 2.1203\n",
      "Iteration 165730: loss = 2.5696\n",
      "Iteration 165740: loss = 2.7486\n",
      "Iteration 165750: loss = 2.3290\n",
      "Iteration 165760: loss = 2.3638\n",
      "Iteration 165770: loss = 2.4211\n",
      "Iteration 165780: loss = 2.8278\n",
      "Iteration 165790: loss = 2.1190\n",
      "Iteration 165800: loss = 2.4439\n",
      "Iteration 165810: loss = 2.5017\n",
      "Iteration 165820: loss = 2.3594\n",
      "Iteration 165830: loss = 2.3055\n",
      "Iteration 165840: loss = 2.2149\n",
      "Iteration 165850: loss = 2.5855\n",
      "Iteration 165860: loss = 2.5148\n",
      "Iteration 165870: loss = 2.1937\n",
      "Iteration 165880: loss = 2.3355\n",
      "Iteration 165890: loss = 2.5525\n",
      "Iteration 165900: loss = 2.1246\n",
      "Iteration 165910: loss = 2.8010\n",
      "Iteration 165920: loss = 2.3713\n",
      "Iteration 165930: loss = 2.6344\n",
      "Iteration 165940: loss = 2.2845\n",
      "Iteration 165950: loss = 2.3002\n",
      "Iteration 165960: loss = 2.6630\n",
      "Iteration 165970: loss = 2.1589\n",
      "Iteration 165980: loss = 2.5729\n",
      "Iteration 165990: loss = 2.3381\n",
      "Iteration 166000: loss = 2.5591\n",
      "Iteration 166010: loss = 2.3472\n",
      "Iteration 166020: loss = 2.4517\n",
      "Iteration 166030: loss = 2.3629\n",
      "Iteration 166040: loss = 2.3088\n",
      "Iteration 166050: loss = 2.4993\n",
      "Iteration 166060: loss = 2.6633\n",
      "Iteration 166070: loss = 2.7662\n",
      "Iteration 166080: loss = 2.2085\n",
      "Iteration 166090: loss = 2.3418\n",
      "Iteration 166100: loss = 2.6424\n",
      "Iteration 166110: loss = 2.1043\n",
      "Iteration 166120: loss = 2.5308\n",
      "Iteration 166130: loss = 2.4858\n",
      "Iteration 166140: loss = 2.2048\n",
      "Iteration 166150: loss = 2.3048\n",
      "Iteration 166160: loss = 2.2894\n",
      "Iteration 166170: loss = 2.2050\n",
      "Iteration 166180: loss = 2.7521\n",
      "Iteration 166190: loss = 2.3925\n",
      "Iteration 166200: loss = 2.9861\n",
      "Iteration 166210: loss = 2.3241\n",
      "Iteration 166220: loss = 2.4891\n",
      "Iteration 166230: loss = 2.1800\n",
      "Iteration 166240: loss = 3.1080\n",
      "Iteration 166250: loss = 2.3004\n",
      "Iteration 166260: loss = 2.3493\n",
      "Iteration 166270: loss = 2.2558\n",
      "Iteration 166280: loss = 2.4524\n",
      "Iteration 166290: loss = 2.2378\n",
      "Iteration 166300: loss = 2.5590\n",
      "Iteration 166310: loss = 2.4731\n",
      "Iteration 166320: loss = 2.2811\n",
      "Iteration 166330: loss = 2.0790\n",
      "Iteration 166340: loss = 2.3703\n",
      "Iteration 166350: loss = 2.2973\n",
      "Iteration 166360: loss = 2.6464\n",
      "Iteration 166370: loss = 2.3614\n",
      "Iteration 166380: loss = 2.1960\n",
      "Iteration 166390: loss = 2.8751\n",
      "Iteration 166400: loss = 2.2758\n",
      "Iteration 166410: loss = 2.0958\n",
      "Iteration 166420: loss = 2.4604\n",
      "Iteration 166430: loss = 2.2460\n",
      "Iteration 166440: loss = 2.3478\n",
      "Iteration 166450: loss = 2.4272\n",
      "Iteration 166460: loss = 2.4866\n",
      "Iteration 166470: loss = 2.3265\n",
      "Iteration 166480: loss = 2.3317\n",
      "Iteration 166490: loss = 2.2252\n",
      "Iteration 166500: loss = 2.6023\n",
      "Iteration 166510: loss = 2.1013\n",
      "Iteration 166520: loss = 2.7032\n",
      "Iteration 166530: loss = 2.1786\n",
      "Iteration 166540: loss = 2.3419\n",
      "Iteration 166550: loss = 2.3462\n",
      "Iteration 166560: loss = 2.2739\n",
      "Iteration 166570: loss = 2.3611\n",
      "Iteration 166580: loss = 2.1826\n",
      "Iteration 166590: loss = 2.6481\n",
      "Iteration 166600: loss = 2.4406\n",
      "Iteration 166610: loss = 2.2049\n",
      "Iteration 166620: loss = 2.3600\n",
      "Iteration 166630: loss = 2.6826\n",
      "Iteration 166640: loss = 2.4595\n",
      "Iteration 166650: loss = 2.2613\n",
      "Iteration 166660: loss = 2.3743\n",
      "Iteration 166670: loss = 2.5744\n",
      "Iteration 166680: loss = 2.0242\n",
      "Iteration 166690: loss = 2.5915\n",
      "Iteration 166700: loss = 2.7481\n",
      "Iteration 166710: loss = 2.4684\n",
      "Iteration 166720: loss = 2.4797\n",
      "Iteration 166730: loss = 2.4303\n",
      "Iteration 166740: loss = 2.3460\n",
      "Iteration 166750: loss = 2.4431\n",
      "Iteration 166760: loss = 2.2639\n",
      "Iteration 166770: loss = 2.2869\n",
      "Iteration 166780: loss = 2.2800\n",
      "Iteration 166790: loss = 2.4683\n",
      "Iteration 166800: loss = 2.2589\n",
      "Iteration 166810: loss = 2.4714\n",
      "Iteration 166820: loss = 2.4041\n",
      "Iteration 166830: loss = 2.4940\n",
      "Iteration 166840: loss = 2.8675\n",
      "Iteration 166850: loss = 2.1663\n",
      "Iteration 166860: loss = 2.2646\n",
      "Iteration 166870: loss = 2.8809\n",
      "Iteration 166880: loss = 2.6108\n",
      "Iteration 166890: loss = 2.4052\n",
      "Iteration 166900: loss = 2.1215\n",
      "Iteration 166910: loss = 2.1085\n",
      "Iteration 166920: loss = 2.4534\n",
      "Iteration 166930: loss = 2.1687\n",
      "Iteration 166940: loss = 2.9833\n",
      "Iteration 166950: loss = 2.3128\n",
      "Iteration 166960: loss = 2.2547\n",
      "Iteration 166970: loss = 2.4665\n",
      "Iteration 166980: loss = 2.5969\n",
      "Iteration 166990: loss = 2.1503\n",
      "Iteration 167000: loss = 2.3647\n",
      "Iteration 167010: loss = 2.1586\n",
      "Iteration 167020: loss = 2.3336\n",
      "Iteration 167030: loss = 2.2890\n",
      "Iteration 167040: loss = 2.5028\n",
      "Iteration 167050: loss = 2.7250\n",
      "Iteration 167060: loss = 2.6397\n",
      "Iteration 167070: loss = 2.1149\n",
      "Iteration 167080: loss = 2.6978\n",
      "Iteration 167090: loss = 2.4098\n",
      "Iteration 167100: loss = 2.2390\n",
      "Iteration 167110: loss = 2.6800\n",
      "Iteration 167120: loss = 2.1002\n",
      "Iteration 167130: loss = 2.2909\n",
      "Iteration 167140: loss = 2.3438\n",
      "Iteration 167150: loss = 2.3584\n",
      "Iteration 167160: loss = 2.2167\n",
      "Iteration 167170: loss = 2.3883\n",
      "Iteration 167180: loss = 2.8368\n",
      "Iteration 167190: loss = 2.3626\n",
      "Iteration 167200: loss = 2.3019\n",
      "Iteration 167210: loss = 2.1896\n",
      "Iteration 167220: loss = 2.4993\n",
      "Iteration 167230: loss = 2.2374\n",
      "Iteration 167240: loss = 2.2220\n",
      "Iteration 167250: loss = 2.3989\n",
      "Iteration 167260: loss = 1.9991\n",
      "Iteration 167270: loss = 2.4587\n",
      "Iteration 167280: loss = 2.4644\n",
      "Iteration 167290: loss = 2.0606\n",
      "Iteration 167300: loss = 2.4935\n",
      "Iteration 167310: loss = 2.3644\n",
      "Iteration 167320: loss = 2.3574\n",
      "Iteration 167330: loss = 2.3300\n",
      "Iteration 167340: loss = 2.1322\n",
      "Iteration 167350: loss = 2.6030\n",
      "Iteration 167360: loss = 2.3508\n",
      "Iteration 167370: loss = 2.7726\n",
      "Iteration 167380: loss = 2.3456\n",
      "Iteration 167390: loss = 2.2834\n",
      "Iteration 167400: loss = 2.3977\n",
      "Iteration 167410: loss = 2.8839\n",
      "Iteration 167420: loss = 2.4266\n",
      "Iteration 167430: loss = 2.4779\n",
      "Iteration 167440: loss = 2.1222\n",
      "Iteration 167450: loss = 2.5458\n",
      "Iteration 167460: loss = 2.5217\n",
      "Iteration 167470: loss = 2.4631\n",
      "Iteration 167480: loss = 2.4974\n",
      "Iteration 167490: loss = 2.6421\n",
      "Iteration 167500: loss = 2.5385\n",
      "Iteration 167510: loss = 2.2653\n",
      "Iteration 167520: loss = 2.4619\n",
      "Iteration 167530: loss = 2.2368\n",
      "Iteration 167540: loss = 2.0614\n",
      "Iteration 167550: loss = 2.5362\n",
      "Iteration 167560: loss = 2.6996\n",
      "Iteration 167570: loss = 1.9571\n",
      "Iteration 167580: loss = 2.9107\n",
      "Iteration 167590: loss = 2.4965\n",
      "Iteration 167600: loss = 2.7253\n",
      "Iteration 167610: loss = 2.5211\n",
      "Iteration 167620: loss = 2.6791\n",
      "Iteration 167630: loss = 2.6668\n",
      "Iteration 167640: loss = 2.4628\n",
      "Iteration 167650: loss = 2.4412\n",
      "Iteration 167660: loss = 2.5168\n",
      "Iteration 167670: loss = 2.5926\n",
      "Iteration 167680: loss = 2.6741\n",
      "Iteration 167690: loss = 2.5399\n",
      "Iteration 167700: loss = 2.4144\n",
      "Iteration 167710: loss = 2.9675\n",
      "Iteration 167720: loss = 2.5015\n",
      "Iteration 167730: loss = 2.9153\n",
      "Iteration 167740: loss = 2.7035\n",
      "Iteration 167750: loss = 2.4000\n",
      "Iteration 167760: loss = 2.2257\n",
      "Iteration 167770: loss = 2.1043\n",
      "Iteration 167780: loss = 2.5892\n",
      "Iteration 167790: loss = 2.5173\n",
      "Iteration 167800: loss = 2.6147\n",
      "Iteration 167810: loss = 2.2420\n",
      "Iteration 167820: loss = 2.1373\n",
      "Iteration 167830: loss = 2.4355\n",
      "Iteration 167840: loss = 2.3998\n",
      "Iteration 167850: loss = 2.6587\n",
      "Iteration 167860: loss = 2.4526\n",
      "Iteration 167870: loss = 2.3568\n",
      "Iteration 167880: loss = 2.4734\n",
      "Iteration 167890: loss = 2.6793\n",
      "Iteration 167900: loss = 2.5194\n",
      "Iteration 167910: loss = 2.3310\n",
      "Iteration 167920: loss = 2.3196\n",
      "Iteration 167930: loss = 2.3799\n",
      "Iteration 167940: loss = 2.6942\n",
      "Iteration 167950: loss = 2.2513\n",
      "Iteration 167960: loss = 2.5035\n",
      "Iteration 167970: loss = 2.0527\n",
      "Iteration 167980: loss = 2.5714\n",
      "Iteration 167990: loss = 2.2755\n",
      "Iteration 168000: loss = 2.5588\n",
      "Iteration 168010: loss = 2.5589\n",
      "Iteration 168020: loss = 2.0507\n",
      "Iteration 168030: loss = 2.8533\n",
      "Iteration 168040: loss = 2.4537\n",
      "Iteration 168050: loss = 2.3802\n",
      "Iteration 168060: loss = 2.6344\n",
      "Iteration 168070: loss = 2.3525\n",
      "Iteration 168080: loss = 2.1124\n",
      "Iteration 168090: loss = 2.1947\n",
      "Iteration 168100: loss = 2.1052\n",
      "Iteration 168110: loss = 2.4905\n",
      "Iteration 168120: loss = 2.3609\n",
      "Iteration 168130: loss = 2.5127\n",
      "Iteration 168140: loss = 2.5173\n",
      "Iteration 168150: loss = 2.1391\n",
      "Iteration 168160: loss = 1.8524\n",
      "Iteration 168170: loss = 2.1488\n",
      "Iteration 168180: loss = 2.2606\n",
      "Iteration 168190: loss = 2.2772\n",
      "Iteration 168200: loss = 2.3054\n",
      "Iteration 168210: loss = 2.5645\n",
      "Iteration 168220: loss = 2.5868\n",
      "Iteration 168230: loss = 2.5025\n",
      "Iteration 168240: loss = 2.5377\n",
      "Iteration 168250: loss = 2.4822\n",
      "Iteration 168260: loss = 2.2150\n",
      "Iteration 168270: loss = 2.6669\n",
      "Iteration 168280: loss = 2.0089\n",
      "Iteration 168290: loss = 2.4659\n",
      "Iteration 168300: loss = 2.0796\n",
      "Iteration 168310: loss = 2.6448\n",
      "Iteration 168320: loss = 2.6384\n",
      "Iteration 168330: loss = 2.6252\n",
      "Iteration 168340: loss = 2.3640\n",
      "Iteration 168350: loss = 2.2039\n",
      "Iteration 168360: loss = 2.7334\n",
      "Iteration 168370: loss = 2.4657\n",
      "Iteration 168380: loss = 2.4608\n",
      "Iteration 168390: loss = 2.3882\n",
      "Iteration 168400: loss = 2.7138\n",
      "Iteration 168410: loss = 2.8211\n",
      "Iteration 168420: loss = 2.4089\n",
      "Iteration 168430: loss = 2.2136\n",
      "Iteration 168440: loss = 2.2308\n",
      "Iteration 168450: loss = 2.2215\n",
      "Iteration 168460: loss = 2.2959\n",
      "Iteration 168470: loss = 2.2715\n",
      "Iteration 168480: loss = 2.5119\n",
      "Iteration 168490: loss = 2.1483\n",
      "Iteration 168500: loss = 2.0401\n",
      "Iteration 168510: loss = 1.8729\n",
      "Iteration 168520: loss = 2.4988\n",
      "Iteration 168530: loss = 2.6447\n",
      "Iteration 168540: loss = 2.3250\n",
      "Iteration 168550: loss = 2.3372\n",
      "Iteration 168560: loss = 2.5115\n",
      "Iteration 168570: loss = 2.1057\n",
      "Iteration 168580: loss = 2.9079\n",
      "Iteration 168590: loss = 2.4703\n",
      "Iteration 168600: loss = 2.6998\n",
      "Iteration 168610: loss = 2.6242\n",
      "Iteration 168620: loss = 2.1823\n",
      "Iteration 168630: loss = 2.7990\n",
      "Iteration 168640: loss = 2.4250\n",
      "Iteration 168650: loss = 2.6123\n",
      "Iteration 168660: loss = 2.1520\n",
      "Iteration 168670: loss = 2.1516\n",
      "Iteration 168680: loss = 2.1669\n",
      "Iteration 168690: loss = 2.2003\n",
      "Iteration 168700: loss = 2.2927\n",
      "Iteration 168710: loss = 2.6126\n",
      "Iteration 168720: loss = 2.3461\n",
      "Iteration 168730: loss = 1.9442\n",
      "Iteration 168740: loss = 2.2470\n",
      "Iteration 168750: loss = 2.3346\n",
      "Iteration 168760: loss = 2.6709\n",
      "Iteration 168770: loss = 3.0428\n",
      "Iteration 168780: loss = 2.2315\n",
      "Iteration 168790: loss = 2.7413\n",
      "Iteration 168800: loss = 2.5048\n",
      "Iteration 168810: loss = 2.7305\n",
      "Iteration 168820: loss = 2.3650\n",
      "Iteration 168830: loss = 2.4793\n",
      "Iteration 168840: loss = 2.9891\n",
      "Iteration 168850: loss = 1.9959\n",
      "Iteration 168860: loss = 2.4725\n",
      "Iteration 168870: loss = 2.4206\n",
      "Iteration 168880: loss = 2.0317\n",
      "Iteration 168890: loss = 2.5358\n",
      "Iteration 168900: loss = 2.4011\n",
      "Iteration 168910: loss = 2.0704\n",
      "Iteration 168920: loss = 2.0276\n",
      "Iteration 168930: loss = 2.2755\n",
      "Iteration 168940: loss = 2.2164\n",
      "Iteration 168950: loss = 2.6229\n",
      "Iteration 168960: loss = 2.2788\n",
      "Iteration 168970: loss = 2.6381\n",
      "Iteration 168980: loss = 2.2695\n",
      "Iteration 168990: loss = 2.4465\n",
      "Iteration 169000: loss = 2.5260\n",
      "Iteration 169010: loss = 2.3415\n",
      "Iteration 169020: loss = 2.1402\n",
      "Iteration 169030: loss = 2.1599\n",
      "Iteration 169040: loss = 2.4444\n",
      "Iteration 169050: loss = 2.1640\n",
      "Iteration 169060: loss = 2.4325\n",
      "Iteration 169070: loss = 2.3033\n",
      "Iteration 169080: loss = 2.5294\n",
      "Iteration 169090: loss = 2.0997\n",
      "Iteration 169100: loss = 2.4234\n",
      "Iteration 169110: loss = 2.4353\n",
      "Iteration 169120: loss = 2.6145\n",
      "Iteration 169130: loss = 2.3670\n",
      "Iteration 169140: loss = 2.1792\n",
      "Iteration 169150: loss = 2.5341\n",
      "Iteration 169160: loss = 2.4061\n",
      "Iteration 169170: loss = 2.6305\n",
      "Iteration 169180: loss = 2.1570\n",
      "Iteration 169190: loss = 2.3114\n",
      "Iteration 169200: loss = 2.4298\n",
      "Iteration 169210: loss = 2.6723\n",
      "Iteration 169220: loss = 2.6421\n",
      "Iteration 169230: loss = 2.5422\n",
      "Iteration 169240: loss = 2.3995\n",
      "Iteration 169250: loss = 2.3650\n",
      "Iteration 169260: loss = 2.4037\n",
      "Iteration 169270: loss = 2.2540\n",
      "Iteration 169280: loss = 2.2998\n",
      "Iteration 169290: loss = 2.2201\n",
      "Iteration 169300: loss = 2.5629\n",
      "Iteration 169310: loss = 2.4190\n",
      "Iteration 169320: loss = 2.4632\n",
      "Iteration 169330: loss = 2.7241\n",
      "Iteration 169340: loss = 2.1957\n",
      "Iteration 169350: loss = 2.2870\n",
      "Iteration 169360: loss = 2.0843\n",
      "Iteration 169370: loss = 2.3302\n",
      "Iteration 169380: loss = 2.1404\n",
      "Iteration 169390: loss = 2.4311\n",
      "Iteration 169400: loss = 2.5215\n",
      "Iteration 169410: loss = 2.2205\n",
      "Iteration 169420: loss = 2.2330\n",
      "Iteration 169430: loss = 3.1436\n",
      "Iteration 169440: loss = 2.2483\n",
      "Iteration 169450: loss = 2.2738\n",
      "Iteration 169460: loss = 2.5776\n",
      "Iteration 169470: loss = 2.7800\n",
      "Iteration 169480: loss = 2.4502\n",
      "Iteration 169490: loss = 2.3829\n",
      "Iteration 169500: loss = 2.6455\n",
      "Iteration 169510: loss = 2.1179\n",
      "Iteration 169520: loss = 2.3307\n",
      "Iteration 169530: loss = 2.4512\n",
      "Iteration 169540: loss = 2.5695\n",
      "Iteration 169550: loss = 2.6991\n",
      "Iteration 169560: loss = 2.5935\n",
      "Iteration 169570: loss = 2.7013\n",
      "Iteration 169580: loss = 2.3318\n",
      "Iteration 169590: loss = 2.0095\n",
      "Iteration 169600: loss = 2.7045\n",
      "Iteration 169610: loss = 2.0931\n",
      "Iteration 169620: loss = 2.7280\n",
      "Iteration 169630: loss = 2.1454\n",
      "Iteration 169640: loss = 2.3495\n",
      "Iteration 169650: loss = 2.4743\n",
      "Iteration 169660: loss = 2.6237\n",
      "Iteration 169670: loss = 2.1900\n",
      "Iteration 169680: loss = 2.5164\n",
      "Iteration 169690: loss = 2.9540\n",
      "Iteration 169700: loss = 2.0242\n",
      "Iteration 169710: loss = 2.7586\n",
      "Iteration 169720: loss = 2.3394\n",
      "Iteration 169730: loss = 2.7164\n",
      "Iteration 169740: loss = 2.2564\n",
      "Iteration 169750: loss = 2.2505\n",
      "Iteration 169760: loss = 2.2539\n",
      "Iteration 169770: loss = 2.4755\n",
      "Iteration 169780: loss = 2.2348\n",
      "Iteration 169790: loss = 2.1433\n",
      "Iteration 169800: loss = 2.5294\n",
      "Iteration 169810: loss = 2.5450\n",
      "Iteration 169820: loss = 2.3227\n",
      "Iteration 169830: loss = 2.6303\n",
      "Iteration 169840: loss = 2.3706\n",
      "Iteration 169850: loss = 2.6098\n",
      "Iteration 169860: loss = 2.4543\n",
      "Iteration 169870: loss = 2.3695\n",
      "Iteration 169880: loss = 2.3288\n",
      "Iteration 169890: loss = 2.3922\n",
      "Iteration 169900: loss = 2.6214\n",
      "Iteration 169910: loss = 2.4064\n",
      "Iteration 169920: loss = 2.4729\n",
      "Iteration 169930: loss = 2.5519\n",
      "Iteration 169940: loss = 2.6549\n",
      "Iteration 169950: loss = 2.4211\n",
      "Iteration 169960: loss = 2.6383\n",
      "Iteration 169970: loss = 2.5890\n",
      "Iteration 169980: loss = 2.3634\n",
      "Iteration 169990: loss = 2.5685\n",
      "Iteration 170000: loss = 2.5340\n",
      "Iteration 170010: loss = 2.4418\n",
      "Iteration 170020: loss = 2.0694\n",
      "Iteration 170030: loss = 2.0453\n",
      "Iteration 170040: loss = 2.6965\n",
      "Iteration 170050: loss = 2.3744\n",
      "Iteration 170060: loss = 3.0187\n",
      "Iteration 170070: loss = 2.6496\n",
      "Iteration 170080: loss = 1.7137\n",
      "Iteration 170090: loss = 1.9382\n",
      "Iteration 170100: loss = 2.4278\n",
      "Iteration 170110: loss = 2.5273\n",
      "Iteration 170120: loss = 2.5689\n",
      "Iteration 170130: loss = 2.3657\n",
      "Iteration 170140: loss = 2.6052\n",
      "Iteration 170150: loss = 2.4229\n",
      "Iteration 170160: loss = 2.3188\n",
      "Iteration 170170: loss = 2.3627\n",
      "Iteration 170180: loss = 2.3359\n",
      "Iteration 170190: loss = 2.4490\n",
      "Iteration 170200: loss = 2.5815\n",
      "Iteration 170210: loss = 2.1557\n",
      "Iteration 170220: loss = 2.5838\n",
      "Iteration 170230: loss = 2.6494\n",
      "Iteration 170240: loss = 2.4329\n",
      "Iteration 170250: loss = 2.6099\n",
      "Iteration 170260: loss = 2.5329\n",
      "Iteration 170270: loss = 2.6292\n",
      "Iteration 170280: loss = 2.4478\n",
      "Iteration 170290: loss = 2.0597\n",
      "Iteration 170300: loss = 1.9194\n",
      "Iteration 170310: loss = 2.4478\n",
      "Iteration 170320: loss = 2.2933\n",
      "Iteration 170330: loss = 2.4848\n",
      "Iteration 170340: loss = 2.1996\n",
      "Iteration 170350: loss = 2.3162\n",
      "Iteration 170360: loss = 2.2462\n",
      "Iteration 170370: loss = 2.0421\n",
      "Iteration 170380: loss = 2.4732\n",
      "Iteration 170390: loss = 2.4917\n",
      "Iteration 170400: loss = 2.6345\n",
      "Iteration 170410: loss = 2.4894\n",
      "Iteration 170420: loss = 2.4952\n",
      "Iteration 170430: loss = 2.3239\n",
      "Iteration 170440: loss = 2.3557\n",
      "Iteration 170450: loss = 2.2395\n",
      "Iteration 170460: loss = 2.4189\n",
      "Iteration 170470: loss = 2.1911\n",
      "Iteration 170480: loss = 2.4663\n",
      "Iteration 170490: loss = 2.7285\n",
      "Iteration 170500: loss = 2.2460\n",
      "Iteration 170510: loss = 1.8807\n",
      "Iteration 170520: loss = 2.4384\n",
      "Iteration 170530: loss = 2.3720\n",
      "Iteration 170540: loss = 2.6269\n",
      "Iteration 170550: loss = 2.3860\n",
      "Iteration 170560: loss = 2.2142\n",
      "Iteration 170570: loss = 2.4131\n",
      "Iteration 170580: loss = 2.2519\n",
      "Iteration 170590: loss = 2.2938\n",
      "Iteration 170600: loss = 2.0409\n",
      "Iteration 170610: loss = 2.4389\n",
      "Iteration 170620: loss = 2.6447\n",
      "Iteration 170630: loss = 2.3176\n",
      "Iteration 170640: loss = 2.7233\n",
      "Iteration 170650: loss = 2.6415\n",
      "Iteration 170660: loss = 1.9816\n",
      "Iteration 170670: loss = 2.3449\n",
      "Iteration 170680: loss = 2.3725\n",
      "Iteration 170690: loss = 2.2973\n",
      "Iteration 170700: loss = 2.3958\n",
      "Iteration 170710: loss = 2.4578\n",
      "Iteration 170720: loss = 2.4385\n",
      "Iteration 170730: loss = 2.7850\n",
      "Iteration 170740: loss = 2.5660\n",
      "Iteration 170750: loss = 2.1932\n",
      "Iteration 170760: loss = 1.9133\n",
      "Iteration 170770: loss = 2.5570\n",
      "Iteration 170780: loss = 2.3060\n",
      "Iteration 170790: loss = 2.5618\n",
      "Iteration 170800: loss = 2.6669\n",
      "Iteration 170810: loss = 2.2380\n",
      "Iteration 170820: loss = 2.3178\n",
      "Iteration 170830: loss = 2.5274\n",
      "Iteration 170840: loss = 2.2413\n",
      "Iteration 170850: loss = 2.6210\n",
      "Iteration 170860: loss = 2.3368\n",
      "Iteration 170870: loss = 2.2988\n",
      "Iteration 170880: loss = 2.2153\n",
      "Iteration 170890: loss = 2.6850\n",
      "Iteration 170900: loss = 2.3912\n",
      "Iteration 170910: loss = 2.3894\n",
      "Iteration 170920: loss = 2.3556\n",
      "Iteration 170930: loss = 2.0440\n",
      "Iteration 170940: loss = 2.3059\n",
      "Iteration 170950: loss = 2.5844\n",
      "Iteration 170960: loss = 2.3689\n",
      "Iteration 170970: loss = 2.4055\n",
      "Iteration 170980: loss = 2.6907\n",
      "Iteration 170990: loss = 2.2911\n",
      "Iteration 171000: loss = 2.4543\n",
      "Iteration 171010: loss = 2.3589\n",
      "Iteration 171020: loss = 2.5530\n",
      "Iteration 171030: loss = 2.7817\n",
      "Iteration 171040: loss = 2.7091\n",
      "Iteration 171050: loss = 2.4230\n",
      "Iteration 171060: loss = 2.6726\n",
      "Iteration 171070: loss = 2.6242\n",
      "Iteration 171080: loss = 2.2882\n",
      "Iteration 171090: loss = 2.1323\n",
      "Iteration 171100: loss = 2.4168\n",
      "Iteration 171110: loss = 2.4223\n",
      "Iteration 171120: loss = 2.4107\n",
      "Iteration 171130: loss = 2.1697\n",
      "Iteration 171140: loss = 2.2157\n",
      "Iteration 171150: loss = 3.3642\n",
      "Iteration 171160: loss = 2.2224\n",
      "Iteration 171170: loss = 2.2274\n",
      "Iteration 171180: loss = 2.6075\n",
      "Iteration 171190: loss = 2.3526\n",
      "Iteration 171200: loss = 2.9160\n",
      "Iteration 171210: loss = 2.6578\n",
      "Iteration 171220: loss = 2.6749\n",
      "Iteration 171230: loss = 2.3616\n",
      "Iteration 171240: loss = 2.6686\n",
      "Iteration 171250: loss = 2.4623\n",
      "Iteration 171260: loss = 2.1820\n",
      "Iteration 171270: loss = 2.2644\n",
      "Iteration 171280: loss = 2.5673\n",
      "Iteration 171290: loss = 2.5060\n",
      "Iteration 171300: loss = 2.9620\n",
      "Iteration 171310: loss = 2.0728\n",
      "Iteration 171320: loss = 2.5028\n",
      "Iteration 171330: loss = 2.3762\n",
      "Iteration 171340: loss = 2.4143\n",
      "Iteration 171350: loss = 2.2293\n",
      "Iteration 171360: loss = 1.8516\n",
      "Iteration 171370: loss = 2.4970\n",
      "Iteration 171380: loss = 2.7152\n",
      "Iteration 171390: loss = 2.0680\n",
      "Iteration 171400: loss = 2.8438\n",
      "Iteration 171410: loss = 2.4622\n",
      "Iteration 171420: loss = 2.4030\n",
      "Iteration 171430: loss = 2.3670\n",
      "Iteration 171440: loss = 1.9420\n",
      "Iteration 171450: loss = 2.3647\n",
      "Iteration 171460: loss = 2.2678\n",
      "Iteration 171470: loss = 2.3645\n",
      "Iteration 171480: loss = 2.3891\n",
      "Iteration 171490: loss = 2.5820\n",
      "Iteration 171500: loss = 2.2342\n",
      "Iteration 171510: loss = 2.3545\n",
      "Iteration 171520: loss = 2.3192\n",
      "Iteration 171530: loss = 2.3117\n",
      "Iteration 171540: loss = 2.0757\n",
      "Iteration 171550: loss = 2.4922\n",
      "Iteration 171560: loss = 2.5195\n",
      "Iteration 171570: loss = 2.3344\n",
      "Iteration 171580: loss = 2.3503\n",
      "Iteration 171590: loss = 2.1225\n",
      "Iteration 171600: loss = 2.3398\n",
      "Iteration 171610: loss = 2.4999\n",
      "Iteration 171620: loss = 2.2531\n",
      "Iteration 171630: loss = 2.4335\n",
      "Iteration 171640: loss = 2.4369\n",
      "Iteration 171650: loss = 2.6560\n",
      "Iteration 171660: loss = 2.3606\n",
      "Iteration 171670: loss = 2.2311\n",
      "Iteration 171680: loss = 2.6494\n",
      "Iteration 171690: loss = 2.6802\n",
      "Iteration 171700: loss = 2.7556\n",
      "Iteration 171710: loss = 2.2382\n",
      "Iteration 171720: loss = 2.6969\n",
      "Iteration 171730: loss = 2.2176\n",
      "Iteration 171740: loss = 2.6651\n",
      "Iteration 171750: loss = 2.3848\n",
      "Iteration 171760: loss = 2.2360\n",
      "Iteration 171770: loss = 2.1804\n",
      "Iteration 171780: loss = 2.4024\n",
      "Iteration 171790: loss = 3.0496\n",
      "Iteration 171800: loss = 2.2754\n",
      "Iteration 171810: loss = 2.6204\n",
      "Iteration 171820: loss = 2.6969\n",
      "Iteration 171830: loss = 2.3082\n",
      "Iteration 171840: loss = 2.4676\n",
      "Iteration 171850: loss = 2.6115\n",
      "Iteration 171860: loss = 2.6816\n",
      "Iteration 171870: loss = 2.2915\n",
      "Iteration 171880: loss = 2.6430\n",
      "Iteration 171890: loss = 2.5589\n",
      "Iteration 171900: loss = 2.1681\n",
      "Iteration 171910: loss = 2.2846\n",
      "Iteration 171920: loss = 2.3451\n",
      "Iteration 171930: loss = 2.3414\n",
      "Iteration 171940: loss = 2.7655\n",
      "Iteration 171950: loss = 2.4852\n",
      "Iteration 171960: loss = 2.4539\n",
      "Iteration 171970: loss = 2.1568\n",
      "Iteration 171980: loss = 2.2502\n",
      "Iteration 171990: loss = 2.1893\n",
      "Iteration 172000: loss = 2.2406\n",
      "Iteration 172010: loss = 2.3551\n",
      "Iteration 172020: loss = 2.3446\n",
      "Iteration 172030: loss = 2.2709\n",
      "Iteration 172040: loss = 2.3493\n",
      "Iteration 172050: loss = 3.1111\n",
      "Iteration 172060: loss = 2.7249\n",
      "Iteration 172070: loss = 2.0713\n",
      "Iteration 172080: loss = 2.3653\n",
      "Iteration 172090: loss = 2.6800\n",
      "Iteration 172100: loss = 2.4591\n",
      "Iteration 172110: loss = 2.2127\n",
      "Iteration 172120: loss = 2.8431\n",
      "Iteration 172130: loss = 2.5449\n",
      "Iteration 172140: loss = 2.5167\n",
      "Iteration 172150: loss = 2.2477\n",
      "Iteration 172160: loss = 2.6323\n",
      "Iteration 172170: loss = 2.8736\n",
      "Iteration 172180: loss = 2.4416\n",
      "Iteration 172190: loss = 2.2894\n",
      "Iteration 172200: loss = 2.4006\n",
      "Iteration 172210: loss = 2.4599\n",
      "Iteration 172220: loss = 2.3362\n",
      "Iteration 172230: loss = 2.4101\n",
      "Iteration 172240: loss = 2.7631\n",
      "Iteration 172250: loss = 2.2462\n",
      "Iteration 172260: loss = 2.3679\n",
      "Iteration 172270: loss = 2.0180\n",
      "Iteration 172280: loss = 2.1672\n",
      "Iteration 172290: loss = 2.5573\n",
      "Iteration 172300: loss = 2.3763\n",
      "Iteration 172310: loss = 2.6078\n",
      "Iteration 172320: loss = 2.5117\n",
      "Iteration 172330: loss = 2.6706\n",
      "Iteration 172340: loss = 2.2957\n",
      "Iteration 172350: loss = 2.3795\n",
      "Iteration 172360: loss = 2.2048\n",
      "Iteration 172370: loss = 2.5298\n",
      "Iteration 172380: loss = 2.3667\n",
      "Iteration 172390: loss = 2.2555\n",
      "Iteration 172400: loss = 1.8618\n",
      "Iteration 172410: loss = 2.6133\n",
      "Iteration 172420: loss = 2.4732\n",
      "Iteration 172430: loss = 2.5068\n",
      "Iteration 172440: loss = 2.2462\n",
      "Iteration 172450: loss = 2.0349\n",
      "Iteration 172460: loss = 2.6864\n",
      "Iteration 172470: loss = 2.6062\n",
      "Iteration 172480: loss = 2.5284\n",
      "Iteration 172490: loss = 2.4781\n",
      "Iteration 172500: loss = 2.4983\n",
      "Iteration 172510: loss = 2.3836\n",
      "Iteration 172520: loss = 2.3366\n",
      "Iteration 172530: loss = 2.1881\n",
      "Iteration 172540: loss = 2.2276\n",
      "Iteration 172550: loss = 2.9002\n",
      "Iteration 172560: loss = 2.3392\n",
      "Iteration 172570: loss = 2.6330\n",
      "Iteration 172580: loss = 2.5697\n",
      "Iteration 172590: loss = 2.4976\n",
      "Iteration 172600: loss = 2.5736\n",
      "Iteration 172610: loss = 2.2804\n",
      "Iteration 172620: loss = 2.3996\n",
      "Iteration 172630: loss = 2.3291\n",
      "Iteration 172640: loss = 2.2979\n",
      "Iteration 172650: loss = 2.3550\n",
      "Iteration 172660: loss = 2.5725\n",
      "Iteration 172670: loss = 2.3307\n",
      "Iteration 172680: loss = 2.5396\n",
      "Iteration 172690: loss = 2.6252\n",
      "Iteration 172700: loss = 2.2134\n",
      "Iteration 172710: loss = 2.4807\n",
      "Iteration 172720: loss = 2.6557\n",
      "Iteration 172730: loss = 2.3360\n",
      "Iteration 172740: loss = 2.1657\n",
      "Iteration 172750: loss = 2.5494\n",
      "Iteration 172760: loss = 2.3941\n",
      "Iteration 172770: loss = 2.7068\n",
      "Iteration 172780: loss = 2.4840\n",
      "Iteration 172790: loss = 2.4447\n",
      "Iteration 172800: loss = 2.7389\n",
      "Iteration 172810: loss = 2.2337\n",
      "Iteration 172820: loss = 2.4224\n",
      "Iteration 172830: loss = 2.3150\n",
      "Iteration 172840: loss = 2.5615\n",
      "Iteration 172850: loss = 2.2419\n",
      "Iteration 172860: loss = 2.3400\n",
      "Iteration 172870: loss = 2.4215\n",
      "Iteration 172880: loss = 2.1283\n",
      "Iteration 172890: loss = 2.3891\n",
      "Iteration 172900: loss = 2.0601\n",
      "Iteration 172910: loss = 2.2219\n",
      "Iteration 172920: loss = 2.2407\n",
      "Iteration 172930: loss = 2.2176\n",
      "Iteration 172940: loss = 2.3284\n",
      "Iteration 172950: loss = 2.6449\n",
      "Iteration 172960: loss = 2.3448\n",
      "Iteration 172970: loss = 1.9906\n",
      "Iteration 172980: loss = 2.2088\n",
      "Iteration 172990: loss = 2.3765\n",
      "Iteration 173000: loss = 2.4983\n",
      "Iteration 173010: loss = 2.4144\n",
      "Iteration 173020: loss = 2.2271\n",
      "Iteration 173030: loss = 2.5799\n",
      "Iteration 173040: loss = 2.3085\n",
      "Iteration 173050: loss = 2.4040\n",
      "Iteration 173060: loss = 2.3420\n",
      "Iteration 173070: loss = 2.5255\n",
      "Iteration 173080: loss = 2.3281\n",
      "Iteration 173090: loss = 2.1650\n",
      "Iteration 173100: loss = 2.0957\n",
      "Iteration 173110: loss = 2.1262\n",
      "Iteration 173120: loss = 2.6581\n",
      "Iteration 173130: loss = 2.0491\n",
      "Iteration 173140: loss = 2.5740\n",
      "Iteration 173150: loss = 2.6864\n",
      "Iteration 173160: loss = 2.3840\n",
      "Iteration 173170: loss = 2.2739\n",
      "Iteration 173180: loss = 2.4659\n",
      "Iteration 173190: loss = 2.3743\n",
      "Iteration 173200: loss = 2.5110\n",
      "Iteration 173210: loss = 2.6363\n",
      "Iteration 173220: loss = 2.7976\n",
      "Iteration 173230: loss = 2.5358\n",
      "Iteration 173240: loss = 2.6900\n",
      "Iteration 173250: loss = 2.9666\n",
      "Iteration 173260: loss = 2.9339\n",
      "Iteration 173270: loss = 2.1033\n",
      "Iteration 173280: loss = 2.2119\n",
      "Iteration 173290: loss = 2.4325\n",
      "Iteration 173300: loss = 2.1280\n",
      "Iteration 173310: loss = 2.2535\n",
      "Iteration 173320: loss = 2.4502\n",
      "Iteration 173330: loss = 2.2154\n",
      "Iteration 173340: loss = 2.7032\n",
      "Iteration 173350: loss = 2.3011\n",
      "Iteration 173360: loss = 2.6834\n",
      "Iteration 173370: loss = 2.5498\n",
      "Iteration 173380: loss = 2.5205\n",
      "Iteration 173390: loss = 2.4071\n",
      "Iteration 173400: loss = 2.3357\n",
      "Iteration 173410: loss = 2.2522\n",
      "Iteration 173420: loss = 2.6356\n",
      "Iteration 173430: loss = 2.4682\n",
      "Iteration 173440: loss = 2.8163\n",
      "Iteration 173450: loss = 2.2092\n",
      "Iteration 173460: loss = 2.0736\n",
      "Iteration 173470: loss = 2.5416\n",
      "Iteration 173480: loss = 2.6608\n",
      "Iteration 173490: loss = 2.4931\n",
      "Iteration 173500: loss = 1.8554\n",
      "Iteration 173510: loss = 2.3145\n",
      "Iteration 173520: loss = 2.4004\n",
      "Iteration 173530: loss = 2.4758\n",
      "Iteration 173540: loss = 2.2868\n",
      "Iteration 173550: loss = 2.2084\n",
      "Iteration 173560: loss = 2.2177\n",
      "Iteration 173570: loss = 2.6972\n",
      "Iteration 173580: loss = 2.4328\n",
      "Iteration 173590: loss = 2.8592\n",
      "Iteration 173600: loss = 2.6847\n",
      "Iteration 173610: loss = 2.7807\n",
      "Iteration 173620: loss = 2.5299\n",
      "Iteration 173630: loss = 2.1957\n",
      "Iteration 173640: loss = 2.3190\n",
      "Iteration 173650: loss = 2.3560\n",
      "Iteration 173660: loss = 2.4858\n",
      "Iteration 173670: loss = 2.4877\n",
      "Iteration 173680: loss = 2.7172\n",
      "Iteration 173690: loss = 2.6173\n",
      "Iteration 173700: loss = 2.4282\n",
      "Iteration 173710: loss = 2.3614\n",
      "Iteration 173720: loss = 2.2773\n",
      "Iteration 173730: loss = 2.7155\n",
      "Iteration 173740: loss = 2.2593\n",
      "Iteration 173750: loss = 2.0696\n",
      "Iteration 173760: loss = 2.2774\n",
      "Iteration 173770: loss = 2.4577\n",
      "Iteration 173780: loss = 2.2677\n",
      "Iteration 173790: loss = 2.3556\n",
      "Iteration 173800: loss = 2.3650\n",
      "Iteration 173810: loss = 2.1495\n",
      "Iteration 173820: loss = 2.4193\n",
      "Iteration 173830: loss = 2.2301\n",
      "Iteration 173840: loss = 2.2641\n",
      "Iteration 173850: loss = 2.5919\n",
      "Iteration 173860: loss = 2.4202\n",
      "Iteration 173870: loss = 2.4588\n",
      "Iteration 173880: loss = 2.0374\n",
      "Iteration 173890: loss = 1.9651\n",
      "Iteration 173900: loss = 2.7231\n",
      "Iteration 173910: loss = 2.5345\n",
      "Iteration 173920: loss = 2.0190\n",
      "Iteration 173930: loss = 2.5710\n",
      "Iteration 173940: loss = 2.2421\n",
      "Iteration 173950: loss = 1.9913\n",
      "Iteration 173960: loss = 2.2554\n",
      "Iteration 173970: loss = 2.5928\n",
      "Iteration 173980: loss = 2.4102\n",
      "Iteration 173990: loss = 2.7500\n",
      "Iteration 174000: loss = 2.1065\n",
      "Iteration 174010: loss = 2.3422\n",
      "Iteration 174020: loss = 2.2540\n",
      "Iteration 174030: loss = 1.9941\n",
      "Iteration 174040: loss = 2.0932\n",
      "Iteration 174050: loss = 2.5138\n",
      "Iteration 174060: loss = 2.8269\n",
      "Iteration 174070: loss = 2.3872\n",
      "Iteration 174080: loss = 2.3054\n",
      "Iteration 174090: loss = 2.3332\n",
      "Iteration 174100: loss = 2.3621\n",
      "Iteration 174110: loss = 2.3830\n",
      "Iteration 174120: loss = 2.4161\n",
      "Iteration 174130: loss = 2.5086\n",
      "Iteration 174140: loss = 2.2232\n",
      "Iteration 174150: loss = 2.2705\n",
      "Iteration 174160: loss = 2.2270\n",
      "Iteration 174170: loss = 2.4878\n",
      "Iteration 174180: loss = 2.6184\n",
      "Iteration 174190: loss = 2.2492\n",
      "Iteration 174200: loss = 2.4309\n",
      "Iteration 174210: loss = 2.7527\n",
      "Iteration 174220: loss = 2.1132\n",
      "Iteration 174230: loss = 2.6464\n",
      "Iteration 174240: loss = 2.7867\n",
      "Iteration 174250: loss = 2.6275\n",
      "Iteration 174260: loss = 2.1742\n",
      "Iteration 174270: loss = 2.5063\n",
      "Iteration 174280: loss = 2.4501\n",
      "Iteration 174290: loss = 2.5376\n",
      "Iteration 174300: loss = 2.4949\n",
      "Iteration 174310: loss = 2.1897\n",
      "Iteration 174320: loss = 2.4042\n",
      "Iteration 174330: loss = 2.3388\n",
      "Iteration 174340: loss = 2.5227\n",
      "Iteration 174350: loss = 2.3266\n",
      "Iteration 174360: loss = 2.1276\n",
      "Iteration 174370: loss = 2.5221\n",
      "Iteration 174380: loss = 2.4198\n",
      "Iteration 174390: loss = 2.3996\n",
      "Iteration 174400: loss = 2.1255\n",
      "Iteration 174410: loss = 2.4960\n",
      "Iteration 174420: loss = 2.3139\n",
      "Iteration 174430: loss = 2.6579\n",
      "Iteration 174440: loss = 2.3525\n",
      "Iteration 174450: loss = 2.4619\n",
      "Iteration 174460: loss = 2.2052\n",
      "Iteration 174470: loss = 2.7000\n",
      "Iteration 174480: loss = 2.3457\n",
      "Iteration 174490: loss = 2.1565\n",
      "Iteration 174500: loss = 2.2750\n",
      "Iteration 174510: loss = 2.4345\n",
      "Iteration 174520: loss = 2.5186\n",
      "Iteration 174530: loss = 2.7140\n",
      "Iteration 174540: loss = 2.7234\n",
      "Iteration 174550: loss = 2.3265\n",
      "Iteration 174560: loss = 2.3043\n",
      "Iteration 174570: loss = 2.3179\n",
      "Iteration 174580: loss = 2.1139\n",
      "Iteration 174590: loss = 2.4337\n",
      "Iteration 174600: loss = 2.1886\n",
      "Iteration 174610: loss = 2.3820\n",
      "Iteration 174620: loss = 2.2232\n",
      "Iteration 174630: loss = 2.2555\n",
      "Iteration 174640: loss = 2.9061\n",
      "Iteration 174650: loss = 2.3125\n",
      "Iteration 174660: loss = 2.3558\n",
      "Iteration 174670: loss = 2.0488\n",
      "Iteration 174680: loss = 2.2915\n",
      "Iteration 174690: loss = 2.5768\n",
      "Iteration 174700: loss = 2.2022\n",
      "Iteration 174710: loss = 2.0838\n",
      "Iteration 174720: loss = 2.8703\n",
      "Iteration 174730: loss = 2.5648\n",
      "Iteration 174740: loss = 2.4409\n",
      "Iteration 174750: loss = 2.5026\n",
      "Iteration 174760: loss = 2.3739\n",
      "Iteration 174770: loss = 1.9208\n",
      "Iteration 174780: loss = 2.3322\n",
      "Iteration 174790: loss = 2.7642\n",
      "Iteration 174800: loss = 2.3583\n",
      "Iteration 174810: loss = 2.5807\n",
      "Iteration 174820: loss = 2.2973\n",
      "Iteration 174830: loss = 2.1127\n",
      "Iteration 174840: loss = 2.6665\n",
      "Iteration 174850: loss = 2.5097\n",
      "Iteration 174860: loss = 2.4422\n",
      "Iteration 174870: loss = 2.4354\n",
      "Iteration 174880: loss = 2.4620\n",
      "Iteration 174890: loss = 2.4133\n",
      "Iteration 174900: loss = 2.2980\n",
      "Iteration 174910: loss = 2.9380\n",
      "Iteration 174920: loss = 2.7485\n",
      "Iteration 174930: loss = 2.8297\n",
      "Iteration 174940: loss = 2.3726\n",
      "Iteration 174950: loss = 2.8067\n",
      "Iteration 174960: loss = 2.1788\n",
      "Iteration 174970: loss = 2.2476\n",
      "Iteration 174980: loss = 2.4647\n",
      "Iteration 174990: loss = 2.2956\n",
      "Iteration 175000: loss = 2.4092\n",
      "Iteration 175010: loss = 2.1229\n",
      "Iteration 175020: loss = 2.4123\n",
      "Iteration 175030: loss = 2.3862\n",
      "Iteration 175040: loss = 2.0155\n",
      "Iteration 175050: loss = 2.5734\n",
      "Iteration 175060: loss = 2.2387\n",
      "Iteration 175070: loss = 2.4806\n",
      "Iteration 175080: loss = 2.3871\n",
      "Iteration 175090: loss = 2.8220\n",
      "Iteration 175100: loss = 2.5240\n",
      "Iteration 175110: loss = 2.5094\n",
      "Iteration 175120: loss = 1.9156\n",
      "Iteration 175130: loss = 2.2116\n",
      "Iteration 175140: loss = 2.4583\n",
      "Iteration 175150: loss = 2.4355\n",
      "Iteration 175160: loss = 1.8730\n",
      "Iteration 175170: loss = 2.0529\n",
      "Iteration 175180: loss = 2.2038\n",
      "Iteration 175190: loss = 2.3354\n",
      "Iteration 175200: loss = 2.6642\n",
      "Iteration 175210: loss = 2.6332\n",
      "Iteration 175220: loss = 2.4418\n",
      "Iteration 175230: loss = 2.3640\n",
      "Iteration 175240: loss = 2.6776\n",
      "Iteration 175250: loss = 2.2675\n",
      "Iteration 175260: loss = 2.3308\n",
      "Iteration 175270: loss = 2.6792\n",
      "Iteration 175280: loss = 2.6622\n",
      "Iteration 175290: loss = 2.1352\n",
      "Iteration 175300: loss = 2.5001\n",
      "Iteration 175310: loss = 2.1453\n",
      "Iteration 175320: loss = 1.9597\n",
      "Iteration 175330: loss = 2.2972\n",
      "Iteration 175340: loss = 2.1747\n",
      "Iteration 175350: loss = 2.6691\n",
      "Iteration 175360: loss = 2.8160\n",
      "Iteration 175370: loss = 2.1498\n",
      "Iteration 175380: loss = 2.9518\n",
      "Iteration 175390: loss = 2.2822\n",
      "Iteration 175400: loss = 2.4147\n",
      "Iteration 175410: loss = 2.4710\n",
      "Iteration 175420: loss = 2.3425\n",
      "Iteration 175430: loss = 2.0569\n",
      "Iteration 175440: loss = 2.1641\n",
      "Iteration 175450: loss = 2.1668\n",
      "Iteration 175460: loss = 2.7010\n",
      "Iteration 175470: loss = 2.3335\n",
      "Iteration 175480: loss = 2.0715\n",
      "Iteration 175490: loss = 2.3530\n",
      "Iteration 175500: loss = 2.2216\n",
      "Iteration 175510: loss = 2.5729\n",
      "Iteration 175520: loss = 2.1181\n",
      "Iteration 175530: loss = 2.6560\n",
      "Iteration 175540: loss = 2.5464\n",
      "Iteration 175550: loss = 2.3081\n",
      "Iteration 175560: loss = 2.5654\n",
      "Iteration 175570: loss = 2.2699\n",
      "Iteration 175580: loss = 2.5817\n",
      "Iteration 175590: loss = 2.1766\n",
      "Iteration 175600: loss = 2.2934\n",
      "Iteration 175610: loss = 2.2753\n",
      "Iteration 175620: loss = 2.5867\n",
      "Iteration 175630: loss = 2.4257\n",
      "Iteration 175640: loss = 2.2932\n",
      "Iteration 175650: loss = 2.2897\n",
      "Iteration 175660: loss = 2.5560\n",
      "Iteration 175670: loss = 2.3344\n",
      "Iteration 175680: loss = 1.9697\n",
      "Iteration 175690: loss = 2.3309\n",
      "Iteration 175700: loss = 2.4576\n",
      "Iteration 175710: loss = 2.8000\n",
      "Iteration 175720: loss = 2.1619\n",
      "Iteration 175730: loss = 2.7269\n",
      "Iteration 175740: loss = 2.3062\n",
      "Iteration 175750: loss = 2.6351\n",
      "Iteration 175760: loss = 2.3035\n",
      "Iteration 175770: loss = 2.2855\n",
      "Iteration 175780: loss = 2.4662\n",
      "Iteration 175790: loss = 2.2010\n",
      "Iteration 175800: loss = 2.5086\n",
      "Iteration 175810: loss = 2.5772\n",
      "Iteration 175820: loss = 2.1606\n",
      "Iteration 175830: loss = 2.1290\n",
      "Iteration 175840: loss = 2.1649\n",
      "Iteration 175850: loss = 2.5352\n",
      "Iteration 175860: loss = 2.1913\n",
      "Iteration 175870: loss = 2.1985\n",
      "Iteration 175880: loss = 2.2528\n",
      "Iteration 175890: loss = 2.2937\n",
      "Iteration 175900: loss = 2.5042\n",
      "Iteration 175910: loss = 2.4090\n",
      "Iteration 175920: loss = 2.1909\n",
      "Iteration 175930: loss = 2.2359\n",
      "Iteration 175940: loss = 2.4773\n",
      "Iteration 175950: loss = 2.6669\n",
      "Iteration 175960: loss = 2.0082\n",
      "Iteration 175970: loss = 2.4089\n",
      "Iteration 175980: loss = 2.4415\n",
      "Iteration 175990: loss = 2.2792\n",
      "Iteration 176000: loss = 2.7852\n",
      "Iteration 176010: loss = 2.6982\n",
      "Iteration 176020: loss = 2.2967\n",
      "Iteration 176030: loss = 2.5201\n",
      "Iteration 176040: loss = 2.1795\n",
      "Iteration 176050: loss = 2.5234\n",
      "Iteration 176060: loss = 2.1852\n",
      "Iteration 176070: loss = 2.7869\n",
      "Iteration 176080: loss = 2.4447\n",
      "Iteration 176090: loss = 2.6236\n",
      "Iteration 176100: loss = 2.1704\n",
      "Iteration 176110: loss = 2.4272\n",
      "Iteration 176120: loss = 2.3910\n",
      "Iteration 176130: loss = 2.4693\n",
      "Iteration 176140: loss = 2.9415\n",
      "Iteration 176150: loss = 2.4690\n",
      "Iteration 176160: loss = 2.4999\n",
      "Iteration 176170: loss = 2.6881\n",
      "Iteration 176180: loss = 2.4107\n",
      "Iteration 176190: loss = 2.6597\n",
      "Iteration 176200: loss = 2.2665\n",
      "Iteration 176210: loss = 2.2329\n",
      "Iteration 176220: loss = 2.6782\n",
      "Iteration 176230: loss = 2.5757\n",
      "Iteration 176240: loss = 2.1932\n",
      "Iteration 176250: loss = 2.4086\n",
      "Iteration 176260: loss = 2.1942\n",
      "Iteration 176270: loss = 2.4026\n",
      "Iteration 176280: loss = 2.6283\n",
      "Iteration 176290: loss = 2.4506\n",
      "Iteration 176300: loss = 2.4652\n",
      "Iteration 176310: loss = 2.3723\n",
      "Iteration 176320: loss = 2.5313\n",
      "Iteration 176330: loss = 2.3960\n",
      "Iteration 176340: loss = 2.4941\n",
      "Iteration 176350: loss = 2.4550\n",
      "Iteration 176360: loss = 2.7255\n",
      "Iteration 176370: loss = 2.9148\n",
      "Iteration 176380: loss = 2.2250\n",
      "Iteration 176390: loss = 2.5522\n",
      "Iteration 176400: loss = 2.8158\n",
      "Iteration 176410: loss = 2.4090\n",
      "Iteration 176420: loss = 2.3016\n",
      "Iteration 176430: loss = 2.3240\n",
      "Iteration 176440: loss = 2.6760\n",
      "Iteration 176450: loss = 2.3516\n",
      "Iteration 176460: loss = 2.3290\n",
      "Iteration 176470: loss = 2.3026\n",
      "Iteration 176480: loss = 2.5162\n",
      "Iteration 176490: loss = 2.0222\n",
      "Iteration 176500: loss = 2.5835\n",
      "Iteration 176510: loss = 2.6943\n",
      "Iteration 176520: loss = 2.2984\n",
      "Iteration 176530: loss = 2.7929\n",
      "Iteration 176540: loss = 2.2874\n",
      "Iteration 176550: loss = 2.0987\n",
      "Iteration 176560: loss = 2.5112\n",
      "Iteration 176570: loss = 2.2621\n",
      "Iteration 176580: loss = 2.3264\n",
      "Iteration 176590: loss = 2.5867\n",
      "Iteration 176600: loss = 2.3408\n",
      "Iteration 176610: loss = 2.4446\n",
      "Iteration 176620: loss = 2.4582\n",
      "Iteration 176630: loss = 2.2146\n",
      "Iteration 176640: loss = 2.6981\n",
      "Iteration 176650: loss = 2.3486\n",
      "Iteration 176660: loss = 2.5504\n",
      "Iteration 176670: loss = 2.2375\n",
      "Iteration 176680: loss = 2.5668\n",
      "Iteration 176690: loss = 2.3847\n",
      "Iteration 176700: loss = 2.6831\n",
      "Iteration 176710: loss = 2.5992\n",
      "Iteration 176720: loss = 2.6199\n",
      "Iteration 176730: loss = 2.5590\n",
      "Iteration 176740: loss = 2.2836\n",
      "Iteration 176750: loss = 2.1761\n",
      "Iteration 176760: loss = 2.2570\n",
      "Iteration 176770: loss = 2.6237\n",
      "Iteration 176780: loss = 2.8297\n",
      "Iteration 176790: loss = 3.0160\n",
      "Iteration 176800: loss = 2.4247\n",
      "Iteration 176810: loss = 2.1943\n",
      "Iteration 176820: loss = 2.3970\n",
      "Iteration 176830: loss = 2.4592\n",
      "Iteration 176840: loss = 2.6366\n",
      "Iteration 176850: loss = 2.6033\n",
      "Iteration 176860: loss = 2.4233\n",
      "Iteration 176870: loss = 2.4690\n",
      "Iteration 176880: loss = 2.3880\n",
      "Iteration 176890: loss = 2.6828\n",
      "Iteration 176900: loss = 2.2731\n",
      "Iteration 176910: loss = 2.4165\n",
      "Iteration 176920: loss = 2.4433\n",
      "Iteration 176930: loss = 2.3146\n",
      "Iteration 176940: loss = 2.4870\n",
      "Iteration 176950: loss = 2.4675\n",
      "Iteration 176960: loss = 2.3048\n",
      "Iteration 176970: loss = 2.6208\n",
      "Iteration 176980: loss = 2.5187\n",
      "Iteration 176990: loss = 2.6652\n",
      "Iteration 177000: loss = 2.6408\n",
      "Iteration 177010: loss = 2.2654\n",
      "Iteration 177020: loss = 2.2904\n",
      "Iteration 177030: loss = 2.3282\n",
      "Iteration 177040: loss = 2.0302\n",
      "Iteration 177050: loss = 2.5423\n",
      "Iteration 177060: loss = 2.0294\n",
      "Iteration 177070: loss = 2.0669\n",
      "Iteration 177080: loss = 2.2686\n",
      "Iteration 177090: loss = 2.1984\n",
      "Iteration 177100: loss = 2.6954\n",
      "Iteration 177110: loss = 2.6622\n",
      "Iteration 177120: loss = 2.4606\n",
      "Iteration 177130: loss = 2.5182\n",
      "Iteration 177140: loss = 1.9484\n",
      "Iteration 177150: loss = 2.5518\n",
      "Iteration 177160: loss = 2.5319\n",
      "Iteration 177170: loss = 2.0594\n",
      "Iteration 177180: loss = 2.3022\n",
      "Iteration 177190: loss = 2.3425\n",
      "Iteration 177200: loss = 2.3605\n",
      "Iteration 177210: loss = 2.6347\n",
      "Iteration 177220: loss = 2.9217\n",
      "Iteration 177230: loss = 2.5962\n",
      "Iteration 177240: loss = 2.2895\n",
      "Iteration 177250: loss = 1.9160\n",
      "Iteration 177260: loss = 2.3398\n",
      "Iteration 177270: loss = 2.2832\n",
      "Iteration 177280: loss = 2.3605\n",
      "Iteration 177290: loss = 2.5004\n",
      "Iteration 177300: loss = 2.1916\n",
      "Iteration 177310: loss = 1.9452\n",
      "Iteration 177320: loss = 2.6331\n",
      "Iteration 177330: loss = 2.3420\n",
      "Iteration 177340: loss = 2.2257\n",
      "Iteration 177350: loss = 2.5636\n",
      "Iteration 177360: loss = 2.9594\n",
      "Iteration 177370: loss = 2.5716\n",
      "Iteration 177380: loss = 2.5357\n",
      "Iteration 177390: loss = 2.5571\n",
      "Iteration 177400: loss = 2.5159\n",
      "Iteration 177410: loss = 2.5394\n",
      "Iteration 177420: loss = 2.2227\n",
      "Iteration 177430: loss = 2.7374\n",
      "Iteration 177440: loss = 2.5136\n",
      "Iteration 177450: loss = 2.2104\n",
      "Iteration 177460: loss = 2.2314\n",
      "Iteration 177470: loss = 2.4585\n",
      "Iteration 177480: loss = 2.2656\n",
      "Iteration 177490: loss = 2.4476\n",
      "Iteration 177500: loss = 2.6429\n",
      "Iteration 177510: loss = 2.3703\n",
      "Iteration 177520: loss = 2.6508\n",
      "Iteration 177530: loss = 2.6202\n",
      "Iteration 177540: loss = 2.2051\n",
      "Iteration 177550: loss = 2.4502\n",
      "Iteration 177560: loss = 2.4579\n",
      "Iteration 177570: loss = 2.4215\n",
      "Iteration 177580: loss = 2.2978\n",
      "Iteration 177590: loss = 2.7343\n",
      "Iteration 177600: loss = 2.4750\n",
      "Iteration 177610: loss = 2.4640\n",
      "Iteration 177620: loss = 2.2932\n",
      "Iteration 177630: loss = 2.1326\n",
      "Iteration 177640: loss = 2.5401\n",
      "Iteration 177650: loss = 2.1164\n",
      "Iteration 177660: loss = 2.1515\n",
      "Iteration 177670: loss = 2.7549\n",
      "Iteration 177680: loss = 2.6233\n",
      "Iteration 177690: loss = 2.3686\n",
      "Iteration 177700: loss = 2.5183\n",
      "Iteration 177710: loss = 2.3014\n",
      "Iteration 177720: loss = 2.2321\n",
      "Iteration 177730: loss = 2.3298\n",
      "Iteration 177740: loss = 2.3235\n",
      "Iteration 177750: loss = 2.2295\n",
      "Iteration 177760: loss = 2.7370\n",
      "Iteration 177770: loss = 2.3067\n",
      "Iteration 177780: loss = 2.2708\n",
      "Iteration 177790: loss = 2.7063\n",
      "Iteration 177800: loss = 2.2438\n",
      "Iteration 177810: loss = 2.4629\n",
      "Iteration 177820: loss = 2.3761\n",
      "Iteration 177830: loss = 2.6448\n",
      "Iteration 177840: loss = 2.5249\n",
      "Iteration 177850: loss = 2.6477\n",
      "Iteration 177860: loss = 2.3808\n",
      "Iteration 177870: loss = 2.2246\n",
      "Iteration 177880: loss = 2.3664\n",
      "Iteration 177890: loss = 2.4235\n",
      "Iteration 177900: loss = 2.3583\n",
      "Iteration 177910: loss = 2.4184\n",
      "Iteration 177920: loss = 2.3677\n",
      "Iteration 177930: loss = 2.3164\n",
      "Iteration 177940: loss = 2.2422\n",
      "Iteration 177950: loss = 2.4127\n",
      "Iteration 177960: loss = 2.7290\n",
      "Iteration 177970: loss = 2.3479\n",
      "Iteration 177980: loss = 2.1121\n",
      "Iteration 177990: loss = 2.3437\n",
      "Iteration 178000: loss = 2.9769\n",
      "Iteration 178010: loss = 2.5257\n",
      "Iteration 178020: loss = 2.2757\n",
      "Iteration 178030: loss = 2.6365\n",
      "Iteration 178040: loss = 2.3446\n",
      "Iteration 178050: loss = 2.4880\n",
      "Iteration 178060: loss = 2.4182\n",
      "Iteration 178070: loss = 2.3317\n",
      "Iteration 178080: loss = 2.4085\n",
      "Iteration 178090: loss = 2.4336\n",
      "Iteration 178100: loss = 2.4716\n",
      "Iteration 178110: loss = 2.2952\n",
      "Iteration 178120: loss = 2.4110\n",
      "Iteration 178130: loss = 2.1433\n",
      "Iteration 178140: loss = 2.4113\n",
      "Iteration 178150: loss = 1.9366\n",
      "Iteration 178160: loss = 2.6783\n",
      "Iteration 178170: loss = 2.5355\n",
      "Iteration 178180: loss = 2.4839\n",
      "Iteration 178190: loss = 2.4002\n",
      "Iteration 178200: loss = 2.4290\n",
      "Iteration 178210: loss = 2.0451\n",
      "Iteration 178220: loss = 2.6058\n",
      "Iteration 178230: loss = 2.7295\n",
      "Iteration 178240: loss = 2.5547\n",
      "Iteration 178250: loss = 2.1357\n",
      "Iteration 178260: loss = 2.3580\n",
      "Iteration 178270: loss = 2.1727\n",
      "Iteration 178280: loss = 2.2816\n",
      "Iteration 178290: loss = 2.5812\n",
      "Iteration 178300: loss = 2.2374\n",
      "Iteration 178310: loss = 2.4126\n",
      "Iteration 178320: loss = 2.4881\n",
      "Iteration 178330: loss = 2.2068\n",
      "Iteration 178340: loss = 2.6751\n",
      "Iteration 178350: loss = 2.6097\n",
      "Iteration 178360: loss = 2.5153\n",
      "Iteration 178370: loss = 2.2129\n",
      "Iteration 178380: loss = 2.3767\n",
      "Iteration 178390: loss = 2.0501\n",
      "Iteration 178400: loss = 2.4474\n",
      "Iteration 178410: loss = 2.6347\n",
      "Iteration 178420: loss = 2.3404\n",
      "Iteration 178430: loss = 2.1963\n",
      "Iteration 178440: loss = 2.2371\n",
      "Iteration 178450: loss = 2.0986\n",
      "Iteration 178460: loss = 2.2537\n",
      "Iteration 178470: loss = 2.0623\n",
      "Iteration 178480: loss = 2.5135\n",
      "Iteration 178490: loss = 2.1690\n",
      "Iteration 178500: loss = 2.3357\n",
      "Iteration 178510: loss = 2.8536\n",
      "Iteration 178520: loss = 2.7587\n",
      "Iteration 178530: loss = 2.0385\n",
      "Iteration 178540: loss = 2.6883\n",
      "Iteration 178550: loss = 2.4912\n",
      "Iteration 178560: loss = 2.2111\n",
      "Iteration 178570: loss = 2.4626\n",
      "Iteration 178580: loss = 2.4577\n",
      "Iteration 178590: loss = 2.5068\n",
      "Iteration 178600: loss = 2.3396\n",
      "Iteration 178610: loss = 2.4264\n",
      "Iteration 178620: loss = 2.3448\n",
      "Iteration 178630: loss = 2.4087\n",
      "Iteration 178640: loss = 2.4548\n",
      "Iteration 178650: loss = 2.4576\n",
      "Iteration 178660: loss = 2.6470\n",
      "Iteration 178670: loss = 2.7127\n",
      "Iteration 178680: loss = 2.5524\n",
      "Iteration 178690: loss = 2.7578\n",
      "Iteration 178700: loss = 2.3429\n",
      "Iteration 178710: loss = 2.5644\n",
      "Iteration 178720: loss = 2.2806\n",
      "Iteration 178730: loss = 2.7698\n",
      "Iteration 178740: loss = 2.6111\n",
      "Iteration 178750: loss = 2.4191\n",
      "Iteration 178760: loss = 2.7816\n",
      "Iteration 178770: loss = 2.2609\n",
      "Iteration 178780: loss = 2.4303\n",
      "Iteration 178790: loss = 1.9285\n",
      "Iteration 178800: loss = 2.7327\n",
      "Iteration 178810: loss = 2.5895\n",
      "Iteration 178820: loss = 2.5049\n",
      "Iteration 178830: loss = 2.2206\n",
      "Iteration 178840: loss = 2.1045\n",
      "Iteration 178850: loss = 2.0916\n",
      "Iteration 178860: loss = 2.4157\n",
      "Iteration 178870: loss = 2.3668\n",
      "Iteration 178880: loss = 2.5954\n",
      "Iteration 178890: loss = 2.7908\n",
      "Iteration 178900: loss = 2.3274\n",
      "Iteration 178910: loss = 2.9034\n",
      "Iteration 178920: loss = 2.4175\n",
      "Iteration 178930: loss = 2.0300\n",
      "Iteration 178940: loss = 1.9081\n",
      "Iteration 178950: loss = 2.5970\n",
      "Iteration 178960: loss = 2.2997\n",
      "Iteration 178970: loss = 2.5382\n",
      "Iteration 178980: loss = 2.3283\n",
      "Iteration 178990: loss = 2.7270\n",
      "Iteration 179000: loss = 2.1576\n",
      "Iteration 179010: loss = 2.4685\n",
      "Iteration 179020: loss = 2.4204\n",
      "Iteration 179030: loss = 1.9656\n",
      "Iteration 179040: loss = 2.1277\n",
      "Iteration 179050: loss = 2.5598\n",
      "Iteration 179060: loss = 2.4447\n",
      "Iteration 179070: loss = 2.4950\n",
      "Iteration 179080: loss = 2.5414\n",
      "Iteration 179090: loss = 2.5089\n",
      "Iteration 179100: loss = 2.3780\n",
      "Iteration 179110: loss = 2.1707\n",
      "Iteration 179120: loss = 2.1961\n",
      "Iteration 179130: loss = 2.6781\n",
      "Iteration 179140: loss = 2.3410\n",
      "Iteration 179150: loss = 2.3837\n",
      "Iteration 179160: loss = 2.2469\n",
      "Iteration 179170: loss = 2.2069\n",
      "Iteration 179180: loss = 2.5304\n",
      "Iteration 179190: loss = 2.4361\n",
      "Iteration 179200: loss = 2.6079\n",
      "Iteration 179210: loss = 2.2479\n",
      "Iteration 179220: loss = 2.3034\n",
      "Iteration 179230: loss = 2.5182\n",
      "Iteration 179240: loss = 2.1236\n",
      "Iteration 179250: loss = 2.2643\n",
      "Iteration 179260: loss = 2.6970\n",
      "Iteration 179270: loss = 2.2572\n",
      "Iteration 179280: loss = 2.0251\n",
      "Iteration 179290: loss = 2.1725\n",
      "Iteration 179300: loss = 2.3140\n",
      "Iteration 179310: loss = 2.0049\n",
      "Iteration 179320: loss = 2.4066\n",
      "Iteration 179330: loss = 2.5523\n",
      "Iteration 179340: loss = 2.5444\n",
      "Iteration 179350: loss = 2.6396\n",
      "Iteration 179360: loss = 2.4371\n",
      "Iteration 179370: loss = 2.1659\n",
      "Iteration 179380: loss = 2.3680\n",
      "Iteration 179390: loss = 2.2171\n",
      "Iteration 179400: loss = 2.0566\n",
      "Iteration 179410: loss = 2.6371\n",
      "Iteration 179420: loss = 2.3124\n",
      "Iteration 179430: loss = 2.3532\n",
      "Iteration 179440: loss = 2.1950\n",
      "Iteration 179450: loss = 2.5664\n",
      "Iteration 179460: loss = 2.1378\n",
      "Iteration 179470: loss = 2.5112\n",
      "Iteration 179480: loss = 2.0705\n",
      "Iteration 179490: loss = 2.7882\n",
      "Iteration 179500: loss = 2.8567\n",
      "Iteration 179510: loss = 2.3573\n",
      "Iteration 179520: loss = 2.6239\n",
      "Iteration 179530: loss = 2.0416\n",
      "Iteration 179540: loss = 2.3687\n",
      "Iteration 179550: loss = 2.6754\n",
      "Iteration 179560: loss = 2.5958\n",
      "Iteration 179570: loss = 2.2536\n",
      "Iteration 179580: loss = 2.5144\n",
      "Iteration 179590: loss = 2.3384\n",
      "Iteration 179600: loss = 2.2527\n",
      "Iteration 179610: loss = 2.4539\n",
      "Iteration 179620: loss = 2.4628\n",
      "Iteration 179630: loss = 2.2787\n",
      "Iteration 179640: loss = 2.5889\n",
      "Iteration 179650: loss = 2.0657\n",
      "Iteration 179660: loss = 2.4541\n",
      "Iteration 179670: loss = 2.4586\n",
      "Iteration 179680: loss = 3.0218\n",
      "Iteration 179690: loss = 2.3462\n",
      "Iteration 179700: loss = 2.0035\n",
      "Iteration 179710: loss = 2.4360\n",
      "Iteration 179720: loss = 2.2504\n",
      "Iteration 179730: loss = 2.6667\n",
      "Iteration 179740: loss = 2.2227\n",
      "Iteration 179750: loss = 2.3935\n",
      "Iteration 179760: loss = 2.6826\n",
      "Iteration 179770: loss = 2.0675\n",
      "Iteration 179780: loss = 2.0962\n",
      "Iteration 179790: loss = 2.2271\n",
      "Iteration 179800: loss = 2.4190\n",
      "Iteration 179810: loss = 2.3399\n",
      "Iteration 179820: loss = 2.3293\n",
      "Iteration 179830: loss = 2.6102\n",
      "Iteration 179840: loss = 2.6321\n",
      "Iteration 179850: loss = 2.3476\n",
      "Iteration 179860: loss = 2.4636\n",
      "Iteration 179870: loss = 2.3466\n",
      "Iteration 179880: loss = 2.0562\n",
      "Iteration 179890: loss = 2.3531\n",
      "Iteration 179900: loss = 2.1606\n",
      "Iteration 179910: loss = 2.5979\n",
      "Iteration 179920: loss = 2.5341\n",
      "Iteration 179930: loss = 2.6546\n",
      "Iteration 179940: loss = 2.3299\n",
      "Iteration 179950: loss = 2.9203\n",
      "Iteration 179960: loss = 2.2389\n",
      "Iteration 179970: loss = 2.0197\n",
      "Iteration 179980: loss = 2.5277\n",
      "Iteration 179990: loss = 2.7111\n",
      "Iteration 180000: loss = 2.6684\n",
      "Iteration 180010: loss = 3.1244\n",
      "Iteration 180020: loss = 2.3088\n",
      "Iteration 180030: loss = 2.6493\n",
      "Iteration 180040: loss = 2.5213\n",
      "Iteration 180050: loss = 2.3944\n",
      "Iteration 180060: loss = 2.4589\n",
      "Iteration 180070: loss = 2.1501\n",
      "Iteration 180080: loss = 2.3503\n",
      "Iteration 180090: loss = 2.3614\n",
      "Iteration 180100: loss = 2.2272\n",
      "Iteration 180110: loss = 2.5916\n",
      "Iteration 180120: loss = 2.3905\n",
      "Iteration 180130: loss = 2.5362\n",
      "Iteration 180140: loss = 2.4772\n",
      "Iteration 180150: loss = 2.6374\n",
      "Iteration 180160: loss = 2.2985\n",
      "Iteration 180170: loss = 2.2490\n",
      "Iteration 180180: loss = 2.2617\n",
      "Iteration 180190: loss = 2.3975\n",
      "Iteration 180200: loss = 2.4606\n",
      "Iteration 180210: loss = 2.2511\n",
      "Iteration 180220: loss = 2.6246\n",
      "Iteration 180230: loss = 2.3752\n",
      "Iteration 180240: loss = 2.4511\n",
      "Iteration 180250: loss = 2.6817\n",
      "Iteration 180260: loss = 2.5821\n",
      "Iteration 180270: loss = 2.9927\n",
      "Iteration 180280: loss = 2.0776\n",
      "Iteration 180290: loss = 2.4497\n",
      "Iteration 180300: loss = 2.6162\n",
      "Iteration 180310: loss = 2.2612\n",
      "Iteration 180320: loss = 2.3456\n",
      "Iteration 180330: loss = 2.6055\n",
      "Iteration 180340: loss = 2.6853\n",
      "Iteration 180350: loss = 2.4474\n",
      "Iteration 180360: loss = 2.4675\n",
      "Iteration 180370: loss = 2.4425\n",
      "Iteration 180380: loss = 2.3317\n",
      "Iteration 180390: loss = 2.3533\n",
      "Iteration 180400: loss = 2.6556\n",
      "Iteration 180410: loss = 2.0251\n",
      "Iteration 180420: loss = 2.4106\n",
      "Iteration 180430: loss = 2.7748\n",
      "Iteration 180440: loss = 2.2169\n",
      "Iteration 180450: loss = 1.8429\n",
      "Iteration 180460: loss = 2.4725\n",
      "Iteration 180470: loss = 2.3796\n",
      "Iteration 180480: loss = 2.2766\n",
      "Iteration 180490: loss = 1.9781\n",
      "Iteration 180500: loss = 2.3998\n",
      "Iteration 180510: loss = 2.3069\n",
      "Iteration 180520: loss = 2.6063\n",
      "Iteration 180530: loss = 2.8005\n",
      "Iteration 180540: loss = 2.6132\n",
      "Iteration 180550: loss = 2.3169\n",
      "Iteration 180560: loss = 2.3415\n",
      "Iteration 180570: loss = 2.4172\n",
      "Iteration 180580: loss = 2.4248\n",
      "Iteration 180590: loss = 2.6066\n",
      "Iteration 180600: loss = 2.1803\n",
      "Iteration 180610: loss = 2.5318\n",
      "Iteration 180620: loss = 2.7620\n",
      "Iteration 180630: loss = 2.6991\n",
      "Iteration 180640: loss = 2.2295\n",
      "Iteration 180650: loss = 2.8227\n",
      "Iteration 180660: loss = 2.9871\n",
      "Iteration 180670: loss = 2.5099\n",
      "Iteration 180680: loss = 2.4855\n",
      "Iteration 180690: loss = 2.4347\n",
      "Iteration 180700: loss = 2.2846\n",
      "Iteration 180710: loss = 2.5741\n",
      "Iteration 180720: loss = 2.6028\n",
      "Iteration 180730: loss = 2.3959\n",
      "Iteration 180740: loss = 2.5015\n",
      "Iteration 180750: loss = 2.1960\n",
      "Iteration 180760: loss = 2.4059\n",
      "Iteration 180770: loss = 2.6312\n",
      "Iteration 180780: loss = 2.1783\n",
      "Iteration 180790: loss = 2.2961\n",
      "Iteration 180800: loss = 2.2458\n",
      "Iteration 180810: loss = 2.4290\n",
      "Iteration 180820: loss = 2.5596\n",
      "Iteration 180830: loss = 2.7156\n",
      "Iteration 180840: loss = 2.3427\n",
      "Iteration 180850: loss = 2.4898\n",
      "Iteration 180860: loss = 2.7787\n",
      "Iteration 180870: loss = 2.0346\n",
      "Iteration 180880: loss = 2.6364\n",
      "Iteration 180890: loss = 2.4522\n",
      "Iteration 180900: loss = 2.3228\n",
      "Iteration 180910: loss = 2.2635\n",
      "Iteration 180920: loss = 2.3384\n",
      "Iteration 180930: loss = 2.4065\n",
      "Iteration 180940: loss = 2.6282\n",
      "Iteration 180950: loss = 2.3859\n",
      "Iteration 180960: loss = 2.9448\n",
      "Iteration 180970: loss = 2.2983\n",
      "Iteration 180980: loss = 2.4568\n",
      "Iteration 180990: loss = 2.3582\n",
      "Iteration 181000: loss = 2.2361\n",
      "Iteration 181010: loss = 2.0070\n",
      "Iteration 181020: loss = 2.6128\n",
      "Iteration 181030: loss = 2.5804\n",
      "Iteration 181040: loss = 2.4518\n",
      "Iteration 181050: loss = 2.3812\n",
      "Iteration 181060: loss = 2.4895\n",
      "Iteration 181070: loss = 2.0486\n",
      "Iteration 181080: loss = 2.2704\n",
      "Iteration 181090: loss = 2.0733\n",
      "Iteration 181100: loss = 2.3301\n",
      "Iteration 181110: loss = 2.2204\n",
      "Iteration 181120: loss = 2.4306\n",
      "Iteration 181130: loss = 2.3872\n",
      "Iteration 181140: loss = 2.1509\n",
      "Iteration 181150: loss = 2.4066\n",
      "Iteration 181160: loss = 2.3553\n",
      "Iteration 181170: loss = 2.3344\n",
      "Iteration 181180: loss = 1.9939\n",
      "Iteration 181190: loss = 2.3734\n",
      "Iteration 181200: loss = 2.7377\n",
      "Iteration 181210: loss = 2.1969\n",
      "Iteration 181220: loss = 2.8547\n",
      "Iteration 181230: loss = 2.1809\n",
      "Iteration 181240: loss = 2.4450\n",
      "Iteration 181250: loss = 2.5312\n",
      "Iteration 181260: loss = 2.0212\n",
      "Iteration 181270: loss = 2.6078\n",
      "Iteration 181280: loss = 2.1167\n",
      "Iteration 181290: loss = 2.2864\n",
      "Iteration 181300: loss = 2.0084\n",
      "Iteration 181310: loss = 2.2312\n",
      "Iteration 181320: loss = 2.0385\n",
      "Iteration 181330: loss = 2.6203\n",
      "Iteration 181340: loss = 2.3513\n",
      "Iteration 181350: loss = 2.7746\n",
      "Iteration 181360: loss = 2.2799\n",
      "Iteration 181370: loss = 2.6544\n",
      "Iteration 181380: loss = 2.1320\n",
      "Iteration 181390: loss = 2.4965\n",
      "Iteration 181400: loss = 2.2641\n",
      "Iteration 181410: loss = 2.1760\n",
      "Iteration 181420: loss = 2.2976\n",
      "Iteration 181430: loss = 2.3420\n",
      "Iteration 181440: loss = 2.5206\n",
      "Iteration 181450: loss = 2.3944\n",
      "Iteration 181460: loss = 2.2865\n",
      "Iteration 181470: loss = 2.6890\n",
      "Iteration 181480: loss = 2.3353\n",
      "Iteration 181490: loss = 2.2937\n",
      "Iteration 181500: loss = 2.1994\n",
      "Iteration 181510: loss = 2.3340\n",
      "Iteration 181520: loss = 2.4208\n",
      "Iteration 181530: loss = 2.6533\n",
      "Iteration 181540: loss = 2.4565\n",
      "Iteration 181550: loss = 2.1714\n",
      "Iteration 181560: loss = 2.7676\n",
      "Iteration 181570: loss = 2.6267\n",
      "Iteration 181580: loss = 2.2216\n",
      "Iteration 181590: loss = 2.0547\n",
      "Iteration 181600: loss = 2.6045\n",
      "Iteration 181610: loss = 2.4843\n",
      "Iteration 181620: loss = 2.1949\n",
      "Iteration 181630: loss = 2.9091\n",
      "Iteration 181640: loss = 2.2103\n",
      "Iteration 181650: loss = 2.7375\n",
      "Iteration 181660: loss = 2.3344\n",
      "Iteration 181670: loss = 2.1979\n",
      "Iteration 181680: loss = 2.3630\n",
      "Iteration 181690: loss = 2.6223\n",
      "Iteration 181700: loss = 2.5479\n",
      "Iteration 181710: loss = 2.6102\n",
      "Iteration 181720: loss = 2.9398\n",
      "Iteration 181730: loss = 2.5914\n",
      "Iteration 181740: loss = 2.3377\n",
      "Iteration 181750: loss = 2.3764\n",
      "Iteration 181760: loss = 2.3981\n",
      "Iteration 181770: loss = 2.4715\n",
      "Iteration 181780: loss = 2.6724\n",
      "Iteration 181790: loss = 2.8166\n",
      "Iteration 181800: loss = 2.3425\n",
      "Iteration 181810: loss = 2.7364\n",
      "Iteration 181820: loss = 2.3339\n",
      "Iteration 181830: loss = 2.3179\n",
      "Iteration 181840: loss = 2.7972\n",
      "Iteration 181850: loss = 2.1020\n",
      "Iteration 181860: loss = 2.5883\n",
      "Iteration 181870: loss = 2.6882\n",
      "Iteration 181880: loss = 2.3634\n",
      "Iteration 181890: loss = 2.3000\n",
      "Iteration 181900: loss = 2.0910\n",
      "Iteration 181910: loss = 2.3639\n",
      "Iteration 181920: loss = 2.4926\n",
      "Iteration 181930: loss = 2.4339\n",
      "Iteration 181940: loss = 2.2865\n",
      "Iteration 181950: loss = 2.4582\n",
      "Iteration 181960: loss = 2.6315\n",
      "Iteration 181970: loss = 2.8416\n",
      "Iteration 181980: loss = 2.4437\n",
      "Iteration 181990: loss = 2.3745\n",
      "Iteration 182000: loss = 2.4622\n",
      "Iteration 182010: loss = 2.3271\n",
      "Iteration 182020: loss = 2.2082\n",
      "Iteration 182030: loss = 2.2082\n",
      "Iteration 182040: loss = 2.5211\n",
      "Iteration 182050: loss = 2.1974\n",
      "Iteration 182060: loss = 2.5984\n",
      "Iteration 182070: loss = 2.5353\n",
      "Iteration 182080: loss = 2.5971\n",
      "Iteration 182090: loss = 2.2313\n",
      "Iteration 182100: loss = 2.2105\n",
      "Iteration 182110: loss = 2.3757\n",
      "Iteration 182120: loss = 2.5695\n",
      "Iteration 182130: loss = 2.6674\n",
      "Iteration 182140: loss = 2.2839\n",
      "Iteration 182150: loss = 2.2026\n",
      "Iteration 182160: loss = 2.2597\n",
      "Iteration 182170: loss = 2.2240\n",
      "Iteration 182180: loss = 2.4094\n",
      "Iteration 182190: loss = 2.3961\n",
      "Iteration 182200: loss = 2.4107\n",
      "Iteration 182210: loss = 2.3615\n",
      "Iteration 182220: loss = 2.0732\n",
      "Iteration 182230: loss = 2.2897\n",
      "Iteration 182240: loss = 2.3266\n",
      "Iteration 182250: loss = 2.4273\n",
      "Iteration 182260: loss = 2.5308\n",
      "Iteration 182270: loss = 2.6061\n",
      "Iteration 182280: loss = 2.4171\n",
      "Iteration 182290: loss = 2.4378\n",
      "Iteration 182300: loss = 2.6187\n",
      "Iteration 182310: loss = 2.3994\n",
      "Iteration 182320: loss = 2.5443\n",
      "Iteration 182330: loss = 2.5745\n",
      "Iteration 182340: loss = 2.6591\n",
      "Iteration 182350: loss = 2.3142\n",
      "Iteration 182360: loss = 2.3232\n",
      "Iteration 182370: loss = 2.1379\n",
      "Iteration 182380: loss = 2.3355\n",
      "Iteration 182390: loss = 2.8248\n",
      "Iteration 182400: loss = 2.4947\n",
      "Iteration 182410: loss = 2.1222\n",
      "Iteration 182420: loss = 2.2463\n",
      "Iteration 182430: loss = 2.6114\n",
      "Iteration 182440: loss = 2.7075\n",
      "Iteration 182450: loss = 2.3630\n",
      "Iteration 182460: loss = 2.3590\n",
      "Iteration 182470: loss = 2.5746\n",
      "Iteration 182480: loss = 2.0623\n",
      "Iteration 182490: loss = 2.4897\n",
      "Iteration 182500: loss = 2.5596\n",
      "Iteration 182510: loss = 2.4894\n",
      "Iteration 182520: loss = 2.3548\n",
      "Iteration 182530: loss = 2.4728\n",
      "Iteration 182540: loss = 2.2227\n",
      "Iteration 182550: loss = 2.2990\n",
      "Iteration 182560: loss = 2.6147\n",
      "Iteration 182570: loss = 2.4415\n",
      "Iteration 182580: loss = 2.2446\n",
      "Iteration 182590: loss = 2.5683\n",
      "Iteration 182600: loss = 2.6442\n",
      "Iteration 182610: loss = 2.6039\n",
      "Iteration 182620: loss = 2.3915\n",
      "Iteration 182630: loss = 2.6357\n",
      "Iteration 182640: loss = 2.3994\n",
      "Iteration 182650: loss = 2.3328\n",
      "Iteration 182660: loss = 2.5838\n",
      "Iteration 182670: loss = 2.1505\n",
      "Iteration 182680: loss = 2.4602\n",
      "Iteration 182690: loss = 2.1714\n",
      "Iteration 182700: loss = 2.4044\n",
      "Iteration 182710: loss = 2.7087\n",
      "Iteration 182720: loss = 2.5550\n",
      "Iteration 182730: loss = 2.4897\n",
      "Iteration 182740: loss = 2.7773\n",
      "Iteration 182750: loss = 2.5732\n",
      "Iteration 182760: loss = 2.6853\n",
      "Iteration 182770: loss = 2.2993\n",
      "Iteration 182780: loss = 2.1611\n",
      "Iteration 182790: loss = 2.2676\n",
      "Iteration 182800: loss = 2.3143\n",
      "Iteration 182810: loss = 2.5865\n",
      "Iteration 182820: loss = 2.7072\n",
      "Iteration 182830: loss = 2.2426\n",
      "Iteration 182840: loss = 2.0096\n",
      "Iteration 182850: loss = 2.6661\n",
      "Iteration 182860: loss = 2.7975\n",
      "Iteration 182870: loss = 2.4602\n",
      "Iteration 182880: loss = 2.3163\n",
      "Iteration 182890: loss = 2.2152\n",
      "Iteration 182900: loss = 2.7439\n",
      "Iteration 182910: loss = 2.9147\n",
      "Iteration 182920: loss = 2.3726\n",
      "Iteration 182930: loss = 2.4646\n",
      "Iteration 182940: loss = 2.6159\n",
      "Iteration 182950: loss = 1.9974\n",
      "Iteration 182960: loss = 2.1719\n",
      "Iteration 182970: loss = 2.5823\n",
      "Iteration 182980: loss = 2.5541\n",
      "Iteration 182990: loss = 2.6109\n",
      "Iteration 183000: loss = 2.5926\n",
      "Iteration 183010: loss = 2.5449\n",
      "Iteration 183020: loss = 2.4194\n",
      "Iteration 183030: loss = 2.2600\n",
      "Iteration 183040: loss = 2.5554\n",
      "Iteration 183050: loss = 2.1922\n",
      "Iteration 183060: loss = 1.9127\n",
      "Iteration 183070: loss = 2.4100\n",
      "Iteration 183080: loss = 1.9853\n",
      "Iteration 183090: loss = 2.4836\n",
      "Iteration 183100: loss = 2.5165\n",
      "Iteration 183110: loss = 2.5693\n",
      "Iteration 183120: loss = 2.2516\n",
      "Iteration 183130: loss = 2.3759\n",
      "Iteration 183140: loss = 2.5458\n",
      "Iteration 183150: loss = 2.4817\n",
      "Iteration 183160: loss = 3.1767\n",
      "Iteration 183170: loss = 2.4475\n",
      "Iteration 183180: loss = 2.5331\n",
      "Iteration 183190: loss = 2.4837\n",
      "Iteration 183200: loss = 2.3934\n",
      "Iteration 183210: loss = 2.0358\n",
      "Iteration 183220: loss = 2.2538\n",
      "Iteration 183230: loss = 2.5913\n",
      "Iteration 183240: loss = 2.5886\n",
      "Iteration 183250: loss = 2.2017\n",
      "Iteration 183260: loss = 2.6541\n",
      "Iteration 183270: loss = 2.3928\n",
      "Iteration 183280: loss = 2.8528\n",
      "Iteration 183290: loss = 2.6795\n",
      "Iteration 183300: loss = 2.6230\n",
      "Iteration 183310: loss = 2.1339\n",
      "Iteration 183320: loss = 2.4228\n",
      "Iteration 183330: loss = 2.4105\n",
      "Iteration 183340: loss = 2.0541\n",
      "Iteration 183350: loss = 2.4999\n",
      "Iteration 183360: loss = 2.1200\n",
      "Iteration 183370: loss = 2.5738\n",
      "Iteration 183380: loss = 2.0986\n",
      "Iteration 183390: loss = 2.4829\n",
      "Iteration 183400: loss = 2.2670\n",
      "Iteration 183410: loss = 2.0541\n",
      "Iteration 183420: loss = 2.4532\n",
      "Iteration 183430: loss = 2.5752\n",
      "Iteration 183440: loss = 2.4040\n",
      "Iteration 183450: loss = 2.5357\n",
      "Iteration 183460: loss = 2.3287\n",
      "Iteration 183470: loss = 2.2691\n",
      "Iteration 183480: loss = 2.1981\n",
      "Iteration 183490: loss = 2.7520\n",
      "Iteration 183500: loss = 2.4210\n",
      "Iteration 183510: loss = 2.2508\n",
      "Iteration 183520: loss = 2.8988\n",
      "Iteration 183530: loss = 2.7262\n",
      "Iteration 183540: loss = 2.4916\n",
      "Iteration 183550: loss = 1.9913\n",
      "Iteration 183560: loss = 2.1853\n",
      "Iteration 183570: loss = 2.5822\n",
      "Iteration 183580: loss = 2.4524\n",
      "Iteration 183590: loss = 2.1414\n",
      "Iteration 183600: loss = 2.2372\n",
      "Iteration 183610: loss = 2.4520\n",
      "Iteration 183620: loss = 1.8572\n",
      "Iteration 183630: loss = 2.6624\n",
      "Iteration 183640: loss = 2.4222\n",
      "Iteration 183650: loss = 2.0301\n",
      "Iteration 183660: loss = 2.6595\n",
      "Iteration 183670: loss = 2.5047\n",
      "Iteration 183680: loss = 2.2743\n",
      "Iteration 183690: loss = 2.5282\n",
      "Iteration 183700: loss = 1.8894\n",
      "Iteration 183710: loss = 2.3785\n",
      "Iteration 183720: loss = 2.4117\n",
      "Iteration 183730: loss = 2.4769\n",
      "Iteration 183740: loss = 2.0853\n",
      "Iteration 183750: loss = 2.0903\n",
      "Iteration 183760: loss = 2.5419\n",
      "Iteration 183770: loss = 2.4300\n",
      "Iteration 183780: loss = 2.5729\n",
      "Iteration 183790: loss = 2.3734\n",
      "Iteration 183800: loss = 2.3204\n",
      "Iteration 183810: loss = 2.1723\n",
      "Iteration 183820: loss = 2.7047\n",
      "Iteration 183830: loss = 2.5536\n",
      "Iteration 183840: loss = 2.3288\n",
      "Iteration 183850: loss = 2.7365\n",
      "Iteration 183860: loss = 2.3961\n",
      "Iteration 183870: loss = 2.3677\n",
      "Iteration 183880: loss = 2.2084\n",
      "Iteration 183890: loss = 2.8109\n",
      "Iteration 183900: loss = 2.8967\n",
      "Iteration 183910: loss = 2.4698\n",
      "Iteration 183920: loss = 2.2412\n",
      "Iteration 183930: loss = 1.9147\n",
      "Iteration 183940: loss = 2.6168\n",
      "Iteration 183950: loss = 2.6388\n",
      "Iteration 183960: loss = 2.3580\n",
      "Iteration 183970: loss = 2.3504\n",
      "Iteration 183980: loss = 2.4260\n",
      "Iteration 183990: loss = 2.2638\n",
      "Iteration 184000: loss = 2.5017\n",
      "Iteration 184010: loss = 2.1940\n",
      "Iteration 184020: loss = 2.6625\n",
      "Iteration 184030: loss = 2.7047\n",
      "Iteration 184040: loss = 2.5647\n",
      "Iteration 184050: loss = 2.1543\n",
      "Iteration 184060: loss = 2.3973\n",
      "Iteration 184070: loss = 2.4217\n",
      "Iteration 184080: loss = 2.4399\n",
      "Iteration 184090: loss = 2.7220\n",
      "Iteration 184100: loss = 2.5688\n",
      "Iteration 184110: loss = 2.4020\n",
      "Iteration 184120: loss = 2.5336\n",
      "Iteration 184130: loss = 2.3412\n",
      "Iteration 184140: loss = 2.4940\n",
      "Iteration 184150: loss = 2.3611\n",
      "Iteration 184160: loss = 2.7183\n",
      "Iteration 184170: loss = 2.3119\n",
      "Iteration 184180: loss = 2.4459\n",
      "Iteration 184190: loss = 2.3088\n",
      "Iteration 184200: loss = 2.3569\n",
      "Iteration 184210: loss = 2.6521\n",
      "Iteration 184220: loss = 2.4484\n",
      "Iteration 184230: loss = 2.8195\n",
      "Iteration 184240: loss = 2.2641\n",
      "Iteration 184250: loss = 2.3516\n",
      "Iteration 184260: loss = 2.4500\n",
      "Iteration 184270: loss = 2.4589\n",
      "Iteration 184280: loss = 2.4853\n",
      "Iteration 184290: loss = 2.3873\n",
      "Iteration 184300: loss = 2.6277\n",
      "Iteration 184310: loss = 2.7322\n",
      "Iteration 184320: loss = 1.9050\n",
      "Iteration 184330: loss = 2.3075\n",
      "Iteration 184340: loss = 2.4596\n",
      "Iteration 184350: loss = 2.5302\n",
      "Iteration 184360: loss = 2.1378\n",
      "Iteration 184370: loss = 2.5853\n",
      "Iteration 184380: loss = 2.3660\n",
      "Iteration 184390: loss = 1.9549\n",
      "Iteration 184400: loss = 2.5088\n",
      "Iteration 184410: loss = 2.2305\n",
      "Iteration 184420: loss = 2.4233\n",
      "Iteration 184430: loss = 2.2830\n",
      "Iteration 184440: loss = 2.4715\n",
      "Iteration 184450: loss = 2.1352\n",
      "Iteration 184460: loss = 2.3081\n",
      "Iteration 184470: loss = 2.6120\n",
      "Iteration 184480: loss = 2.6152\n",
      "Iteration 184490: loss = 2.1960\n",
      "Iteration 184500: loss = 2.3252\n",
      "Iteration 184510: loss = 2.4176\n",
      "Iteration 184520: loss = 2.4091\n",
      "Iteration 184530: loss = 2.2034\n",
      "Iteration 184540: loss = 2.2545\n",
      "Iteration 184550: loss = 2.4716\n",
      "Iteration 184560: loss = 2.3709\n",
      "Iteration 184570: loss = 2.1291\n",
      "Iteration 184580: loss = 2.2815\n",
      "Iteration 184590: loss = 2.1110\n",
      "Iteration 184600: loss = 2.1658\n",
      "Iteration 184610: loss = 2.4580\n",
      "Iteration 184620: loss = 2.1329\n",
      "Iteration 184630: loss = 2.4432\n",
      "Iteration 184640: loss = 2.7810\n",
      "Iteration 184650: loss = 2.3682\n",
      "Iteration 184660: loss = 2.3764\n",
      "Iteration 184670: loss = 2.3810\n",
      "Iteration 184680: loss = 2.4237\n",
      "Iteration 184690: loss = 2.2258\n",
      "Iteration 184700: loss = 2.4550\n",
      "Iteration 184710: loss = 2.4451\n",
      "Iteration 184720: loss = 2.6182\n",
      "Iteration 184730: loss = 2.4164\n",
      "Iteration 184740: loss = 2.1078\n",
      "Iteration 184750: loss = 2.4535\n",
      "Iteration 184760: loss = 2.5036\n",
      "Iteration 184770: loss = 2.2835\n",
      "Iteration 184780: loss = 2.5367\n",
      "Iteration 184790: loss = 2.4753\n",
      "Iteration 184800: loss = 2.1155\n",
      "Iteration 184810: loss = 2.6529\n",
      "Iteration 184820: loss = 2.2864\n",
      "Iteration 184830: loss = 2.3771\n",
      "Iteration 184840: loss = 2.3915\n",
      "Iteration 184850: loss = 2.4725\n",
      "Iteration 184860: loss = 2.4128\n",
      "Iteration 184870: loss = 2.1360\n",
      "Iteration 184880: loss = 2.5372\n",
      "Iteration 184890: loss = 2.2312\n",
      "Iteration 184900: loss = 2.4014\n",
      "Iteration 184910: loss = 2.6009\n",
      "Iteration 184920: loss = 2.3843\n",
      "Iteration 184930: loss = 2.4571\n",
      "Iteration 184940: loss = 2.4345\n",
      "Iteration 184950: loss = 2.1052\n",
      "Iteration 184960: loss = 2.4789\n",
      "Iteration 184970: loss = 2.4366\n",
      "Iteration 184980: loss = 2.5723\n",
      "Iteration 184990: loss = 2.3932\n",
      "Iteration 185000: loss = 2.6892\n",
      "Iteration 185010: loss = 2.7996\n",
      "Iteration 185020: loss = 2.3879\n",
      "Iteration 185030: loss = 2.0944\n",
      "Iteration 185040: loss = 2.4314\n",
      "Iteration 185050: loss = 2.1631\n",
      "Iteration 185060: loss = 2.3836\n",
      "Iteration 185070: loss = 2.5751\n",
      "Iteration 185080: loss = 2.1352\n",
      "Iteration 185090: loss = 2.4078\n",
      "Iteration 185100: loss = 2.5070\n",
      "Iteration 185110: loss = 2.4138\n",
      "Iteration 185120: loss = 2.3309\n",
      "Iteration 185130: loss = 2.0036\n",
      "Iteration 185140: loss = 2.4313\n",
      "Iteration 185150: loss = 2.2032\n",
      "Iteration 185160: loss = 2.3471\n",
      "Iteration 185170: loss = 2.3777\n",
      "Iteration 185180: loss = 2.2607\n",
      "Iteration 185190: loss = 2.7315\n",
      "Iteration 185200: loss = 2.3139\n",
      "Iteration 185210: loss = 2.3811\n",
      "Iteration 185220: loss = 2.1673\n",
      "Iteration 185230: loss = 2.9218\n",
      "Iteration 185240: loss = 2.5963\n",
      "Iteration 185250: loss = 2.5848\n",
      "Iteration 185260: loss = 2.2888\n",
      "Iteration 185270: loss = 2.5546\n",
      "Iteration 185280: loss = 2.6696\n",
      "Iteration 185290: loss = 2.4765\n",
      "Iteration 185300: loss = 2.4330\n",
      "Iteration 185310: loss = 2.2314\n",
      "Iteration 185320: loss = 2.4654\n",
      "Iteration 185330: loss = 2.5670\n",
      "Iteration 185340: loss = 2.8165\n",
      "Iteration 185350: loss = 2.5484\n",
      "Iteration 185360: loss = 2.2852\n",
      "Iteration 185370: loss = 2.2117\n",
      "Iteration 185380: loss = 2.2987\n",
      "Iteration 185390: loss = 2.2972\n",
      "Iteration 185400: loss = 2.5001\n",
      "Iteration 185410: loss = 2.0555\n",
      "Iteration 185420: loss = 2.2921\n",
      "Iteration 185430: loss = 2.6586\n",
      "Iteration 185440: loss = 2.4965\n",
      "Iteration 185450: loss = 2.4790\n",
      "Iteration 185460: loss = 2.8033\n",
      "Iteration 185470: loss = 2.6743\n",
      "Iteration 185480: loss = 2.5963\n",
      "Iteration 185490: loss = 2.5844\n",
      "Iteration 185500: loss = 2.2477\n",
      "Iteration 185510: loss = 2.1864\n",
      "Iteration 185520: loss = 2.5822\n",
      "Iteration 185530: loss = 2.5435\n",
      "Iteration 185540: loss = 2.5837\n",
      "Iteration 185550: loss = 2.2264\n",
      "Iteration 185560: loss = 2.4062\n",
      "Iteration 185570: loss = 2.7534\n",
      "Iteration 185580: loss = 2.2139\n",
      "Iteration 185590: loss = 2.3872\n",
      "Iteration 185600: loss = 2.4694\n",
      "Iteration 185610: loss = 2.8612\n",
      "Iteration 185620: loss = 2.1904\n",
      "Iteration 185630: loss = 2.2293\n",
      "Iteration 185640: loss = 2.0845\n",
      "Iteration 185650: loss = 2.2969\n",
      "Iteration 185660: loss = 2.6177\n",
      "Iteration 185670: loss = 1.7561\n",
      "Iteration 185680: loss = 2.4085\n",
      "Iteration 185690: loss = 2.8950\n",
      "Iteration 185700: loss = 2.3860\n",
      "Iteration 185710: loss = 2.0244\n",
      "Iteration 185720: loss = 2.5753\n",
      "Iteration 185730: loss = 2.6284\n",
      "Iteration 185740: loss = 2.2767\n",
      "Iteration 185750: loss = 2.5682\n",
      "Iteration 185760: loss = 2.1328\n",
      "Iteration 185770: loss = 2.0928\n",
      "Iteration 185780: loss = 2.2994\n",
      "Iteration 185790: loss = 2.1635\n",
      "Iteration 185800: loss = 2.3238\n",
      "Iteration 185810: loss = 2.1285\n",
      "Iteration 185820: loss = 2.1581\n",
      "Iteration 185830: loss = 2.5038\n",
      "Iteration 185840: loss = 2.6924\n",
      "Iteration 185850: loss = 2.4622\n",
      "Iteration 185860: loss = 2.0896\n",
      "Iteration 185870: loss = 2.4923\n",
      "Iteration 185880: loss = 2.3417\n",
      "Iteration 185890: loss = 2.3689\n",
      "Iteration 185900: loss = 2.6116\n",
      "Iteration 185910: loss = 2.4219\n",
      "Iteration 185920: loss = 2.6551\n",
      "Iteration 185930: loss = 2.2841\n",
      "Iteration 185940: loss = 2.6727\n",
      "Iteration 185950: loss = 2.3131\n",
      "Iteration 185960: loss = 2.5529\n",
      "Iteration 185970: loss = 2.5355\n",
      "Iteration 185980: loss = 2.4844\n",
      "Iteration 185990: loss = 2.2171\n",
      "Iteration 186000: loss = 2.5884\n",
      "Iteration 186010: loss = 2.1766\n",
      "Iteration 186020: loss = 2.2578\n",
      "Iteration 186030: loss = 2.4472\n",
      "Iteration 186040: loss = 2.6898\n",
      "Iteration 186050: loss = 2.5769\n",
      "Iteration 186060: loss = 2.2844\n",
      "Iteration 186070: loss = 2.7582\n",
      "Iteration 186080: loss = 2.6523\n",
      "Iteration 186090: loss = 2.2354\n",
      "Iteration 186100: loss = 2.0558\n",
      "Iteration 186110: loss = 2.1654\n",
      "Iteration 186120: loss = 2.2039\n",
      "Iteration 186130: loss = 2.2593\n",
      "Iteration 186140: loss = 2.2660\n",
      "Iteration 186150: loss = 2.3594\n",
      "Iteration 186160: loss = 2.8811\n",
      "Iteration 186170: loss = 2.3287\n",
      "Iteration 186180: loss = 2.2085\n",
      "Iteration 186190: loss = 2.7511\n",
      "Iteration 186200: loss = 2.4932\n",
      "Iteration 186210: loss = 2.3184\n",
      "Iteration 186220: loss = 2.2088\n",
      "Iteration 186230: loss = 2.1576\n",
      "Iteration 186240: loss = 2.5834\n",
      "Iteration 186250: loss = 2.2270\n",
      "Iteration 186260: loss = 2.2605\n",
      "Iteration 186270: loss = 2.6555\n",
      "Iteration 186280: loss = 2.3023\n",
      "Iteration 186290: loss = 2.3048\n",
      "Iteration 186300: loss = 2.5607\n",
      "Iteration 186310: loss = 2.4582\n",
      "Iteration 186320: loss = 2.4073\n",
      "Iteration 186330: loss = 2.5873\n",
      "Iteration 186340: loss = 2.3622\n",
      "Iteration 186350: loss = 2.1521\n",
      "Iteration 186360: loss = 2.0656\n",
      "Iteration 186370: loss = 2.5490\n",
      "Iteration 186380: loss = 2.5288\n",
      "Iteration 186390: loss = 2.5721\n",
      "Iteration 186400: loss = 2.4619\n",
      "Iteration 186410: loss = 2.3040\n",
      "Iteration 186420: loss = 2.7706\n",
      "Iteration 186430: loss = 2.7584\n",
      "Iteration 186440: loss = 2.2667\n",
      "Iteration 186450: loss = 3.0178\n",
      "Iteration 186460: loss = 2.7391\n",
      "Iteration 186470: loss = 2.3126\n",
      "Iteration 186480: loss = 2.6815\n",
      "Iteration 186490: loss = 2.2851\n",
      "Iteration 186500: loss = 2.2414\n",
      "Iteration 186510: loss = 2.3952\n",
      "Iteration 186520: loss = 2.5296\n",
      "Iteration 186530: loss = 2.6705\n",
      "Iteration 186540: loss = 2.5790\n",
      "Iteration 186550: loss = 2.1448\n",
      "Iteration 186560: loss = 2.5641\n",
      "Iteration 186570: loss = 2.4438\n",
      "Iteration 186580: loss = 2.3083\n",
      "Iteration 186590: loss = 2.8819\n",
      "Iteration 186600: loss = 1.9157\n",
      "Iteration 186610: loss = 2.3129\n",
      "Iteration 186620: loss = 2.4911\n",
      "Iteration 186630: loss = 2.3840\n",
      "Iteration 186640: loss = 2.1690\n",
      "Iteration 186650: loss = 2.5763\n",
      "Iteration 186660: loss = 2.6257\n",
      "Iteration 186670: loss = 2.2786\n",
      "Iteration 186680: loss = 2.7016\n",
      "Iteration 186690: loss = 2.5749\n",
      "Iteration 186700: loss = 2.2770\n",
      "Iteration 186710: loss = 2.3291\n",
      "Iteration 186720: loss = 2.5698\n",
      "Iteration 186730: loss = 2.5168\n",
      "Iteration 186740: loss = 2.1739\n",
      "Iteration 186750: loss = 2.5803\n",
      "Iteration 186760: loss = 2.1549\n",
      "Iteration 186770: loss = 2.5601\n",
      "Iteration 186780: loss = 2.2342\n",
      "Iteration 186790: loss = 2.3139\n",
      "Iteration 186800: loss = 2.1682\n",
      "Iteration 186810: loss = 1.6885\n",
      "Iteration 186820: loss = 2.7015\n",
      "Iteration 186830: loss = 2.3718\n",
      "Iteration 186840: loss = 2.6042\n",
      "Iteration 186850: loss = 2.5315\n",
      "Iteration 186860: loss = 2.5566\n",
      "Iteration 186870: loss = 2.6284\n",
      "Iteration 186880: loss = 2.4804\n",
      "Iteration 186890: loss = 2.3657\n",
      "Iteration 186900: loss = 2.5117\n",
      "Iteration 186910: loss = 2.4940\n",
      "Iteration 186920: loss = 2.6976\n",
      "Iteration 186930: loss = 2.3959\n",
      "Iteration 186940: loss = 2.4109\n",
      "Iteration 186950: loss = 2.0409\n",
      "Iteration 186960: loss = 2.2241\n",
      "Iteration 186970: loss = 2.4916\n",
      "Iteration 186980: loss = 2.9529\n",
      "Iteration 186990: loss = 2.1883\n",
      "Iteration 187000: loss = 1.9551\n",
      "Iteration 187010: loss = 2.4255\n",
      "Iteration 187020: loss = 2.3943\n",
      "Iteration 187030: loss = 1.8792\n",
      "Iteration 187040: loss = 2.5105\n",
      "Iteration 187050: loss = 2.1714\n",
      "Iteration 187060: loss = 2.6571\n",
      "Iteration 187070: loss = 2.1470\n",
      "Iteration 187080: loss = 2.4447\n",
      "Iteration 187090: loss = 2.3604\n",
      "Iteration 187100: loss = 2.5773\n",
      "Iteration 187110: loss = 2.6747\n",
      "Iteration 187120: loss = 2.2022\n",
      "Iteration 187130: loss = 2.2026\n",
      "Iteration 187140: loss = 1.9394\n",
      "Iteration 187150: loss = 2.4292\n",
      "Iteration 187160: loss = 2.3930\n",
      "Iteration 187170: loss = 2.1149\n",
      "Iteration 187180: loss = 2.4696\n",
      "Iteration 187190: loss = 2.3422\n",
      "Iteration 187200: loss = 2.3427\n",
      "Iteration 187210: loss = 2.6658\n",
      "Iteration 187220: loss = 2.2074\n",
      "Iteration 187230: loss = 2.3619\n",
      "Iteration 187240: loss = 2.5622\n",
      "Iteration 187250: loss = 2.6048\n",
      "Iteration 187260: loss = 2.8416\n",
      "Iteration 187270: loss = 3.0189\n",
      "Iteration 187280: loss = 1.9828\n",
      "Iteration 187290: loss = 2.6801\n",
      "Iteration 187300: loss = 2.4087\n",
      "Iteration 187310: loss = 2.6537\n",
      "Iteration 187320: loss = 2.4554\n",
      "Iteration 187330: loss = 2.4599\n",
      "Iteration 187340: loss = 2.2698\n",
      "Iteration 187350: loss = 2.6250\n",
      "Iteration 187360: loss = 2.2960\n",
      "Iteration 187370: loss = 2.9171\n",
      "Iteration 187380: loss = 2.2797\n",
      "Iteration 187390: loss = 2.6553\n",
      "Iteration 187400: loss = 2.1444\n",
      "Iteration 187410: loss = 2.5422\n",
      "Iteration 187420: loss = 2.3690\n",
      "Iteration 187430: loss = 1.8859\n",
      "Iteration 187440: loss = 2.6115\n",
      "Iteration 187450: loss = 1.9230\n",
      "Iteration 187460: loss = 2.4223\n",
      "Iteration 187470: loss = 2.4758\n",
      "Iteration 187480: loss = 2.7588\n",
      "Iteration 187490: loss = 2.4808\n",
      "Iteration 187500: loss = 2.1859\n",
      "Iteration 187510: loss = 2.1908\n",
      "Iteration 187520: loss = 2.4083\n",
      "Iteration 187530: loss = 2.1677\n",
      "Iteration 187540: loss = 2.3186\n",
      "Iteration 187550: loss = 2.3451\n",
      "Iteration 187560: loss = 2.6065\n",
      "Iteration 187570: loss = 2.3643\n",
      "Iteration 187580: loss = 2.5895\n",
      "Iteration 187590: loss = 2.3597\n",
      "Iteration 187600: loss = 2.1439\n",
      "Iteration 187610: loss = 2.6410\n",
      "Iteration 187620: loss = 2.7096\n",
      "Iteration 187630: loss = 2.5732\n",
      "Iteration 187640: loss = 2.2794\n",
      "Iteration 187650: loss = 2.6612\n",
      "Iteration 187660: loss = 2.2757\n",
      "Iteration 187670: loss = 2.2273\n",
      "Iteration 187680: loss = 2.5675\n",
      "Iteration 187690: loss = 2.5775\n",
      "Iteration 187700: loss = 2.6150\n",
      "Iteration 187710: loss = 2.5027\n",
      "Iteration 187720: loss = 2.0053\n",
      "Iteration 187730: loss = 2.2723\n",
      "Iteration 187740: loss = 2.1345\n",
      "Iteration 187750: loss = 2.1115\n",
      "Iteration 187760: loss = 2.4830\n",
      "Iteration 187770: loss = 2.4083\n",
      "Iteration 187780: loss = 2.6061\n",
      "Iteration 187790: loss = 1.7681\n",
      "Iteration 187800: loss = 2.2669\n",
      "Iteration 187810: loss = 2.4981\n",
      "Iteration 187820: loss = 2.5468\n",
      "Iteration 187830: loss = 2.2717\n",
      "Iteration 187840: loss = 2.9502\n",
      "Iteration 187850: loss = 2.3277\n",
      "Iteration 187860: loss = 2.1331\n",
      "Iteration 187870: loss = 2.5904\n",
      "Iteration 187880: loss = 2.4322\n",
      "Iteration 187890: loss = 2.7482\n",
      "Iteration 187900: loss = 2.2569\n",
      "Iteration 187910: loss = 2.3277\n",
      "Iteration 187920: loss = 2.2859\n",
      "Iteration 187930: loss = 2.2012\n",
      "Iteration 187940: loss = 2.5823\n",
      "Iteration 187950: loss = 2.1857\n",
      "Iteration 187960: loss = 2.3722\n",
      "Iteration 187970: loss = 2.6454\n",
      "Iteration 187980: loss = 2.1772\n",
      "Iteration 187990: loss = 1.9232\n",
      "Iteration 188000: loss = 2.5770\n",
      "Iteration 188010: loss = 2.5425\n",
      "Iteration 188020: loss = 2.2840\n",
      "Iteration 188030: loss = 2.4078\n",
      "Iteration 188040: loss = 2.0600\n",
      "Iteration 188050: loss = 2.3803\n",
      "Iteration 188060: loss = 2.6753\n",
      "Iteration 188070: loss = 2.3371\n",
      "Iteration 188080: loss = 2.5817\n",
      "Iteration 188090: loss = 2.0906\n",
      "Iteration 188100: loss = 2.7390\n",
      "Iteration 188110: loss = 2.0718\n",
      "Iteration 188120: loss = 2.6356\n",
      "Iteration 188130: loss = 2.0759\n",
      "Iteration 188140: loss = 2.5523\n",
      "Iteration 188150: loss = 2.6018\n",
      "Iteration 188160: loss = 2.0736\n",
      "Iteration 188170: loss = 2.1394\n",
      "Iteration 188180: loss = 2.2495\n",
      "Iteration 188190: loss = 2.3706\n",
      "Iteration 188200: loss = 1.9848\n",
      "Iteration 188210: loss = 2.0896\n",
      "Iteration 188220: loss = 2.5301\n",
      "Iteration 188230: loss = 2.4287\n",
      "Iteration 188240: loss = 2.8457\n",
      "Iteration 188250: loss = 2.3203\n",
      "Iteration 188260: loss = 2.4847\n",
      "Iteration 188270: loss = 2.2400\n",
      "Iteration 188280: loss = 2.4353\n",
      "Iteration 188290: loss = 2.1906\n",
      "Iteration 188300: loss = 2.4552\n",
      "Iteration 188310: loss = 2.5352\n",
      "Iteration 188320: loss = 2.4764\n",
      "Iteration 188330: loss = 2.5236\n",
      "Iteration 188340: loss = 2.3040\n",
      "Iteration 188350: loss = 2.2986\n",
      "Iteration 188360: loss = 2.6201\n",
      "Iteration 188370: loss = 2.5076\n",
      "Iteration 188380: loss = 2.5778\n",
      "Iteration 188390: loss = 2.4755\n",
      "Iteration 188400: loss = 2.2922\n",
      "Iteration 188410: loss = 2.1683\n",
      "Iteration 188420: loss = 2.3808\n",
      "Iteration 188430: loss = 2.3220\n",
      "Iteration 188440: loss = 2.4802\n",
      "Iteration 188450: loss = 2.3269\n",
      "Iteration 188460: loss = 2.2458\n",
      "Iteration 188470: loss = 2.1052\n",
      "Iteration 188480: loss = 2.3612\n",
      "Iteration 188490: loss = 2.7695\n",
      "Iteration 188500: loss = 2.3156\n",
      "Iteration 188510: loss = 2.3385\n",
      "Iteration 188520: loss = 2.3692\n",
      "Iteration 188530: loss = 2.6114\n",
      "Iteration 188540: loss = 2.4274\n",
      "Iteration 188550: loss = 2.1737\n",
      "Iteration 188560: loss = 2.4548\n",
      "Iteration 188570: loss = 2.6041\n",
      "Iteration 188580: loss = 2.2910\n",
      "Iteration 188590: loss = 2.3263\n",
      "Iteration 188600: loss = 2.4751\n",
      "Iteration 188610: loss = 2.4298\n",
      "Iteration 188620: loss = 2.1516\n",
      "Iteration 188630: loss = 2.4420\n",
      "Iteration 188640: loss = 2.3938\n",
      "Iteration 188650: loss = 2.2619\n",
      "Iteration 188660: loss = 2.2796\n",
      "Iteration 188670: loss = 2.7122\n",
      "Iteration 188680: loss = 2.6571\n",
      "Iteration 188690: loss = 2.6414\n",
      "Iteration 188700: loss = 2.2294\n",
      "Iteration 188710: loss = 2.4332\n",
      "Iteration 188720: loss = 2.6093\n",
      "Iteration 188730: loss = 2.1863\n",
      "Iteration 188740: loss = 2.2891\n",
      "Iteration 188750: loss = 2.3884\n",
      "Iteration 188760: loss = 2.1900\n",
      "Iteration 188770: loss = 2.7669\n",
      "Iteration 188780: loss = 2.4656\n",
      "Iteration 188790: loss = 2.2206\n",
      "Iteration 188800: loss = 2.3793\n",
      "Iteration 188810: loss = 2.2853\n",
      "Iteration 188820: loss = 2.5181\n",
      "Iteration 188830: loss = 1.9952\n",
      "Iteration 188840: loss = 2.1895\n",
      "Iteration 188850: loss = 2.6919\n",
      "Iteration 188860: loss = 2.0832\n",
      "Iteration 188870: loss = 2.1778\n",
      "Iteration 188880: loss = 1.7307\n",
      "Iteration 188890: loss = 2.5809\n",
      "Iteration 188900: loss = 1.8497\n",
      "Iteration 188910: loss = 2.5520\n",
      "Iteration 188920: loss = 2.5021\n",
      "Iteration 188930: loss = 2.6627\n",
      "Iteration 188940: loss = 2.6294\n",
      "Iteration 188950: loss = 2.3647\n",
      "Iteration 188960: loss = 2.6412\n",
      "Iteration 188970: loss = 2.2448\n",
      "Iteration 188980: loss = 2.3084\n",
      "Iteration 188990: loss = 2.3995\n",
      "Iteration 189000: loss = 2.5127\n",
      "Iteration 189010: loss = 1.7119\n",
      "Iteration 189020: loss = 2.0968\n",
      "Iteration 189030: loss = 2.2682\n",
      "Iteration 189040: loss = 2.4153\n",
      "Iteration 189050: loss = 2.4668\n",
      "Iteration 189060: loss = 2.6575\n",
      "Iteration 189070: loss = 2.5686\n",
      "Iteration 189080: loss = 1.9274\n",
      "Iteration 189090: loss = 2.6163\n",
      "Iteration 189100: loss = 2.5711\n",
      "Iteration 189110: loss = 2.7289\n",
      "Iteration 189120: loss = 2.4832\n",
      "Iteration 189130: loss = 2.4218\n",
      "Iteration 189140: loss = 2.5263\n",
      "Iteration 189150: loss = 2.5113\n",
      "Iteration 189160: loss = 2.4138\n",
      "Iteration 189170: loss = 2.1810\n",
      "Iteration 189180: loss = 2.3019\n",
      "Iteration 189190: loss = 2.7342\n",
      "Iteration 189200: loss = 2.4572\n",
      "Iteration 189210: loss = 2.2917\n",
      "Iteration 189220: loss = 2.4173\n",
      "Iteration 189230: loss = 2.7696\n",
      "Iteration 189240: loss = 2.3832\n",
      "Iteration 189250: loss = 2.8468\n",
      "Iteration 189260: loss = 2.9352\n",
      "Iteration 189270: loss = 2.7012\n",
      "Iteration 189280: loss = 2.7125\n",
      "Iteration 189290: loss = 2.4427\n",
      "Iteration 189300: loss = 2.3617\n",
      "Iteration 189310: loss = 2.1636\n",
      "Iteration 189320: loss = 2.9626\n",
      "Iteration 189330: loss = 2.3283\n",
      "Iteration 189340: loss = 2.0370\n",
      "Iteration 189350: loss = 2.2513\n",
      "Iteration 189360: loss = 2.3860\n",
      "Iteration 189370: loss = 2.6561\n",
      "Iteration 189380: loss = 2.3154\n",
      "Iteration 189390: loss = 2.3685\n",
      "Iteration 189400: loss = 2.2317\n",
      "Iteration 189410: loss = 2.0693\n",
      "Iteration 189420: loss = 2.4014\n",
      "Iteration 189430: loss = 2.2019\n",
      "Iteration 189440: loss = 2.4147\n",
      "Iteration 189450: loss = 2.0246\n",
      "Iteration 189460: loss = 1.9992\n",
      "Iteration 189470: loss = 2.0395\n",
      "Iteration 189480: loss = 2.2490\n",
      "Iteration 189490: loss = 2.3286\n",
      "Iteration 189500: loss = 2.3174\n",
      "Iteration 189510: loss = 2.2549\n",
      "Iteration 189520: loss = 2.1594\n",
      "Iteration 189530: loss = 2.2443\n",
      "Iteration 189540: loss = 2.0695\n",
      "Iteration 189550: loss = 1.8595\n",
      "Iteration 189560: loss = 2.5337\n",
      "Iteration 189570: loss = 2.5018\n",
      "Iteration 189580: loss = 2.8081\n",
      "Iteration 189590: loss = 2.4736\n",
      "Iteration 189600: loss = 2.6676\n",
      "Iteration 189610: loss = 2.5421\n",
      "Iteration 189620: loss = 2.1615\n",
      "Iteration 189630: loss = 2.1490\n",
      "Iteration 189640: loss = 2.8005\n",
      "Iteration 189650: loss = 2.6769\n",
      "Iteration 189660: loss = 2.3917\n",
      "Iteration 189670: loss = 2.5815\n",
      "Iteration 189680: loss = 2.3083\n",
      "Iteration 189690: loss = 2.6395\n",
      "Iteration 189700: loss = 2.3381\n",
      "Iteration 189710: loss = 2.0464\n",
      "Iteration 189720: loss = 2.5310\n",
      "Iteration 189730: loss = 2.3565\n",
      "Iteration 189740: loss = 2.6885\n",
      "Iteration 189750: loss = 2.4879\n",
      "Iteration 189760: loss = 2.1889\n",
      "Iteration 189770: loss = 2.6326\n",
      "Iteration 189780: loss = 2.4431\n",
      "Iteration 189790: loss = 2.9259\n",
      "Iteration 189800: loss = 2.2489\n",
      "Iteration 189810: loss = 2.4129\n",
      "Iteration 189820: loss = 2.2500\n",
      "Iteration 189830: loss = 2.1462\n",
      "Iteration 189840: loss = 2.5173\n",
      "Iteration 189850: loss = 2.6295\n",
      "Iteration 189860: loss = 2.5258\n",
      "Iteration 189870: loss = 2.4151\n",
      "Iteration 189880: loss = 2.5622\n",
      "Iteration 189890: loss = 2.6363\n",
      "Iteration 189900: loss = 2.4065\n",
      "Iteration 189910: loss = 2.3957\n",
      "Iteration 189920: loss = 2.5897\n",
      "Iteration 189930: loss = 2.4015\n",
      "Iteration 189940: loss = 2.4302\n",
      "Iteration 189950: loss = 2.2892\n",
      "Iteration 189960: loss = 2.8074\n",
      "Iteration 189970: loss = 2.1923\n",
      "Iteration 189980: loss = 2.5637\n",
      "Iteration 189990: loss = 2.3668\n",
      "Iteration 190000: loss = 2.1322\n",
      "Iteration 190010: loss = 2.4847\n",
      "Iteration 190020: loss = 2.1144\n",
      "Iteration 190030: loss = 2.8932\n",
      "Iteration 190040: loss = 2.3707\n",
      "Iteration 190050: loss = 2.2933\n",
      "Iteration 190060: loss = 2.7193\n",
      "Iteration 190070: loss = 2.3157\n",
      "Iteration 190080: loss = 2.9586\n",
      "Iteration 190090: loss = 2.2809\n",
      "Iteration 190100: loss = 2.2349\n",
      "Iteration 190110: loss = 2.7099\n",
      "Iteration 190120: loss = 2.2147\n",
      "Iteration 190130: loss = 2.3606\n",
      "Iteration 190140: loss = 2.3963\n",
      "Iteration 190150: loss = 2.4109\n",
      "Iteration 190160: loss = 2.3170\n",
      "Iteration 190170: loss = 2.3188\n",
      "Iteration 190180: loss = 2.5733\n",
      "Iteration 190190: loss = 2.4295\n",
      "Iteration 190200: loss = 2.5308\n",
      "Iteration 190210: loss = 2.3020\n",
      "Iteration 190220: loss = 2.4265\n",
      "Iteration 190230: loss = 2.1144\n",
      "Iteration 190240: loss = 2.4719\n",
      "Iteration 190250: loss = 2.2107\n",
      "Iteration 190260: loss = 2.1130\n",
      "Iteration 190270: loss = 2.8280\n",
      "Iteration 190280: loss = 2.0088\n",
      "Iteration 190290: loss = 2.5984\n",
      "Iteration 190300: loss = 2.4886\n",
      "Iteration 190310: loss = 2.6236\n",
      "Iteration 190320: loss = 2.1990\n",
      "Iteration 190330: loss = 2.2977\n",
      "Iteration 190340: loss = 2.2209\n",
      "Iteration 190350: loss = 2.5285\n",
      "Iteration 190360: loss = 2.2760\n",
      "Iteration 190370: loss = 2.2192\n",
      "Iteration 190380: loss = 2.2901\n",
      "Iteration 190390: loss = 2.6030\n",
      "Iteration 190400: loss = 2.4209\n",
      "Iteration 190410: loss = 2.7008\n",
      "Iteration 190420: loss = 2.3375\n",
      "Iteration 190430: loss = 2.4687\n",
      "Iteration 190440: loss = 2.4344\n",
      "Iteration 190450: loss = 2.4434\n",
      "Iteration 190460: loss = 2.5991\n",
      "Iteration 190470: loss = 2.5687\n",
      "Iteration 190480: loss = 2.6969\n",
      "Iteration 190490: loss = 2.2365\n",
      "Iteration 190500: loss = 2.6506\n",
      "Iteration 190510: loss = 2.4386\n",
      "Iteration 190520: loss = 2.3398\n",
      "Iteration 190530: loss = 2.6034\n",
      "Iteration 190540: loss = 2.2544\n",
      "Iteration 190550: loss = 2.6089\n",
      "Iteration 190560: loss = 2.1337\n",
      "Iteration 190570: loss = 2.3070\n",
      "Iteration 190580: loss = 2.3601\n",
      "Iteration 190590: loss = 2.0304\n",
      "Iteration 190600: loss = 2.2184\n",
      "Iteration 190610: loss = 2.4888\n",
      "Iteration 190620: loss = 2.3215\n",
      "Iteration 190630: loss = 1.9982\n",
      "Iteration 190640: loss = 2.6506\n",
      "Iteration 190650: loss = 2.5257\n",
      "Iteration 190660: loss = 2.4084\n",
      "Iteration 190670: loss = 2.8503\n",
      "Iteration 190680: loss = 2.3155\n",
      "Iteration 190690: loss = 2.2375\n",
      "Iteration 190700: loss = 2.9292\n",
      "Iteration 190710: loss = 2.5459\n",
      "Iteration 190720: loss = 2.5530\n",
      "Iteration 190730: loss = 2.7081\n",
      "Iteration 190740: loss = 2.4957\n",
      "Iteration 190750: loss = 2.1482\n",
      "Iteration 190760: loss = 2.3519\n",
      "Iteration 190770: loss = 2.6054\n",
      "Iteration 190780: loss = 2.4893\n",
      "Iteration 190790: loss = 2.4960\n",
      "Iteration 190800: loss = 2.2426\n",
      "Iteration 190810: loss = 2.1205\n",
      "Iteration 190820: loss = 2.4191\n",
      "Iteration 190830: loss = 2.2902\n",
      "Iteration 190840: loss = 2.5162\n",
      "Iteration 190850: loss = 2.2405\n",
      "Iteration 190860: loss = 2.0602\n",
      "Iteration 190870: loss = 2.2278\n",
      "Iteration 190880: loss = 2.8728\n",
      "Iteration 190890: loss = 2.7443\n",
      "Iteration 190900: loss = 2.3154\n",
      "Iteration 190910: loss = 2.0678\n",
      "Iteration 190920: loss = 2.2660\n",
      "Iteration 190930: loss = 2.7792\n",
      "Iteration 190940: loss = 2.6205\n",
      "Iteration 190950: loss = 2.3573\n",
      "Iteration 190960: loss = 2.7359\n",
      "Iteration 190970: loss = 2.2261\n",
      "Iteration 190980: loss = 1.9684\n",
      "Iteration 190990: loss = 2.3131\n",
      "Iteration 191000: loss = 2.6367\n",
      "Iteration 191010: loss = 2.9290\n",
      "Iteration 191020: loss = 2.3601\n",
      "Iteration 191030: loss = 2.2271\n",
      "Iteration 191040: loss = 2.0527\n",
      "Iteration 191050: loss = 2.4603\n",
      "Iteration 191060: loss = 2.5176\n",
      "Iteration 191070: loss = 2.5597\n",
      "Iteration 191080: loss = 2.4135\n",
      "Iteration 191090: loss = 2.5666\n",
      "Iteration 191100: loss = 2.0692\n",
      "Iteration 191110: loss = 2.4931\n",
      "Iteration 191120: loss = 2.8303\n",
      "Iteration 191130: loss = 2.4994\n",
      "Iteration 191140: loss = 2.2407\n",
      "Iteration 191150: loss = 2.5436\n",
      "Iteration 191160: loss = 2.3798\n",
      "Iteration 191170: loss = 2.3313\n",
      "Iteration 191180: loss = 2.3129\n",
      "Iteration 191190: loss = 2.3792\n",
      "Iteration 191200: loss = 2.4123\n",
      "Iteration 191210: loss = 2.5379\n",
      "Iteration 191220: loss = 2.4571\n",
      "Iteration 191230: loss = 2.5638\n",
      "Iteration 191240: loss = 2.7180\n",
      "Iteration 191250: loss = 2.3208\n",
      "Iteration 191260: loss = 2.3856\n",
      "Iteration 191270: loss = 2.6803\n",
      "Iteration 191280: loss = 2.2894\n",
      "Iteration 191290: loss = 2.5230\n",
      "Iteration 191300: loss = 2.2612\n",
      "Iteration 191310: loss = 2.3925\n",
      "Iteration 191320: loss = 2.3927\n",
      "Iteration 191330: loss = 2.5176\n",
      "Iteration 191340: loss = 2.4953\n",
      "Iteration 191350: loss = 2.5177\n",
      "Iteration 191360: loss = 2.1283\n",
      "Iteration 191370: loss = 2.7083\n",
      "Iteration 191380: loss = 2.4294\n",
      "Iteration 191390: loss = 2.3891\n",
      "Iteration 191400: loss = 2.2394\n",
      "Iteration 191410: loss = 2.5108\n",
      "Iteration 191420: loss = 2.3850\n",
      "Iteration 191430: loss = 2.1848\n",
      "Iteration 191440: loss = 2.3411\n",
      "Iteration 191450: loss = 2.7652\n",
      "Iteration 191460: loss = 2.2811\n",
      "Iteration 191470: loss = 2.4462\n",
      "Iteration 191480: loss = 2.2722\n",
      "Iteration 191490: loss = 2.3035\n",
      "Iteration 191500: loss = 2.3206\n",
      "Iteration 191510: loss = 2.7667\n",
      "Iteration 191520: loss = 2.5568\n",
      "Iteration 191530: loss = 2.4655\n",
      "Iteration 191540: loss = 2.1003\n",
      "Iteration 191550: loss = 2.7600\n",
      "Iteration 191560: loss = 2.3313\n",
      "Iteration 191570: loss = 2.5485\n",
      "Iteration 191580: loss = 2.3331\n",
      "Iteration 191590: loss = 2.8087\n",
      "Iteration 191600: loss = 2.4288\n",
      "Iteration 191610: loss = 2.4534\n",
      "Iteration 191620: loss = 2.8375\n",
      "Iteration 191630: loss = 2.1818\n",
      "Iteration 191640: loss = 2.2715\n",
      "Iteration 191650: loss = 2.4741\n",
      "Iteration 191660: loss = 2.2818\n",
      "Iteration 191670: loss = 2.1197\n",
      "Iteration 191680: loss = 2.3744\n",
      "Iteration 191690: loss = 2.3409\n",
      "Iteration 191700: loss = 2.6767\n",
      "Iteration 191710: loss = 2.3050\n",
      "Iteration 191720: loss = 2.4596\n",
      "Iteration 191730: loss = 2.0637\n",
      "Iteration 191740: loss = 2.3523\n",
      "Iteration 191750: loss = 2.1297\n",
      "Iteration 191760: loss = 2.2033\n",
      "Iteration 191770: loss = 2.6440\n",
      "Iteration 191780: loss = 2.4364\n",
      "Iteration 191790: loss = 2.2325\n",
      "Iteration 191800: loss = 2.7413\n",
      "Iteration 191810: loss = 2.2690\n",
      "Iteration 191820: loss = 2.4016\n",
      "Iteration 191830: loss = 2.6424\n",
      "Iteration 191840: loss = 2.5461\n",
      "Iteration 191850: loss = 2.4169\n",
      "Iteration 191860: loss = 2.4624\n",
      "Iteration 191870: loss = 2.6859\n",
      "Iteration 191880: loss = 2.7890\n",
      "Iteration 191890: loss = 2.5619\n",
      "Iteration 191900: loss = 2.2832\n",
      "Iteration 191910: loss = 2.3306\n",
      "Iteration 191920: loss = 2.5829\n",
      "Iteration 191930: loss = 2.6740\n",
      "Iteration 191940: loss = 2.3070\n",
      "Iteration 191950: loss = 2.4965\n",
      "Iteration 191960: loss = 2.4548\n",
      "Iteration 191970: loss = 2.0033\n",
      "Iteration 191980: loss = 2.4194\n",
      "Iteration 191990: loss = 2.3378\n",
      "Iteration 192000: loss = 2.5106\n",
      "Iteration 192010: loss = 2.4795\n",
      "Iteration 192020: loss = 2.4740\n",
      "Iteration 192030: loss = 2.7621\n",
      "Iteration 192040: loss = 2.3205\n",
      "Iteration 192050: loss = 2.1318\n",
      "Iteration 192060: loss = 2.7065\n",
      "Iteration 192070: loss = 2.0491\n",
      "Iteration 192080: loss = 2.3830\n",
      "Iteration 192090: loss = 2.6463\n",
      "Iteration 192100: loss = 2.3480\n",
      "Iteration 192110: loss = 2.4334\n",
      "Iteration 192120: loss = 2.3700\n",
      "Iteration 192130: loss = 2.2566\n",
      "Iteration 192140: loss = 3.0358\n",
      "Iteration 192150: loss = 2.6799\n",
      "Iteration 192160: loss = 2.4746\n",
      "Iteration 192170: loss = 2.2858\n",
      "Iteration 192180: loss = 2.5183\n",
      "Iteration 192190: loss = 2.0703\n",
      "Iteration 192200: loss = 2.4945\n",
      "Iteration 192210: loss = 2.2809\n",
      "Iteration 192220: loss = 2.3700\n",
      "Iteration 192230: loss = 2.4604\n",
      "Iteration 192240: loss = 2.3683\n",
      "Iteration 192250: loss = 2.3062\n",
      "Iteration 192260: loss = 2.5755\n",
      "Iteration 192270: loss = 2.1591\n",
      "Iteration 192280: loss = 2.5261\n",
      "Iteration 192290: loss = 2.5760\n",
      "Iteration 192300: loss = 2.1695\n",
      "Iteration 192310: loss = 2.2670\n",
      "Iteration 192320: loss = 2.4660\n",
      "Iteration 192330: loss = 2.0211\n",
      "Iteration 192340: loss = 2.1391\n",
      "Iteration 192350: loss = 2.7965\n",
      "Iteration 192360: loss = 2.3828\n",
      "Iteration 192370: loss = 2.8292\n",
      "Iteration 192380: loss = 2.5732\n",
      "Iteration 192390: loss = 2.7218\n",
      "Iteration 192400: loss = 2.4581\n",
      "Iteration 192410: loss = 2.0360\n",
      "Iteration 192420: loss = 2.4567\n",
      "Iteration 192430: loss = 2.5168\n",
      "Iteration 192440: loss = 1.7318\n",
      "Iteration 192450: loss = 2.0119\n",
      "Iteration 192460: loss = 2.4527\n",
      "Iteration 192470: loss = 2.6313\n",
      "Iteration 192480: loss = 2.4346\n",
      "Iteration 192490: loss = 2.1937\n",
      "Iteration 192500: loss = 2.0581\n",
      "Iteration 192510: loss = 2.4771\n",
      "Iteration 192520: loss = 2.6388\n",
      "Iteration 192530: loss = 2.1510\n",
      "Iteration 192540: loss = 2.4662\n",
      "Iteration 192550: loss = 2.2782\n",
      "Iteration 192560: loss = 2.0219\n",
      "Iteration 192570: loss = 2.3031\n",
      "Iteration 192580: loss = 2.7913\n",
      "Iteration 192590: loss = 2.6242\n",
      "Iteration 192600: loss = 2.4399\n",
      "Iteration 192610: loss = 2.8606\n",
      "Iteration 192620: loss = 2.1912\n",
      "Iteration 192630: loss = 2.5041\n",
      "Iteration 192640: loss = 2.6317\n",
      "Iteration 192650: loss = 2.3234\n",
      "Iteration 192660: loss = 2.6247\n",
      "Iteration 192670: loss = 2.4064\n",
      "Iteration 192680: loss = 2.0737\n",
      "Iteration 192690: loss = 2.4012\n",
      "Iteration 192700: loss = 2.3362\n",
      "Iteration 192710: loss = 2.3941\n",
      "Iteration 192720: loss = 2.4387\n",
      "Iteration 192730: loss = 2.6066\n",
      "Iteration 192740: loss = 2.5430\n",
      "Iteration 192750: loss = 2.4824\n",
      "Iteration 192760: loss = 2.3926\n",
      "Iteration 192770: loss = 2.4013\n",
      "Iteration 192780: loss = 2.4696\n",
      "Iteration 192790: loss = 2.4054\n",
      "Iteration 192800: loss = 2.2215\n",
      "Iteration 192810: loss = 2.3612\n",
      "Iteration 192820: loss = 2.1739\n",
      "Iteration 192830: loss = 2.3936\n",
      "Iteration 192840: loss = 2.5129\n",
      "Iteration 192850: loss = 2.2698\n",
      "Iteration 192860: loss = 2.5183\n",
      "Iteration 192870: loss = 3.0491\n",
      "Iteration 192880: loss = 2.1918\n",
      "Iteration 192890: loss = 2.4477\n",
      "Iteration 192900: loss = 2.5505\n",
      "Iteration 192910: loss = 2.1256\n",
      "Iteration 192920: loss = 2.5002\n",
      "Iteration 192930: loss = 2.4828\n",
      "Iteration 192940: loss = 2.4813\n",
      "Iteration 192950: loss = 2.5505\n",
      "Iteration 192960: loss = 2.9721\n",
      "Iteration 192970: loss = 2.2459\n",
      "Iteration 192980: loss = 2.4704\n",
      "Iteration 192990: loss = 2.1476\n",
      "Iteration 193000: loss = 2.4106\n",
      "Iteration 193010: loss = 1.9579\n",
      "Iteration 193020: loss = 2.5254\n",
      "Iteration 193030: loss = 2.0028\n",
      "Iteration 193040: loss = 2.3575\n",
      "Iteration 193050: loss = 2.5249\n",
      "Iteration 193060: loss = 2.4704\n",
      "Iteration 193070: loss = 2.4372\n",
      "Iteration 193080: loss = 2.3137\n",
      "Iteration 193090: loss = 2.5709\n",
      "Iteration 193100: loss = 2.6992\n",
      "Iteration 193110: loss = 2.1130\n",
      "Iteration 193120: loss = 2.1245\n",
      "Iteration 193130: loss = 2.1381\n",
      "Iteration 193140: loss = 2.7783\n",
      "Iteration 193150: loss = 2.4474\n",
      "Iteration 193160: loss = 2.4470\n",
      "Iteration 193170: loss = 2.3927\n",
      "Iteration 193180: loss = 2.2164\n",
      "Iteration 193190: loss = 2.6541\n",
      "Iteration 193200: loss = 2.7361\n",
      "Iteration 193210: loss = 2.3973\n",
      "Iteration 193220: loss = 2.2839\n",
      "Iteration 193230: loss = 2.1765\n",
      "Iteration 193240: loss = 2.1399\n",
      "Iteration 193250: loss = 2.4084\n",
      "Iteration 193260: loss = 2.3666\n",
      "Iteration 193270: loss = 2.3243\n",
      "Iteration 193280: loss = 2.4054\n",
      "Iteration 193290: loss = 2.5907\n",
      "Iteration 193300: loss = 2.2800\n",
      "Iteration 193310: loss = 1.9468\n",
      "Iteration 193320: loss = 2.1570\n",
      "Iteration 193330: loss = 3.0457\n",
      "Iteration 193340: loss = 2.8201\n",
      "Iteration 193350: loss = 2.1413\n",
      "Iteration 193360: loss = 2.7528\n",
      "Iteration 193370: loss = 2.2656\n",
      "Iteration 193380: loss = 2.6514\n",
      "Iteration 193390: loss = 2.6769\n",
      "Iteration 193400: loss = 2.5465\n",
      "Iteration 193410: loss = 2.5436\n",
      "Iteration 193420: loss = 2.8374\n",
      "Iteration 193430: loss = 2.6316\n",
      "Iteration 193440: loss = 2.6593\n",
      "Iteration 193450: loss = 2.3474\n",
      "Iteration 193460: loss = 2.3479\n",
      "Iteration 193470: loss = 2.1290\n",
      "Iteration 193480: loss = 2.8103\n",
      "Iteration 193490: loss = 2.2424\n",
      "Iteration 193500: loss = 2.2545\n",
      "Iteration 193510: loss = 2.2380\n",
      "Iteration 193520: loss = 2.5462\n",
      "Iteration 193530: loss = 2.8528\n",
      "Iteration 193540: loss = 2.5811\n",
      "Iteration 193550: loss = 2.7651\n",
      "Iteration 193560: loss = 2.4794\n",
      "Iteration 193570: loss = 2.7767\n",
      "Iteration 193580: loss = 1.9517\n",
      "Iteration 193590: loss = 2.7557\n",
      "Iteration 193600: loss = 2.3613\n",
      "Iteration 193610: loss = 2.1772\n",
      "Iteration 193620: loss = 2.9692\n",
      "Iteration 193630: loss = 2.2951\n",
      "Iteration 193640: loss = 2.6387\n",
      "Iteration 193650: loss = 2.4551\n",
      "Iteration 193660: loss = 2.8785\n",
      "Iteration 193670: loss = 2.2556\n",
      "Iteration 193680: loss = 2.3956\n",
      "Iteration 193690: loss = 2.9449\n",
      "Iteration 193700: loss = 2.2614\n",
      "Iteration 193710: loss = 2.2936\n",
      "Iteration 193720: loss = 2.4698\n",
      "Iteration 193730: loss = 2.5469\n",
      "Iteration 193740: loss = 2.5252\n",
      "Iteration 193750: loss = 2.6926\n",
      "Iteration 193760: loss = 2.4656\n",
      "Iteration 193770: loss = 2.7676\n",
      "Iteration 193780: loss = 2.6511\n",
      "Iteration 193790: loss = 2.5132\n",
      "Iteration 193800: loss = 2.6226\n",
      "Iteration 193810: loss = 2.5598\n",
      "Iteration 193820: loss = 2.5793\n",
      "Iteration 193830: loss = 2.7699\n",
      "Iteration 193840: loss = 2.9713\n",
      "Iteration 193850: loss = 2.4940\n",
      "Iteration 193860: loss = 2.4366\n",
      "Iteration 193870: loss = 2.4985\n",
      "Iteration 193880: loss = 2.3355\n",
      "Iteration 193890: loss = 2.3672\n",
      "Iteration 193900: loss = 2.5759\n",
      "Iteration 193910: loss = 2.4128\n",
      "Iteration 193920: loss = 2.2541\n",
      "Iteration 193930: loss = 2.2583\n",
      "Iteration 193940: loss = 1.8485\n",
      "Iteration 193950: loss = 2.6151\n",
      "Iteration 193960: loss = 2.1760\n",
      "Iteration 193970: loss = 2.2643\n",
      "Iteration 193980: loss = 2.1822\n",
      "Iteration 193990: loss = 2.2876\n",
      "Iteration 194000: loss = 2.1845\n",
      "Iteration 194010: loss = 2.2336\n",
      "Iteration 194020: loss = 2.4031\n",
      "Iteration 194030: loss = 2.3831\n",
      "Iteration 194040: loss = 2.5118\n",
      "Iteration 194050: loss = 2.5357\n",
      "Iteration 194060: loss = 2.4455\n",
      "Iteration 194070: loss = 2.4730\n",
      "Iteration 194080: loss = 2.4816\n",
      "Iteration 194090: loss = 2.5558\n",
      "Iteration 194100: loss = 2.0885\n",
      "Iteration 194110: loss = 2.0903\n",
      "Iteration 194120: loss = 2.0773\n",
      "Iteration 194130: loss = 2.5047\n",
      "Iteration 194140: loss = 2.3391\n",
      "Iteration 194150: loss = 2.2313\n",
      "Iteration 194160: loss = 2.7296\n",
      "Iteration 194170: loss = 2.3995\n",
      "Iteration 194180: loss = 2.4870\n",
      "Iteration 194190: loss = 2.3581\n",
      "Iteration 194200: loss = 2.3416\n",
      "Iteration 194210: loss = 2.2883\n",
      "Iteration 194220: loss = 2.2529\n",
      "Iteration 194230: loss = 2.2834\n",
      "Iteration 194240: loss = 2.6055\n",
      "Iteration 194250: loss = 2.6180\n",
      "Iteration 194260: loss = 2.5900\n",
      "Iteration 194270: loss = 2.4818\n",
      "Iteration 194280: loss = 2.7375\n",
      "Iteration 194290: loss = 2.4442\n",
      "Iteration 194300: loss = 2.1944\n",
      "Iteration 194310: loss = 2.3805\n",
      "Iteration 194320: loss = 1.7523\n",
      "Iteration 194330: loss = 2.3980\n",
      "Iteration 194340: loss = 2.3143\n",
      "Iteration 194350: loss = 2.3343\n",
      "Iteration 194360: loss = 2.4413\n",
      "Iteration 194370: loss = 2.5111\n",
      "Iteration 194380: loss = 2.6747\n",
      "Iteration 194390: loss = 2.6980\n",
      "Iteration 194400: loss = 2.1909\n",
      "Iteration 194410: loss = 2.3631\n",
      "Iteration 194420: loss = 2.9197\n",
      "Iteration 194430: loss = 2.4109\n",
      "Iteration 194440: loss = 2.1816\n",
      "Iteration 194450: loss = 2.0575\n",
      "Iteration 194460: loss = 2.4549\n",
      "Iteration 194470: loss = 2.2231\n",
      "Iteration 194480: loss = 2.5115\n",
      "Iteration 194490: loss = 2.1931\n",
      "Iteration 194500: loss = 2.1588\n",
      "Iteration 194510: loss = 2.0260\n",
      "Iteration 194520: loss = 2.2223\n",
      "Iteration 194530: loss = 2.4933\n",
      "Iteration 194540: loss = 2.4543\n",
      "Iteration 194550: loss = 2.7189\n",
      "Iteration 194560: loss = 2.3324\n",
      "Iteration 194570: loss = 2.2440\n",
      "Iteration 194580: loss = 2.2914\n",
      "Iteration 194590: loss = 2.6378\n",
      "Iteration 194600: loss = 2.5902\n",
      "Iteration 194610: loss = 2.5470\n",
      "Iteration 194620: loss = 2.0934\n",
      "Iteration 194630: loss = 2.4582\n",
      "Iteration 194640: loss = 2.1946\n",
      "Iteration 194650: loss = 2.1100\n",
      "Iteration 194660: loss = 2.6024\n",
      "Iteration 194670: loss = 2.6593\n",
      "Iteration 194680: loss = 1.9814\n",
      "Iteration 194690: loss = 2.4108\n",
      "Iteration 194700: loss = 2.6069\n",
      "Iteration 194710: loss = 2.4343\n",
      "Iteration 194720: loss = 1.9721\n",
      "Iteration 194730: loss = 2.2301\n",
      "Iteration 194740: loss = 2.0309\n",
      "Iteration 194750: loss = 2.5186\n",
      "Iteration 194760: loss = 2.6488\n",
      "Iteration 194770: loss = 2.4738\n",
      "Iteration 194780: loss = 2.8496\n",
      "Iteration 194790: loss = 2.3807\n",
      "Iteration 194800: loss = 2.2801\n",
      "Iteration 194810: loss = 2.8140\n",
      "Iteration 194820: loss = 2.2982\n",
      "Iteration 194830: loss = 2.5309\n",
      "Iteration 194840: loss = 2.3966\n",
      "Iteration 194850: loss = 2.3489\n",
      "Iteration 194860: loss = 2.6913\n",
      "Iteration 194870: loss = 2.4557\n",
      "Iteration 194880: loss = 2.5503\n",
      "Iteration 194890: loss = 2.4248\n",
      "Iteration 194900: loss = 2.2624\n",
      "Iteration 194910: loss = 2.4474\n",
      "Iteration 194920: loss = 2.2653\n",
      "Iteration 194930: loss = 2.0784\n",
      "Iteration 194940: loss = 2.4523\n",
      "Iteration 194950: loss = 2.5104\n",
      "Iteration 194960: loss = 2.6632\n",
      "Iteration 194970: loss = 2.3153\n",
      "Iteration 194980: loss = 2.6302\n",
      "Iteration 194990: loss = 2.8602\n",
      "Iteration 195000: loss = 2.3097\n",
      "Iteration 195010: loss = 2.4248\n",
      "Iteration 195020: loss = 2.4164\n",
      "Iteration 195030: loss = 2.6127\n",
      "Iteration 195040: loss = 2.1299\n",
      "Iteration 195050: loss = 2.4878\n",
      "Iteration 195060: loss = 2.2984\n",
      "Iteration 195070: loss = 2.3809\n",
      "Iteration 195080: loss = 2.1793\n",
      "Iteration 195090: loss = 2.6060\n",
      "Iteration 195100: loss = 2.4095\n",
      "Iteration 195110: loss = 2.6214\n",
      "Iteration 195120: loss = 2.4066\n",
      "Iteration 195130: loss = 2.3037\n",
      "Iteration 195140: loss = 2.5718\n",
      "Iteration 195150: loss = 2.4029\n",
      "Iteration 195160: loss = 2.7022\n",
      "Iteration 195170: loss = 2.2067\n",
      "Iteration 195180: loss = 2.3860\n",
      "Iteration 195190: loss = 2.1938\n",
      "Iteration 195200: loss = 2.0928\n",
      "Iteration 195210: loss = 2.3805\n",
      "Iteration 195220: loss = 2.4917\n",
      "Iteration 195230: loss = 2.0978\n",
      "Iteration 195240: loss = 2.1970\n",
      "Iteration 195250: loss = 2.8100\n",
      "Iteration 195260: loss = 2.1312\n",
      "Iteration 195270: loss = 2.0383\n",
      "Iteration 195280: loss = 2.5471\n",
      "Iteration 195290: loss = 2.3111\n",
      "Iteration 195300: loss = 2.0808\n",
      "Iteration 195310: loss = 2.4492\n",
      "Iteration 195320: loss = 2.6535\n",
      "Iteration 195330: loss = 2.2179\n",
      "Iteration 195340: loss = 2.2294\n",
      "Iteration 195350: loss = 2.3018\n",
      "Iteration 195360: loss = 2.5172\n",
      "Iteration 195370: loss = 2.5637\n",
      "Iteration 195380: loss = 2.6398\n",
      "Iteration 195390: loss = 2.4068\n",
      "Iteration 195400: loss = 2.4599\n",
      "Iteration 195410: loss = 2.7153\n",
      "Iteration 195420: loss = 2.3527\n",
      "Iteration 195430: loss = 2.3399\n",
      "Iteration 195440: loss = 2.5454\n",
      "Iteration 195450: loss = 2.5049\n",
      "Iteration 195460: loss = 2.1366\n",
      "Iteration 195470: loss = 2.4277\n",
      "Iteration 195480: loss = 2.5302\n",
      "Iteration 195490: loss = 2.3768\n",
      "Iteration 195500: loss = 2.3660\n",
      "Iteration 195510: loss = 2.4194\n",
      "Iteration 195520: loss = 2.1110\n",
      "Iteration 195530: loss = 2.3149\n",
      "Iteration 195540: loss = 2.2266\n",
      "Iteration 195550: loss = 2.4237\n",
      "Iteration 195560: loss = 2.5472\n",
      "Iteration 195570: loss = 2.5796\n",
      "Iteration 195580: loss = 2.6394\n",
      "Iteration 195590: loss = 2.3801\n",
      "Iteration 195600: loss = 2.7333\n",
      "Iteration 195610: loss = 2.1559\n",
      "Iteration 195620: loss = 2.2224\n",
      "Iteration 195630: loss = 2.4744\n",
      "Iteration 195640: loss = 2.1727\n",
      "Iteration 195650: loss = 2.4350\n",
      "Iteration 195660: loss = 2.1072\n",
      "Iteration 195670: loss = 2.1612\n",
      "Iteration 195680: loss = 2.6734\n",
      "Iteration 195690: loss = 2.5619\n",
      "Iteration 195700: loss = 2.6049\n",
      "Iteration 195710: loss = 2.4101\n",
      "Iteration 195720: loss = 2.2494\n",
      "Iteration 195730: loss = 2.5284\n",
      "Iteration 195740: loss = 2.5111\n",
      "Iteration 195750: loss = 2.1319\n",
      "Iteration 195760: loss = 2.2061\n",
      "Iteration 195770: loss = 2.3065\n",
      "Iteration 195780: loss = 2.3495\n",
      "Iteration 195790: loss = 2.4245\n",
      "Iteration 195800: loss = 2.2984\n",
      "Iteration 195810: loss = 2.3863\n",
      "Iteration 195820: loss = 2.3337\n",
      "Iteration 195830: loss = 1.7826\n",
      "Iteration 195840: loss = 2.5405\n",
      "Iteration 195850: loss = 2.5523\n",
      "Iteration 195860: loss = 2.4148\n",
      "Iteration 195870: loss = 2.6351\n",
      "Iteration 195880: loss = 2.2763\n",
      "Iteration 195890: loss = 2.4595\n",
      "Iteration 195900: loss = 1.7209\n",
      "Iteration 195910: loss = 2.4642\n",
      "Iteration 195920: loss = 1.8566\n",
      "Iteration 195930: loss = 2.2940\n",
      "Iteration 195940: loss = 2.3863\n",
      "Iteration 195950: loss = 2.2127\n",
      "Iteration 195960: loss = 2.6629\n",
      "Iteration 195970: loss = 2.5904\n",
      "Iteration 195980: loss = 2.2050\n",
      "Iteration 195990: loss = 2.6152\n",
      "Iteration 196000: loss = 2.2624\n",
      "Iteration 196010: loss = 2.6393\n",
      "Iteration 196020: loss = 2.4326\n",
      "Iteration 196030: loss = 2.1136\n",
      "Iteration 196040: loss = 2.7104\n",
      "Iteration 196050: loss = 3.2190\n",
      "Iteration 196060: loss = 1.9624\n",
      "Iteration 196070: loss = 2.3251\n",
      "Iteration 196080: loss = 2.3036\n",
      "Iteration 196090: loss = 2.4348\n",
      "Iteration 196100: loss = 2.6105\n",
      "Iteration 196110: loss = 2.3022\n",
      "Iteration 196120: loss = 2.6375\n",
      "Iteration 196130: loss = 2.5782\n",
      "Iteration 196140: loss = 2.1735\n",
      "Iteration 196150: loss = 3.0662\n",
      "Iteration 196160: loss = 2.2940\n",
      "Iteration 196170: loss = 2.4774\n",
      "Iteration 196180: loss = 2.1940\n",
      "Iteration 196190: loss = 2.2533\n",
      "Iteration 196200: loss = 2.2981\n",
      "Iteration 196210: loss = 2.3444\n",
      "Iteration 196220: loss = 2.5480\n",
      "Iteration 196230: loss = 2.5066\n",
      "Iteration 196240: loss = 2.4473\n",
      "Iteration 196250: loss = 2.3403\n",
      "Iteration 196260: loss = 2.5315\n",
      "Iteration 196270: loss = 2.0659\n",
      "Iteration 196280: loss = 2.2431\n",
      "Iteration 196290: loss = 2.4026\n",
      "Iteration 196300: loss = 2.4192\n",
      "Iteration 196310: loss = 2.3751\n",
      "Iteration 196320: loss = 2.8175\n",
      "Iteration 196330: loss = 2.3645\n",
      "Iteration 196340: loss = 2.8321\n",
      "Iteration 196350: loss = 2.0619\n",
      "Iteration 196360: loss = 2.0559\n",
      "Iteration 196370: loss = 2.1076\n",
      "Iteration 196380: loss = 2.7060\n",
      "Iteration 196390: loss = 2.3722\n",
      "Iteration 196400: loss = 2.6116\n",
      "Iteration 196410: loss = 2.4287\n",
      "Iteration 196420: loss = 2.5097\n",
      "Iteration 196430: loss = 2.2875\n",
      "Iteration 196440: loss = 2.4138\n",
      "Iteration 196450: loss = 2.2627\n",
      "Iteration 196460: loss = 2.5222\n",
      "Iteration 196470: loss = 2.3929\n",
      "Iteration 196480: loss = 2.8569\n",
      "Iteration 196490: loss = 2.0203\n",
      "Iteration 196500: loss = 2.2437\n",
      "Iteration 196510: loss = 2.0028\n",
      "Iteration 196520: loss = 2.7356\n",
      "Iteration 196530: loss = 3.1537\n",
      "Iteration 196540: loss = 2.4782\n",
      "Iteration 196550: loss = 2.1416\n",
      "Iteration 196560: loss = 2.3540\n",
      "Iteration 196570: loss = 2.2997\n",
      "Iteration 196580: loss = 2.4046\n",
      "Iteration 196590: loss = 2.4502\n",
      "Iteration 196600: loss = 2.6838\n",
      "Iteration 196610: loss = 2.1491\n",
      "Iteration 196620: loss = 2.4873\n",
      "Iteration 196630: loss = 2.5965\n",
      "Iteration 196640: loss = 2.6335\n",
      "Iteration 196650: loss = 2.7925\n",
      "Iteration 196660: loss = 2.4080\n",
      "Iteration 196670: loss = 2.4393\n",
      "Iteration 196680: loss = 2.3857\n",
      "Iteration 196690: loss = 2.7310\n",
      "Iteration 196700: loss = 2.4331\n",
      "Iteration 196710: loss = 1.9692\n",
      "Iteration 196720: loss = 2.6965\n",
      "Iteration 196730: loss = 2.3700\n",
      "Iteration 196740: loss = 2.5211\n",
      "Iteration 196750: loss = 2.3342\n",
      "Iteration 196760: loss = 2.4829\n",
      "Iteration 196770: loss = 2.4548\n",
      "Iteration 196780: loss = 2.5688\n",
      "Iteration 196790: loss = 2.4149\n",
      "Iteration 196800: loss = 2.6247\n",
      "Iteration 196810: loss = 2.1487\n",
      "Iteration 196820: loss = 2.2743\n",
      "Iteration 196830: loss = 2.4631\n",
      "Iteration 196840: loss = 2.1603\n",
      "Iteration 196850: loss = 2.1233\n",
      "Iteration 196860: loss = 2.3107\n",
      "Iteration 196870: loss = 2.7913\n",
      "Iteration 196880: loss = 2.1650\n",
      "Iteration 196890: loss = 2.2372\n",
      "Iteration 196900: loss = 2.4389\n",
      "Iteration 196910: loss = 2.2475\n",
      "Iteration 196920: loss = 3.1185\n",
      "Iteration 196930: loss = 2.2759\n",
      "Iteration 196940: loss = 2.1418\n",
      "Iteration 196950: loss = 2.3052\n",
      "Iteration 196960: loss = 2.7497\n",
      "Iteration 196970: loss = 2.3143\n",
      "Iteration 196980: loss = 2.0403\n",
      "Iteration 196990: loss = 2.1495\n",
      "Iteration 197000: loss = 2.1491\n",
      "Iteration 197010: loss = 2.6931\n",
      "Iteration 197020: loss = 2.2978\n",
      "Iteration 197030: loss = 2.1904\n",
      "Iteration 197040: loss = 2.4105\n",
      "Iteration 197050: loss = 2.5603\n",
      "Iteration 197060: loss = 2.3544\n",
      "Iteration 197070: loss = 2.5073\n",
      "Iteration 197080: loss = 2.0966\n",
      "Iteration 197090: loss = 3.1279\n",
      "Iteration 197100: loss = 2.3979\n",
      "Iteration 197110: loss = 1.8468\n",
      "Iteration 197120: loss = 2.4502\n",
      "Iteration 197130: loss = 2.0490\n",
      "Iteration 197140: loss = 2.1217\n",
      "Iteration 197150: loss = 2.4499\n",
      "Iteration 197160: loss = 2.1364\n",
      "Iteration 197170: loss = 2.4313\n",
      "Iteration 197180: loss = 2.9648\n",
      "Iteration 197190: loss = 2.1767\n",
      "Iteration 197200: loss = 2.4257\n",
      "Iteration 197210: loss = 2.5752\n",
      "Iteration 197220: loss = 2.4156\n",
      "Iteration 197230: loss = 2.8002\n",
      "Iteration 197240: loss = 2.6013\n",
      "Iteration 197250: loss = 2.4223\n",
      "Iteration 197260: loss = 2.6357\n",
      "Iteration 197270: loss = 2.4215\n",
      "Iteration 197280: loss = 2.5108\n",
      "Iteration 197290: loss = 2.5352\n",
      "Iteration 197300: loss = 2.4830\n",
      "Iteration 197310: loss = 2.1535\n",
      "Iteration 197320: loss = 2.2816\n",
      "Iteration 197330: loss = 2.2841\n",
      "Iteration 197340: loss = 2.6173\n",
      "Iteration 197350: loss = 2.4559\n",
      "Iteration 197360: loss = 2.2015\n",
      "Iteration 197370: loss = 2.4879\n",
      "Iteration 197380: loss = 2.6360\n",
      "Iteration 197390: loss = 2.4219\n",
      "Iteration 197400: loss = 2.4320\n",
      "Iteration 197410: loss = 2.5920\n",
      "Iteration 197420: loss = 2.0567\n",
      "Iteration 197430: loss = 2.4217\n",
      "Iteration 197440: loss = 2.7796\n",
      "Iteration 197450: loss = 2.2037\n",
      "Iteration 197460: loss = 2.4080\n",
      "Iteration 197470: loss = 2.4698\n",
      "Iteration 197480: loss = 2.4838\n",
      "Iteration 197490: loss = 2.5014\n",
      "Iteration 197500: loss = 2.6129\n",
      "Iteration 197510: loss = 2.1798\n",
      "Iteration 197520: loss = 2.1837\n",
      "Iteration 197530: loss = 2.8250\n",
      "Iteration 197540: loss = 2.6901\n",
      "Iteration 197550: loss = 2.0528\n",
      "Iteration 197560: loss = 2.4452\n",
      "Iteration 197570: loss = 2.6761\n",
      "Iteration 197580: loss = 2.1524\n",
      "Iteration 197590: loss = 2.1715\n",
      "Iteration 197600: loss = 2.3744\n",
      "Iteration 197610: loss = 2.0282\n",
      "Iteration 197620: loss = 2.4447\n",
      "Iteration 197630: loss = 2.8273\n",
      "Iteration 197640: loss = 2.5973\n",
      "Iteration 197650: loss = 2.2276\n",
      "Iteration 197660: loss = 2.0841\n",
      "Iteration 197670: loss = 2.2689\n",
      "Iteration 197680: loss = 2.5150\n",
      "Iteration 197690: loss = 2.3783\n",
      "Iteration 197700: loss = 2.4917\n",
      "Iteration 197710: loss = 2.5545\n",
      "Iteration 197720: loss = 2.4379\n",
      "Iteration 197730: loss = 2.1955\n",
      "Iteration 197740: loss = 2.3646\n",
      "Iteration 197750: loss = 2.3775\n",
      "Iteration 197760: loss = 2.1321\n",
      "Iteration 197770: loss = 2.5909\n",
      "Iteration 197780: loss = 2.4778\n",
      "Iteration 197790: loss = 2.5205\n",
      "Iteration 197800: loss = 2.4696\n",
      "Iteration 197810: loss = 2.3966\n",
      "Iteration 197820: loss = 2.2571\n",
      "Iteration 197830: loss = 2.0977\n",
      "Iteration 197840: loss = 2.7927\n",
      "Iteration 197850: loss = 2.4225\n",
      "Iteration 197860: loss = 2.2837\n",
      "Iteration 197870: loss = 2.1053\n",
      "Iteration 197880: loss = 2.5441\n",
      "Iteration 197890: loss = 2.5064\n",
      "Iteration 197900: loss = 2.3747\n",
      "Iteration 197910: loss = 2.5880\n",
      "Iteration 197920: loss = 2.0397\n",
      "Iteration 197930: loss = 2.2761\n",
      "Iteration 197940: loss = 2.2891\n",
      "Iteration 197950: loss = 2.2573\n",
      "Iteration 197960: loss = 1.9054\n",
      "Iteration 197970: loss = 1.9476\n",
      "Iteration 197980: loss = 2.3446\n",
      "Iteration 197990: loss = 2.5584\n",
      "Iteration 198000: loss = 2.5712\n",
      "Iteration 198010: loss = 2.7019\n",
      "Iteration 198020: loss = 2.5436\n",
      "Iteration 198030: loss = 2.4257\n",
      "Iteration 198040: loss = 2.6141\n",
      "Iteration 198050: loss = 2.3398\n",
      "Iteration 198060: loss = 2.2483\n",
      "Iteration 198070: loss = 2.2539\n",
      "Iteration 198080: loss = 2.3613\n",
      "Iteration 198090: loss = 2.5599\n",
      "Iteration 198100: loss = 2.5642\n",
      "Iteration 198110: loss = 2.7835\n",
      "Iteration 198120: loss = 2.5310\n",
      "Iteration 198130: loss = 2.5575\n",
      "Iteration 198140: loss = 2.3131\n",
      "Iteration 198150: loss = 2.1632\n",
      "Iteration 198160: loss = 2.3359\n",
      "Iteration 198170: loss = 2.4439\n",
      "Iteration 198180: loss = 2.1541\n",
      "Iteration 198190: loss = 2.4271\n",
      "Iteration 198200: loss = 2.7383\n",
      "Iteration 198210: loss = 2.3756\n",
      "Iteration 198220: loss = 2.4837\n",
      "Iteration 198230: loss = 2.7584\n",
      "Iteration 198240: loss = 2.2077\n",
      "Iteration 198250: loss = 2.4017\n",
      "Iteration 198260: loss = 2.6979\n",
      "Iteration 198270: loss = 2.6933\n",
      "Iteration 198280: loss = 2.4286\n",
      "Iteration 198290: loss = 2.4860\n",
      "Iteration 198300: loss = 2.6488\n",
      "Iteration 198310: loss = 2.6599\n",
      "Iteration 198320: loss = 2.4284\n",
      "Iteration 198330: loss = 2.0672\n",
      "Iteration 198340: loss = 2.2966\n",
      "Iteration 198350: loss = 2.5022\n",
      "Iteration 198360: loss = 2.4565\n",
      "Iteration 198370: loss = 2.7022\n",
      "Iteration 198380: loss = 2.4306\n",
      "Iteration 198390: loss = 2.4362\n",
      "Iteration 198400: loss = 2.3977\n",
      "Iteration 198410: loss = 2.3023\n",
      "Iteration 198420: loss = 2.4865\n",
      "Iteration 198430: loss = 1.9217\n",
      "Iteration 198440: loss = 2.2057\n",
      "Iteration 198450: loss = 2.4182\n",
      "Iteration 198460: loss = 2.4029\n",
      "Iteration 198470: loss = 2.2465\n",
      "Iteration 198480: loss = 2.2774\n",
      "Iteration 198490: loss = 2.6480\n",
      "Iteration 198500: loss = 2.3041\n",
      "Iteration 198510: loss = 1.8799\n",
      "Iteration 198520: loss = 2.5371\n",
      "Iteration 198530: loss = 2.1035\n",
      "Iteration 198540: loss = 2.4413\n",
      "Iteration 198550: loss = 2.4070\n",
      "Iteration 198560: loss = 2.4707\n",
      "Iteration 198570: loss = 2.1587\n",
      "Iteration 198580: loss = 2.9148\n",
      "Iteration 198590: loss = 2.5479\n",
      "Iteration 198600: loss = 2.6575\n",
      "Iteration 198610: loss = 2.5812\n",
      "Iteration 198620: loss = 2.3475\n",
      "Iteration 198630: loss = 2.6569\n",
      "Iteration 198640: loss = 2.3165\n",
      "Iteration 198650: loss = 2.4977\n",
      "Iteration 198660: loss = 2.0838\n",
      "Iteration 198670: loss = 2.2890\n",
      "Iteration 198680: loss = 2.2381\n",
      "Iteration 198690: loss = 2.4815\n",
      "Iteration 198700: loss = 2.3064\n",
      "Iteration 198710: loss = 2.0750\n",
      "Iteration 198720: loss = 2.1678\n",
      "Iteration 198730: loss = 2.4811\n",
      "Iteration 198740: loss = 2.1100\n",
      "Iteration 198750: loss = 2.4778\n",
      "Iteration 198760: loss = 2.0569\n",
      "Iteration 198770: loss = 2.4971\n",
      "Iteration 198780: loss = 2.8461\n",
      "Iteration 198790: loss = 2.3619\n",
      "Iteration 198800: loss = 2.3835\n",
      "Iteration 198810: loss = 2.9497\n",
      "Iteration 198820: loss = 2.3082\n",
      "Iteration 198830: loss = 2.2070\n",
      "Iteration 198840: loss = 2.5138\n",
      "Iteration 198850: loss = 2.4131\n",
      "Iteration 198860: loss = 2.2078\n",
      "Iteration 198870: loss = 2.2634\n",
      "Iteration 198880: loss = 2.7274\n",
      "Iteration 198890: loss = 2.6429\n",
      "Iteration 198900: loss = 1.9272\n",
      "Iteration 198910: loss = 2.1996\n",
      "Iteration 198920: loss = 2.6256\n",
      "Iteration 198930: loss = 1.8743\n",
      "Iteration 198940: loss = 2.6395\n",
      "Iteration 198950: loss = 2.3138\n",
      "Iteration 198960: loss = 2.4060\n",
      "Iteration 198970: loss = 2.2396\n",
      "Iteration 198980: loss = 2.1021\n",
      "Iteration 198990: loss = 2.4621\n",
      "Iteration 199000: loss = 2.3938\n",
      "Iteration 199010: loss = 2.2601\n",
      "Iteration 199020: loss = 1.8038\n",
      "Iteration 199030: loss = 2.5921\n",
      "Iteration 199040: loss = 2.6250\n",
      "Iteration 199050: loss = 2.3556\n",
      "Iteration 199060: loss = 2.5432\n",
      "Iteration 199070: loss = 2.0951\n",
      "Iteration 199080: loss = 2.8136\n",
      "Iteration 199090: loss = 2.6733\n",
      "Iteration 199100: loss = 2.3834\n",
      "Iteration 199110: loss = 2.2309\n",
      "Iteration 199120: loss = 2.5824\n",
      "Iteration 199130: loss = 1.8499\n",
      "Iteration 199140: loss = 2.2673\n",
      "Iteration 199150: loss = 2.4134\n",
      "Iteration 199160: loss = 2.2302\n",
      "Iteration 199170: loss = 2.5880\n",
      "Iteration 199180: loss = 2.7391\n",
      "Iteration 199190: loss = 2.4777\n",
      "Iteration 199200: loss = 2.3549\n",
      "Iteration 199210: loss = 2.6868\n",
      "Iteration 199220: loss = 2.5627\n",
      "Iteration 199230: loss = 2.3950\n",
      "Iteration 199240: loss = 2.2896\n",
      "Iteration 199250: loss = 2.3945\n",
      "Iteration 199260: loss = 2.3044\n",
      "Iteration 199270: loss = 2.1264\n",
      "Iteration 199280: loss = 2.8100\n",
      "Iteration 199290: loss = 2.5104\n",
      "Iteration 199300: loss = 2.2062\n",
      "Iteration 199310: loss = 2.4724\n",
      "Iteration 199320: loss = 2.4523\n",
      "Iteration 199330: loss = 2.1483\n",
      "Iteration 199340: loss = 2.2299\n",
      "Iteration 199350: loss = 2.4087\n",
      "Iteration 199360: loss = 2.7354\n",
      "Iteration 199370: loss = 2.3576\n",
      "Iteration 199380: loss = 2.1219\n",
      "Iteration 199390: loss = 2.2253\n",
      "Iteration 199400: loss = 2.0815\n",
      "Iteration 199410: loss = 2.4201\n",
      "Iteration 199420: loss = 2.6975\n",
      "Iteration 199430: loss = 2.4069\n",
      "Iteration 199440: loss = 2.4209\n",
      "Iteration 199450: loss = 2.4862\n",
      "Iteration 199460: loss = 2.2807\n",
      "Iteration 199470: loss = 2.7274\n",
      "Iteration 199480: loss = 2.3740\n",
      "Iteration 199490: loss = 2.2366\n",
      "Iteration 199500: loss = 2.4305\n",
      "Iteration 199510: loss = 2.6864\n",
      "Iteration 199520: loss = 2.1383\n",
      "Iteration 199530: loss = 2.3993\n",
      "Iteration 199540: loss = 2.4922\n",
      "Iteration 199550: loss = 2.2922\n",
      "Iteration 199560: loss = 2.3228\n",
      "Iteration 199570: loss = 2.3667\n",
      "Iteration 199580: loss = 2.1855\n",
      "Iteration 199590: loss = 1.9904\n",
      "Iteration 199600: loss = 2.1321\n",
      "Iteration 199610: loss = 2.4472\n",
      "Iteration 199620: loss = 2.3050\n",
      "Iteration 199630: loss = 2.3432\n",
      "Iteration 199640: loss = 2.0694\n",
      "Iteration 199650: loss = 2.2017\n",
      "Iteration 199660: loss = 2.5200\n",
      "Iteration 199670: loss = 2.3492\n",
      "Iteration 199680: loss = 2.5496\n",
      "Iteration 199690: loss = 2.9308\n",
      "Iteration 199700: loss = 2.2473\n",
      "Iteration 199710: loss = 2.4178\n",
      "Iteration 199720: loss = 2.2497\n",
      "Iteration 199730: loss = 2.2333\n",
      "Iteration 199740: loss = 2.1346\n",
      "Iteration 199750: loss = 2.5429\n",
      "Iteration 199760: loss = 2.6834\n",
      "Iteration 199770: loss = 2.2910\n",
      "Iteration 199780: loss = 1.9381\n",
      "Iteration 199790: loss = 2.4161\n",
      "Iteration 199800: loss = 2.6827\n",
      "Iteration 199810: loss = 2.3390\n",
      "Iteration 199820: loss = 2.6943\n",
      "Iteration 199830: loss = 2.5949\n",
      "Iteration 199840: loss = 2.4512\n",
      "Iteration 199850: loss = 2.7363\n",
      "Iteration 199860: loss = 2.5164\n",
      "Iteration 199870: loss = 2.7657\n",
      "Iteration 199880: loss = 2.8308\n",
      "Iteration 199890: loss = 2.3956\n",
      "Iteration 199900: loss = 2.7319\n",
      "Iteration 199910: loss = 2.5237\n",
      "Iteration 199920: loss = 2.4053\n",
      "Iteration 199930: loss = 2.1461\n",
      "Iteration 199940: loss = 2.6964\n",
      "Iteration 199950: loss = 2.4474\n",
      "Iteration 199960: loss = 2.0150\n",
      "Iteration 199970: loss = 2.4953\n",
      "Iteration 199980: loss = 2.5233\n",
      "Iteration 199990: loss = 2.9539\n",
      "Training complete. Final loss: 2.0411\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "params, data = train(200_000, generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation (Dev) Loss\n",
    "\n",
    "After each training run or at checkpoint intervals, we measure the loss ***without updating the weights*** on **unseen** data inputs to see how well the model generalizes to unseen data.\n",
    "\n",
    "We use this loss to fine-tune the ``hyperparameters`` of the model: learning rate, number and size of hidden layers, regularization rate, embedding dimension size etc.\n",
    "\n",
    "We can use dev loss to decide when to stop training based on the following observations:\n",
    "\n",
    "1. A significant gap between training loss and dev loss indicates **overfitting**, meaning the model has memorized the training data but does not generalize well to new data. \n",
    "\n",
    "2. If both losses are high, the model is **underfitting** and needs more capacity or training.\n",
    "\n",
    "3. If both losses are close and small, the model is **generalizing well** and we have found a good balance between fitting the training data and generalizing to unseen data. At this point, we can stop training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare dev loss with trained loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dev_loss(\n",
    "    split_data: SplitData,\n",
    "    trained_params: Parameters,\n",
    ") -> float:\n",
    "    \"\"\"Compute the development loss without touching gradients.\"\"\"\n",
    "    X_dev, Y_dev, block_size = split_data.dev_data\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, loss = forward_pass(X_dev, Y_dev, trained_params, block_size)\n",
    "\n",
    "    print(f\"Dev loss: {loss.item()}\")\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev loss: 2.432872772216797\n"
     ]
    }
   ],
   "source": [
    "dev_loss = compute_dev_loss(data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Generation (Sampling)\n",
    "\n",
    "Generate new text by sampling from the trained model one character at a time.\n",
    "\n",
    "### Process:\n",
    "1. Start with a context of padding characters (index 0)\n",
    "2. Feed context through the network to get probability distribution over next characters\n",
    "3. Sample a character from this distribution\n",
    "4. Update context by appending the sampled character and removing the oldest\n",
    "5. Repeat until we sample the end-of-word token (.)\n",
    "\n",
    "The quality of generated text reflects how well the model learned character-level patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(\n",
    "    trained_params: Parameters, count: int, block_size: int, generator: torch.Generator\n",
    "):\n",
    "    C, W1, b1, W2, b2 = (\n",
    "        trained_params.C,\n",
    "        trained_params.W1,\n",
    "        trained_params.b1,\n",
    "        trained_params.W2,\n",
    "        trained_params.b2,\n",
    "    )\n",
    "\n",
    "    _, itos, _ = build_vocab_from_words()\n",
    "    for _ in range(count):\n",
    "        out = []\n",
    "        context = [0] * block_size\n",
    "        while True:\n",
    "            emb = C[torch.tensor([context])]  # [1, block_size, emb_dims]\n",
    "            h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "            logits = h @ W2 + b2\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            next_idx = torch.multinomial(probs, 1, True, generator=generator).item()\n",
    "            context = context[1:] + [next_idx]\n",
    "            out.append(next_idx)\n",
    "            if next_idx == 0:\n",
    "                break\n",
    "\n",
    "        print(\"\".join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aded.\n",
      "gened.\n",
      "nan.\n",
      "uls.\n",
      "bekders.\n",
      "squaring.\n",
      "exion.\n",
      "reny.\n",
      "dillong.\n",
      "iruking.\n",
      "ohhhhhhhhhhn.\n",
      "ile.\n",
      "fayh.\n",
      "halls.\n",
      "vandradows.\n",
      "ferego.\n",
      "bankers.\n",
      "feliskin.\n",
      "soker.\n",
      "etrikayendy.\n",
      "fuctions.\n",
      "bermikakiercation.\n",
      "regerde.\n",
      "heblime.\n",
      "ooeymecreomenteet.\n",
      "onamake.\n",
      "leys.\n",
      "jand.\n",
      "focevoulawlo.\n",
      "shits.\n",
      "doyeced.\n",
      "gaide.\n",
      "hattizin.\n",
      "swailetapling.\n",
      "locked.\n",
      "woochedlowed.\n",
      "somed.\n",
      "skin.\n",
      "eccoppund.\n",
      "excing.\n",
      "coll.\n",
      "usumm.\n",
      "dicangund.\n",
      "perterinahahahardia.\n",
      "tehotopic.\n",
      "blans.\n",
      "crights.\n",
      "bried.\n",
      "fick.\n",
      "scalonosedidan.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(SAMPLE_SEED + 10)\n",
    "\n",
    "examples = 50\n",
    "\n",
    "sample_from_model(params, examples, BLOCK_SIZE, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Finding the Optimal Learning Rate\n",
    "\n",
    "This experiment uses a **learning rate range test** to identify the best initial learning rate for training.\n",
    "\n",
    "### Method:\n",
    "- Start with a small learning rate (10⁻³ or 10⁻²) and gradually increase it to 1.0\n",
    "- Train for a fixed number of iterations, updating the learning rate at each step\n",
    "- Plot loss vs learning rate to find the region where loss decreases fastest\n",
    "\n",
    "### Goal:\n",
    "Find the learning rate that:\n",
    "1. Decreases loss quickly (steep negative slope)\n",
    "2. Remains stable (doesn't cause divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 30_000\n",
    "\n",
    "# Build vocabulary and dataset.\n",
    "stoi, itos, words = build_vocab_from_words()\n",
    "vocab_size = len(stoi)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Build training dataset from all words.\n",
    "X, Y, block_size = build_dataset(words, stoi)\n",
    "print(f\"Dataset shape: X={X.shape}, Y={Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss vs learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "# Initialize network parameters.\n",
    "params = initialize_parameters(vocab_size, block_size, generator=generator)\n",
    "\n",
    "n_params = sum(p.nelement() for p in params.parameters)\n",
    "print(\"Total paramters:\", n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learning rate exponents from -2 to 0 with 1000 points\n",
    "lre = torch.linspace(-2, 0, iterations)\n",
    "# Convert exponents to actual learning rates (10^lre)\n",
    "lrs = 10**lre\n",
    "\n",
    "# Initialize lists to track learning rates and losses during training\n",
    "lr_x = []\n",
    "loss_y = []\n",
    "\n",
    "batch_generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "# Training loop.\n",
    "for i in range(iterations):\n",
    "    # mini batch construct\n",
    "    ix = torch.randint(0, X.shape[0], (BATCH_SIZE,), generator=batch_generator)\n",
    "\n",
    "    # extract the batches\n",
    "    X_batch, Y_batch = X[ix], Y[ix]\n",
    "\n",
    "    # Forward pass: compute predictions and loss with the mini batch of inputs\n",
    "    params, loss = forward_pass(X_batch, Y_batch, params, block_size)\n",
    "\n",
    "    lr = lrs[i]\n",
    "\n",
    "    # Print loss at specified intervals.\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: loss = {loss.item():.4f}, lr = {lr:.6f}\")\n",
    "\n",
    "    # Backward pass: compute gradients and update parameters.\n",
    "    backward_pass(list(params.parameters), loss, lr)\n",
    "\n",
    "    # track stats\n",
    "    lr_x.append(lr.item())\n",
    "    loss_y.append(loss.item())\n",
    "\n",
    "\n",
    "print(f\"Training complete. Final loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lr_x, loss_y)\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Learning Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss vs learning rate exponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize weights so Experiment 1b starts from the same point.\n",
    "generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "# Initialize network parameters.\n",
    "params = initialize_parameters(vocab_size, block_size, generator=generator)\n",
    "\n",
    "n_params = sum(p.nelement() for p in params.parameters)\n",
    "print(\"Total paramters:\", n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learning rate exponents from -3 to 0\n",
    "lre = torch.linspace(-3, 0, iterations)\n",
    "# Convert exponents to actual learning rates (10^exponent)\n",
    "lrs = 10**lre\n",
    "\n",
    "\n",
    "# Initialize lists to track learning rates and losses for plotting\n",
    "lr_x = []\n",
    "loss_y = []\n",
    "\n",
    "batch_generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "# Training loop.\n",
    "for i in range(iterations):\n",
    "    # mini batch construct\n",
    "    ix = torch.randint(0, X.shape[0], (BATCH_SIZE,), generator=batch_generator)\n",
    "\n",
    "    # extract the batches\n",
    "    X_batch, Y_batch = X[ix], Y[ix]\n",
    "\n",
    "    # Forward pass: compute predictions and loss with the mini batch of inputs\n",
    "    params, loss = forward_pass(X_batch, Y_batch, params, block_size)\n",
    "\n",
    "    lr = lrs[i]\n",
    "\n",
    "    # Print loss at specified intervals.\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: loss = {loss.item():.4f}, lr = {lr:.6f}\")\n",
    "\n",
    "    # Backward pass: compute gradients and update parameters.\n",
    "    backward_pass(list(params.parameters), loss, lr)\n",
    "\n",
    "    # track stats\n",
    "    lr_x.append(lre[i])\n",
    "    loss_y.append(loss.item())\n",
    "\n",
    "\n",
    "print(f\"Training complete. Final loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lr_x, loss_y)\n",
    "plt.xlabel(\"Learning Rate Exponent\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Learning Rate Exponent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Impact of Hidden Layer Size on Training\n",
    "\n",
    "This experiment investigates how the number of neurons in the hidden layer affects model performance.\n",
    "\n",
    "### Method:\n",
    "- Train multiple models with different `HIDDEN_LAYER_SIZE` values (e.g., 100, 200, 300, 500)\n",
    "- Use the optimal learning rate from Experiment 1\n",
    "- Compare training loss curves to see convergence speed and final loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration.\n",
    "HIDDEN_LAYER_SIZE = 500  # Test different values: 100, 200, 300, 500.\n",
    "LEARNING_RATE = 0.2  # Optimal LR from Experiment 1.\n",
    "\n",
    "# Build vocabulary and dataset.\n",
    "stoi, itos, words = build_vocab_from_words()\n",
    "vocab_size = len(stoi)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Build training dataset from all words.\n",
    "X, Y, block_size = build_dataset(words, stoi)\n",
    "print(f\"Dataset shape: X={X.shape}, Y={Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "# Initialize network parameters.\n",
    "params = initialize_parameters(vocab_size, block_size, generator=generator)\n",
    "\n",
    "n_params = sum(p.nelement() for p in params.parameters)\n",
    "print(\"Total paramters:\", n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_x = []\n",
    "loss_y = []\n",
    "\n",
    "batch_generator = torch.Generator().manual_seed(SAMPLE_SEED)\n",
    "\n",
    "# Training loop.\n",
    "for i in range(30_000):\n",
    "    # construct mini batches of size BATCH_SIZE\n",
    "    ix = torch.randint(0, X.shape[0], (BATCH_SIZE,), generator=batch_generator)\n",
    "\n",
    "    # extract the batches\n",
    "    X_batch, Y_batch = X[ix], Y[ix]\n",
    "\n",
    "    # Forward pass: compute predictions and loss with the mini batch of inputs\n",
    "    params, loss = forward_pass(X_batch, Y_batch, params, block_size)\n",
    "\n",
    "    # Print loss at specified intervals.\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Iteration {i:5d}: loss = {loss.item():.4f}\")\n",
    "\n",
    "    # Backward pass: compute gradients and update parameters.\n",
    "    backward_pass(list(params.parameters), loss, LEARNING_RATE)\n",
    "\n",
    "    # track stats\n",
    "    step_x.append(i)\n",
    "    loss_y.append(loss.item())\n",
    "\n",
    "\n",
    "print(f\"Training complete. Final loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(step_x, loss_y)\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Iterations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
